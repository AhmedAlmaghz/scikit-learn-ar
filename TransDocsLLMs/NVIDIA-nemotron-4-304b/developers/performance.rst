  هذا هو النص الذي تم ترجمته إلى اللغة العربية:

    .. _performance-howto:

    =========================
    كيفية التحسين من أجل السرعة
    =========================

    فيما يلي بعض الإرشادات العملية لمساعدتك في كتابة كود فعال لمشروع scikit-learn.

    .. note::

      على الرغم من أنه من المفيد دائمًا تحليل الكود الخاص بك للتحقق من افتراضات الأداء، إلا أنه من المستحسن بشدة مراجعة الأدبيات للتأكد من أن الخوارزمية المنفذة هي أحدث ما توصلت إليه التكنولوجيا للمهمة قبل الاستثمار في تحسين التنفيذ المكلف.

      في كثير من الأحيان، تم إبطال ساعات من الجهود المستثمرة في تحسين تفاصيل التنفيذ المعقدة من خلال الاكتشاف اللاحق لـ "حيل الخوارزمية" البسيطة، أو باستخدام خوارزمية أخرى أكثر ملاءمة للمشكلة.

      تقدم الأقسام :ref:`warm-restarts` مثالاً على مثل هذه الحيلة.


    Python، Cython أو C/C++؟
    ========================

    .. currentmodule:: sklearn

    عمومًا، يؤكد مشروع scikit-learn على **قابلية قراءة** شفرة المصدر لجعلها سهلة لمستخدمي المشروع للغوص في شفرة المصدر لفهم كيفية تصرف الخوارزمية على بياناتهم ولكن أيضًا لسهولة الصيانة (من قبل المطورين).

    عند تنفيذ خوارزمية جديدة، يوصى **ببدء** تنفيذها في Python باستخدام Numpy و Scipy مع الحرص على تجنب رمز الحلقة باستخدام تعبيرات المتجه لتلك المكتبات. في الممارسة العملية، هذا يعني محاولة **استبدال أي حلقات for متداخلة باستدعاءات لطرق مجموعة Numpy المكافئة**. الهدف هو منع وحدة المعالجة المركزية من إضاعة الوقت في مترجم Python بدلاً من حساب الأرقام لتناسب نموذجك الإحصائي. من الجيد عمومًا التفكير في نصائح أداء NumPy و SciPy: https://scipy.github.io/old-wiki/pages/PerformanceTips

    ومع ذلك، في بعض الأحيان لا يمكن التعبير عن الخوارزمية بكفاءة في رمز Numpy متجه بسيط. في هذه الحالة، تتمثل الإستراتيجية الموصى بها فيما يلي:

    1. **تحليل** التنفيذ في Python للعثور على عنق الزجاجة الرئيسي وعزله في **وظيفة مخصصة على مستوى الوحدة**. سيتم إعادة تنفيذ هذه الوظيفة كوحدة نمطية تمديد مجمعة.

    2. إذا كان هناك تنفيذ **C/C++** جيد الصيانة لنفس الخوارزمية التي ليست كبيرة جدًا، فيمكنك كتابة **غلاف Cython** له وتضمين نسخة من شفرة المصدر للمكتبة في شجرة مصدر scikit-learn: تستخدم هذه الإستراتيجية للفئات :class:`svm.LinearSVC`، :class:`svm.SVC` و :class:`linear_model.LogisticRegression` (أغلفة لـ liblinear و libsvm).

    3. خلاف ذلك، اكتب إصدارًا محسنًا من وظيفة Python الخاصة بك باستخدام **Cython** مباشرة. تستخدم هذه الإستراتيجية للفئات :class:`linear_model.ElasticNet` و :class:`linear_model.SGDClassifier` على سبيل المثال.

    4. **انقل إصدار Python من الوظيفة في الاختبارات** واستخدمه للتحقق من أن نتائج الامتداد المجمع متسقة مع إصدار Python القياسي الذهبي وسهل التصحيح.

    5. بمجرد تحسين الشفرة (لا يمكن اكتشاف عنق الزجاجة البسيط عن طريق التنميط)، تحقق مما إذا كان من الممكن أن يكون هناك **توازي حبيبي خشن** يمكن الوصول إليه **متعدد المعالجة** باستخدام فئة ``joblib.Parallel``.

    .. _profiling-python-code:

    تحليل رمز Python
    
    (ملاحظة: لم يتم ترجمة الروابط والتاجات والشفرات البرمجية والمعادلات الرياضية والرموز الخاصة وفقا لطلبك)

من أجل إجراء عملية التنميط (Profiling) لكود بايثون، نوصي بكتابة برنامج نصي يقوم بتحميل وإعداد بياناتك ثم استخدام أداة التنميط المتكاملة في IPython لاستكشاف الجزء ذي الصلة من الكود بشكل تفاعلي.

لنفترض أننا نريد إجراء عملية التنميط لوحدة التحليل العاملي للمصفوفة غير السالبة (Non Negative Matrix Factorization) في حزمة scikit-learn. لنبدأ جلسة جديدة في IPython ونحمل مجموعة بيانات digits كما في المثال التالي:

```python
In [1]: from sklearn.decomposition import NMF

In [2]: from sklearn.datasets import load_digits

In [3]: X, _ = load_digits(return_X_y=True)
```

قبل بدء جلسة التنميط والانخراط في تكرارات التجربة والتحسين، من المهم قياس إجمالي وقت التنفيذ للوظيفة التي نريد تحسينها دون أي نوع من حمولة زائدة لأداة التنميط وحفظه في مكان ما للرجوع إليه لاحقًا:

```python
In [4]: %timeit NMF(n_components=16, tol=1e-2).fit(X)
1 loops, best of 3: 1.7 s per loop
```

لإلقاء نظرة على ملف تعريف الأداء العام باستخدام الأمر السحري ``%prun``:

```python
In [5]: %prun -l nmf.py NMF(n_components=16, tol=1e-2).fit(X)
        14496 function calls in 1.682 CPU seconds

   Ordered by: internal time
   List reduced from 9. to 9 due to restriction <'nmf.py'>

   ncalls tottime percall cumtime percall filename:lineno(function)
        36    0.609    0.017    1.499    0.042 nmf.py:151(_nls_subproblem)
      1263    0.157    0.000    0.157    0.000 nmf.py:18(_pos)
         1    0.053    0.053    1.681    1.681 nmf.py:352(fit_transform)
       673    0.008    0.000    0.057    0.000 nmf.py:28(norm)
         1    0.006    0.006    0.047    0.047 nmf.py:42(_initialize_nmf)
        36    0.001    0.000    0.010    0.000 nmf.py:36(_sparseness)
        30    0.001    0.000    0.001    0.000 nmf.py:23(_neg)
         1    0.000    0.000    0.000    0.000 nmf.py:337(__init__)
         1    0.000    0.000    1.681    1.681 nmf.py:461(fit)
```

عمود ``tottime`` هو الأكثر إثارة للاهتمام: فهو يعطي إجمالي الوقت المستغرق في تنفيذ كود وظيفة معينة مع تجاهل الوقت المستغرق في تنفيذ الوظائف الفرعية. إجمالي الوقت الحقيقي (رمز محلي + مكالمات وظيفة فرعية) يُعطى بواسطة عمود ``cumtime``.

لاحظ استخدام ``-l nmf.py`` الذي يحد من الإخراج إلى السطور التي تحتوي على سلسلة "nmf.py". هذا مفيد لإلقاء نظرة سريعة على النقاط الساخنة لوحدة nmf بايثون نفسها مع تجاهل كل شيء آخر.

فيما يلي بداية الإخراج لنفس الأمر بدون فلتر ``-l nmf.py``:

```python
In [5] %prun NMF(n_components=16, tol=1e-2).fit(X)
        16159 function calls in 1.840 CPU seconds

   Ordered by: internal time

   ncalls tottime percall cumtime percall filename:lineno(function)
     2833    0.653    0.000    0.653    0.000 {numpy.core._dotblas.dot}
        46    0.651    0.014    1.636    0.036 nmf.py:151(_nls_subproblem)
     1397    0.171    0.000    0.171    0.000 nmf.py:18(_pos)
     2780    0.167    0.000    0.167    0.000 {method 'sum' of 'numpy.ndarray' objects}
         1    0.064    0.064    1.840    1.840 nmf.py:352(fit_transform)
     1542    0.043    0.000    0.043    0.000 {method 'flatten' of 'numpy.ndarray' objects}
      337    0.019    0.000    0.019    0.000 {method 'all' of 'numpy.ndarray' objects}
     2734    0.011    0.000    0.181    0.000 fromnumeric.py:1185(sum)
         2    0.010    0.005    0.010    0.005 {numpy.linalg.lapack_lite.dgesdd}
      748    0.009    0.000    0.065    0.000 nmf.py:28(norm)
...
```

تُظهر النتائج المذكورة أعلاه أن التنفيذ يهيمن عليه إلى حد كبير عمليات ضرب النقاط (التي يتم تفويضها إلى blas). وبالتالي لا يوجد على الأرجح مكسب ضخم يمكن توقعه من خلال إعادة كتابة هذا الكود في Cython أو C / C ++: في هذه الحالة من أصل 1.7 ثانية من إجمالي وقت التنفيذ ، يقضي ما يقرب من 0.7 ثانية في الكود المترجم الذي يمكن اعتباره الأمثل. من خلال إعادة كتابة باقي كود بايثون بافتراض أنه يمكننا تحقيق زيادة بنسبة 1000٪ على هذا الجزء (وهو أمر غير مرجح بشدة نظرًا لبساطة حلقات بايثون) ، لن نكسب أكثر من 2.4x سرعة عالمية.

وبالتالي لا يمكن تحقيق تحسينات كبيرة إلا من خلال **التحسينات الخوارزمية** في هذا المثال المحدد (على سبيل المثال محاولة العثور على عملية مكلفة وغير مجدية لتجنب حسابها بدلاً من محاولة تحسين تنفيذها).

ومع ذلك ، لا يزال من المثير للاهتمام التحقق مما يحدث داخل وظيفة ``_nls_subproblem`` التي تعد النقطة الساخنة إذا نظرنا فقط إلى كود بايثون: فهي تستغرق حوالي 100٪ من الوقت المتراكم للوحدة. من أجل فهم أفضل لملف تعريف هذه الوظيفة المحددة ، دعنا نقوم بتثبيت ``line_profiler`` وربطه بـ IPython:

```bash
pip install line_profiler
```

**تحت IPython 0.13+** ، أنشئ أولاً ملف تعريف التكوين:

```bash
ipython profile create
```

بعد ذلك ، قم بتسجيل ملحق line_profiler في ``~/.ipython/profile_default/ipython_config.py``:

```python
c.TerminalIPythonApp.extensions.append('line_profiler')
c.InteractiveShellApp.extensions.append('line_profiler')
```

سيؤدي هذا إلى تسجيل الأمر السحري ``%lprun`` في تطبيق IPython Terminal والتطبيقات الأخرى مثل qtconsole و notebook.

الآن أعد تشغيل IPython ودعنا نستخدم هذه اللعبة الجديدة:

```python
In [1]: from sklearn.datasets import load_digits

In [2]: from sklearn.decomposition import NMF
    ... : from sklearn.decomposition._nmf import _nls_subproblem

In [3]: X, _ = load_digits(return_X_y=True)

In [4]: %lprun -f _nls_subproblem NMF(n_components=16, tol=1e-2).fit(X)

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع مراعاة عدم ترجمة الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

الصف رقم      الزيارات         الوقت  لكل زيارة   % الوقت  محتويات السطر
  ==============================================================
     137                                           def _nls_subproblem(V, W, H_init, tol, max_iter):
     138                                               """حل المعادلات الأقل مربعا غير السلبية
     ...
     170                                               """
     171        48         5863    122.1      0.3      if (H_init < 0).any():
     172                                                   raise ValueError("قيم سالبة في H_init تم تمريرها لحل NLS.")
     173
     174        48          139      2.9      0.0      H = H_init
     175        48       112141   2336.3      5.8      WtV = np.dot(W.T, V)
     176        48        16144    336.3      0.8      WtW = np.dot(W.T, W)
     177
     178                                               # قيم مبررة في الورقة البحثية
     179        48          144      3.0      0.0      alpha = 1
     180        48          113      2.4      0.0      beta = 0.1
     181       638         1880      2.9      0.1      for n_iter in range(1, max_iter + 1):
     182       638       195133    305.9     10.2          grad = np.dot(WtW, H) - WtV
     183       638       495761    777.1     25.9          proj_gradient = norm(grad[np.logical_or(grad < 0, H > 0)])
     184       638         2449      3.8      0.1          if proj_gradient < tol:
     185        48          130      2.7      0.0              break
     186
     187      1474         4474      3.0      0.2          for inner_iter in range(1, 20):
     188      1474        83833     56.9      4.4              Hn = H - alpha * grad
     189                                                       # Hn = np.where(Hn > 0, Hn, 0)
     190      1474       194239    131.8     10.1              Hn = _pos(Hn)
     191      1474        48858     33.1      2.5              d = Hn - H
     192      1474       150407    102.0      7.8              gradd = np.sum(grad * d)
     193      1474       515390    349.7     26.9              dQd = np.sum(np.dot(WtW, d) * d)
     ...

من خلال النظر إلى أعلى قيم عمود "% الوقت"، من السهل تحديد التعبيرات الأكثر تكلفة التي تستحق عناية إضافية.


تصنيف استخدام الذاكرة

    
(ملاحظة: تم الاحتفاظ بالرموز الأصلية والأسطر الفارغة والحروف بالأحرف الكبيرة كما هي في النص الأصلي)

هذا هو النص الذي تم تنسيقه باستخدام RST (ReStructuredText) والذي ترجمناه إلى اللغة العربية. يرجى ملاحظة أننا لم نترجم الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

========

يمكنك تحليل استخدام الذاكرة لأي كود Python بتفصيل كبير بمساعدة `memory_profiler <https://pypi.org/project/memory_profiler/>`_. أولاً، قم بتثبيت أحدث إصدار:

.. prompt:: bash $

 pip install -U memory_profiler

بعد ذلك، قم بإعداد السحر بطريقة مشابهة لـ ``line_profiler``.

**تحت IPython 0.11+**، قم أولاً بإنشاء ملف تعريف التكوين:

.. prompt:: bash $

    ipython profile create


ثم قم بتسجيل الإضافة في ``~/.ipython/profile_default/ipython_config.py``
جنبًا إلى جنب مع محلل الأداء الخطي::

    c.TerminalIPythonApp.extensions.append('memory_profiler')
    c.InteractiveShellApp.extensions.append('memory_profiler')

سيؤدي هذا إلى تسجيل أوامر السحر ``%memit`` و ``%mprun`` في تطبيق IPython الطرفي والواجهات الأخرى مثل qtconsole و notebook.

``%mprun`` مفيد لفحص استخدام الذاكرة سطراً بسطر للوظائف الرئيسية في برنامجك. إنه مشابه جدًا لـ ``%lprun``، الذي تمت مناقشته في القسم السابق. على سبيل المثال، من دليل ``memory_profiler`` ``examples``::

    In [1] from example import my_func

    In [2] %mprun -f my_func my_func()
    Filename: example.py

    Line #    Mem usage  Increment   Line Contents
    ==============================================
         3                           @profile
         4      5.97 MB    0.00 MB   def my_func():
         5     13.61 MB    7.64 MB       a = [1] * (10 ** 6)
         6    166.20 MB  152.59 MB       b = [2] * (2 * 10 ** 7)
         7     13.61 MB -152.59 MB       del b
         8     13.61 MB    0.00 MB       return a

سحر آخر مفيد يحدده ``memory_profiler`` هو ``%memit``، والذي يشبه ``%timeit``. يمكن استخدامه على النحو التالي::

    In [1]: import numpy as np

    In [2]: %memit np.zeros(1e7)
    maximum of 3: 76.402344 MB per loop

لمزيد من التفاصيل، راجع مستندات السحر، باستخدام ``%memit؟`` و ``%mprun؟``.


استخدام Cython
==============

إذا كشف تحليل كود Python أن النفقات العامة لمترجم Python أكبر بمقدار واحد أو أكثر من حجم حسابات الأرقام الفعلية (على سبيل المثال، حلقات ``for`` فوق مكونات المتجه، والتقييم المتداخل للتعبير الشرطي، والحسابات العددية ...) ، فمن المحتمل أنه مناسب لاستخراج جزء النقطة الفعالة من الكود كدالة قائمة بذاتها في ملف ``.pyx``، وإضافة إعلانات النوع الثابت ثم استخدام Cython لإنشاء برنامج C مناسب ليتم ترجمته كوحدة تمديد Python.

تحتوي `وثائق Cython <http://docs.cython.org/>`_ على برنامج تعليمي ودليل مرجعي لتطوير مثل هذه الوحدة النمطية.
لمزيد من المعلومات حول التطوير في Cython لـ scikit-learn، انظر :ref:`cython`.


.. _profiling-compiled-extension:

تنميط الملحقات المترجمة
=======================

عند العمل مع الإضافات المجمعة (المكتوبة بلغة C / C ++ مع غلاف أو مباشرة كملحق Cython)، يكون محلل Python الافتراضي عديم الفائدة:
نحن بحاجة إلى أداة مخصصة للتدقيق فيما يحدث داخل الامتداد المترجم نفسه.

استخدام yep و gperftools
------------------------

التنميط السهل بدون خيارات تجميع خاصة يستخدم yep:

- https://pypi.org/project/yep/
- https://fa.bianp.net/blog/2011/a-profiler-for-python-extensions

استخدام مصحح أخطاء، gdb
---------------------

* من المفيد استخدام ``gdb`` للتصحيح. للقيام بذلك، يجب استخدام مترجم Python مبني بدعم التصحيح (رموز التصحيح والتحسين المناسب). لإنشاء بيئة جديدة (قد تحتاج إلى إلغاء تنشيطها وإعادة تنشيطها بعد الإنشاء / التثبيت) مع مترجم CPython مبني من المصدر:

  .. code-block:: bash

         git clone https://github.com/python/cpython.git
         conda create -n debug-scikit-dev
         conda activate debug-scikit-dev
         cd cpython
         mkdir debug
         cd debug
         ../configure --prefix=$CONDA_PREFIX --with-pydebug
         make EXTRA_CFLAGS='-DPy_DEBUG' -j<num_cores>
         make install


استخدام gprof
-------------

من أجل تنميط ملحقات Python المترجمة، يمكن للمرء استخدام ``gprof``
بعد إعادة تجميع المشروع باستخدام ``gcc -pg`` واستخدام متغير ``python-dbg`` للمترجم على دبيان / أوبونتو: ومع ذلك
يتطلب هذا النهج أيضًا الحصول على ``numpy`` و ``scipy`` إعادة التجميع
مع ``-pg`` وهو أمر معقد للغاية للعمل.

لحسن الحظ، يوجد محللان بديلان لا يتطلبان منك إعادة تجميع كل شيء.

استخدام valgrind / callgrind / kcachegrind
----------------------------------------

kcachegrind
~~~~~~~~~~~

يمكن استخدام ``yep`` لإنشاء تقرير التنميط.
يوفر ``kcachegrind`` بيئة رسومية لتصور هذا التقرير:

.. prompt:: bash $

  # تشغيل yep لتنميط بعض نص بايثون
 python -m yep -c my_file.py

.. prompt:: bash $

  # فتح my_file.py.callgrin مع kcachegrind
  kcachegrind my_file.py.prof

.. note::

   يمكن تنفيذ ``yep`` مع الوسيطة ``--lines`` أو ``-l`` لتجميع تقرير التنميط 'خطًا بخط'.

التوازي متعدد النواة باستخدام ``joblib.Parallel``
================================================

راجع `joblib documentation <https://joblib.readthedocs.io>`_


.. _warm-restarts:

خدعة خوارزمية بسيطة: عمليات إعادة التشغيل الدافئة
================================================

راجع مدخل المسرد لـ :term:`warm_start`
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    