.. currentmodule:: sklearn.model_selection

.. _TunedThresholdClassifierCV:

==================================================
ضبط عتبة القرار لتوقع الفئة
==================================================

من الأفضل تقسيم التصنيف إلى جزئين:

* المشكلة الإحصائية لتعلم نموذج للتنبؤ، بشكل مثالي، باحتمالات الفئة؛
* مشكلة القرار لاتخاذ إجراء ملموس بناءً على تلك التنبؤات الاحتمالية.

دعونا نأخذ مثالًا مباشرًا يتعلق بتوقعات الطقس: النقطة الأولى تتعلق بالإجابة على "ما هي فرصة هطول الأمطار غدًا؟" بينما النقطة الثانية تتعلق بالإجابة على "هل يجب أن أحمل مظلة غدًا؟".

عندما يتعلق الأمر بواجهة برمجة تطبيقات scikit-learn، تتم معالجة النقطة الأولى من خلال توفير درجات باستخدام :term:`predict_proba` أو :term:`decision_function`. يعيد الأول تقديرات الاحتمالات الشرطية :math:`P(y|X)` لكل فئة، بينما يعيد الأخير درجة قرار لكل فئة.

يتم الحصول على القرار المقابل للتصنيفات باستخدام :term:`predict`. في التصنيف الثنائي، يتم بعد ذلك تحديد قاعدة القرار أو الإجراء عن طريق عتبة الدرجات، مما يؤدي إلى التنبؤ بتسمية فئة واحدة لكل عينة. بالنسبة للتصنيف الثنائي في scikit-learn، يتم الحصول على تنبؤات تسميات الفئات عن طريق قواعد القطع المشفرة: يتم التنبؤ بفئة إيجابية عندما يكون الاحتمال المشروط :math:`P(y|X)` أكبر من ٠.٥ (تم الحصول عليه باستخدام :term:`predict_proba`) أو إذا كانت درجة القرار أكبر من ٠ (تم الحصول عليها باستخدام :term:`decision_function`).

هنا، نعرض مثالًا يوضح العلاقة بين تقديرات الاحتمالات الشرطية :math:`P(y|X)` وتسميات الفئات::

    >>> from sklearn.datasets import make_classification
    >>> from sklearn.tree import DecisionTreeClassifier
    >>> X, y = make_classification(random_state=0)
    >>> classifier = DecisionTreeClassifier(max_depth=2, random_state=0).fit(X, y)
    >>> classifier.predict_proba(X[:4])
    array([[0.94     , 0.06     ],
           [0.94     , 0.06     ],
           [0.0416..., 0.9583...],
           [0.0416..., 0.9583...]])
    >>> classifier.predict(X[:4])
    array([0, 0, 1, 1])

بينما قد تبدو هذه القواعد المشفرة منطقية في البداية كإعداد افتراضي، إلا أنها بالتأكيد ليست مثالية لمعظم حالات الاستخدام. دعونا نوضح بمثال.

فكر في سيناريو يتم فيه نشر نموذج تنبؤي لمساعدة الأطباء في اكتشاف الأورام. في هذا الإعداد، سيكون الأطباء مهتمين على الأرجح بتحديد جميع المرضى المصابين بالسرطان وعدم تفويت أي شخص مصاب بالسرطان حتى يتمكنوا من تزويدهم بالعلاج المناسب. بمعنى آخر، يركز الأطباء على تحقيق معدل استدعاء مرتفع. هذا التركيز على الاستدعاء يأتي، بالطبع، مع المقايضة المتمثلة في زيادة احتمالية التنبؤات الإيجابية الكاذبة، مما يقلل من دقة النموذج. هذه مخاطرة يرغب الأطباء في قبولها لأن تكلفة فقدان الإصابة بالسرطان أعلى بكثير من تكلفة مزيد من الاختبارات التشخيصية. وبالتالي، عندما يتعلق الأمر باتخاذ قرار بشأن تصنيف المريض على أنه مصاب بالسرطان أم لا، فقد يكون من الأكثر فائدة تصنيفه على أنه مصاب بالسرطان بشكل إيجابي عندما يكون تقدير الاحتمال الشرطي أقل بكثير من ٠.٥.

ضبط عتبة القرار بعد التدريب

    

واحدة من الحلول لمعالجة المشكلة المذكورة في المقدمة هي ضبط عتبة القرار الخاصة بمصنف بعد الانتهاء من تدريبه. تُضبط هذه العتبة باستخدام التحقق المتقاطع الداخلي من خلال الدالة :class:`~sklearn.model_selection.TunedThresholdClassifierCV`، ويتم اختيار العتبة المثلى لتعظيم مقياس معين.

توضح الصورة التالية ضبط عتبة القرار لمصنف التدرج الداعم. بينما يوفر كل من المصنف البسيط والمصنف المضبوط نفس ناتج :term:`predict_proba` وبالتالي نفس منحنى ROC ومنحنى الدقة-الاسترجاع، فإن توقعات فئة التسمية تختلف بسبب عتبة القرار المضبوطة. يتوقع المصنف البسيط فئة الاهتمام لاحتمال شرطي أكبر من 0.5 بينما يتوقع المصنف المضبوط فئة الاهتمام لاحتمال منخفض جدًا (حوالي 0.02). تضبط عتبة القرار هذه مقياس المنفعة الذي تحدده المؤسسة (في هذه الحالة شركة تأمين).

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cost_sensitive_learning_002.png
   :target: ../auto_examples/model_selection/plot_cost_sensitive_learning.html
   :align: center

خيارات لضبط عتبة القرار
------------------------

يمكن ضبط عتبة القرار من خلال استراتيجيات مختلفة يتم التحكم فيها بواسطة الوسيط `scoring`.

إحدى الطرق لضبط العتبة هي من خلال تعظيم مقياس محدد مسبقًا في مكتبة scikit-learn. يمكن العثور على هذه المقاييس من خلال استدعاء الدالة :func:`~sklearn.metrics.get_scorer_names`. بشكل افتراضي، يتم استخدام دقة متوازنة كالمقياس، ولكن يجب الانتباه إلى أنه يجب اختيار مقياس ذي مغزى لحالة الاستخدام الخاصة بك.

.. note::

    من المهم ملاحظة أن هذه المقاييس تأتي مع معلمات افتراضية، خاصة تسمية فئة الاهتمام (أي `pos_label`). لذلك، إذا كانت هذه التسمية غير مناسبة لتطبيقك، فيجب عليك تحديد وظيفة التسجيل وتمرير `pos_label` الصحيح (والمعلمات الإضافية) باستخدام الدالة :func:`~sklearn.metrics.make_scorer`. راجع :ref:`scoring` للحصول على معلومات لتحديد دالة التسجيل الخاصة بك. على سبيل المثال، نعرض كيفية تمرير المعلومات إلى المسجل بأن تسمية الفئة محل الاهتمام هي `0` عند تعظيم :func:`~sklearn.metrics.f1_score`::

        >>> from sklearn.linear_model import LogisticRegression
        >>> from sklearn.model_selection import TunedThresholdClassifierCV
        >>> from sklearn.metrics import make_scorer, f1_score
        >>> X, y = make_classification(
        ...   n_samples=1_000, weights=[0.1, 0.9], random_state=0)
        >>> pos_label = 0
        >>> scorer = make_scorer(f1_score, pos_label=pos_label)
        >>> base_model = LogisticRegression()
        >>> model = TunedThresholdClassifierCV(base_model, scoring=scorer)
        >>> scorer(model.fit(X, y), X, y)
        0.88...
        >>> # compare it with the internal score found by cross-validation
        >>> model.best_score_
        0.86...

ملاحظات مهمة تتعلق بالتحقق المتقاطع الداخلي
-------------------------------------------

بشكل افتراضي، تستخدم :class:`~sklearn.model_selection.TunedThresholdClassifierCV` التحقق المتقاطع الطبقي المكون من 5 أقسام لضبط عتبة القرار. يسمح وسيط `cv` بالتحكم في استراتيجية التحقق المتقاطع. من الممكن تجاوز التحقق المتقاطع عن طريق تعيين `cv="prefit"` وتوفير مصنف مناسب. في هذه الحالة، يتم ضبط عتبة القرار على البيانات المقدمة إلى دالة `fit`.

ومع ذلك، يجب أن تكون حذرًا للغاية عند استخدام هذا الخيار. يجب ألا تستخدم نفس البيانات لتدريب المصنف وضبط عتبة القرار بسبب خطر الإفراط في التخصيص. راجع قسم الأمثلة التالي لمزيد من التفاصيل (انظر: :ref:`TunedThresholdClassifierCV_no_cv`). إذا كانت مواردك محدودة، ففكر في استخدام رقم عشري لـ `cv` للحد من الانقسام الداخلي للتدريب والاختبار.

يجب استخدام الخيار `cv="prefit"` فقط عندما يكون المصنف المقدم قد تم تدريبه بالفعل، وتريد فقط العثور على أفضل عتبة قرار باستخدام مجموعة تحقق جديدة.

.. _FixedThresholdClassifier:

ضبط عتبة القرار يدويًا
---------------------

ناقشت الأقسام السابقة استراتيجيات لإيجاد عتبة قرار مثالية. من الممكن أيضًا ضبط عتبة القرار يدويًا باستخدام الفئة :class:`~sklearn.model_selection.FixedThresholdClassifier`. في حالة عدم رغبتك في إعادة تركيب النموذج عند استدعاء `fit`، يمكنك تعيين الوسيط `prefit=True`.

أمثلة
-----

- راجع المثال بعنوان
  :ref:`sphx_glr_auto_examples_model_selection_plot_tuned_decision_threshold.py`،
  للحصول على نظرة ثاقبة حول ما بعد ضبط عتبة القرار.
- راجع المثال بعنوان
  :ref:`sphx_glr_auto_examples_model_selection_plot_cost_sensitive_learning.py`،
  لتعلم المزيد عن التعلم الحساس للتكلفة وضبط عتبة القرار.
