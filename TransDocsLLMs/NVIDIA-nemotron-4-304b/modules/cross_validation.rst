========================================================================
التحقق المتقاطع: تقييم أداء المقدّر
========================================================================

.. currentmodule:: sklearn.model_selection

إن تعلم معلمات دالة التنبؤ واختبارها على نفس البيانات هو خطأ منهجي: فموديل الذي يعيد فقط تسميات العينات التي رآها للتو سيكون له درجة مثالية ولكنه سيفشل في التنبؤ بأي شيء مفيد على البيانات التي لم يتم رؤيتها بعد. تسمى هذه الحالة **overfitting** (حفظ زائد). لتجنب ذلك، من الممارسات الشائعة عند إجراء تجربة (خاضعة للإشراف) في التعلم الآلي أن يتم الاحتفاظ بجزء من البيانات المتاحة كمجموعة **اختبار** ``X_test, y_test``. لاحظ أن كلمة "تجربة" لا تعني الاستخدام الأكاديمي فقط، لأنه حتى في الإعدادات التجارية، عادة ما يبدأ التعلم الآلي بشكل تجريبي. فيما يلي مخطط انسيابي لنموذجية سير عمل التحقق المتقاطع في تدريب الموديل. يمكن تحديد أفضل المعلمات بواسطة تقنيات :ref:`grid search <grid_search>` (البحث الشبكي).

.. image:: ../images/grid_search_workflow.png
   :width: 400px
   :height: 240px
   :alt: Grid Search Workflow (مخطط سير عمل البحث الشبكي)
   :align: center

في مكتبة scikit-learn، يمكن حساب انقسام عشوائي بسرعة إلى مجموعات تدريب واختبار باستخدام دالة المساعد :func:`train_test_split`. دعونا نحمل مجموعة بيانات iris لتناسب آلة المتجهات الداعمة الخطية عليها::

  >>> import numpy as np
  >>> from sklearn.model_selection import train_test_split
  >>> from sklearn import datasets
  >>> from sklearn import svm

  >>> X, y = datasets.load_iris(return_X_y=True)
  >>> X.shape, y.shape
  ((150, 4), (150,))

يمكننا الآن أخذ عينة بسرعة لمجموعة تدريب مع الاحتفاظ بنسبة 40% من البيانات للاختبار (تقييم) جهاز التصنيف الخاص بنا::

  >>> X_train, X_test, y_train, y_test = train_test_split(
  ...     X, y, test_size=0.4, random_state=0)

  >>> X_train.shape, y_train.shape
  ((90, 4), (90,))
  >>> X_test.shape, y_test.shape
  ((60, 4), (60,))

  >>> clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
  >>> clf.score(X_test, y_test)
  0.96...

عند تقييم إعدادات مختلفة ("فرط المعلمات") للمقدّرات، مثل إعداد ``C`` الذي يجب تعيينه يدويًا لـ SVM، لا يزال هناك خطر من overfitting (الحفظ الزائد) *على مجموعة الاختبار* لأنه يمكن تعديل المعلمات حتى يؤدى المقدّر بأداء مثالي. بهذه الطريقة، يمكن أن "تتسرب" معرفة مجموعة الاختبار إلى الموديل ولم تعد مقاييس التقييم تبلغ عن أداء التعميم. لحل هذه المشكلة، يمكن الاحتفاظ بجزء آخر من مجموعة البيانات كـ "مجموعة تحقق": يستمر التدريب على مجموعة التدريب، وبعد ذلك يتم التقييم على مجموعة التحقق، وعندما يبدو أن التجربة ناجحة، يمكن إجراء التقييم النهائي على مجموعة الاختبار.

ومع ذلك، من خلال تقسيم البيانات المتاحة إلى ثلاث مجموعات، فإننا نقلل بشكل كبير من عدد العينات التي يمكن استخدامها لتعلم الموديل، ويمكن أن تعتمد النتائج على اختيار معين عشوائي لزوج (التدريب، التحقق) مجموعات.

الحل لهذه المشكلة هو إجراء يسمى `التحقق المتقاطع <https://en.wikipedia.org/wiki/Cross-validation_(statistics)>`_ (CV باختصار). يجب أن يتم الاحتفاظ بمجموعة اختبار للتقييم النهائي، ولكن لم تعد هناك حاجة إلى مجموعة التحقق عند إجراء CV. في النهج الأساسي، الذي يسمى *k*-fold CV، تنقسم مجموعة التدريب إلى *k* مجموعات أصغر (يتم وصف الأساليب الأخرى أدناه، ولكنها تتبع بشكل عام نفس المبادئ). يتم اتباع الإجراء التالي لكل من *k* "طي":

* يتم تدريب الموديل باستخدام :math:`k-1` من الطيات كبيانات تدريب؛
* يتم التحقق من صحة الموديل الناتج على الجزء المتبقي من البيانات (أي يتم استخدامه كمجموعة اختبار لحساب مقياس الأداء مثل الدقة).

مقياس الأداء الذي أبلغ عنه *k*-fold cross-validation هو متوسط القيم المحسوبة في الحلقة. يمكن أن يكون هذا النهج مكلفًا حسابيًا، ولكنه لا يهدر الكثير من البيانات (كما هو الحال عند تثبيت مجموعة تحقق عشوائية)، وهو ميزة رئيسية في مشاكل مثل الاستدلال العكسي حيث يكون عدد العينات صغيرًا جدًا.

.. image:: ../images/grid_search_cross_validation.png
   :width: 50

...

(تم اقتطاع بقية النص لأنه يتجاوز الحد الأقصى لعدد الأحرف)


    =================================

    أبسط طريقة لاستخدام التحقق المتقاطع هي استدعاء الدالة المساعدة :func:`cross_val_score` على المقدّر ومجموعة البيانات.

    يوضح المثال التالي كيفية تقدير دقة آلة متجهات الدعم ذات النواة الخطية على مجموعة بيانات القزحية عن طريق تقسيم البيانات، وتجهيز النموذج وحساب الدرجة 5 مرات متتالية (مع تقسيمات مختلفة في كل مرة)::

      >>> from sklearn.model_selection import cross_val_score
      >>> clf = svm.SVC(kernel='linear', C=1, random_state=42)
      >>> scores = cross_val_score(clf, X, y, cv=5)
      >>> scores
      array([0.96..., 1. , 0.96..., 0.96..., 1. ])

    يتم إعطاء متوسط الدرجة والانحراف المعياري على التوالي بواسطة::

      >>> print("%0.2f accuracy with a standard deviation of %0.2f" % (scores.mean(), scores.std()))
      0.98 accuracy with a standard deviation of 0.02

    بشكل افتراضي، الدرجة المحسوبة في كل تكرار للتحقق المتقاطع هي طريقة ``score`` للمقدّر. يمكن تغيير ذلك باستخدام معلمة ``scoring``::

      >>> from sklearn import metrics
      >>> scores = cross_val_score(
      ...     clf, X, y, cv=5, scoring='f1\_macro')
      >>> scores
      array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])

    انظر :ref:`scoring\_parameter` للتفاصيل. في حالة مجموعة بيانات القزحية، تكون العينات متوازنة عبر فئات الهدف وبالتالي تكون الدقة ودرجة F1 متساوية تقريبًا.

    عندما يكون وسيطة ``cv`` عددًا صحيحًا، فإن دالة :func:`cross\_val\_score` تستخدم استراتيجيات :class:`KFold` أو :class:`StratifiedKFold` بشكل افتراضي، ويتم استخدام الأخير إذا كان المقدّر مستمدًا من :class:`ClassifierMixin <sklearn.base.ClassifierMixin>`.

    من الممكن أيضًا استخدام استراتيجيات التحقق المتقاطع الأخرى عن طريق تمرير مُكرِّر التحقق المتقاطع بدلاً من ذلك، على سبيل المثال::

      >>> from sklearn.model_selection import ShuffleSplit
      >>> n\_samples = X.shape[0]
      >>> cv = ShuffleSplit(n\_splits=5, test\_size=0.3, random\_state=0)
      >>> cross\_val\_score(clf, X, y, cv=cv)
      array([0.977..., 0.977..., 1.  ..., 0.955..., 1.        ])

    خيار آخر هو استخدام قائمة قابلة للتكرار تعطي تقسيمات (تدريب، اختبار) كصفائف من المؤشرات، على سبيل المثال::

      >>> def custom\_cv\_2folds(X):
      ...     n = X.shape[0]
      ...     i = 1
      ...     while i <= 2:
      ...         idx = np.arange(n \* (i - 1) / 2, n \* i / 2, dtype=int)
      ...         yield idx, idx
      ...         i += 1
      ...
      >>> custom\_cv = custom\_cv\_2folds(X)
      >>> cross\_val\_score(clf, X, y, cv=custom\_cv)
      array([1.        , 0.973...])

    .. dropdown:: تحويل البيانات مع بيانات محجوبة

      تمامًا كما أنه من المهم اختبار التوقع على البيانات المحجوبة من التدريب، يجب أيضًا تعلم المعالجة المسبقة (مثل التوحيد القياسي، واختيار الميزات، وما إلى ذلك) وتحويلات البيانات المماثلة :ref:`data-transforms` من مجموعة التدريب وتطبيقها على البيانات المحجوبة للتوقع::

        >>> from sklearn import preprocessing
        >>> X\_train, X\_test, y\_train, y\_test = train\_test\_split(
        ...     X, y, test\_size=0.4, random\_state=0)
        >>> scaler = preprocessing.StandardScaler().fit(X\_train)
        >>> X\_train\_transformed = scaler.transform(X\_train)
        >>> clf = svm.SVC(C=1).fit(X\_train\_transformed, y\_train)
        >>> X\_test\_transformed = scaler.transform(X\_test)
        >>> clf.score(X\_test\_transformed, y\_test)
        0.9333...

      تسهل :class:`Pipeline <sklearn.pipeline.Pipeline>` تجميع المقدّرين، وتوفير هذا السلوك تحت التحقق المتقاطع::

        >>> from sklearn.pipeline import make\_pipeline
        >>> clf = make\_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))
        >>> cross\_val\_score(clf, X, y, cv=cv)
        array([0.977..., 0.933..., 0.955..., 0.933..., 0.977...])

      انظر :ref:`combining\_estimators`.


    .. _multimetric\_cross\_validation:

    دالة cross\_validate والتقييم المتعدد المقاييس
    
    (تم ترك هذا القسم دون ترجمة لأنه لا يحتوي على نص بل على روابط خارجية فقط)
    
    .. toctree::
       :maxdepth: 2
######################

    تختلف الدالة :func:`cross_validate` عن الدالة :func:`cross_val_score` بطريقتين:

    - تسمح بتحديد مقاييس تقييم متعددة.
    - تعيد قاموسًا يحتوي على أوقات التناسب، وأوقات التقييم (وأيضًا درجات التدريب، والمقدرَّات المجهزة، ومؤشرات تقسيم التدريب والاختبار بشكل اختياري) بالإضافة إلى درجة الاختبار.

    بالنسبة لتقييم المقياس الفردي، حيث يكون معامل التسجيل سلسلة أو دالة قابلة للاستدعاء أو None، ستكون المفاتيح - ``['test_score', 'fit_time', 'score_time']``

    وبالنسبة لتقييم المقاييس المتعددة، ستكون قيمة الإرجاع قاموسًا بالمفاتيح التالية -
    ``['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']``

    يتم ضبط ``return_train_score`` على ``False`` بشكل افتراضي لتوفير وقت الحساب. لتقييم الدرجات على مجموعة التدريب أيضًا، تحتاج إلى ضبطه على ``True``. يمكنك أيضًا الاحتفاظ بالمقدر المجهز على كل مجموعة تدريب عن طريق ضبط ``return_estimator=True``. وبالمثل، يمكنك ضبط `return_indices=True` للاحتفاظ بمؤشرات التدريب والاختبار المستخدمة لتقسيم مجموعة البيانات إلى مجموعتي تدريب واختبار لكل تقسيمات التحقق المتبادل.

    يمكن تحديد المقاييس المتعددة إما كقائمة أو tuple أو مجموعة من أسماء مقاييس محددة مسبقًا::

        >>> from sklearn.model_selection import cross_validate
        >>> from sklearn.metrics import recall_score
        >>> scoring = ['precision_macro', 'recall_macro']
        >>> clf = svm.SVC(kernel='linear', C=1, random_state=0)
        >>> scores = cross_validate(clf, X, y, scoring=scoring)
        >>> sorted(scores.keys())
        ['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']
        >>> scores['test_recall_macro']
        array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])

    أو كقاموس يرسم اسم المقياس إلى دالة تسجيل محددة مسبقًا أو مخصصة::

        >>> from sklearn.metrics import make_scorer
        >>> scoring = {'prec_macro': 'precision_macro',
        ...            'rec_macro': make_scorer(recall_score, average='macro')}
        >>> scores = cross_validate(clf, X, y, scoring=scoring,
        ...                         cv=5, return_train_score=True)
        >>> sorted(scores.keys())
        ['fit_time', 'score_time', 'test_prec_macro', 'test_rec_macro',
         'train_prec_macro', 'train_rec_macro']
        >>> scores['train_rec_macro']
        array([0.97..., 0.97..., 0.99..., 0.98..., 0.98...])

    فيما يلي مثال على ``cross_validate`` باستخدام مقياس واحد::

        >>> scores = cross_validate(clf, X, y,
        ...                         scoring='precision_macro', cv=5,
        ...                         return_estimator=True)
        >>> sorted(scores.keys())
        ['estimator', 'fit_time', 'score_time', 'test_score']

    الحصول على التوقعات بالتحقق المتبادل
    ------------------------------------

    تحتوي الدالة :func:`cross_val_predict` على واجهة مشابهة للدالة :func:`cross_val_score`، ولكنها تعيد، لكل عنصر في الإدخال، التوقع الذي تم الحصول عليه لهذا العنصر عندما كان في مجموعة الاختبار. يمكن استخدام استراتيجيات التحقق المتبادل التي تعين جميع العناصر لمجموعة اختبار مرة واحدة فقط (وإلا، يتم رفع استثناء).

    .. warning:: ملاحظة حول الاستخدام غير المناسب لـ cross_val_predict

        قد تختلف نتيجة :func:`cross_val_predict` عن تلك التي تم الحصول عليها باستخدام :func:`cross_val_score` لأن العناصر يتم تجميعها بطرق مختلفة. تأخذ الدالة :func:`cross_val_score` متوسطًا على طيات التحقق المتبادل، في حين أن :func:`cross_val_predict` تعيد ببساطة التسمية (أو الاحتمالات) من عدة نماذج مميزة دون تمييز. وبالتالي، فإن :func:`cross_val_predict` ليست مقياسًا مناسبًا لخطأ التعميم.

    الدالة :func:`cross_val_predict` مناسبة لـ:
      - تصور التوقعات التي تم الحصول عليها من نماذج مختلفة.
      - مزج النماذج: عندما يتم استخدام توقعات أحد المقيمين الخاضعين للإشراف لتدريب مقيم آخر في طرق التجميع.

    يتم تقديم مكررات التحقق المتبادل المتاحة في القسم التالي.

    .. rubric:: أمثلة

    * :ref:`sphx_glr_auto_examples_model_selection_plot_roc_crossval.py`,
    * :ref:`sphx_glr_auto_examples_feature_selection_plot_rfe_with_cross_validation.py`,
    * :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`,
    * :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_text_feature_extraction.py`,
    * :ref:`sphx_glr_auto_examples_model_selection_plot_cv_predict.py`,
    * :ref:`sphx_glr_auto_examples_model_selection_plot_nested_cross_validation_iris.py`.

    مكررات التحقق المتبادل
    
    (ملحوظة: قد تحتوي الترجمة على بعض الكلمات الإنجليزية التي تم الاحتفاظ بها كما هي في النص الأصلي، حيث إنها أسماء دوال أو متغيرات أو محددات مسبقة في المكتبة البرمجية، ولم يتم ترجمتها لضمان صحة الترجمة وسهولة فهمها للمستخدمين الذين يمتلكون معرفة مسبقة بالمكتبة.)

النص التالي بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي:

==========================

تحتوي الأقسام التالية على الأدوات المساعدة لتوليد الفهارس التي يمكن استخدامها لتوليد تقسيمات البيانات وفقًا لاستراتيجيات تقاطع التحقق المختلفة.

.. _iid_cv:

مكررات تقاطع التحقق للبيانات المستقلة والتوزيعية بنفس الطريقة (i.i.d.)

    
(ملاحظة: لم يتم ترجمة الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية في هذا النص).

  هذا نص بتنسيق RST مترجم إلى اللغة العربية:

    افتراض أن بعض البيانات مستقلة ومتطابقة التوزيع (i.i.d.) يعني افتراض أن جميع العينات تنشأ من نفس العملية التوليدية وأن العملية التوليدية لا تحتفظ بذاكرة العينات السابقة التي تم توليدها.

    يمكن استخدام أدوات التحقق المتبادل التالية في مثل هذه الحالات.

    .. note::

      على الرغم من أن افتراض بيانات i.i.d. هو افتراض شائع في نظرية التعلم الآلي، إلا أنه نادرًا ما يكون صحيحًا في الممارسة العملية. إذا كان معروفًا أن العينات قد تم إنشاؤها باستخدام عملية تعتمد على الوقت، فمن الأفضل استخدام :ref:`مخطط التحقق المتبادل الذي يأخذ في الاعتبار السلاسل الزمنية <timeseries_cv>`. وبالمثل، إذا عرفنا أن العملية التوليدية لها بنية جماعية (عينات يتم جمعها من موضوعات مختلفة أو تجارب أو أجهزة قياس)، فمن الأفضل استخدام :ref:`التحقق المتبادل الجماعي <group_cv>`.

    .. _k_fold:

    K-Fold
    ^^^^^^

    تقسم :class:`KFold` جميع العينات في :math:`k` مجموعات من العينات، تسمى الطيات (إذا :math:`k = n`، فإن هذا يعادل استراتيجية *ترك واحد خارجًا*)، بأحجام متساوية (إذا أمكن). يتم تعلم دالة التنبؤ باستخدام :math:`k - 1` طية، ويتم استخدام الطية المتبقية للاختبار.

    مثال على التحقق المتبادل لـ 2-fold على مجموعة بيانات تحتوي على 4 عينات::

      >>> import numpy as np
      >>> from sklearn.model_selection import KFold

      >>> X = ["a", "b", "c", "d"]
      >>> kf = KFold(n_splits=2)
      >>> for train, test in kf.split(X):
      ...     print("%s %s" % (train, test))
      [2 3] [0 1]
      [0 1] [2 3]

    فيما يلي تصور لسلوك التحقق المتبادل. لاحظ أن :class:`KFold` لا يتأثر بالفئات أو المجموعات.

    .. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_006.png
       :target: ../auto_examples/model_selection/plot_cv_indices.html
       :align: center
       :scale: 75%

    يتكون كل طية من صفيفين: الأول يتعلق *مجموعة التدريب*، والثاني *مجموعة الاختبار*.
    وبالتالي، يمكن إنشاء مجموعات التدريب / الاختبار باستخدام فهرسة numpy::

      >>> X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])
      >>> y = np.array([0, 1, 0, 1])
      >>> X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]

    .. _repeated_k_fold:

    تكرار K-Fold
    ^^^^^^^^^^^^^^^

    :class:`RepeatedKFold` يكرر K-Fold n مرة. يمكن استخدامه عندما يتطلب الأمر تشغيل :class:`KFold` n مرة، وإنتاج انقسامات مختلفة في كل تكرار.

    مثال على K-Fold لـ 2-fold مكرر مرتين::

      >>> import numpy as np
      >>> from sklearn.model_selection import RepeatedKFold
      >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
      >>> random_state = 12883823
      >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)
      >>> for train, test in rkf.split(X):
      ...     print("%s %s" % (train, test))
      ...
      [2 3] [0 1]
      [0 1] [2 3]
      [0 2] [1 3]
      [1 3] [0 2]


    وبالمثل، :class:`RepeatedStratifiedKFold` يكرر K-Fold الطبقي n مرة مع اختلافات عشوائية في كل تكرار.

    .. _leave_one_out:

    ترك واحد خارجًا (LOO)
    ^^^^^^^^^^^^^^^^^^^

    :class:`LeaveOneOut` (أو LOO) هو التحقق المتبادل البسيط. يتم إنشاء كل مجموعة تعليمية عن طريق أخذ جميع العينات باستثناء واحدة، ويتم استخدام العينة المتبقية كمجموعة اختبار. وبالتالي، بالنسبة لـ :math:`n` عينات، لدينا :math:`n` مجموعات تدريب مختلفة و:math:`n` مجموعة اختبار مختلفة. لا يهدر إجراء التحقق المتبادل هذا الكثير من البيانات نظرًا لأنه تتم إزالة عينة واحدة فقط من مجموعة التدريب::

      >>> from sklearn.model_selection import LeaveOneOut

      >>> X = [1, 2, 3, 4]
      >>> loo = LeaveOneOut()
      >>> for train, test in loo.split(X):
      ...     print("%s %s" % (train, test))
      [1 2 3] [0]
      [0 2 3] [1]
      [0 1 3] [2]
      [0 1 2] [3]


    يجب على المستخدمين المحتملين لـ LOO من أجل اختيار النموذج مراعاة بعض المحاذير المعروفة. عند المقارنة مع :math:`k`-fold التحقق المتبادل، يقوم المرء ببناء :math:`n` نماذج من :math:`n` عينات بدلاً من :math:`k` نماذج، حيث :math:`n > k`.
    علاوة على ذلك، يتم تدريب كل نموذج على :math:`n - 1` عينات بدلاً من
    :math:`(k-1) n / k`. في كلتا الحالتين، بافتراض أن :math:`k` ليست كبيرة جدًا
    و :math:`k < n`، فإن LOO أكثر تكلفة حسابيًا من :math:`k`-fold التحقق المتبادل.

    من حيث الدقة، غالبًا ما يؤدي LOO إلى تباين كبير كمقدر لخطأ الاختبار. بشكل حدسي، نظرًا لأن :math:`n - 1` من
    :math:`n` العينات تُستخدم لبناء كل نموذج، فإن النماذج التي تم إنشاؤها من
    الطيّات متطابقة عمليًا مع بعضها البعض ومع النموذج الذي تم إنشاؤه من
    مجموعة التدريب بأكملها.

    ومع ذلك، إذا كانت منحنى التعلم حادًا لحجم التدريب المعني،
    فإن التحقق المتبادل من 5 أو 10 أضعاف يمكن أن يبالغ في تقدير خطأ التعميم.

    كقاعدة عامة، يقترح معظم المؤلفين، والأدلة التجريبية، أنه يجب تفضيل التحقق المتبادل من 5 أو 1

    .. dropdown:: المراجع

      * `<http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html>`_;
      * T. Hastie, R. Tibshirani, J. Friedman,  `The Elements of Statistical Learning
        <https://web.stanford.edu/~hastie/ElemStatLearn/>`_, Springer 2009
      * L. Breiman, P. Spector `Submodel selection and evaluation in regression: The X-random case
        <https://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf>`_, International Statistical Review 1992;
      * R. Kohavi, `A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection
        <https://www.ijcai.org/Proceedings/95-2/Papers/016.pdf>`_, Intl. Jnt. Conf. AI
      * R. Bharat Rao, G. Fung, R. Rosales, `On the Dangers of Cross-Validation. An Experimental Evaluation
        <https://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf>`_, SIAM 2008;
      * G. James, D. Witten, T. Hastie, R Tibshirani, `An Introduction to
        Statistical Learning <https://www.statlearning.com>`_, Springer 2013.

    ..
  هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي:

    ```python
    >>> X = np.ones(4)
    >>> lpo = LeavePOut(p=2)
    >>> for train, test in lpo.split(X):
    ...     print("%s %s" % (train, test))
    [2 3] [0 1]
    [1 3] [0 2]
    [1 2] [0 3]
    [0 3] [1 2]
    [0 2] [1 3]
    [0 1] [2 3]
    ```

    .. _ShuffleSplit:

    تصنيف التقسيمات العشوائية للتحقق المتقاطع، المعروف أيضًا باسم Shuffle & Split
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

    سوف يقوم تكرار :class:`ShuffleSplit` بإنشاء عدد محدد من المستخدم من تقسيمات بيانات التدريب / الاختبار المستقلة. يتم أولاً خلط العينات ثم تقسيمها إلى زوج من مجموعات التدريب والاختبار.

    من الممكن التحكم في العشوائية لضمان تكرار النتائج عن طريق ضبط بادئة "random_state" لمولد الأرقام الزائفة العشوائية.

    فيما يلي مثال على الاستخدام::

    >>> from sklearn.model_selection import ShuffleSplit
    >>> X = np.arange(10)
    >>> ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)
    >>> for train_index, test_index in ss.split(X):
    ...     print("%s %s" % (train_index, test_index))
    [9 1 6 7 3 0 5] [2 8 4]
    [2 9 8 0 6 7 4] [3 5 1]
    [4 5 1 0 6 9 7] [2 3 8]
    [2 7 5 8 0 3 4] [6 1 9]
    [4 1 0 6 8 9 3] [5 2 7]

    فيما يلي توضيح لسلوك التحقق المتقاطع. لاحظ أن :class:`ShuffleSplit` لا يتأثر بالفئات أو المجموعات.

    .. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_008.png
       :target: ../auto_examples/model_selection/plot_cv_indices.html
       :align: center
       :scale: 75%

    وبالتالي، يعتبر :class:`ShuffleSplit` بديلاً جيدًا لتحقق التقاطع :class:`KFold` الذي يسمح بالتحكم الدقيق في عدد التكرارات ونسبة العينات في كل جانب من تقسيم التدريب / الاختبار.

    .. _stratification:

    تكرارات التحقق المتقاطع مع التقسيم الطبقي بناءً على تسميات الفئات
    ----------------------------------------------------------------
    
    (ملاحظة: النص أعلاه يحتوي على أجزاء غير مترجمة لأنها عبارة عن رموز خاصة أو معادلات رياضية أو روابط أو تاجات أو شفرة برمجية.)

في بعض مشاكل التصنيف، يمكن أن يظهر خلل كبير في توزيع الفئات المستهدفة: على سبيل المثال، قد يكون هناك عدة أضعاف من العينات السلبية أكثر من العينات الإيجابية. في مثل هذه الحالات، يوصى باستخدام العينات الطبقية كما هي مط

...

بة في :class:`StratifiedKFold` و:class:`StratifiedShuffleSplit` لضمان الحفاظ على الترددات النسبية للفئات تقريبا في كل مجموعة تدريب وتحقق.

تقسيم ك-طبقية (Stratified k-fold)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

:class:`StratifiedKFold` هو تباين من *k-fold* الذي يعيد مجموعات طبقية: كل مجموعة تحتوي على نفس النسبة المئوية تقريبا من العينات لكل فئة مستهدفة كما في المجموعة الكاملة.

فيما يلي مثال على 3-fold cross-validation طبقية على مجموعة بيانات تحتوي على 50 عينة من فئتين غير متوازنتين. نحن نظهر عدد العينات في كل فئة ونقارن مع :class:`KFold`.

  >>> from sklearn.model_selection import StratifiedKFold, KFold
  >>> import numpy as np
  >>> X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))
  >>> skf = StratifiedKFold(n_splits=3)
  >>> for train, test in skf.split(X, y):
  ...     print('train -  {}   |   test -  {}'.format(
  ...         np.bincount(y[train]), np.bincount(y[test])))
 train -  [30  3]   |   test -  [15  2]
 train -  [30  3]   |   test -  [15  2]
 train -  [30  4]   |   test -  [15  1]
  >>> kf = KFold(n_splits=3)
  >>> for train, test in kf.split(X, y):
  ...     print('train -  {}   |   test -  {}'.format(
  ...         np.bincount(y[train]), np.bincount(y[test])))
 train -  [28  5]   |   test -  [17]
 train -  [28  5]   |   test -  [17]
 train -  [34]   |   test -  [11  5]

يمكننا أن نرى أن :class:`StratifiedKFold` يحافظ على نسب الفئات (تقريبا 1 / 10) في كل من مجموعة التدريب والاختبار.

فيما يلي تصور لسلوك التحقق المتقاطع.

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_009.png
   :target: ../auto_examples/model_selection/plot_cv_indices.html
   :align: center
   :scale: 75%

يمكن استخدام :class:`RepeatedStratifiedKFold` لتكرار Stratified K-Fold n مرات مع تصادفية مختلفة في كل تكرار.

تقسيم خلط طبقية (Stratified Shuffle Split)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

:class:`StratifiedShuffleSplit` هو تباين من *ShuffleSplit*، والذي يعيد تقسيمات طبقية، أي الذي ينشئ تقسيمات بالحفاظ على نفس النسبة المئوية لكل فئة مستهدفة كما في المجموعة الكاملة.

فيما يلي تصور لسلوك التحقق المتقاطع.

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_012.png
   :target: ../auto_examples/model_selection/plot_cv_indices.html
   :align: center
   :scale: 75%

تقسيمات مسبقة
-------------

لبعض مجموعات البيانات، يوجد بالفعل تقسيم مسبق للبيانات إلى مجموعة تدريب وتحقق أو إلى عدة تقسيمات للتحقق المتقاطع. باستخدام :class:`PredefinedSplit`، من الممكن استخدام هذه التقسيمات، على سبيل المثال عند البحث عن

...

المعلمات المثلى.

على سبيل المثال، عند استخدام مجموعة تحقق، اضبط ``test_fold`` على 0 لجميع العينات التي هي جزء من مجموعة التحقق، وعلى -1 لجميع العينات الأخرى.

تقسيمات التحقق المتقاطع للبيانات المجمعة
---------------------------------------

    

الافتراض i.i.d. يتم انتهاكه إذا كانت عملية التوليد الكامنة تسفر عن مجموعات من العينات التابعة.

هذه التجميع للبيانات خاص بالمجال. ومن الأمثلة على ذلك عندما تكون هناك بيانات طبية تم جمعها من عدة مرضى، مع أخذ عدة عينات من كل مريض. ومن المرجح أن تعتمد هذه البيانات على المجموعة الفردية. في مثالنا، سيكون معرف المريض لكل عينة هو معرّف المجموعة الخاص به.

في هذه الحالة، نود أن نعرف ما إذا كان النموذج المدرب على مجموعة معينة من المجموعات يعمم بشكل جيد على المجموعات غير المرئية. لقياس هذا، نحتاج إلى التأكد من أن جميع العينات في مجموعة التحقق تأتي من مجموعات غير ممثلة على الإطلاق في مجموعة التدريب المقترنة.

يمكن استخدام أدوات تقسيم التحقق المتبادل التالية للقيام بذلك. يتم تحديد معرف التجميع للعينات عبر معامل "groups".

.. _group_k_fold:

طي k-مجموعة
^^^^^^^^^^^

:class:`GroupKFold` هو تباين لطي k الذي يضمن عدم تمثيل نفس المجموعة في كل من مجموعة الاختبار والتدريب. على سبيل المثال، إذا تم الحصول على البيانات من موضوعات مختلفة مع عدة عينات لكل موضوع وإذا كان النموذج مرنًا بما يكفي للتعلم من ميزات محددة لكل شخص، فقد يفشل في التعميم على موضوعات جديدة. :class:`GroupKFold` يجعل من الممكن الكشف عن هذا النوع من المواقف الزائدة عن الحاجة.

تخيل أن لديك ثلاثة موضوعات، كل منها مرتبط برقم من 1 إلى 3::

  >>> from sklearn.model_selection import GroupKFold

  >>> X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]
  >>> y = ["a", "b", "b", "b", "c", "c", "c", "d", "d", "d"]
  >>> groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]

  >>> gkf = GroupKFold(n_splits=3)
  >>> for train, test in gkf.split(X, y, groups=groups):
  ...     print("%s %s" % (train, test))
  [0 1 2 3 4 5] [6 7 8 9]
  [0 1 2 6 7 8 9] [3 4 5]
  [3 4 5 6 7 8 9] [0 1 2]

كل موضوع في مجموعة اختبار مختلفة، ولا يتم تمثيل نفس الموضوع في كل من الاختبار والتدريب. لاحظ أن الطيات ليس لها نفس الحجم تمامًا بسبب عدم التوازن في البيانات. إذا كان يجب موازنة نسب الفئات عبر الطيات، فإن :class:`StratifiedGroupKFold` خيار أفضل.

فيما يلي عرض مرئي لسلوك التحقق المتقاطع.

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_007.png
   :target: ../auto_examples/model_selection/plot_cv_indices.html
   :align: center
   :scale: 75%

على غرار :class:`KFold`، ستشكل مجموعات الاختبار من :class:`GroupKFold` قسمًا كاملاً لجميع البيانات. على عكس :class:`KFold`، لا يتمتع :class:`GroupKFold` بأي عشوائية على الإطلاق، في حين أن :class:`KFold` عشوائي عند ``shuffle=True``.

.. _stratified_group_k_fold:

StratifiedGroupKFold
^^^^^^^^^^^^^^^^^^^^

:class:`StratifiedGroupKFold` هو نظام للتحقق المتبادل يجمع بين كل من :class:`StratifiedKFold` و :class:`GroupKFold`. والفكرة هي محاولة الحفاظ على توزيع الفئات في كل تقسيم مع الحفاظ على كل مجموعة داخل قسم واحد. قد يكون ذلك مفيدًا عندما يكون لديك مجموعة بيانات غير متوازنة بحيث قد يؤدي استخدام :class:`GroupKFold` إلى انقسامات ملتوية.

مثال::

  >>> from sklearn.model_selection import StratifiedGroupKFold
  >>> X = list(range(18))
  >>> y = [1] * 6 + [0] * 12
  >>> groups = [1, 2, 3, 3, 4, 4, 1, 1, 2, 2, 3, 4, 5, 5, 5, 6, 6, 6]
  >>> sgkf = StratifiedGroupKFold(n_splits=3)
  >>> for train, test in sgkf.split(X, y, groups=groups):
  ...     print("%s %s" % (train, test))
  [ 0  2  3  4  5  6  7 10 11 15 16 17] [ 1  8  9 12 13 14]
  [ 0  1  4  5  6  7  8  9 11 12 13 14] [ 2  3 10 15 16 17]
  [ 1  2  3  8  9 10 12 13 14 15 16 17] [ 0  4  5  6  7 11]

.. dropdown:: Implementation notes

  - مع التنفيذ الحالي، لا يمكن التوزيع العشوائي الكامل في معظم السيناريوهات. عندما يكون shuffle=True، يحدث ما يلي:

    1. يتم خلط جميع المجموعات.
    2. يتم ترتيب المجموعات حسب الانحراف المعياري للفئات باستخدام ترتيب مستقر.
    3. يتم تكرار المجموعات المصنفة ويتم تعيينها إلى الطيات.

    وهذا يعني أنه سيتم خلط المجموعات التي لها نفس الانحراف المعياري لتوزيع الفئات فقط، مما قد يكون مفيدًا عندما تحتوي كل مجموعة على فئة واحدة فقط.
  - يقوم الخوارزمية بتعيين كل مجموعة بشكل جشع إلى واحدة من n_splits مجموعات الاختبار، مع اختيار مجموعة الاختبار التي تقلل من التباين في توزيع الفئات عبر مجموعات الاختبار. يتم تعيين المجموعة من المجموعات ذات التباين الأعلى إلى الأدنى في تردد الفئة، أي يتم تعيين مجموعات كبيرة ذات قمة على فئة واحدة أو أكثر أولاً.
  - هذا التقسيم ليس أمثل بمعنى أنه قد ينتج انقسامات غير متوازنة حتى لو كان التقسيم الطبقي المثالي ممكنًا. إذا كان لديك توزيع نسبي للفئات في كل مجموعة، فمن الأفضل استخدام :class:`GroupKFold`.


فيما يلي عرض مرئي لسلوك التحقق المتقاطع للمجموعات غير المتساوية:

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_005.png
   :target: ../auto_examples/model_selection/plot_cv_indices.html
   :align: center
   :scale: 75%

.. _leave_one_group_out:

تجاهل مجموعة واحدة
^^^^^^^^^^^^^^^^^^^

:class:`LeaveOneGroupOut` هو نظام للتحقق المتبادل حيث يحتفظ كل تقسيم بالعينات التي تنتمي إلى مجموعة معينة. يتم توفير معلومات المجموعة عبر صفيف يشفر مجموعة كل عينة.

يتكون كل مجموعة تدريب من جميع العينات باستثناء العينات المتعلقة بمجموعة معينة. هذا هو نفسه :class:`LeavePGroupsOut` مع `n_groups=1` ونفسه :class:`GroupKFold` مع `n_splits` مساوٍ لعدد التسميات الفريدة التي تم تمريرها إلى معامل `groups`.

على سبيل المثال، في حالات التجارب المتعددة، يمكن استخدام :class:`LeaveOneGroupOut` لإنشاء عملية تحقق متقاطع تستند إلى التجارب المختلفة: نقوم بإنشاء مجموعة تدريب باستخدام عينات من جميع التجارب باستثناء تجربة واحدة::

  >>> from sklearn.model_selection import LeaveOneGroupOut

  >>> X = [1, 2, 3, 4, 5, 6]
  >>> y = [1, 2, 3, 4, 5, 6]
  >>> groups = [1, 1, 2, 2, 3, 3]
  >>> logo = LeaveOneGroupOut()
  >>> for train, test in logo.split(X, y, groups):
  ...     print("%s %s" % (train, test))
  [2 3] [0 1]
  [0 1] [2 3]
  
  هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي:

    ```python
    >>> X = [1, 5, 10, 50, 60, 70, 80]
    >>> y = [0, 1, 1, 2, 2, 2, 2]
    >>> groups = [1, 1, 2, 2, 3, 3, 3]
    >>> logo = LeaveOneGroupOut()
    >>> for train, test in logo.split(X, y, groups=groups):
    ...     print("%s %s" % (train, test))
    [2 3 4 5 6] [0 1]
    [0 1 4 5 6] [2 3]
    [0 1 2 3] [4 5 6]
    ```

    تطبيق شائع آخر هو استخدام معلومات الوقت: على سبيل المثال، يمكن أن تكون المجموعات عبارة عن سنة جمع العينات، وبالتالي تسمح بالتحقق المتبادل ضد الانقسامات القائمة على الوقت.

    .. _leave_p_groups_out:

    ترك P مجموعات خارج
    ^^^^^^^^^^^^^^^^^^

    :class:`LeavePGroupsOut` مشابه لـ :class:`LeaveOneGroupOut`، ولكنه يزيل العينات المتعلقة بـ :math:`P` مجموعات لكل مجموعة تدريب / اختبار. يتم ترك جميع التركيبات الممكنة لـ :math:`P` مجموعات، مما يعني أن مجموعات الاختبار ستتداخل لـ :math:`P>1`.

    مثال على ترك 2-مجموعة خارج::

    >>> from sklearn.model_selection import LeavePGroupsOut

    >>> X = np.arange(6)
    >>> y = [1, 1, 1, 2, 2, 2]
    >>> groups = [1, 1, 2, 2, 3, 3]
    >>> lpgo = LeavePGroupsOut(n_groups=2)
    >>> for train, test in lpgo.split(X, y, groups=groups):
    ...     print("%s %s" % (train, test))
    [4 5] [0 1 2 3]
    [2 3] [0 1 4 5]
    [0 1] [2 3 4 5]

    .. _group_shuffle_split:

    توزيع المجموعة العشوائية
    ^^^^^^^^^^^^^^^^^^^

    يتصرف تكرار :class:`GroupShuffleSplit` كمزيج من :class:`ShuffleSplit` و :class:`LeavePGroupsOut`، وينشئ تسلسلًا من الأقسام العشوائية التي يتم فيها الاحتفاظ بمجموعة فرعية من المجموعات لكل انقسام. يتم تنفيذ كل تقسيم تدريب / اختبار بشكل مستقل مما يعني أنه لا توجد علاقة مضمونة بين مجموعات الاختبار المتعاقبة.

    فيما يلي مثال على الاستخدام::

    >>> from sklearn.model_selection import GroupShuffleSplit

    >>> X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]
    >>> y = ["a", "b", "b", "b", "c", "c", "c", "a"]
    >>> groups = [1, 1, 2, 2, 3, 3, 4, 4]
    >>> gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)
    >>> for train, test in gss.split(X, y, groups=groups):
    ...     print("%s %s" % (train, test))
    [0 1 2 3] [4 5 6 7]
    [2 3 6 7] [0 1 4 5]
    [2 3 4 5] [0 1 6 7]
    [4 5 6 7] [0 1 2 3]

    فيما يلي تصور لسلوك التحقق المتبادل.

    .. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_011.png
       :target: ../auto_examples/model_selection/plot_cv_indices.html
       :align: center
       :scale: 75%

    هذه الفئة مفيدة عندما يكون السلوك المطلوب هو سلوك :class:`LeavePGroupsOut`، ولكن عدد المجموعات كبير بما يكفي بحيث يكون إنشاء جميع الأقسام الممكنة مع :math:`P` مجموعات محجوبة باهظ التكلفة. في مثل هذا السيناريو، يوفر :class:`GroupShuffleSplit` عينة عشوائية (مع الاستبدال) من التقسيمات التدريبية / الاختبارية التي تم إنشاؤها بواسطة :class:`LeavePGroupsOut`.

    استخدام تكرارات التحقق المتبادل لتقسيم التدريب والاختبار
    
    (ملاحظة: تم الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي في الترجمة.)

يُمكن أن تكون وظائف التحقق المتبادل للمجموعات المذكورة أعلاه مفيدة أيضًا لتقسيم مجموعة البيانات إلى مجموعات فرعية للتدريب والاختبار.لاحظ أن دالة الملاءمة :func:`train_test_split` هي مُغلّف حول :func:`ShuffleSplit` وبالتالي تسمح فقط بالتقسيم الطبقي (باستخدام تسميات الفئة) ولا يمكنها حساب المجموعات.

لتنفيذ تقسيم التدريب والاختبار، استخدم مؤشرات لمجموعات فرعية للتدريب والاختبار تم إرجاعها بواسطة ناتج المُنشئ بواسطة طريقة `split()` من مقسم التحقق المتبادل. على سبيل المثال::

  >>> import numpy as np
  >>> from sklearn.model_selection import GroupShuffleSplit

  >>> X = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001])
  >>> y = np.array(["a", "b", "b", "b", "c", "c", "c", "a"])
  >>> groups = np.array([1, 1, 2, 2, 3, 3, 4, 4])
  >>> train_indx, test_indx = next(
  ...     GroupShuffleSplit(random_state=7).split(X, y, groups)
  ... )
  >>> X_train, X_test, y_train, y_test = \
  ...     X[train_indx], X[test_indx], y[train_indx], y[test_indx]
  >>> X_train.shape, X_test.shape
  ((6,), (2,))
  >>> np.unique(groups[train_indx]), np.unique(groups[test_indx])
  (array([1, 2, 4]), array([3]))

.. _timeseries_cv:

التحقق المتبادل لبيانات السلاسل الزمنية
----------------------------------------

تتميز بيانات السلاسل الزمنية بالارتباط بين المشاهدات القريبة في الوقت (الترابط الذاتي). ومع ذلك، فإن تقنيات التحقق المتبادل الكلاسيكية مثل :class:`KFold` و :class:`ShuffleSplit` تفترض أن العينات مستقلة ومتطابقة التوزيع، وسوف يؤدي ذلك إلى ارتباط غير معقول بين الحالات التدريبية والاختبارية (مما يؤدي إلى تقديرات ضعيفة لخطأ التعميم) في بيانات السلاسل الزمنية. لذلك، من المهم جدًا تقييم نموذجنا لبيانات السلاسل الزمنية على المشاهدات "المستقبلية" الأقل تشابهًا مع تلك المستخدمة لتدريب النموذج. لتحقيق ذلك، يتم توفير حل واحد بواسطة :class:`TimeSeriesSplit`.

.. _time_series_split:

تقسيم السلاسل الزمنية
^^^^^^^^^^^^^^^^^^^^^

:class:`TimeSeriesSplit` هو اختلاف في *k-fold* الذي يعيد أول :math:`k` طيات كمجموعة تدريب والطية :math:`(k+1)` كمجموعة اختبار. لاحظ أنه على عكس طرق التحقق المتبادل القياسية، تكون مجموعات التدريب المتعاقبة صورًا فرعية لتلك التي تأتي قبلها. أيضًا، يضيف جميع البيانات الفائضة إلى قسم التدريب الأول، والذي يستخدم دائمًا لتدريب النموذج.

يمكن استخدام هذا الفصل للتحقق المتبادل من عينات بيانات السلاسل الزمنية التي يتم ملاحظتها على فترات زمنية ثابتة.

مثال على التحقق المتبادل للسلاسل الزمنية المكون من 3 أجزاء في مجموعة بيانات تحتوي على 6 عينات::

  >>> from sklearn.model_selection import TimeSeriesSplit

  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])
  >>> y = np.array([1, 2, 3, 4, 5, 6])
  >>> tscv = TimeSeriesSplit(n_splits=3)
  >>> print(tscv)
  TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)
  >>> for train, test in tscv.split(X):
  ...     print("%s %s" % (train, test))
  [0 1 2] [3]
  [0 1 2 3] [4]
  [0 1 2 3 4] [5]

فيما يلي عرض مرئي لسلوك التحقق المتبادل.

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cv_indices_013.png
   :target: ../auto_examples/model_selection/plot_cv_indices.html
   :align: center
   :scale: 75%

ملاحظة حول التبديل

    

(**ملاحظة**: لم يتم تضمين الشفرة البرمجية لرسم الصورة في النص الأصلي)

  إذا لم يكن ترتيب البيانات عشوائيًا (على سبيل المثال، تكون العينات ذات الملصقات من نفس الفئة متجاورة)، فقد يكون خلطها أولاً ضروريًا للحصول على نتيجة تحقق تقاطعي ذات مغزى. ومع ذلك، قد يكون العكس صحيحًا إذا لم تكن العينات مستقلة ومتطابقة التوزيع. على سبيل المثال، إذا كانت العينات تتوافق مع مقالات إخبارية، ويتم ترتيبها حسب وقت نشرها، فإن خلط البيانات سيؤدي على الأرجح إلى نموذج مفرط التوافق ودرجة تحقق مصطنعة عالية: سيتم اختباره على عينات متشابهة بشكل مصطنع (قريبة في الوقت) لعينات التدريب.

    تحتوي بعض مُكررات التحقق التقاطعي، مثل :class:`KFold`، على خيار مدمج لخلط مؤشرات البيانات قبل تقسيمها. لاحظ أن:

    * هذا يستهلك ذاكرة أقل من خلط البيانات مباشرة.
    * بشكل افتراضي، لا يحدث أي خلط، بما في ذلك التحقق التقاطعي (المستوى) K الذي يتم تنفيذه عن طريق تحديد ``cv=some_integer`` إلى :func:`cross_val_score`، والبحث الشبكي، وما إلى ذلك. ضع في اعتبارك أن :func:`train_test_split` لا تزال تعيد تقسيمًا عشوائيًا.
    * تبرمج معلم ``random_state`` على ``None``، مما يعني أن الخلط سيكون مختلفًا في كل مرة يتم فيها تكرار ``KFold(..., shuffle=True)``. ومع ذلك، سيستخدم ``GridSearchCV`` نفس الخلط لكل مجموعة من المعلمات التي يتم التحقق من صحتها بواسطة استدعاء واحد لطريقة ``fit`` الخاصة به.
    * للحصول على نتائج متطابقة لكل زوج، قم بتعيين ``random_state`` على عدد صحيح.

    لمزيد من التفاصيل حول كيفية التحكم في عشوائية أدوات تقطيع cv وتجنب المزالق الشائعة، راجع :ref:`randomness`.

    التحقق التقاطعي واختيار النموذج
    ===========================

    يمكن أيضًا استخدام مُكررات التحقق التقاطعي لأداء اختيار النموذج مباشرةً باستخدام البحث الشبكي عن معاملات النموذج المثلى. هذا هو موضوع القسم التالي: :ref:`grid_search`.

    .. _permutation_test_score:

    درجة اختبار التبديل
    ========================

    تقدم :func:`~sklearn.model_selection.permutation_test_score` طريقة أخرى لتقييم أداء المصنفات. إنها توفر قيمة p تستند إلى التبديل، والتي تمثل مدى احتمالية الحصول على أداء لوحظ للمصنف عن طريق الصدفة. الفرضية الصفرية في هذا الاختبار هي أن المصنف يفشل في الاستفادة من أي تبعية إحصائية بين الميزات والملصقات لإجراء تنبؤات صحيحة على البيانات المتبقية. :func:`~sklearn.model_selection.permutation_test_score` يولد توزيعًا فارغًا عن طريق حساب `n_permutations` من التباديل المختلفة للبيانات. في كل تبديل، يتم خلط الملصقات بشكل عشوائي، مما يزيل أي تبعية بين الميزات والملصقات. قيمة p الناتجة هي جزء من التباديل التي يكون فيها متوسط ​​درجة التحقق المتقاطع التي يحصل عليها النموذج أفضل من درجة التحقق المتقاطع التي يحصل عليها النموذج باستخدام البيانات الأصلية. للحصول على نتائج موثوقة، يجب أن يكون ``n_permutations`` عادةً أكبر من 100 و ``cv`` بين 3-10 طيات.

    توفر قيمة p المنخفضة دليلًا على أن مجموعة البيانات تحتوي على تبعية حقيقية بين الميزات والملصقات وكان المصنف قادرًا على الاستفادة من هذا للحصول على نتائج جيدة. يمكن أن ترجع قيمة p العالية إلى عدم وجود تبعية بين الميزات والملصقات (لا يوجد فرق في قيم الميزات بين الفئات) أو لأن المصنف لم يتمكن من استخدام التبعية في البيانات. في الحالة الأخيرة، فإن استخدام مصنف أكثر ملاءمة قادر على الاستفادة من البنية في البيانات، سينتج عنه قيمة p أقل.

    يوفر التحقق المتقاطع معلومات حول مدى نجاح المصنف في التعميم، وعلى وجه التحديد نطاق الأخطاء المتوقعة للمصنف. ومع ذلك، قد يظل المصنف المدرب على مجموعة بيانات عالية الأبعاد بدون بنية يعمل بشكل أفضل من المتوقع في التحقق المتقاطع، لمجرد الصدفة. يمكن أن يحدث هذا عادةً مع مجموعات البيانات الصغيرة التي تحتوي على أقل من بضع مئات من العينات. :func:`~sklearn.model_selection.permutation_test_score` يوفر معلومات حول ما إذا كان المصنف قد وجد بنية فئة حقيقية ويمكن أن يساعد في تقييم أداء المصنف.

    من المهم ملاحظة أن هذا الاختبار قد ثبت أنه ينتج قيم p منخفضة حتى إذا كانت هناك بنية ضعيفة فقط في البيانات لأنه في مجموعات البيانات المتبادلة المقابلة لا توجد بنية على الإطلاق. لذلك فإن هذا الاختبار قادر فقط على إظهار متى يتفوق النموذج بشكل موثوق على التخمين العشوائي.

    أخيرًا، يتم حساب :func:`~sklearn.model_selection.permutation_test_score` باستخدام القوة الغاشمة ويلائم داخليًا ``(n_permutations + 1) * n_cv`` نماذج. لذلك فهو قابل للتتبع فقط مع مجموعات البيانات الصغيرة التي يكون فيها تركيب نموذج فردي سريع جدًا.

    .. rubric:: أمثلة

    * :ref:`sphx_glr_auto_examples_model_selection_plot_permutation_tests_for_classification.py`

    .. dropdown:: المراجع

      * Ojala و Garriga. `اختبارات التبديل لدراسة أداء المصنف
        <http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf>`_.
        J. Mach. Learn. Res. 201

    
    (ملاحظة: لم تتم ترجمة روابط ومراجع الخارجية، لأنها غير متوفرة باللغة العربية)
