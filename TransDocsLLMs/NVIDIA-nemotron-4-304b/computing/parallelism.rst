التوازي، إدارة الموارد، والتكوين

(ملحوظة: لم يتم ترجمة الرموز الخاصة ولا الرموز والمعادلات الرياضية ولا الروابط والتاجات ولا الشفرة البرمجية كما طلبتم)

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية دون ترجمة:

===================================================

.. _parallelism:

التوازي (Parallelism)

    
(ملاحظة: لم يتم ترجمة كلمة "Parallelism" لأنها مصطلح تقني متخصص في مجال معين، ولتجنب أي لبس أو سوء فهم، تم تركها كما هي في النص الأصلي).

  هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرياضية والروابط والتاجات والشفرة البرمجية دون ترجمة:

---

تقوم بعض أدوات التقدير والأدوات المساعدة في Scikit-learn بتهيئة العمليات المكلفة باستخدام عدة أنوية CPU.

اعتمادًا على نوع أداة التقدير وأحيانًا قيم معلمات البناء، يتم تنفيذ ذلك إما:

- بالتوازي عالي المستوى عبر `joblib <https://joblib.readthedocs.io/en/latest/>`_.
- بالتوازي منخفض المستوى عبر OpenMP، المستخدم في شيفرة C أو Cython.
- بالتوازي منخفض المستوى عبر BLAS، المستخدم من قبل NumPy و SciPy للعمليات العامة على المصفوفات.

تتحكم معلمات `n_jobs` لأدوات التقدير دائمًا في مقدار التوازي الذي يديره joblib (عمليات أو مؤشرات ترابط اعتمادًا على الواجهة الخلفية لـ joblib).
التوازي على مستوى مؤشر الترابط الذي تديره OpenMP في شيفرة Cython الخاصة بـ Scikit-learn أو المكتبات BLAS و LAPACK المستخدمة من قبل عمليات NumPy و SciPy المستخدمة في Scikit-learn يتم التحكم فيه دائمًا بواسطة متغيرات البيئة أو `threadpoolctl` كما هو موضح أدناه.
لاحظ أن بعض أدوات التقدير يمكنها الاستفادة من جميع أنواع التوازي الثلاثة في نقاط مختلفة من طرق التدريب والتنبؤ الخاصة بها.

سنشرح هذه الأنواع الثلاثة من التوازي في الأقسام الفرعية التالية بمزيد من التفاصيل.

التوازي عالي المستوى مع joblib
....................................

عندما يستخدم التنفيذ الأساسي joblib، يمكن التحكم في عدد norskere (المؤشرات أو العمليات) التي يتم إنشاؤها بالتوازي عبر معلمة ``n_jobs``.

.. note::

    أين (وكيف) يحدث التوازي في أدوات التقدير التي تستخدم joblib من خلال تحديد `n_jobs` غير موثق بشكل جيد حاليًا.
    يرجى مساعدتنا في تحسين وثائقنا والتعامل مع `المشكلة 1422
    <https://github.com/scikit-learn/scikit-learn/issues/14228>`_!

يمكن لـ Joblib دعم كل من تعدد المعالجة وتعدد مؤشرات الترابط. سواء اختارت joblib إنشاء مؤشر ترابط أو عملية يعتمد على **الواجهة الخلفية** التي تستخدمها.

تعتمد Scikit-learn بشكل عام على الواجهة الخلفية ``loky``، والتي هي الواجهة الخلفية الافتراضية لـ joblib. Loky هي واجهة خلفية متعددة المعالجة. عند القيام بتعدد المعالجة، من أجل تجنب تكرار الذاكرة في كل عملية (وهو أمر غير معقول مع مجموعات البيانات الكبيرة)، ستقوم joblib بإنشاء `memmap <https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html>`_ التي يمكن أن تشاركها جميع العمليات، عندما تكون البيانات أكبر من 1 ميغابايت.

في بعض الحالات المحددة (عندما تقوم الشيفرة التي يتم تشغيلها بالتوازي بتحرير GIL)، ستشير Scikit-learn إلى ``joblib`` أن الواجهة الخلفية ذات مؤشرات ترابط متعددة هي الأفضل.

كمستخدم، يمكنك التحكم في الواجهة الخلفية التي ستستخدمها joblib (بغض النظر عما توصي به Scikit-learn) باستخدام مدير السياق::

    from joblib import parallel_backend

    with parallel_backend('threading', n_jobs=2):
        # شيفرة Scikit-learn الخاصة بك هنا

يرجى الرجوع إلى `وثائق joblib <https://joblib.readthedocs.io/en/latest/parallel.html#thread-based-parallelism-vs-process-based-parallelism>`_ لمزيد من التفاصيل.

في الممارسة العملية، يعتمد ما إذا كان التوازي مفيدًا في تحسين وقت التشغيل على العديد من العوامل. من الجيد عادةً التجربة بدلاً من افتراض أن زيادة عدد norskere هو دائمًا أمر جيد. في بعض الحالات، يمكن أن يكون من الضار للغاية للأداء تشغيل نسخ متعددة من بعض أدوات التقدير أو الوظائف بالتوازي (انظر الاشتراك الزائد أدناه).

التوازي منخفض المستوى مع OpenMP
...................................

يتم استخدام OpenMP لتهيئة الشيفرة المكتوبة في Cython أو C، مع الاعتماد على مؤشرات ترابط متعددة حصريًا. افتراضيًا، ستستخدم عمليات التنفيذ التي تستخدم OpenMP أكبر عدد ممكن من مؤشرات الترابط، أي أكبر عدد ممكن من الأنوية المنطقية.

يمكنك التحكم في العدد الدقيق لمؤشرات الترابط المستخدمة إما:

- عبر متغير البيئة ``OMP_NUM_THREADS``، على سبيل المثال عند:
  تشغيل برنامج Python:

  .. prompt:: bash $

      OMP_NUM_THREADS=4 python my_script.py

- أو عبر `threadpoolctl` كما هو موضح في `هذه القطعة من التوثيق
  <https://github.com/joblib/threadpoolctl/#setting-the-maximum-size-of-thread-pools>`_.

الروتينات المتوازية NumPy و SciPy من المكتبات العددية
..........................................................

تعتمد Scikit-learn بشكل كبير على NumPy و SciPy، والتي تستدعي داخليًا إجراءات جبرية خطية متعددة مؤشرات الترابط (BLAS & LAPACK) المطبقة في مكتبات مثل MKL أو OpenBLAS أو BLIS.

يمكنك التحكم في العدد الدقيق لمؤشرات الترابط التي تستخدمها BLAS لكل مكتبة باستخدام متغيرات البيئة، وهي:

- ``MKL_NUM_THREADS`` يضبط عدد مؤشرات الترابط التي تستخدمها MKL،
- ``OPENBLAS_NUM_THREADS`` يضبط عدد مؤشرات الترابط التي تستخدمها OpenBLAS
- ``BLIS_NUM_THREADS`` يضبط عدد مؤشرات الترابط التي تستخدمها BLIS

لاحظ أن عمليات تنفيذ BLAS & LAPACK يمكن أن تتأثر أيضًا بـ
`OMP_NUM_THREADS`. للتحقق مما إذا كانت هذه هي الحالة في بيئتك،
يمكنك فحص كيفية تأثر عدد مؤشرات الترابط المستخدمة فعليًا من قبل تلك المكتبات عند تشغيل الأمر التالي في طرفية bash أو zsh
لقيم مختلفة من `OMP_NUM_THREADS`:

.. prompt:: bash $

    OMP_NUM_THREADS=2 python -m threadpoolctl -i numpy scipy

.. note::
    في وقت الكتابة (2022)، يتم ربط حزم NumPy و SciPy الموزعة على pypi.org (أي تلك التي يتم تثبيتها عبر ``pip install``)
    وعلى قناة conda-forge (أي تلك التي يتم تثبيتها عبر
    ``conda install --channel conda-forge``) باستخدام OpenBLAS، بينما
    ترتبط حزم NumPy و SciPy الموزعة على قناة ``defaults`` من Anaconda.org (أي تلك التي يتم تثبيتها عبر ``conda install``)
    بشكل افتراضي مع MKL.


الاشتراك الزائد: إنشاء عدد كبير جدًا من مؤشرات الترابط
...........................................

من المستحسن عمومًا تجنب استخدام عمليات أو مؤشرات ترابط أكثر بكثير من عدد وحدات المعالجة المركزية على جهاز. يحدث الاشتراك الزائد عندما يقوم البرنامج بتشغيل مؤشرات ترابط كثيرة جدًا في نفس الوقت.
    

افترض أن لديك جهازًا يحتوي على 8 وحدات CPU. ضع في اعتبارك حالة تقوم فيها بتشغيل :class:`~sklearn.model_selection.GridSearchCV` (موازية باستخدام joblib) مع ``n_jobs=8`` على :class:`~sklearn.ensemble.HistGradientBoostingClassifier` (موازية باستخدام OpenMP). سوف يقوم كل مثيل من :class:`~sklearn.ensemble.HistGradientBoostingClassifier` بتوليد 8 مؤشرات ترابط (نظرًا لأن لديك 8 وحدات CPU). هذا إجمالي ``8 * 8 = 64`` مؤشر ترابط، مما يؤدي إلى زيادة في عدد المؤشرات الترابطية لوحدات CPU الفعلية وبالتالي حدوث زيادة في النفقات العامة للجدولة.

يمكن أن تنشأ زيادة عدد المؤشرات الترابطية بنفس الطريقة مع الروتينيات الموازية من MKL أو OpenBLAS أو BLIS المتداخلة في مكالمات joblib.

بدءًا من ``joblib >= 0.14``، عندما يتم استخدام الواجهة الخلفية ``loky`` (والتي تعتبر الافتراضية)، ستخبر joblib عملياتها الابنة بتقييد عدد مؤشرات الترابط التي يمكن استخدامها، وذلك لتجنب زيادة عدد المؤشرات الترابطية. في الممارسة العملية، فإن الاستدلال الذي تستخدمه joblib هو إخبار العمليات باستخدام ``max_threads = n_cpus // n_jobs``، عبر متغير البيئة المقابل لها. عودة إلى مثالنا السابق، نظرًا لأن الواجهة الخلفية joblib لـ :class:`~sklearn.model_selection.GridSearchCV` هي ``loky``، فإن كل عملية ستكون قادرة فقط على استخدام مؤشر ترابط واحد بدلاً من 8، وبالتالي تخفيف مشكلة المبالغة في عدد مؤشرات الترابط.

لاحظ ما يلي:

- سيؤدي تعيين أحد متغيرات البيئة يدويًا (``OMP_NUM_THREADS`` أو ``MKL_NUM_THREADS`` أو ``OPENBLAS_NUM_THREADS`` أو ``BLIS_NUM_THREADS``) إلى الأسبقية على ما تحاول joblib القيام به. سيكون إجمالي عدد مؤشرات الترابط ``n_jobs * <LIB>_NUM_THREADS``. لاحظ أن تعيين هذا الحد سيؤثر أيضًا على عملياتك الحسابية في العملية الرئيسية، والتي لن تستخدم إلا ``<LIB>_NUM_THREADS``. تعرض Joblib مدير سياق للتحكم بشكل أدق في عدد مؤشرات الترابط في العاملين بها (انظر وثائق joblib المرتبطة أدناه).
- عندما يتم تكوين joblib لاستخدام الواجهة الخلفية ``threading``، لا توجد آلية لتجنب الاشتراكات الزائدة عند الاتصال بمكتبات أصلية متوازية في مؤشرات ترابط joblib المُدارة.
- جميع مقدرات scikit-learn التي تعتمد صراحةً على OpenMP في كود Cython الخاص بها تستخدم دائمًا `threadpoolctl` داخليًا للتكيف تلقائيًا مع أعداد مؤشرات الترابط المستخدمة بواسطة OpenMP ومكالمات BLAS المتداخلة المحتملة لتجنب زيادة في عدد مؤشرات الترابط.

ستجد تفاصيل إضافية حول تخفيف joblib للاشتراكات الزائدة في `وثائق joblib <https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-resources>`_.

ستجد تفاصيل إضافية حول التوازي في مكتبات بايثون العددية في `هذه الوثيقة من Thomas J. Fan <https://thomasjpfan.github.io/parallelism-python-libraries-design/>`_.

مفاتيح التكوين

    

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية. لا تترجم الرموز الخاصة ولا الرموز والمعادلات الرياضية ولا تترجم الروابط والتاجات ولا الشفرة البرمجية:

-----------------------

Python API
..........

يمكن استخدام :func:`sklearn.set_config` و :func:`sklearn.config_context` لتغيير معلمات التكوين التي تتحكم في جوانب التوازي.

.. _environment_variable:

متغيرات البيئة
..............

يجب تعيين متغيرات البيئة هذه قبل استيراد scikit-learn.

`SKLEARN_ASSUME_FINITE`
~~~~~~~~~~~~~~~~~~~~~~~

تعيين القيمة الافتراضية وسيطة `assume_finite` لـ :func:`sklearn.set_config`.

`SKLEARN_WORKING_MEMORY`
~~~~~~~~~~~~~~~~~~~~~~~~

تعيين القيمة الافتراضية وسيطة `working_memory` لـ :func:`sklearn.set_config`.

`SKLEARN_SEED`
~~~~~~~~~~~~~~

تعيين البذرة لمولد الأرقام العشوائية العالمي عند تشغيل الاختبارات، للتكاثر.

لاحظ أنه من المتوقع أن تعمل اختبارات scikit-learn بشكل حتمي مع التلقيح الصريح لمثيلات RNG المستقلة الخاصة بها بدلاً من الاعتماد على Singletons RNG لمكتبة Python أو numpy القياسية للتأكد من أن نتائج الاختبار مستقلة عن ترتيب تنفيذ الاختبار. ومع ذلك، قد تنسى بعض الاختبارات استخدام البذر الصريح وهذه المتغير هي طريقة للتحكم في الحالة الأولية للمتغيرات المذكورة أعلاه.

`SKLEARN_TESTS_GLOBAL_RANDOM_SEED`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

يتحكم في زرع مولد الأرقام العشوائية المستخدم في الاختبارات التي تعتمد على تركيبات `global_random_seed`.

تقبل جميع الاختبارات التي تستخدم هذه التركيبات العقد الذي يجب أن تجتازه بشكل حتمي لأي قيمة بذرة من 0 إلى 99 مدرجة.

في بناء CI الليلي، يتم رسم متغير البيئة `SKLEARN_TESTS_GLOBAL_RANDOM_SEED` بشكل عشوائي في النطاق المذكور أعلاه وسيتم تشغيل جميع الاختبارات المعينة لتلك البذرة المحددة. الهدف هو ضمان أن CI لدينا بمرور الوقت سيشغل جميع الاختبارات باستخدام بذور مختلفة مع الحفاظ على مدة اختبار تشغيل مجموعة الاختبار الكاملة المحدودة. سيتحقق هذا من أن تأكيدات الاختبارات المكتوبة لاستخدام هذه التركيبات لا تعتمد على قيمة بذرة محددة.

يقتصر نطاق قيم البذور المسموح بها على [0، 99] لأنه غالبًا ما يكون من غير الممكن كتابة اختبار يمكن أن يعمل لأي بذرة ممكنة ونريد تجنب وجود اختبارات تفشل عشوائيًا على CI.

قيم صالحة لـ `SKLEARN_TESTS_GLOBAL_RANDOM_SEED`:

- `SKLEARN_TESTS_GLOBAL_RANDOM_SEED="42"`: تشغيل الاختبارات مع بذرة ثابتة من 42
- `SKLEARN_TESTS_GLOBAL_RANDOM_SEED="40-42"`: تشغيل الاختبارات بجميع البذور بين 40 و 42 مدرجة
- `SKLEARN_TESTS_GLOBAL_RANDOM_SEED="all"`: تشغيل الاختبارات بجميع البذور بين 0 و 99 مدرجة. قد يستغرق هذا وقتًا طويلاً: استخدم فقط للاختبارات الفردية، وليس مجموعة الاختبار الكاملة!

إذا لم يتم تعيين المتغير، فسيتم استخدام 42 كبذرة عالمية بطريقة حتمية. يضمن هذا أنه، بشكل افتراضي، مجموعة اختبار scikit-learn تكون محددة قدر الإمكان لتجنب تعطيل صيانة حزم الجهات الخارجية الودودة لدينا. وبالمثل، لا ينبغي تعيين هذا المتغير في تكوين CI لطلبات السحب للتأكد من أن المساهمين الودودين ليسوا أول الأشخاص الذين يواجهون انحدار حساس للبذور في اختبار لا علاقة له بتغييرات PR الخاصة بهم. فقط محافظو scikit-learn الذين يشاهدون نتائج البنيات الليلية من المتوقع أن ينزعجوا من هذا.

عند كتابة دالة اختبار جديدة تستخدم هذه التركيبات، يرجى استخدام الأمر التالي للتأكد من أنها تمر بشكل حتمي لجميع البذور المسموح بها على جهازك المحلي:

.. prompt:: bash $

    SKLEARN_TESTS_GLOBAL_RANDOM_SEED="all" pytest -v -k test_your_test_name

`SKLEARN_SKIP_NETWORK_TESTS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى قيمة غير الصفر، يتم تخطي الاختبارات التي تحتاج إلى الوصول إلى الشبكة. عندما لا يتم تعيين متغير البيئة هذا، يتم تخطي اختبارات الشبكة.

`SKLEARN_RUN_FLOAT32_TESTS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى '1'، يتم أيضًا تشغيل الاختبارات باستخدام تركيبات `global_dtype` على بيانات float32.
عندما لا يتم تعيين متغير البيئة هذا، يتم تشغيل الاختبارات فقط على بيانات float64.

`SKLEARN_ENABLE_DEBUG_CYTHON_DIRECTIVES`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى قيمة غير الصفر، يتم تعيين `Cython` المشتقة، `boundscheck` إلى `True`. هذا مفيد لإيجاد segfaults.

`SKLEARN_BUILD_ENABLE_DEBUG_SYMBOLS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى قيمة غير الصفر، سيتم تضمين رموز التصحيح في امتدادات C المجمعة. يتم تكوين رموز تصحيح الأخطاء لنظام التشغيل POSIX فقط.

`SKLEARN_PAIRWISE_DIST_CHUNK_SIZE`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

يحدد هذا حجم الجزء الذي سيتم استخدامه بواسطة عمليات تطبيق `PairwiseDistancesReductions` الأساسية. القيمة الافتراضية هي `256` والتي تم إظهارها على أنها مناسبة على معظم الأجهزة.

قد يرغب المستخدمون الذين يبحثون عن أفضل أداء في ضبط هذا المتغير باستخدام قوى 2 للحصول على أفضل سلوك للتوازي لأجهزتهم، خاصة فيما يتعلق بحجم ذاكرة التخزين المؤقت الخاصة بهم.

`SKLEARN_WARNINGS_AS_ERRORS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

يتم استخدام متغير البيئة هذا لتحويل التحذيرات إلى أخطاء في الاختبارات وبناء الوثائق.

تعيّن بعض عمليات بناء CI (التكامل المستمر) `SKLEARN_WARNINGS_AS_ERRORS=1`، على سبيل المثال للتأكد من أننا نلتقط تحذيرات الإهمال من تبعياتنا وأننا نكيف رمزنا.

للتشغيل محليًا بنفس إعداد "التحذيرات كأخطاء" كما هو الحال في عمليات بناء CI هذه، يمكنك تعيين `SKLEARN_WARNINGS_AS_ERRORS=1`.

بشكل افتراضي، لا يتم تحويل التحذيرات إلى أخطاء. هذا هو الحال إذا كان `SKLEARN_WARNINGS_AS_ERRORS` غير محدد، أو `SKLEARN_WARNINGS_AS_ERRORS=0`.

يستخدم متغير البيئة هذا عوامل تصفية تحذير محددة لتجاهل بعض التحذيرات، نظرًا لأن التحذيرات تنشأ أحيانًا من مكتبات تابعة لجهات خارجية وليس هناك الكثير الذي يمكننا القيام به حيال ذلك. يمكنك رؤية عوامل تصفية التحذير في دالة `_get_warnings_filters_info_list` في `sklearn/utils/_testing.py`.

لاحظ أنه بالنسبة لبناء الوثائق، `SKLEARN_WARNING_AS_ERRORS=1` يتحقق من أن بناء الوثائق، ولا سيما تشغيل الأمثلة، لا ينتج أي تحذيرات. هذا يختلف عن وسيطة `-W` `sphinx-build` التي تلتقط تحذيرات بناء الجملة في ملفات rst.
