

.. rubric:: Related examples

.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we give an overview of TransformedTargetRegressor. We use two examples to illustrate the benefit of transforming the targets before learning a linear regression model. The first example uses synthetic data while the second example is based on the Ames housing data set.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_transformed_target_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_transformed_target.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Effect of transforming the targets in regression model</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_compose_plot_transformed_target.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The PCA does an unsupervised dimensionality reduction, while the logistic regression does the prediction.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_digits_pipe_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_digits_pipe.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Pipelining: chaining a PCA and a logistic regression</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_compose_plot_digits_pipe.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to visualize how well calibrated the predicted probabilities are using calibration curves, also known as reliability diagrams. Calibration of an uncalibrated classifier will also be demonstrated.">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_curve_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration_curve.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability Calibration curves</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_calibration_plot_calibration_curve.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&#x27;s score (see https://en.wikipedia.org/wiki/Brier_score).">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability calibration of classifiers</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_calibration_plot_calibration.py`

.. thumbnail-parent-div-close

.. raw:: html

    </div>

