

.. rubric:: Related examples

.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Here we fit a multinomial logistic regression with L1 penalty on a subset of the MNIST digits classification task. We use the SAGA algorithm for this purpose: this a solver that is fast when the number of samples is significantly larger than the number of features and is able to finely optimize non-smooth objective functions which is the case with the l1-penalty. Test accuracy reaches &gt; 0.8, while weight vectors remains sparse and therefore more easily interpretable.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_sparse_logistic_regression_mnist_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_sparse_logistic_regression_mnist.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">MNIST classification using multinomial logistic + L1</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_linear_model_plot_sparse_logistic_regression_mnist.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot the classification probability for different classifiers. We use a 3 class dataset, and we classify it with a Support Vector classifier, L1 and L2 penalized logistic regression (multinomial multiclass), a One-Vs-Rest version with logistic regression, and Gaussian process classification.">

.. only:: html

  .. image:: /auto_examples/classification/images/thumb/sphx_glr_plot_classification_probability_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_classification_plot_classification_probability.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot classification probability</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_classification_plot_classification_probability.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Plot decision surface of multinomial and One-vs-Rest Logistic Regression. The hyperplanes corresponding to the three One-vs-Rest (OVR) classifiers are represented by the dashed lines.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_logistic_multinomial_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_logistic_multinomial.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Plot multinomial and One-vs-Rest Logistic Regression</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_linear_model_plot_logistic_multinomial.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Comparison of the sparsity (percentage of zero coefficients) of solutions when L1, L2 and Elastic-Net penalty are used for different values of C. We can see that large values of C give more freedom to the model.  Conversely, smaller values of C constrain the model more. In the L1 penalty case, this leads to sparser solutions. As expected, the Elastic-Net penalty sparsity is between that of L1 and L2.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_logistic_l1_l2_sparsity_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_logistic_l1_l2_sparsity.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">L1 Penalty and Sparsity in Logistic Regression</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_linear_model_plot_logistic_l1_l2_sparsity.py`

.. thumbnail-parent-div-close

.. raw:: html

    </div>

