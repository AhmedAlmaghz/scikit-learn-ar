

.. rubric:: Related examples

.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A decision tree is boosted using the AdaBoost.R2 [1]_ algorithm on a 1D sinusoidal dataset with a small amount of Gaussian noise. 299 boosts (300 decision trees) is compared with a single decision tree regressor. As the number of boosts is increased the regressor can fit more detail.">

.. only:: html

  .. image:: /auto_examples/ensemble/images/thumb/sphx_glr_plot_adaboost_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decision Tree Regression with AdaBoost</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_regression.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A 1D regression with decision tree.">

.. only:: html

  .. image:: /auto_examples/tree/images/thumb/sphx_glr_plot_tree_regression_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_tree_plot_tree_regression.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Decision Tree Regression</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_tree_plot_tree_regression.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Ridge regression is basically minimizing a penalised version of the least-squared function. The penalising shrinks the value of the regression coefficients. Despite the few data points in each dimension, the slope of the prediction is much more stable and the variance in the line itself is greatly reduced, in comparison to that of the standard linear regression">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ols_ridge_variance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ols_ridge_variance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Ordinary Least Squares and Ridge Regression Variance</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_linear_model_plot_ols_ridge_variance.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Well calibrated classifiers are probabilistic classifiers for which the output of predict_proba can be directly interpreted as a confidence level. For instance, a well calibrated (binary) classifier should classify the samples such that for the samples to which it gave a predict_proba value close to 0.8, approximately 80% actually belong to the positive class.">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_compare_calibration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_compare_calibration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparison of Calibration of Classifiers</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_calibration_plot_compare_calibration.py`

.. thumbnail-parent-div-close

.. raw:: html

    </div>

