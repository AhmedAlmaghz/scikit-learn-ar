

.. rubric:: Related examples

.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example shows characteristics of different anomaly detection algorithms on 2D datasets. Datasets contain one or two modes (regions of high density) to illustrate the ability of algorithms to cope with multimodal data.">

.. only:: html

  .. image:: /auto_examples/miscellaneous/images/thumb/sphx_glr_plot_anomaly_comparison_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_miscellaneous_plot_anomaly_comparison.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Comparing anomaly detection algorithms for outlier detection on toy datasets</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_miscellaneous_plot_anomaly_comparison.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The Local Outlier Factor (LOF) algorithm is an unsupervised anomaly detection method which computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. This example shows how to use LOF for outlier detection which is the default use case of this estimator in scikit-learn. Note that when LOF is used for outlier detection it has no predict, decision_function and score_samples methods. See the User Guide &lt;outlier_detection&gt; for details on the difference between outlier detection and novelty detection and how to use LOF for novelty detection.">

.. only:: html

  .. image:: /auto_examples/neighbors/images/thumb/sphx_glr_plot_lof_outlier_detection_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neighbors_plot_lof_outlier_detection.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Outlier detection with Local Outlier Factor (LOF)</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_neighbors_plot_lof_outlier_detection.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example plots the covariance ellipsoids of each class and the decision boundary learned by LinearDiscriminantAnalysis (LDA) and QuadraticDiscriminantAnalysis (QDA). The ellipsoids display the double standard deviation for each class. With LDA, the standard deviation is the same for all the classes, while each class has its own standard deviation with QDA.">

.. only:: html

  .. image:: /auto_examples/classification/images/thumb/sphx_glr_plot_lda_qda_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_classification_plot_lda_qda.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Linear and Quadratic Discriminant Analysis with covariance ellipsoid</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_classification_plot_lda_qda.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The usual covariance maximum likelihood estimate is very sensitive to the presence of outliers in the data set. In such a case, it would be better to use a robust estimator of covariance to guarantee that the estimation is resistant to &quot;erroneous&quot; observations in the data set. [1]_, [2]_">

.. only:: html

  .. image:: /auto_examples/covariance/images/thumb/sphx_glr_plot_robust_vs_empirical_covariance_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_covariance_plot_robust_vs_empirical_covariance.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Robust vs Empirical covariance estimate</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_covariance_plot_robust_vs_empirical_covariance.py`

.. thumbnail-parent-div-close

.. raw:: html

    </div>

