

.. rubric:: Related examples

.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to visualize how well calibrated the predicted probabilities are using calibration curves, also known as reliability diagrams. Calibration of an uncalibrated classifier will also be demonstrated.">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_curve_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration_curve.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability Calibration curves</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_calibration_plot_calibration_curve.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="When performing classification you often want to predict not only the class label, but also the associated probability. This probability gives you some kind of confidence on the prediction. However, not all classifiers provide well-calibrated probabilities, some being over-confident while others being under-confident. Thus, a separate calibration of predicted probabilities is often desirable as a postprocessing. This example illustrates two different methods for this calibration and evaluates the quality of the returned probabilities using Brier&#x27;s score (see https://en.wikipedia.org/wiki/Brier_score).">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability calibration of classifiers</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_calibration_plot_calibration.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example illustrates how sigmoid calibration changes predicted probabilities for a 3-class classification problem. Illustrated is the standard 2-simplex, where the three corners correspond to the three classes. Arrows point from the probability vectors predicted by an uncalibrated classifier to the probability vectors predicted by the same classifier after sigmoid calibration on a hold-out validation set. Colors indicate the true class of an instance (red: class 1, green: class 2, blue: class 3).">

.. only:: html

  .. image:: /auto_examples/calibration/images/thumb/sphx_glr_plot_calibration_multiclass_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_calibration_plot_calibration_multiclass.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Probability Calibration for 3-class classification</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_calibration_plot_calibration_multiclass.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Clustering can be expensive, especially when our dataset contains millions of datapoints. Many clustering algorithms are not inductive and so cannot be directly applied to new data samples without recomputing the clustering, which may be intractable. Instead, we can use clustering to then learn an inductive model with a classifier, which has several benefits:">

.. only:: html

  .. image:: /auto_examples/cluster/images/thumb/sphx_glr_plot_inductive_clustering_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_cluster_plot_inductive_clustering.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Inductive Clustering</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_cluster_plot_inductive_clustering.py`

.. thumbnail-parent-div-close

.. raw:: html

    </div>

