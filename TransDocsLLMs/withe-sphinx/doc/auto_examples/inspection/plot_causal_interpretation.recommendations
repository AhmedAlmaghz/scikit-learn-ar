

.. rubric:: Related examples

.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In linear models, the target value is modeled as a linear combination of the features (see the linear_model User Guide section for a description of a set of linear models available in scikit-learn). Coefficients in multiple linear models represent the relationship between the given feature, X_i and the target, y, assuming that all the other features remain constant (conditional dependence). This is different from plotting X_i versus y and fitting a linear relationship: in that case all possible values of the other features are taken into account in the estimation (marginal dependence).">

.. only:: html

  .. image:: /auto_examples/inspection/images/thumb/sphx_glr_plot_linear_model_coefficient_interpretation_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_inspection_plot_linear_model_coefficient_interpretation.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Common pitfalls in the interpretation of coefficients of linear models</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_inspection_plot_linear_model_coefficient_interpretation.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we fit a linear model with positive constraints on the regression coefficients and compare the estimated coefficients to a classic linear regression.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_nnls_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Non-negative least squares</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_linear_model_plot_nnls.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="A model that overfits learns the training data too well, capturing both the underlying patterns and the noise in the data. However, when applied to unseen data, the learned associations may not hold. We normally detect this when we apply our trained predictions to the test data and see the statistical performance drop significantly compared to the training data.">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_ridge_coeffs_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_ridge_coeffs.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Ridge coefficients as a function of the L2 Regularization</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_linear_model_plot_ridge_coeffs.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The present example compares three l1-based regression models on a synthetic signal obtained from sparse and correlated features that are further corrupted with additive gaussian noise:">

.. only:: html

  .. image:: /auto_examples/linear_model/images/thumb/sphx_glr_plot_lasso_and_elasticnet_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_and_elasticnet.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">L1-based models for Sparse Signals</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_linear_model_plot_lasso_and_elasticnet.py`

.. thumbnail-parent-div-close

.. raw:: html

    </div>

