.. _calibration:

=======================
معايرة الاحتمالات
فيما يلي ترجمة للنص المحدد بتنسيق RST إلى اللغة العربية، مع اتباع التعليمات المذكورة:

=======================

عند إجراء التصنيف، غالبًا ما ترغب ليس فقط في التنبؤ بعلامة الفئة، ولكن أيضًا في الحصول على احتمال العلامة المقابلة. يمنحك هذا الاحتمال نوعًا من الثقة في التنبؤ. يمكن أن تعطيك بعض النماذج تقديرات سيئة لاحتمالات الفئات، بل إن بعضها لا يدعم التنبؤ بالاحتمالات (على سبيل المثال، بعض مثيلات ~ sklearn.linear_model.SGDClassifier). تسمح لك وحدة المعايرة بمعايرة أفضل لاحتمالات نموذج معين، أو إضافة دعم للتنبؤ بالاحتمالات.

التصنيف المعاير جيدًا هو مصنفات احتمالية يمكن تفسير إخراج طريقة term: 'predict_proba' الخاصة بها مباشرةً على أنه مستوى ثقة. على سبيل المثال، يجب أن يصنف المصنف المعاير جيدًا (الثنائي) العينات بحيث من بين العينات التي أعطاها قيمة term: 'predict_proba' قريبة من، لنقل، 0.8، ينتمي حوالي 80% منها بالفعل إلى الفئة الإيجابية.

قبل أن نوضح كيفية إعادة معايرة مصنف، نحتاج أولاً إلى طريقة للكشف عن مدى جودة معايرة المصنف.

.. note::
   تقيم قواعد التسجيل الصارمة للتنبؤات الاحتمالية مثل sklearn.metrics.brier_score_loss و sklearn.metrics.log_loss المعايرة (الموثوقية) والقوة التمييزية (الدقة) لنموذج، بالإضافة إلى عشوائية البيانات (عدم اليقين) في نفس الوقت. ينبع هذا من تفكيك درجة Brier الشهيرة لمرفي [1] _. نظرًا لأنه من غير الواضح أي مصطلح يسيطر، فإن النتيجة محدودة الفائدة لتقييم المعايرة بمفردها (ما لم يتم حساب كل مصطلح من التفكيك). لا يعني انخفاض الخسارة Brier، على سبيل المثال، بالضرورة نموذجًا معايرًا بشكل أفضل، فقد يعني أيضًا نموذجًا معايرًا بشكل أسوأ بقوة تمييزية أكبر، على سبيل المثال، باستخدام ميزات أكثر بكثير.

.. _calibration_curve:

منحنيات المعايرة
------------------

تقارن منحنيات المعايرة، والتي يشار إليها أيضًا باسم مخططات الموثوقية (ويلكس 1995 [2] _)، مدى جودة معايرة تنبؤات الاحتمالية لمصنف ثنائي. إنه يرسم تكرار العلامة الإيجابية (ليكون أكثر دقة، تقدير احتمال الحدث الشرطي :math: 'P (Y = 1 | text {predict_proba})') على y- المحور مقابل احتمال التنبؤ term: 'predict_proba' لنموذج على x- المحور. الجزء الحرج هو الحصول على قيم لمحور y.

في Scikit-learn، يتم تحقيق ذلك عن طريق تجميع التوقعات بحيث يمثل x- المحور متوسط الاحتمال المتوقع في كل دلو. ثم يكون y- المحور هو "نسبة الإيجابيات" بالنظر إلى تنبؤات هذا الدلو، أي نسبة العينات التي تنتمي فئتها إلى الفئة الإيجابية (في كل دلو).

تم إنشاء مخطط معايرة المعايرة العلوي بواسطة CalibrationDisplay.from_estimator، والذي يستخدم طريقة المعايرة لحساب متوسط الاحتمالات المتوقعة ونسبة الإيجابيات لكل دلو. يأخذ CalibrationDisplay.from_estimator كإدخال مصنفًا مناسبًا، والذي يتم استخدامه لحساب الاحتمالات المتوقعة. وبالتالي، يجب أن يكون للمصنف طريقة term: 'predict_proba'. بالنسبة للمصنفات القليلة التي لا تحتوي على طريقة term: 'predict_proba'، من الممكن استخدام CalibratedClassifierCV لمعايرة مخرجات المصنف إلى احتمالات.

يوفر مخطط الهستوجرام السفلي بعض الأفكار حول سلوك كل مصنف من خلال إظهار عدد العينات في كل دلو من الاحتمالات المتوقعة.

.. figure:: ../auto_examples/calibration/images/sphx_glr_plot_compare_calibration_001.png
   :target: ../auto_examples/calibration/plot_compare_calibration.html
   :align: center

.. currentmodule:: sklearn.linear_model

من المرجح أن تعيد LogisticRegression تنبؤات معايرة جيدة بمفردها نظرًا لوجود دالة ارتباط كانونية لفقدانها، أي رابط اللوغاريتم للخسارة اللوجستية. في حالة عدم وجود عقوبة، يؤدي هذا إلى ما يسمى **ميزة التوازن**، راجع [8] _ و Logistic_regression. في المخطط أعلاه، يتم إنشاء البيانات وفقًا لآلية خطية، والتي تتوافق مع نموذج LogisticRegression (النموذج "محدد جيدًا")، وتم ضبط قيمة معامل التنظيم 'C' ليكون مناسبًا (لا قويًا جدًا ولا منخفضًا جدًا). ونتيجة لذلك، يعيد هذا النموذج تنبؤات دقيقة من طريقة 'predict_proba' الخاصة به. على النقيض من ذلك، تعيد النماذج الأخرى المعروضة احتمالات متحيزة؛ مع تحيزات مختلفة لكل نموذج.

.. currentmodule:: sklearn.naive_bayes

يميل GaussianNB (Naive Bayes) إلى دفع الاحتمالات إلى 0 أو 1 (لاحظ العدادات في مخططات الهستوجرام). ويرجع ذلك أساسًا إلى افتراضه أن الميزات مستقلة شرطيًا بالنظر إلى الفئة، وهو ما لا يحدث في مجموعة البيانات هذه التي تحتوي على ميزتين متكررتين.

.. currentmodule:: sklearn.ensemble

يظهر RandomForestClassifier السلوك المعاكس: تظهر مخططات الهستوجرام قممًا عند احتمالات تبلغ حوالي 0.2 و0.9، في حين أن الاحتمالات القريبة من 0 أو 1 نادرة جدًا. يقدم Niculescu-Mizil and Caruana [3] _ تفسيرًا لذلك: "تواجه الطرق مثل bagging والغابات العشوائية التي تقوم بمعدل تنبؤات من مجموعة أساسية من النماذج صعوبة في إجراء تنبؤات بالقرب من 0 و1 لأن التباين في النماذج الأساسية سيؤدي إلى تحيز التنبؤات التي يجب أن تكون بالقرب من الصفر أو الواحد بعيدًا عن هذه القيم. نظرًا لأن التنبؤات مقيدة بالفاصل [0،1]، فإن الأخطاء التي يسببها التباين تميل إلى جانب واحد بالقرب من الصفر والواحد. على سبيل المثال، إذا كان من المفترض أن يتنبأ نموذج بقيمة p = 0 لحالة ما، فإن الطريقة الوحيدة التي يمكن أن يحقق بها bagging ذلك هي إذا تنبأت جميع الأشجار المعبأة بالصفر. إذا أضفنا ضوضاء إلى الأشجار التي نعبئها، فستتسبب هذه الضوضاء في قيام بعض الأشجار بالتنبؤ بقيم أكبر من 0 لهذه الحالة، مما يؤدي إلى تحريك متوسط تنبؤات المجموعة المعبأة بعيدًا عن الصفر. نلاحظ هذا التأثير بشكل أقوى مع الغابات العشوائية لأن أشجار المستوى الأساسي التي تم تدريبها باستخدام الغابات العشوائية بها تباين نسبيًا مرتفع بسبب مجموعة الميزات الفرعية. "ونتيجة لذلك، يظهر منحنى المعايرة شكلًا مميزًا للمنحنى S، مما يشير إلى أن المصنف يمكنه الوثوق بـ" حدسه "أكثر وإعادة احتمالات أقرب إلى 0 أو 1 بشكل نموذجي.

.. currentmodule:: sklearn.svm

يُظهر LinearSVC (SVC) منحنى أكثر انسيابية من الغابة العشوائية، وهو أمر شائع لأساليب الحد الأقصى للهامش (قارن Niculescu-Mizil and Caruana [3] _)، والتي تركز على العينات الصعبة التي يصعب تصنيفها بالقرب من حد القرار (المتجهات الداعمة).

معايرة مصنف
------------------------

.. currentmodule:: sklearn.calibration

تتكون معايرة مصنف من تناسب مُرجع (يُطلق عليه اسم "معاير") يقوم بميْز إخراج المصنف (كما هو محدد بواسطة وظيفة القرار أو طريقة term: 'predict_proba') إلى احتمال معاير في الفاصل [0،1]. مع الإشارة إلى إخراج المصنف لعينة معينة بواسطة :math: 'f_i'، يحاول المعاير التنبؤ باحتمال الحدث الشرطي :math: 'P (y_i = 1 | f_i)'.

في الوضع المثالي، يتم ضبط المعاير على مجموعة بيانات مستقلة عن بيانات التدريب المستخدمة لضبط المصنف في المقام الأول.

هذا لأن أداء المصنف على بيانات التدريب الخاصة به سيكون أفضل من البيانات الجديدة. سيؤدي استخدام إخراج المصنف لبيانات التدريب لمعايرة المعاير إلى معاير متحيز يقوم بميْز الاحتمالات إلى قيم أقرب إلى 0 و 1 مما ينبغي.

الاستخدام
تستخدم فئة :class:`CalibratedClassifierCV` لمعايرة مصنف.

يستخدم :class:`CalibratedClassifierCV` نهج التقسيم إلى مجموعات متصالبة لضمان استخدام بيانات غير متحيزة دائمًا لضبط المعاير. يتم تقسيم البيانات إلى k من الأزواج `(مجموعة_التدريب، مجموعة_الاختبار)` (كما يحددها `cv`). عندما `ensemble=True` (افتراضي)، يتم تكرار الإجراء التالي بشكل مستقل لكل تقسيم متقاطع للتحقق:

1. يتم تدريب نسخة من `base_estimator` على مجموعة التدريب الفرعية
2. يقوم `base_estimator` المدرب بعمل تنبؤات على مجموعة الاختبار الفرعية
3. يتم استخدام التنبؤات لضبط المعاير (إما من خلال الانحدار اللوغاريتمي أو الانحدار المتساوي) (عندما تكون البيانات متعددة التصنيفات، يتم ضبط معاير لكل صنف)

ويؤدي ذلك إلى مجموعة من k من أزواج `(المصنف، المعاير)` حيث يقوم كل معاير برسم ناتج مصنفه المقابل إلى [0،1]. يتم عرض كل زوج في خاصية `calibrated_classifiers_`، حيث يكون كل إدخال مصنفًا مضبوطًا بمعاير به طريقة :term:`predict_proba` التي تخرج احتمالات مضبوطة. ويكون ناتج :term:`predict_proba` للفئة الرئيسية :class:`CalibratedClassifierCV` هو متوسط الاحتمالات المتوقعة للمصنفات `k` في قائمة `calibrated_classifiers_`. ويكون ناتج :term:`predict` هو الفئة ذات أعلى احتمال.

من المهم اختيار `cv` بعناية عند استخدام `ensemble=True`. يجب أن تكون جميع الفئات موجودة في كل من مجموعات التدريب والاختبار لكل تقسيم. عندما تكون فئة ما غائبة في مجموعة التدريب الفرعية، فإن الاحتمال المتوقع لتلك الفئة سيكون افتراضيًا 0 بالنسبة لزوج `(المصنف، المعاير)` لذلك التقسيم. وهذا يشوه :term:`predict_proba` لأنه يحسب المتوسط عبر جميع الأزواج. عندما تكون فئة ما غائبة في مجموعة الاختبار الفرعية، يتم ضبط المعاير لتلك الفئة (ضمن زوج `(المصنف، المعاير)` لذلك التقسيم) على بيانات بدون فئة إيجابية. يؤدي هذا إلى معايرة غير فعالة.

عندما `ensemble=False`، يتم استخدام التقسيم إلى مجموعات متصالبة للحصول على تنبؤات 'غير متحيزة' لجميع البيانات، عبر :func:`~sklearn.model_selection.cross_val_predict`. يتم بعد ذلك استخدام هذه التنبؤات غير المتحيزة لتدريب المعاير. تتكون خاصية `calibrated_classifiers_` من زوج واحد فقط من `(المصنف، المعاير)` حيث يكون المصنف هو `base_estimator` المدرب على جميع البيانات. في هذه الحالة، يكون ناتج :term:`predict_proba` للفئة :class:`CalibratedClassifierCV` هو الاحتمالات المتوقعة التي تم الحصول عليها من زوج `(المصنف، المعاير)` الوحيد.

الميزة الرئيسية لـ `ensemble=True` هي الاستفادة من تأثير التجميع التقليدي (مشابه لـ :ref:`bagging`). يجب أن يكون التجميع الناتج مضبوطًا جيدًا وأكثر دقة قليلًا من `ensemble=False`. الميزة الرئيسية لاستخدام `ensemble=False` هي حسابية: فهي تقلل وقت الضبط الإجمالي عن طريق تدريب زوج مصنف ومعاير واحد فقط، وتقلل حجم النموذج النهائي وتزيد من سرعة التنبؤ.

بدلاً من ذلك، يمكن معايرة مصنف مدرب بالفعل عن طريق ضبط `cv="prefit"`. في هذه الحالة، لا يتم تقسيم البيانات ويتم استخدامها كلها لضبط المعاير. يتولى المستخدم مسؤولية التأكد من أن البيانات المستخدمة لضبط المعاير مختلفة عن البيانات المستخدمة لضبط المصنف.

تدعم فئة :class:`CalibratedClassifierCV` استخدام تقنيتين للانحدار للمعايرة عبر معامل `method`: `"sigmoid"` و `"isotonic"`.

.. _sigmoid_regressor:

انحدار لوجستي
^^^^^^^^^^^^^^^

يستند الانحدار اللوجستي، `method="sigmoid"`، إلى نموذج لوجستي لبلات [4]_:

.. math::
       p(y_i = 1 | f_i) = \frac{1}{1 + \exp(A f_i + B)} \,,

حيث :math:`y_i` هو التصنيف الحقيقي للعينة :math:`i` و :math:`f_i`
هو ناتج المصنف غير المضبوط للعينة :math:`i`. :math:`A`
و :math:`B` هما عددان حقيقيان يتم تحديدهما عند ضبط المعاير عبر الاحتمال الأقصى.

يفترض أسلوب الانحدار اللوجستي أن :ref:`منحنى المعايرة <calibration_curve>`
يمكن تصحيحه عن طريق تطبيق دالة لوجستية على التنبؤات الخام. تم تبرير هذا الافتراض تجريبيًا في حالة :ref:`svm` مع دالات نواة شائعة على مجموعات بيانات مرجعية مختلفة في القسم 2.1 من Platt 1999 [4]_ ولكنه لا ينطبق بالضرورة بشكل عام. بالإضافة إلى ذلك، يعمل النموذج اللوجستي بشكل أفضل إذا كان خطأ المعايرة متماثلًا، مما يعني
أن ناتج المصنف لكل فئة ثنائية يكون موزعة توزيعاً طبيعياً بنفس الانحراف المعياري [7]_. يمكن أن يمثل ذلك مشكلة لمشكلات التصنيف غير المتوازنة للغاية، حيث لا يكون للنواتج انحرافات معيارية متساوية.

بشكل عام، تكون هذه الطريقة أكثر فعالية لحجم العينات الصغيرة أو عندما يكون النموذج غير المضبوط أقل ثقة وله أخطاء معايرة مماثلة لكل من النواتج العالية والمنخفضة.

انحدار متساو
^^^^^^^^^^^^

يقوم `method="isotonic"` بضبط معاير غير معلمي متساوي، والذي ينتج
دالة متزايدة خطوة بخطوة، راجع :mod:`sklearn.isotonic`. فهو يقلل:

.. math::
       \sum_{i=1}^{n} (y_i - \hat{f}_i)^2

رهناً بـ :math:`\hat{f}_i \geq \hat{f}_j` عندما
:math:`f_i \geq f_j`. :math:`y_i` هو التصنيف
الحقيقي للعينة :math:`i` و :math:`\hat{f}_i` هو ناتج
المصنف المضبوط للعينة :math:`i` (أي الاحتمال المضبوط). هذه الطريقة أكثر عمومية مقارنة بـ 'sigmoid' حيث أن التقييد الوحيد هو أن دالة الخريطة متزايدة بشكل أحادي. وبالتالي، فهي أكثر قوة حيث يمكنها تصحيح أي تشويه أحادي الاتجاه للنموذج غير المضبوط. ومع ذلك، فهي أكثر عرضة للإفراط في الضبط، خاصة على مجموعات البيانات الصغيرة [6]_.

بشكل عام، سيؤدي "isotonic" إلى أداء أفضل أو مماثل لـ "sigmoid" عندما تكون هناك بيانات كافية (أكبر من ~ 1000 عينة) لتجنب الإفراط في الضبط [3]_.

.. note:: التأثير على مقاييس الترتيب مثل AUC

    من المتوقع بشكل عام أن لا تؤثر المعايرة على مقاييس الترتيب مثل ROC-AUC. ومع ذلك، قد تختلف هذه المقاييس بعد المعايرة عند استخدام
    `method="isotonic"` لأن الانحدار المتساوي يقدم تعادلات في الاحتمالات المتوقعة. يمكن اعتبار ذلك ضمن عدم اليقين في تنبؤات النموذج. في هذه الحالة، إذا كنت تريد الحفاظ على الترتيب وبالتالي درجات AUC، استخدم
    `method="sigmoid"` الذي يعد تحويلًا أحادي الاتجاه بشكل صارم ويحافظ على الترتيب.

دعم التصنيف متعدد الفئات
^^^^^^^^^^^^^^^^^^^^^^^^^^

يدعم كل من الانحدار المتساوي والانحدار اللوجستي بيانات أحادية البعد فقط (على سبيل المثال، إخراج التصنيف الثنائي) ولكنهما ممتدان للتصنيف متعدد الفئات إذا كان `base_estimator` يدعم تنبؤات متعددة الفئات. بالنسبة للتنبؤات متعددة الفئات،
يقوم :class:`CalibratedClassifierCV` بالمعايرة لكل فئة بشكل منفصل بطريقة :ref:`ovr_classification` [5]_. عند
التنبؤ
بالاحتمالات، يتم التنبؤ بالاحتمالات المضبوطة لكل فئة
بشكل منفصل. نظرًا لأن هذه الاحتمالات لا تصل بالضرورة إلى واحد، يتم إجراء معالجة لاحقة لتطبيعها.

.. rubric:: أمثلة

* :ref:`sphx_glr_auto_examples_calibration_plot_calibration_curve.py`
* :ref:`sphx_glr_auto_examples_calibration_plot_calibration_multiclass.py`
* :ref:`sphminx_glr_auto_examples_calibration_plot_calibration.py`
* :ref:`sphx_glr_auto_examples_calibration_plot_compare_calibration.py`

.. rubric:: مراجع

.. [1] Allan H. Murphy (1973).
       :doi:`"A New Vector Partition of the Probability Score"
       <10.1175/1520-0450(1973)012%3C0595:ANVPOT%3E2.0.CO;2>`
       Journal of Applied Meteorology and Climatology

.. [2] `On the combination of forecast probabilities for
       consecutive precipitation periods.
       <https://journals.ametsoc.org/waf/article/5/4/640/40179>`_
       Wea. Forecasting, 5, 640–650., Wilks, D. S., 1990a

.. [3] `Predicting Good Probabilities with Supervised Learning
       <https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf>`_,
       A. Niculescu-Mizil & R. Caruana, ICML 2005

.. [4] `Probabilistic Outputs for Support Vector Machines and Comparisons
       to Regularized Likelihood Methods.
       <https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf>`_
       J. Platt, (1999)

.. [5] `Transforming Classifier Scores into Accurate Multiclass
       Probability Estimates.
       <https://dl.acm.org/doi/pdf/10.1145/775047.775151>`_
       B. Zadrozny & C. Elkan, (KDD 2002)

.. [6] `Predicting accurate probabilities with a ranking loss.
       <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4180410/>`_
       Menon AK, Jiang XJ, Vembu S, Elkan C, Ohno-Machado L.
       Proc Int Conf Mach Learn. 2012;2012:703-710

.. [7] `Beyond sigmoids: How to obtain well-calibrated probabilities from
       binary classifiers with beta calibration
       <https://projecteuclid.org/euclid.ejs/1513306867>`_
       Kull, M., Silva Filho, T. M., & Flach, P. (2017).

.. [8] Mario V. Wüthrich, Michael Merz (2023).
       :doi:`"Statistical Foundations of Actuarial Learning and its Applications"
       <10.1007/978-3-031-12409-9>`
       Springer Actuarial