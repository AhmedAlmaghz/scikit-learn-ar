مخططات الاعتماد الجزئي وتوقع الشرط الفردي
===============================================================

يمكن استخدام مخططات الاعتماد الجزئي (PDP) وتوقع الشرط الفردي (ICE) لتصور وتحليل التفاعل بين استجابة الهدف [1] _ ومجموعة من ميزات الإدخال ذات الاهتمام.

يفترض كل من PDPs [H2009] _ و ICEs [G2015] _ أن ميزات الإدخال ذات الاهتمام مستقلة عن الميزات المكملة، و غالبًا ما يتم انتهاك هذا الافتراض في الممارسة العملية. وبالتالي، في حالة الميزات المترابطة، سنقوم بإنشاء نقاط بيانات سخيفة لحساب PDP / ICE [M2019] _.

مخططات الاعتماد الجزئي
========================

توضح مخططات الاعتماد الجزئي (PDP) الاعتماد بين استجابة الهدف ومجموعة من ميزات الإدخال ذات الاهتمام، مع تجاهل قيم جميع ميزات الإدخال الأخرى (ميزات "التكملة"). يمكننا بداهة تفسير الاعتماد الجزئي على أنه استجابة الهدف المتوقعة كدالة لميزات الإدخال ذات الاهتمام.

بسبب حدود الإدراك البشري، يجب أن يكون حجم مجموعة ميزات الإدخال ذات الاهتمام صغيرًا (عادةً ما يكون واحدًا أو اثنين) وبالتالي يتم عادةً اختيار ميزات الإدخال ذات الاهتمام من بين أهم الميزات.

يوضح الشكل أدناه مخططين أحاديين الاتجاه ومخططًا ثنائي الاتجاه للاعتماد الجزئي لمجموعة بيانات مشاركة الدراجات، باستخدام
: class: ~ sklearn.ensemble.HistGradientBoostingRegressor:

.. figure:: ../auto_examples/inspection/images/sphx_glr_plot_partial_dependence_006.png
   : target: ../auto_examples/inspection/plot_partial_dependence.html
   : align: center
   : scale: 70

تخبرنا PDPs أحادية الاتجاه بالتفاعل بين استجابة الهدف وميزة إدخال ذات اهتمام (على سبيل المثال، خطي، غير خطي). يوضح المخطط الأيسر في الشكل أعلاه تأثير درجة الحرارة على عدد استئجار الدراجات؛ يمكننا أن نرى بوضوح أن ارتفاع درجة الحرارة يرتبط بارتفاع عدد استئجار الدراجات. وبالمثل، يمكننا تحليل تأثير الرطوبة على عدد استئجار الدراجات (المخطط الأوسط).

وهكذا، تكون هذه التفسيرات هامشية، مع الأخذ في الاعتبار ميزة في كل مرة.

توضح PDPs بميزتي إدخال الاهتمام التفاعلات بين الميزتين. على سبيل المثال، يوضح مخطط PDP ثنائي المتغيرات في الشكل أعلاه اعتماد عدد استئجار الدراجات على القيم المشتركة لدرجة الحرارة والرطوبة. يمكننا أن نرى بوضوح تفاعلًا بين الميزتين: عند درجة حرارة أعلى من 20 درجة مئوية، يكون للرطوبة بشكل أساسي تأثير قوي على عدد استئجار الدراجات. بالنسبة لدرجات الحرارة المنخفضة، لكل من درجة الحرارة والرطوبة تأثير على عدد استئجار الدراجات.

توفر الوحدة النمطية sklearn.inspection دالة ملائمة
: func: ~ PartialDependenceDisplay.from_estimator لإنشاء مخططات اعتماد جزئي أحادية الاتجاه وثنائية الاتجاه. في المثال أدناه، نوضح كيفية إنشاء شبكة من
مخططات الاعتماد الجزئي: مخططان أحاديان الاتجاه لميزتي "0" و "1" ومخطط ثنائي الاتجاه بين الميزتين::

    >>> from sklearn.datasets import make_hastie_10_2
    >>> from sklearn.ensemble import GradientBoostingClassifier
    >>> from sklearn.inspection import PartialDependenceDisplay

    >>> X، y = make_hastie_10_2 (random_state=0)
    >>> clf = GradientBoostingClassifier (n_estimators=100، learning_rate=1.0،
    ...     max_depth=1، random_state=0).fit (X، y)
    >>> الميزات = [0، 1، (0، 1)]
    >>> PartialDependenceDisplay.from_estimator (clf، X، الميزات)
    <...>

يمكنك الوصول إلى كائنات Figure و Axes التي تم إنشاؤها حديثًا باستخدام "plt.gcf()"
و "plt.gca()".

لإنشاء مخطط اعتماد جزئي بميزات فئوية، يجب تحديد الميزات الفئوية باستخدام
المعلمة 'categorical_features'. يأخذ هذا المعلمة قائمة من المؤشرات، أو أسماء الميزات الفئوية، أو قناع منطقي. التمثيل الرسومي للاعتماد الجزئي للميزات الفئوية هو
مخطط شريطي أو خريطة حرارية ثنائية الأبعاد.

.. dropdown:: PDPs للتصنيف متعدد الفئات

بالنسبة للتصنيف متعدد الفئات، يجب تعيين تسمية الفئة التي يجب إنشاء PDPs لها عبر
حجة "الهدف"::

    >>> from sklearn.datasets import load_iris
    >>> iris = load_iris()
    >>> mc_clf = GradientBoostingClassifier (n_estimators=10،
    ...     max_depth=1).fit (iris.data، iris.target)
    >>> الميزات = [3، 2، (3، 2)]
    >>> PartialDependenceDisplay.from_estimator (mc_clf، X، الميزات، الهدف=0)
    <...>

يتم استخدام نفس المعلمة "الهدف" لتحديد الهدف في إعدادات الانحدار متعدد الإخراج.

إذا كنت بحاجة إلى القيم الخام لدالة الاعتماد الجزئي بدلاً من
المخططات، يمكنك استخدام الدالة
: func: 'sklearn.inspection.partial_dependence`::

    >>> from sklearn.inspection import partial_dependence

    >>> النتائج = partial_dependence (clf، X، [0])
    >>> النتائج ["متوسط"]
    array ([[2.466 ...، 2.466 ...، ...
    >>> النتائج ["grid_values"]
    [array ([-1.624 ...، -1.592 ...، ...

تتم مباشرةً توليد القيم التي يجب تقييم الاعتماد الجزئي عندها من "X". بالنسبة للاعتماد الجزئي ثنائي الاتجاه، يتم إنشاء شبكة ثنائية الأبعاد من القيم. يعيد الحقل "القيم" الذي تم إرجاعه بواسطة
: func: 'sklearn.inspection.partial_dependence` القيم الفعلية
يتم استخدامها في الشبكة لكل ميزة إدخال ذات أهمية. كما أنها تتوافق مع
محور المخططات.

.. _individual_conditional:

مخطط توقع الشرط الفردي (ICE)
=============================================

على غرار PDP، يوضح مخطط توقع الشرط الفردي (ICE) الاعتماد بين دالة الهدف وميزة إدخال ذات أهمية. ومع ذلك، على عكس PDP، الذي يوضح التأثير المتوسط ​​لميزة الإدخال، يقوم مخطط ICE بتصور اعتماد التنبؤ على ميزة لكل عينة بشكل منفصل مع خط واحد لكل عينة.
بسبب حدود الإدراك البشري، يتم دعم ميزة إدخال اهتمام واحدة فقط لمخططات ICE.

توضح الأشكال أدناه مخططين ICE لمجموعة بيانات مشاركة الدراجات،
مع : class: ~ sklearn.ensemble.HistGradientBoostingRegressor:.
ترسم الأشكال خط PD المقابل فوق خطوط ICE.

.. figure:: ../auto_examples/inspection/images/sphx_glr_plot_partial_dependence_004.png
   : target: ../auto_examples/inspection/plot_partial_dependence.html
   : align: center
   : scale: 70

في حين أن مخططات PDP جيدة في إظهار التأثير المتوسط ​​لميزات الهدف، إلا أنها يمكن أن تحجب علاقة غير متجانسة ناتجة عن التفاعلات.
عندما تكون التفاعلات موجودة، سيوفر مخطط ICE العديد من الأفكار.
على سبيل المثال، نرى أن ICE لميزة درجة الحرارة يعطينا بعض
معلومات إضافية: بعض خطوط ICE مسطحة في حين أن البعض الآخر
يظهر انخفاض الاعتماد لدرجة حرارة أعلى من 35 درجة مئوية.
نلاحظ نمطًا مشابهًا لميزة الرطوبة: يظهر بعض خطوط ICE انخفاضًا حادًا عندما تكون الرطوبة أعلى من 80%.

يمكن استخدام دالة الراحة في الوحدة النمطية sklearn.inspection's :meth: 'PartialDependenceDisplay.from_estimator`
لإنشاء مخططات ICE عن طريق تعيين "kind='individual'". في المثال أدناه، نوضح كيفية إنشاء شبكة من
مخططات ICE:

    >>> from sklearn.datasets import make_hastie_10_2
    >>> from sklearn.ensemble import GradientBoostingClassifier
    >>> from sklearn.inspection import PartialDependenceDisplay

    >>> X، y = make_hastie_10_2 (random_state=0)
    >>> clf = GradientBoostingClassifier (n_estimators=100، learning_rate=1.0،
    ...     max_depth=1، random_state=0).fit (X، y)
    >>> الميزات = [0، 1]
    >>> PartialDependenceDisplay.from_estimator (clf، X، الميزات،
    ...     kind='individual')
    <...>

في مخططات ICE، قد لا يكون من السهل رؤية التأثير المتوسط ​​لميزة الإدخال ذات الاهتمام. لذلك، يوصى باستخدام مخططات ICE جنبًا إلى جنب مع PDPs. يمكن رسمها معًا مع
"kind='both'".

    >>> PartialDependenceDisplay.from_estimator (clf، X، الميزات،
    ...     kind='both')
    <...>

إذا كان هناك الكثير من الخطوط في مخطط ICE، فقد يكون من الصعب رؤية
الاختلافات بين العينات الفردية وفهم النموذج. إن تركيز ICE على القيمة الأولى على المحور x
ينتج مخططات توقع شرطية فردية مركزة (cICE) [G2015] _. وهذا يسلط الضوء على تباعد
التوقعات الشرطية الفردية من خط الوسط، مما يجعل من السهل
استكشاف العلاقات غير المتجانسة. يمكن رسم مخططات cICE عن طريق تعيين "centered=True":

    >>> PartialDependenceDisplay.from_estimator (clf، X، الميزات،
    ...     kind='both'، centered=True)
    <...>

التعريف الرياضي
=======================

دع :math: 'X_S` تكون مجموعة ميزات الإدخال ذات الاهتمام (أي معلمة "الميزات") ودع :math: 'X_C` تكون المكملة لها.

يتم تعريف الاعتماد الجزئي للاستجابة :math: 'f` في نقطة :math: 'x_S`
كما يلي:

.. math::

    pd_ {X_S} (x_S) & \ overset {def} {=} \ mathbb {E} _ {X_C} \ left [f (x_S، X_C) \ right] \\
                  &= \ int f (x_S، x_C) p (x_C) dx_C،

حيث :math: 'f (x_S، x_C)` هي دالة الاستجابة (: term: 'predict`،
: term: 'predict_proba` أو : term: 'decision_function`) لعينة معينة يتم تعريف قيمها بواسطة :math: 'x_S` للميزات في :math: 'X_S`، وبـ :math: 'x_C` للميزات في :math: 'X_C `. لاحظ أن :math: 'x_S` و
:math: 'x_C` قد تكون توابل.

يحسب هذا التكامل لقيم مختلفة من :math: 'x_S` ينتج مخطط PDP كما هو موضح أعلاه. يتم تعريف خط ICE على أنه :math: 'f (x_ {S}، x_ {C} ^ { (i)})`
تقييم في :math: 'x_ {S}`.

طرق الحساب
هناك طريقتان رئيسيتان لتقريب التكامل الموضح أعلاه، وهما طريقة "الكلية" (brute) وطريقة "الاستدعاء الذاتي" (recursion). يتحكم معامل "الطريقة" (method) في تحديد الطريقة التي سيتم استخدامها.

طريقة "الكلية" هي طريقة عامة تعمل مع أي خوارزمية تقدير. تجدر الإشارة إلى أن حساب مخططات التأثير المشروط الفردي (ICE plots) مدعوم فقط باستخدام طريقة "الكلية". تقوم هذه الطريقة بتقريب التكامل أعلاه من خلال حساب المتوسط على بيانات "X":

.. math::

    pd_{X_S}(x_S) \approx \frac{1}{n_\text{samples}} \sum_{i=1}^n f(x_S, x_C^{(i)}),

حيث :math:`x_C^{(i)}` هي قيمة العينة i-th للسمات في :math:`X_C`. بالنسبة لكل قيمة من :math:`x_S`، تتطلب هذه الطريقة المرور عبر مجموعة البيانات الكاملة "X" والتي تعد عملية مكثفة حسابياً.

كل دالة من دوال :math:`f(x_{S}, x_{C}^{(i)})` تقابل خط ICE مقيم عند :math:`x_{S}`. وعند حساب هذه الدالة لقيم متعددة من :math:`x_{S}`، نحصل على خط ICE كامل. كما هو واضح، متوسط خطوط ICE يقابل خط الاعتماد الجزئي.

أما طريقة "الاستدعاء الذاتي" فهي أسرع من طريقة "الكلية"، ولكنها مدعومة فقط لمخططات PDP من قبل بعض خوارزميات التقدير القائمة على الشجرة. يتم حسابها على النحو التالي. بالنسبة لنقطة معينة :math:`x_S`، يتم إجراء مسح شجري مرجح: إذا كانت عقدة الانقسام تتضمن سمة دخل مثيرة للاهتمام، يتم اتباع الفرع الأيسر أو الأيمن المقابل؛ وإلا يتم اتباع كلا الفرعين، مع إعطاء كل فرع وزنًا يعتمد على نسبة عينات التدريب التي دخلت ذلك الفرع. وأخيرًا، يتم حساب الاعتماد الجزئي كمتوسط مرجح لجميع قيم الأوراق التي تمت زيارتها.

في طريقة "الكلية"، يتم استخدام معامل "X" لتوليد شبكة قيم :math:`x_S` وقيم السمات المكملة :math:`x_C`. ومع ذلك، في طريقة "الاستدعاء الذاتي"، يتم استخدام "X" فقط لقيم الشبكة: ضمنيًا، تكون قيم :math:`x_C` هي قيم بيانات التدريب.

وبشكل افتراضي، يتم استخدام طريقة "الاستدعاء الذاتي" لرسم مخططات PDP على خوارزميات التقدير القائمة على الشجرة التي تدعمها، بينما يتم استخدام طريقة "الكلية" لبقية الحالات.

.. _pdp_method_differences:

.. note::

    على الرغم من أن الطريقتين يجب أن تكونا متشابهتين بشكل عام، إلا أنهما قد تختلفان في بعض الإعدادات المحددة. تفترض طريقة "الكلية" وجود نقاط البيانات :math:`(x_S، x_C^{(i)})`. عندما تكون السمات مترابطة، قد يكون لهذه العينات الافتراضية كتلة احتمال منخفضة جدًا. ومن المحتمل أن تختلف طريقتا "الكلية" و"الاستدعاء الذاتي" فيما يتعلق بقيمة الاعتماد الجزئي، لأنهما ستتعاملان مع هذه العينات غير المحتملة بشكل مختلف. ومع ذلك، تذكر أن الافتراض الأساسي لتفسير مخططات PDP هو أن السمات يجب أن تكون مستقلة.


.. rubric:: الأمثلة

* :ref:`sphx_glr_auto_examples_inspection_plot_partial_dependence.py`

.. rubric:: الحواشي السفلية

.. [1] بالنسبة للتصنيف، قد يكون الاستجابة المستهدفة هي احتمال فئة (الفئة الإيجابية للتصنيف الثنائي)، أو دالة القرار.

.. rubric:: المراجع

.. [H2009] T. Hastie, R. Tibshirani and J. Friedman,
    'The Elements of Statistical Learning
    <https://web.stanford.edu/~hastie/ElemStatLearn//>_'
    ، الطبعة الثانية، القسم 10.13.2، سبرينغر، 2009.

.. [M2019] C. Molnar،
    'Interpretable Machine Learning
    <https://christophm.github.io/interpretable-ml-book/>`_
    ، القسم 5.1، 2019.

.. [G2015] :arxiv:`A. Goldstein, A. Kapelner, J. Bleich, and E. Pitkin,
    "Peeking Inside the Black Box: Visualizing Statistical
    Learning With Plots of Individual Conditional Expectation"،
    Journal of Computational and Graphical Statistics،
    24(1): 44-65, Springer, 2015. <1309.6392>`