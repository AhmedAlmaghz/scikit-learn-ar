ضبط المعلمات فائقة المعلمات التي لا يتم تعلمها مباشرة داخل المعلمات.
في scikit-learn يتم تمريرها كحجج إلى منشئ فئات المعلمات. تشمل الأمثلة النموذجية "C" و "kernel" و "gamma"
لتصنيف الدعم الموجه، "alpha" لLasso، وما إلى ذلك.

من الممكن والموصى به البحث في مساحة المعلمة فائقة للحصول على أفضل نتيجة
نتيجة التحقق من صحة متقاطعة.

يمكن تحسين أي معلمة مقدمة أثناء إنشاء معلمة بهذه الطريقة. على وجه التحديد، للعثور على أسماء والقيم الحالية لجميع
المعلمات لمعلمة معينة، استخدم:

معلمة (معلمة. get_params ())

يتكون البحث مما يلي:

- معلمة (مرجع أو مصنف مثل "sklearn.svm.SVC ()")؛
- مساحة المعلمات؛
- طريقة للبحث أو أخذ عينات المرشحين؛
- مخطط التحقق من الصحة المتقاطع؛ و
- دالة النتيجة: ref:` <gridsearch_scoring>`.

يوفر scikit-learn نهجين عامين للبحث عن المعلمات: بالنسبة للقيم المعطاة، ينظر GridSearchCV بشكل شامل
جميع مجموعات المعلمات، في حين أن RandomizedSearchCV يمكن أن تعين عينة
عدد معين من المرشحين من مساحة المعلمات مع توزيع محدد. كلا من هذه الأدوات لها نظائرها النصفية المتعاقبة
HalvingGridSearchCV و HalvingRandomSearchCV، والتي يمكن أن تكون
أسرع بكثير في العثور على مجموعة جيدة من المعلمات.

بعد وصف هذه الأدوات، نقدم تفاصيل حول أفضل الممارسات
ممارسات <grid_search_tips> المطبقة على هذه الأساليب. تسمح بعض النماذج باستراتيجيات بحث متخصصة وفعالة عن المعلمات،
مخطط لها في التحقق من صحة بديل.

لاحظ أنه من الشائع أن تؤثر مجموعة فرعية صغيرة من تلك المعلمات بشكل كبير على أداء التنبؤ أو الحساب للنموذج في حين يمكن ترك الآخرين
قيمها الافتراضية. يُنصح بقراءة docstring لفئة المعلمة للحصول على فهم أدق لسلوكها المتوقع،
ربما عن طريق قراءة المرجع المضمن إلى الأدبيات.

البحث الشامل عن الشبكة
======================

تولد شبكة البحث التي يوفرها GridSearchCV بشكل شامل المرشحين من شبكة من قيم المعلمات المحددة باستخدام
معلمة "param_grid". على سبيل المثال، فإن "param_grid" التالية::

  param_grid = [
    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},
   ]

تحدد أنه يجب استكشاف شبكتين: واحدة ذات نواة خطية
وقيم "C" في [1، 10، 100، 1000]، والثانية ذات نواة RBF،
والجدول الضمني لقيم "C" التي تتراوح في [1، 10، 100، 1000] وقيم "gamma" في [0.001، 0.0001].

يحتوي مثيل GridSearchCV على واجهة برمجة التطبيقات المعتادة للمعلمات: عند
"تناسبها" على مجموعة بيانات يتم تقييم جميع مجموعات قيم المعلمات والاحتفاظ بأفضل مجموعة.

.. _randomized_parameter_search:

تحسين المعلمة العشوائي
=====================
في حين أن استخدام شبكة من إعدادات المعلمات هو حاليًا الطريقة الأكثر استخدامًا على نطاق واسع
لتحسين المعلمات، فإن طرق البحث الأخرى لها خصائص أكثر ملاءمة.
ينفذ RandomizedSearchCV بحثًا عشوائيًا عبر المعلمات، حيث يتم أخذ كل إعداد كعينة من
توزيع على قيم المعلمات المحتملة. يوفر هذا فوائد رئيسية على البحث الشامل:

* يمكن اختيار ميزانية مستقلة عن عدد المعلمات والقيم المحتملة.
* إضافة معلمات لا تؤثر على الأداء لا تقلل من الكفاءة.

يتم تحديد كيفية أخذ عينات المعلمات باستخدام قاموس، مشابه جدًا لتحديد المعلمات لـ
GridSearchCV. بالإضافة إلى ذلك، يتم تحديد ميزانية الحساب، والتي تكون عدد المرشحين المعينين أو
تكرار العينات، باستخدام معلمة "n_iter".
بالنسبة لكل معلمة، يمكن تحديد توزيع على القيم الممكنة أو قائمة
الخيارات المنفصلة (التي سيتم أخذ عينات منها بالتساوي)::

  {'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1),
    'kernel': ['rbf'], 'class_weight':['balanced', None]}

يستخدم هذا المثال وحدة "scipy.stats"، والتي تحتوي على العديد من التوزيعات المفيدة
لأخذ عينات المعلمات، مثل "expon"، و "gamma"، و "uniform"، و "loguniform"، أو "randint".

من حيث المبدأ، يمكن تمرير أي دالة توفر طريقة "rvs" (عينة عشوائية) لعينة
قيمة. يجب أن يوفر استدعاء دالة "rvs" عينات عشوائية مستقلة من قيم المعلمات المحتملة
على المكالمات المتتالية.

.. warning::

    لا تسمح التوزيعات في "scipy.stats" قبل إصدار scipy 0.16 بتحديد حالة عشوائية. بدلاً من ذلك، فإنها تستخدم
حالة numpy العشوائية العالمية، والتي يمكن بذرها عبر "np.random.seed" أو تعيينها
باستخدام "np.random.set_state". ومع ذلك، بدءًا من الإصدار 0.18 من scikit-learn،
تعيين وحدة sklearn.model_selection حالة عشوائية التي يوفرها المستخدم إذا كان scipy >= 0.16 متاح أيضًا.

بالنسبة للمعلمات المستمرة، مثل "C" أعلاه، من المهم تحديد
توزيع مستمر للاستفادة الكاملة من العشوائية. بهذه الطريقة،
سيؤدي زيادة "n_iter" دائمًا إلى بحث أكثر دقة.

تعد المتغير العشوائي المستمر والموحد بشكل لوغاريتمي إصدارًا مستمرًا من
معلمة متباعدة لوغاريتميًا. على سبيل المثال، لتحديد ما يعادل "C" من أعلاه،
يمكن استخدام "loguniform (1، 100)" بدلاً من "[1، 10، 100]".

انعكاسًا للمثال أعلاه في البحث الشبكي، يمكننا تحديد متغير عشوائي مستمر
موزعة بشكل لوغاريتمي بين "1e0" و "1e3"::

  من sklearn.utils.fixes import loguniform
  {'C': loguniform(1e0, 1e3),
   'gamma': loguniform(1e-4, 1e-3),
   'kernel': ['rbf'],
   'class_weight':['balanced', None]}

.. _successive_halving_user_guide:

البحث عن المعلمات المثلى مع التخفيض المتتالي
يوفر Scikit-learn أيضًا أداتي التقدير HalvingGridSearchCV و HalvingRandomSearchCV اللتين يمكن استخدامهما للبحث في مساحة المعلمات باستخدام التخفيض المتعاقب [1] [2]. التخفيض المتعاقب (SH) يشبه بطولة بين مجموعات معلمات المرشحين. SH هي عملية اختيار تكرارية يتم فيها تقييم جميع المرشحين (مجموعات المعلمات) باستخدام كمية صغيرة من الموارد في التكرار الأول. يتم اختيار بعض فقط من هؤلاء المرشحين للتكرار التالي، والذي سيتم تخصيص المزيد من الموارد له. بالنسبة لضبط المعلمات، فإن المورد هو عادةً عدد عينات التدريب، ولكنه يمكن أن يكون أيضًا معلمة رقمية تعسفية مثل n_estimators في غابة عشوائية.

.. note::

   يجب أن تكون الزيادة في الموارد المختارة كبيرة بما يكفي بحيث يتم الحصول على تحسن كبير في الدرجات عند مراعاة الدلالة الإحصائية.

كما هو موضح في الشكل أدناه، لا "ينجو" سوى مجموعة فرعية من المرشحين حتى التكرار الأخير. هؤلاء هم المرشحون الذين تم تصنيفهم باستمرار ضمن أفضل المرشحين الحاصلين على الدرجات عبر جميع التكرارات. يتم تخصيص كمية متزايدة من الموارد لكل مرشح، وهنا عدد العينات، في كل تكرار.

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_successive_halving_iterations_001.png
   :target: ../auto_examples/model_selection/plot_successive_halving_iterations.html
   :align: center

نقوم هنا بوصف المعلمات الرئيسية بإيجاز، ولكن يتم وصف كل معلمة وتفاعلاتها بالتفصيل في الأقسام أدناه. تتحكم معلمة "العامل" (> 1) في معدل نمو الموارد، ومعدل انخفاض عدد المرشحين. في كل تكرار، يتم ضرب عدد الموارد لكل مرشح في "العامل" ويتم قسمة عدد المرشحين على نفس العامل. إلى جانب "الموارد" و "min_resources"، فإن "العامل" هو أهم معلمة للتحكم في البحث في تنفيذنا، على الرغم من أن القيمة 3 تعمل بشكل جيد عادةً. يتحكم "العامل" بشكل فعال في عدد التكرارات في HalvingGridSearchCV وعدد المرشحين (بشكل افتراضي) والتكرارات في HalvingRandomSearchCV. يمكن أيضًا استخدام aggressive_elimination=True إذا كان عدد الموارد المتاحة صغيرًا. تتوفر إمكانية التحكم بشكل أكبر من خلال ضبط معلمة min_resources.

هذه التقديرات لا تزال **تجريبية**: قد تتغير تنبؤاتها وواجهة برمجة التطبيقات الخاصة بها دون أي دورة إهمال. لاستخدامها، يجب عليك استيراد enable_halving_search_cv بشكل صريح::

  >>> # تطلب صراحةً هذه الميزة التجريبية
  >>> from sklearn.experimental import enable_halving_search_cv  # noqa
  >>> # الآن يمكنك الاستيراد بشكل طبيعي من model_selection
  >>> from sklearn.model_selection import HalvingGridSearchCV
  >>> from sklearn.model_selection import HalvingRandomSearchCV

.. rubric:: الأمثلة

* :ref: sphx_glr_auto_examples_model_selection_plot_successive_halving_heatmap.py
* :ref: sphx_glr_auto_examples_model_selection_plot_successive_halving_iterations.py

اختيار "min_resources" وعدد المرشحين
------------------------------------

بجانب "العامل"، هناك معلمتان رئيسيتان تؤثران على سلوك البحث بالتخفيض المتعاقب هما معلمة "min_resources"، وعدد المرشحين (أو مجموعات المعلمات) التي يتم تقييمها. "min_resources" هي كمية الموارد المخصصة في التكرار الأول لكل مرشح. يتم تحديد عدد المرشحين مباشرة في HalvingRandomSearchCV، ويتم تحديده من معلمة "param_grid" في HalvingGridSearchCV.

لنأخذ حالة تكون فيها الموارد هي عدد العينات، ولدينا 1000 عينة. من الناحية النظرية، مع "min_resources=10" و "factor=2"، يمكننا تشغيل **كحد أقصى** 7 تكرارات بعدد العينات التالي: "[10، 20، 40، 80، 160، 320، 640]".

ولكن اعتمادًا على عدد المرشحين، قد نقوم بتشغيل أقل من 7 تكرارات: إذا بدأنا بعدد **صغير** من المرشحين، فقد يستخدم التكرار الأخير أقل من 640 عينة، مما يعني عدم استخدام جميع الموارد المتاحة (العينات). على سبيل المثال، إذا بدأنا بخمسة مرشحين، فسنحتاج إلى تكرارين فقط: 5 مرشحين للتكرار الأول، ثم "5 // 2 = 2" مرشحين في التكرار الثاني، وبعد ذلك نعرف أي مرشح يؤدي أفضل أداء (لذلك لا نحتاج إلى ثالث). سنستخدم ما لا يزيد عن 20 عينة فقط، وهو أمر غير فعال حيث لدينا 1000 عينة تحت تصرفنا. من ناحية أخرى، إذا بدأنا بعدد **مرتفع** من المرشحين، فقد ينتهي بنا الأمر بعدد كبير من المرشحين في التكرار الأخير، وهو ما قد لا يكون مثاليًا دائمًا: وهذا يعني أن العديد من المرشحين سيتم تشغيلهم بالموارد الكاملة، مما يقلل فعليًا الإجراء إلى البحث القياسي.

في حالة HalvingRandomSearchCV، يتم تعيين عدد المرشحين افتراضيًا بحيث يستخدم التكرار الأخير أكبر قدر ممكن من الموارد المتاحة. بالنسبة لـ HalvingGridSearchCV، يتم تحديد عدد المرشحين بواسطة معلمة "param_grid". سيؤثر تغيير قيمة "min_resources" على عدد التكرارات الممكنة، ونتيجة لذلك، سيكون له أيضًا تأثير على العدد المثالي للمرشحين.

هناك اعتبار آخر عند اختيار "min_resources" وهو ما إذا كان من السهل التمييز بين المرشحين الجيدين والسيئين باستخدام كمية صغيرة من الموارد. على سبيل المثال، إذا كنت بحاجة إلى الكثير من العينات للتمييز بين المعلمات الجيدة والسيئة، فيوصى باستخدام "min_resources" عالية. من ناحية أخرى، إذا كان التمييز واضحًا حتى بعدد صغير من العينات، فقد يكون "min_resources" الصغير مفضلًا لأنه سيسرع الحساب.

لاحظ في المثال أعلاه أن التكرار الأخير لا يستخدم الحد الأقصى من الموارد المتاحة: هناك 1000 عينة متاحة، ومع ذلك يتم استخدام 640 عينة كحد أقصى. بشكل افتراضي، يحاول كل من HalvingRandomSearchCV و HalvingGridSearchCV استخدام أكبر عدد ممكن من الموارد في التكرار الأخير، بشرط أن يكون مقدار الموارد هذا مضاعفًا لكل من "min_resources" و "factor" (سيصبح هذا القيد واضحًا في القسم التالي). يحقق HalvingRandomSearchCV ذلك عن طريق أخذ عينات من العدد الصحيح من المرشحين، بينما يحقق HalvingGridSearchCV ذلك عن طريق ضبط "min_resources" بشكل صحيح. يرجى الاطلاع على القسم exhausting_the_resources للحصول على التفاصيل.

.. _amount_of_resource_and_number_of_candidates:

كمية الموارد وعدد المرشحين في كل تكرار
---------------------------------------------

في أي تكرار i، يتم تخصيص كمية معينة من الموارد لكل مرشح والتي نطلق عليها اسم n_resources_i. يتم التحكم في هذه الكمية بواسطة معلمتي "العامل" و "min_resources" كما يلي (يكون "العامل" أكبر بشكل صارم من 1)::

    n_resources_i = factor ** i * min_resources،

أو ما يعادله::

    n_resources_ {i+1} = n_resources_i * factor

حيث "min_resources == n_resources_0" هي كمية الموارد المستخدمة في التكرار الأول. يحدد "العامل" أيضًا نسب المرشحين الذين سيتم اختيارهم للتكرار التالي::

    n_candidates_i = n_candidates // (factor ** i)

أو ما يعادله::

    n_candidates_0 = n_candidates
    n_candidates_ {i+1} = n_candidates_i // factor

لذلك، في التكرار الأول، نستخدم موارد "min_resources" عدد مرات "n_candidates". في التكرار الثاني، نستخدم موارد "min_resources * factor" عدد مرات "n_candidates // factor". التكرار الثالث يضاعف مرة أخرى الموارد لكل مرشح ويقسم عدد المرشحين. تتوقف هذه العملية عندما يتم الوصول إلى الحد الأقصى لمقدار الموارد لكل مرشح، أو عندما نحدد أفضل مرشح. يتم تحديد أفضل مرشح في التكرار الذي يقيم "العامل" أو أقل من المرشحين (انظر التفسير أدناه).

هنا مثال على "min_resources=3" و "factor=2"، بدءًا من 70 مرشحًا:

+-----------------------+-----------------------+
| "n_resources_i"     | "n_candidates_i"    |
+=======================+=======================+
| 3 (=min_resources)    | 70 (=n_candidates)    |
+-----------------------+-----------------------+
| 3 * 2 = 6             | 70 // 2 = 35          |
+-----------------------+-----------------------+
| 6 * 2 = 12            | 35 // 2 = 17          |
+-----------------------+-----------------------+
| 12 * 2 = 24           | 17 // 2 = 8           |
+-----------------------+-----------------------+
| 24 * 2 = 48           | 8 // 2 = 4            |
+-----------------------+-----------------------+
| 48 * 2 = 96           | 4 // 2 = 2            |
+-----------------------+-----------------------+

يمكننا ملاحظة ما يلي:

- تتوقف العملية في التكرار الأول الذي يقيم "العامل=2" من المرشحين: أفضل مرشح هو الأفضل من بين هذين المرشحين. ليس من الضروري تشغيل تكرار إضافي، حيث أنه سيقيم مرشحًا واحدًا فقط (وهو أفضل مرشح، والذي حددناه بالفعل). لهذا السبب، نريد بشكل عام أن يستخدم التكرار الأخير عددًا من المرشحين لا يزيد عن "العامل". إذا قام التكرار الأخير بتقييم أكثر من "العامل" من المرشحين، فإن هذا التكرار الأخير يصبح مثل البحث العادي (كما هو الحال في RandomizedSearchCV أو GridSearchCV).
- كل "n_resources_i" هو مضاعف لكل من "العامل" و "min_resources" (وهو ما تؤكده تعريفه أعلاه).

يمكن العثور على كمية الموارد المستخدمة في كل تكرار في سمة "n_resources_".

اختيار مورد
-------------

بشكل افتراضي، يتم تعريف المورد من حيث عدد العينات. أي أن كل تكرار سيستخدم عددًا متزايدًا من العينات للتدريب عليها. ومع ذلك، يمكنك تحديد معلمة لاستخدامها كمورد يدويًا باستخدام معلمة "resource". فيما يلي مثال يتم فيه تعريف المورد من حيث عدد المُقدّرات في غابة عشوائية::

    >>> from sklearn.datasets import make_classification
    >>> from sklearn.ensemble import RandomForestClassifier
    >>> from sklearn.experimental import enable_halving_search_cv  # noqa
    >>> from sklearn.model_selection import HalvingGridSearchCV
    >>> import pandas as pd
    >>>
    >>> param_grid = {'max_depth': [3, 5, 10],
    ...               'min_samples_split': [2, 5, 10]}
    >>> base_estimator = RandomForestClassifier(random_state=0)
    >>> X, y = make_classification(n_samples=1000, random_state=0)
    >>> sh = HalvingGridSearchCV(base_estimator، param_grid، cv=5،
    ...                          factor=2، resource='n_estimators'،
    ...                          max_resources=30).fit(X، y)
    >>> sh.best_estimator_
    RandomForestClassifier(max_depth=5، n_estimators=24، random_state=0)

لاحظ أنه لا يمكن وضع ميزانية لمعلمة تكون جزءًا من شبكة المعلمات.

.. _exhausting_the_resources:

استنفاد الموارد المتاحة
كما ذكر أعلاه، يعتمد عدد الموارد المستخدمة في كل تكرار على معلمة "min_resources". إذا كان لديك الكثير من الموارد المتاحة ولكنك تبدأ بعدد قليل من الموارد، فقد يتم هدر بعضها (أي عدم استخدامها).

تعتمد عملية البحث على 80 مورد كحد أقصى، في حين أن الحد الأقصى لعدد الموارد المتاحة لدينا هو "n_samples=1000". هنا، لدينا "min_resources = r_0 = 20".

بالنسبة لـ "HalvingGridSearchCV"، يتم ضبط معلمة "min_resources" افتراضيًا على "exhaust". وهذا يعني أن "min_resources" يتم ضبطها تلقائيًا بحيث يمكن للتكرار الأخير استخدام أكبر عدد ممكن من الموارد، ضمن حد "max_resources".

بالنسبة لـ "HalvingRandomSearchCV"، يمكن استنفاد الموارد بطريقتين:

- عن طريق ضبط "min_resources='exhaust'"، تمامًا مثل "HalvingGridSearchCV".
- عن طريق ضبط "n_candidates='exhaust'".

الخياران متنافيان: يتطلب استخدام "min_resources='exhaust'" معرفة عدد المرشحين، وبالمثل، يتطلب استخدام "n_candidates='exhaust'" معرفة "min_resources".

وبشكل عام، يؤدي استنفاد العدد الإجمالي للموارد إلى الحصول على أفضل معلمة مرشحة نهائية، وهو أكثر كثافة في الوقت قليلاً.

## القضاء العدواني على المرشحين

في الوضع المثالي، نريد أن يقوم التكرار الأخير بتقييم "factor" من المرشحين (راجع: كمية الموارد وعدد المرشحين). بعد ذلك، كل ما علينا فعله هو اختيار الأفضل. عندما يكون عدد الموارد المتاحة صغيرًا مقارنة بعدد المرشحين، فقد يضطر التكرار الأخير إلى تقييم أكثر من "factor" من المرشحين.

نظرًا لأنه لا يمكننا استخدام أكثر من "max_resources=40" من الموارد، يجب أن تتوقف العملية عند التكرار الثاني الذي يقيم أكثر من "factor=2" من المرشحين.

باستخدام معلمة "aggressive_elimination"، يمكنك إجبار عملية البحث على الانتهاء بأقل من "factor" من المرشحين في التكرار الأخير. للقيام بذلك، ستعمل العملية على القضاء على أكبر عدد ممكن من المرشحين باستخدام موارد "min_resources".

لاحظ أننا ننهي بمرشحين اثنين في التكرار الأخير لأننا قضينا على عدد كافٍ من المرشحين خلال التكرارات الأولى، باستخدام "n_resources = min_resources = 20".

## تحليل النتائج باستخدام صفة "cv_results_"

تحتوي صفة "cv_results_" على معلومات مفيدة لتحليل نتائج البحث. يمكن تحويلها إلى إطار بيانات بن بانداس باستخدام "df = pd.DataFrame(est.cv_results_)". إن صفة "cv_results_" لكل من "HalvingGridSearchCV" و"HalvingRandomSearchCV" مشابهة لصفة "GridSearchCV" و"RandomizedSearchCV"، مع معلومات إضافية تتعلق بعملية التخفيض المتعاقب.

هنا مثال على بعض أعمدة إطار البيانات (المقتطع):

==== ====== =============== ================= ========================================================================================
.. iter n_resources mean_test_score params
==== ====== =============== ================= ========================================================================================
0 0 125 0.983667 {'criterion': 'log_loss', 'max_depth': None, 'max_features': 9, 'min_samples_split': 5}
1 0 125 0.983667 {'criterion': 'gini', 'max_depth': None, 'max_features': 8, 'min_samples_split': 7}
2 0 125 0.983667 {'criterion': 'gini', 'max_depth': None, 'max_features': 10, 'min_samples_split': 10}
3 0 125 0.983667 {'criterion': 'log_loss', 'max_depth': None, 'max_features': 6, 'min_samples_split': 6}
... ... ... ... ...
15 2 500 0.951958 {'criterion': 'log_loss', 'max_depth': None, 'max_features': 9, 'min_samples_split': 10}
16 2 500 0.947958 {'criterion': 'gini', 'max_depth': None, 'max_features': 10, 'min_samples_split': 10}
17 2 500 0.951958 {'criterion': 'gini', 'max_depth': None, 'max_features': 10, 'min_samples_split': 4}
18 3 1000 0.961009 {'criterion': 'log_loss', 'max_depth': None, 'max_features': 9, 'min_samples_split': 10}
19 3 1000 0.955989 {'criterion': 'gini', 'max_depth': None, 'max_features': 10, 'min_samples_split': 4}
==== ====== =============== ================= ========================================================================================

يمثل كل صف مجموعة معينة من المعلمات (مرشح) وتكرار معين. يعطى التكرار بواسطة عمود "iter". ويخبرك عمود "n_resources" بعدد الموارد المستخدمة.

في المثال أعلاه، أفضل مجموعة من المعلمات هي " {'criterion': 'log_loss', 'max_depth': None, 'max_features': 9, 'min_samples_split': 10}" لأنها وصلت إلى التكرار الأخير (3) بأعلى درجة: 0.96.

## المراجع

[1] K. Jamieson, A. Talwalkar, Non-stochastic Best Arm Identification and Hyperparameter Optimization, in proc. of Machine Learning Research, 2016.

[2] L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, A. Talwalkar, Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization, in Machine Learning Research 18, 2018.

## نصائح للبحث عن المعلمات
هذا هو نص RST مترجم إلى اللغة العربية مع اتباع التعليمات المحددة:

=========================

تحديد مقياس موضوعي
------------------------------

بشكل افتراضي، يستخدم البحث عن المعلمات دالة "score" في المثمن لتقييم إعداد المعلمة. هذه هي
:func:`sklearn.metrics.accuracy_score` للتصنيف و
:func:`sklearn.metrics.r2_score` للانحدار.  بالنسبة لبعض التطبيقات،
تكون دالات التسجيل الأخرى أكثر ملاءمة (على سبيل المثال، في التصنيف غير المتوازن، تكون درجة الدقة غير مفيدة في كثير من الأحيان). يمكن تحديد دالة تسجيل بديلة عبر
معلمة "التسجيل" في معظم أدوات البحث عن المعلمات. راجع :ref:`scoring_parameter` لمزيد من التفاصيل.

.. _multimetric_grid_search:

تحديد مقاييس متعددة للتقييم
------------------------------------------

:class:`GridSearchCV` و :class:`RandomizedSearchCV` تسمح بتحديد
مقاييس متعددة لمعلمة "التسجيل".

يمكن تحديد التسجيل متعدد المقاييس إما على أنه قائمة من السلاسل لمعرفات الأسماء المحددة مسبقًا أو قاموس يقوم بتعيين اسم المسجل إلى دالة المسجل و/أو اسم (أسماء) المسجل المحدد مسبقًا. راجع :ref:`multimetric_scoring` لمزيد من التفاصيل.

عند تحديد مقاييس متعددة، يجب تعيين معلمة "refit" على المقياس (سلسلة) الذي سيتم من خلاله العثور على "best_params_" واستخدامه لبناء "best_estimator_" على مجموعة البيانات بأكملها. إذا لم يكن البحث يجب أن يعاد ضبطه، فحدد "refit=False". سيؤدي ترك إعادة الضبط إلى قيمة افتراضية "None" إلى حدوث خطأ عند استخدام مقاييس متعددة.

راجع :ref:`sphx_glr_auto_examples_model_selection_plot_multi_metric_evaluation.py`
لمثال على الاستخدام.

:class:`HalvingRandomSearchCV` و :class:`HalvingGridSearchCV` لا تدعم
التسجيل متعدد المقاييس.

.. _composite_grid_search:

المثمنات المركبة ومساحات المعلمات
-----------------------------------------
:class:`GridSearchCV` و :class:`RandomizedSearchCV` تسمح بالبحث في
معلمات المثمنات المركبة أو المضمنة مثل
:class:`~sklearn.pipeline.Pipeline`،
:class:`~sklearn.compose.ColumnTransformer`،
:class:`~sklearn.ensemble.VotingClassifier` أو
:class:`~sklearn.calibration.CalibratedClassifierCV` باستخدام بناء جملة مخصص
``<estimator>__<parameter>``::

  >>> from sklearn.model_selection import GridSearchCV
  >>> from sklearn.calibration import CalibratedClassifierCV
  >>> from sklearn.ensemble import RandomForestClassifier
  >>> from sklearn.datasets import make_moons
  >>> X, y = make_moons()
  >>> calibrated_forest = CalibratedClassifierCV(
  ...    estimator=RandomForestClassifier(n_estimators=10))
  >>> param_grid = {
  ...    'estimator__max_depth': [2, 4, 6, 8]}
  >>> search = GridSearchCV(calibrated_forest, param_grid, cv=5)
  >>> search.fit(X, y)
  GridSearchCV(cv=5,
               estimator=CalibratedClassifierCV(...),
               param_grid={'estimator__max_depth': [2, 4, 6, 8]})

هنا، ``<estimator>`` هو اسم معلمة المثمن المضمن،
في هذه الحالة "المثمن".
إذا تم بناء المثمن الفوقي كمجموعة من المثمنات كما هو الحال في
`pipeline.Pipeline`، فإن ``<estimator>`` يشير إلى اسم المثمن،
راجع :ref:`pipeline_nested_parameters`. في الممارسة العملية، يمكن أن يكون هناك عدة
مستويات من التضمين::

  >>> from sklearn.pipeline import Pipeline
  >>> from sklearn.feature_selection import SelectKBest
  >>> pipe = Pipeline([
  ...    ('select', SelectKBest()),
  ...    ('model', calibrated_forest)])
  >>> param_grid = {
  ...    'select__k': [1, 2],
  ...    'model__estimator__max_depth': [2, 4, 6, 8]}
  >>> search = GridSearchCV(pipe, param_grid, cv=5).fit(X, y)

يرجى الرجوع إلى :ref:`pipeline` لإجراء عمليات بحث عن المعلمات عبر الأنابيب.

اختيار النموذج: التطوير والتقييم
-------------------------------------------

يمكن اعتبار اختيار النموذج عن طريق تقييم إعدادات المعلمات المختلفة كطريقة
لاستخدام البيانات الموسومة لتدريب معلمات الشبكة.

عند تقييم النموذج الناتج، من المهم القيام بذلك على
عينات محجوزة لم يتم رؤيتها أثناء عملية البحث في الشبكة:
من المستحسن تقسيم البيانات إلى مجموعة **تطوير** (لتغذية
مثيل :class:`GridSearchCV`) ومجموعة **تقييم**
لحساب مقاييس الأداء.

يمكن القيام بذلك باستخدام دالة المساعدة :func:`train_test_split`.

التوازي
-----------

تقوم أدوات البحث عن المعلمات بتقييم كل مجموعة من المعلمات على كل طية من طيات البيانات
بشكل مستقل. يمكن تشغيل الحسابات بالتوازي عن طريق استخدام الكلمة الأساسية "n_jobs=-1". راجع توقيع الدالة لمزيد من التفاصيل، وكذلك إدخال مسرد المصطلحات لـ :term:`n_jobs`.

الصلابة ضد الفشل
---------------------

قد تؤدي بعض إعدادات المعلمات إلى فشل "fit" في طية واحدة أو أكثر من طيات البيانات.
بافتراضياً، سيؤدي هذا إلى فشل البحث بأكمله، حتى إذا كان من الممكن تقييم بعض إعدادات المعلمات بشكل كامل. يؤدي تعيين "error_score=0"
(أو `=np.nan`) إلى جعل الإجراء صلبًا ضد مثل هذا الفشل، وإصدار تحذير وتعيين درجة الطية إلى 0 (أو "نان")، ولكن إكمال البحث.

.. _alternative_cv:

بدائل للبحث المعلمي بالقوة الغاشمة
============================================

التصنيف المتقاطع المحدد للنموذج
-------------------------------


يمكن لبعض النماذج ملاءمة البيانات لنطاق من القيم لبعض المعلمات بنفس الكفاءة تقريبًا
كما هو الحال في ملاءمة المثمن لقيمة واحدة من المعلمة. يمكن الاستفادة من هذه الميزة لإجراء
تصنيف متقاطع أكثر كفاءة يستخدم لاختيار نموذج لهذه المعلمة.

المعلمة الأكثر شيوعًا التي يمكنها استيعاب هذه الاستراتيجية هي المعلمة
ترميز قوة المنظم. في هذه الحالة نقول أننا
حساب **مسار التنظيم** للمثمن.

فيما يلي قائمة بهذه النماذج:

.. currentmodule:: sklearn

.. autosummary::

   linear_model.ElasticNetCV
   linear_model.LarsCV
   linear_model.LassoCV
   linear_model.LassoLarsCV
   linear_model.LogisticRegressionCV
   linear_model.MultiTaskElasticNetCV
   linear_model.MultiTaskLassoCV
   linear_model.OrthogonalMatchingPursuitCV
   linear_model.RidgeCV
   linear_model.RidgeClassifierCV


معيار المعلومات
---------------------

يمكن لبعض النماذج تقديم صيغة مغلقة نظرية للمعلومات لمعامل التنظيم الأمثل عن طريق حساب
مسار التنظيم الفردي (بدلاً من عدة مسارات عند استخدام التصنيف المتقاطع).

فيما يلي قائمة بالنماذج التي تستفيد من معيار المعلومات أكايكي (AIC) أو معيار المعلومات الخليجية (BIC) لاختيار النموذج التلقائي:

.. autosummary::

   linear_model.LassoLarsIC


.. _out_of_bag:

تقديرات خارج الحقيبة
--------------------

عند استخدام أساليب التجميع المستندة إلى التجميع، أي إنشاء مجموعات تدريب جديدة باستخدام
العينات مع الاستبدال، يظل جزء من مجموعة التدريب غير مستخدم.  بالنسبة لكل مصنف في المجموعة،
يتم ترك جزء مختلف من مجموعة التدريب.

يمكن استخدام هذا الجزء المتروك لتقدير خطأ التعميم
دون الحاجة إلى الاعتماد على مجموعة تحقق صحة منفصلة.  يأتي هذا التقدير "مجانًا" حيث لا توجد بيانات إضافية مطلوبة ويمكن استخدامه لاختيار النموذج.

هذا منفذ حاليًا في الفئات التالية:

.. autosummary::

    ensemble.RandomForestClassifier
    ensemble.RandomForestRegressor
    ensemble.ExtraTreesClassifier
    ensemble.ExtraTreesRegressor
    ensemble.GradientBoostingClassifier
    ensemble.GradientBoostingRegressor