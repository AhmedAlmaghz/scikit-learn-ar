
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="2.9. التجميع" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/clustering.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="يمكن تنفيذ تجميع البيانات غير الموسومة باستخدام الوحدة النمطية sklearn.cluster. تأتي كل خوارزمية تجميع في متغيرين: فئة، تقوم بتنفيذ طريقة “التناسب” لتعلم التجميعات على بيانات التدريب، ودالة، تعيد، ..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_cluster_comparison_001.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="يمكن تنفيذ تجميع البيانات غير الموسومة باستخدام الوحدة النمطية sklearn.cluster. تأتي كل خوارزمية تجميع في متغيرين: فئة، تقوم بتنفيذ طريقة “التناسب” لتعلم التجميعات على بيانات التدريب، ودالة، تعيد، ..." />

    <title>2.9. التجميع &#8212; scikit-learn 1.5.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=e4cb1417" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=44dfd65d"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/clustering';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.5.1';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="biclustering.html" />
    <link rel="prev" title="2.3. تعلم المنوال" href="manifold.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <script>document.write(`<img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark" alt="scikit-learn homepage"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    مرجع المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    بدء الاستخدام
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    تاريخ الإصدارات
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    الدعم
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    التعاون مع الأطر الأخرى وتحسينها
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    خارطة الطريق
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    الحوكمة
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    مرجع المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    بدء الاستخدام
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    تاريخ الإصدارات
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    الدعم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    التعاون مع الأطر الأخرى وتحسينها
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    خارطة الطريق
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    الحوكمة
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning.html">1. التعلم الخَلفي</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../unsupervised_learning.html">2. التعلم غير الخاضع للإشراف</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mixture.html">2.1. نماذج المزيج الغاوسي</a></li>

<li class="toctree-l2"><a class="reference internal" href="manifold.html">2.3. تعلم المنوال</a></li>





<li class="toctree-l2 current active"><a class="current reference internal" href="#">2.9. التجميع</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">2.10. تفكيك الإشارات إلى مكونات (مشاكل تحليل المصفوفة)</a></li>


<li class="toctree-l2"><a class="reference internal" href="covariance.html">2.13. التغاير التجريبي</a></li>


<li class="toctree-l2"><a class="reference internal" href="outlier_detection.html">2.16. تناسب غلاف إهليلجي</a></li>










<li class="toctree-l2"><a class="reference internal" href="density.html">2.27. تقدير الكثافة</a></li>


<li class="toctree-l2"><a class="reference internal" href="neural_networks_unsupervised.html">2.30. نماذج الشبكات العصبية (غير الخاضعة للإشراف)</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_selection.html">3. اختيار النموذج وتقييمه</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="cross_validation.html">3.1. التدقيق المتقاطع: تقييم أداء أداة التقدير</a></li>


<li class="toctree-l2"><a class="reference internal" href="grid_search.html">3.4. البحث الشامل عن الشبكة</a></li>


<li class="toctree-l2"><a class="reference internal" href="classification_threshold.html">3.7. تعديل عتبة القرار للتنبؤ بالصنف</a></li>

<li class="toctree-l2"><a class="reference internal" href="model_evaluation.html">3.9. مقاييس الأداء وتقييمها: تقييم جودة التنبؤات كميًا</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_curve.html">3.10. منحنيات التحقق: رسم الدرجات لتقييم النماذج</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../inspection.html">4. التفتيش</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualizations.html">5. التمثيل المرئي</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_transforms.html">6. تحويلات مجموعة البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="compose.html">6.1. خطوط الأنابيب ومقدّرات المُركّبات</a></li>


<li class="toctree-l2"><a class="reference internal" href="feature_extraction.html">6.4. استخراج الخصائص</a></li>


<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">6.7. معالجة البيانات الأولية</a></li>




<li class="toctree-l2"><a class="reference internal" href="impute.html">6.12. إكمال القيم المفقودة</a></li>






<li class="toctree-l2"><a class="reference internal" href="unsupervised_reduction.html">6.19. PCA: التحليل التكويني الرئيسي</a></li>


<li class="toctree-l2"><a class="reference internal" href="random_projection.html">6.22. الإسقاط العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_approximation.html">6.23. طريقة Nystroem لتقريب النواة</a></li>




<li class="toctree-l2"><a class="reference internal" href="metrics.html">6.28. مقاييس الاقتران، الألفة والنواة</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing_targets.html">6.29. تحويل هدف التنبؤ (<code class="docutils literal notranslate"><span class="pre">y</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datasets.html">7. مرافق تحميل مجموعة البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datasets/toy_dataset.html">7.1. مجموعات البيانات التجريبية</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/real_world.html">7.2. مجموعات البيانات من العالم الحقيقي</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/sample_generators.html">7.3. المجموعات البيانات المولدة</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/loading_other_datasets.html">7.4. أمثلة</a></li>




</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../computing.html">8. الحوسبة باستخدام scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_persistence.html">9. نظرة عامة على سير العمل</a></li>




<li class="toctree-l1"><a class="reference internal" href="../common_pitfalls.html">14. المعالجة المسبقة غير المتسقة</a></li>

<li class="toctree-l1"><a class="reference internal" href="../dispatching.html">16. التشغيل التلقائي</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning_map.html">17. اختيار المحلل المناسب</a></li>
<li class="toctree-l1"><a class="reference internal" href="../presentations.html">18. الموارد الخارجية، الفيديوهات، والمحاضرات</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../user_guide.html" class="nav-link">مرجع المستخدم</a></li>
    
    
    <li class="breadcrumb-item"><a href="../unsupervised_learning.html" class="nav-link"><span class="section-number">2. </span>التعلم غير الخاضع للإشراف</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="clustering">
<span id="id1"></span><h1><span class="section-number">2.9. </span>التجميع<a class="headerlink" href="#clustering" title="Link to this heading">#</a></h1>
<p>يمكن تنفيذ تجميع البيانات غير الموسومة باستخدام الوحدة النمطية <a class="reference internal" href="../api/sklearn.cluster.html#module-sklearn.cluster" title="sklearn.cluster"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.cluster</span></code></a>.</p>
<p>تأتي كل خوارزمية تجميع في متغيرين: فئة، تقوم بتنفيذ طريقة “التناسب” لتعلم التجميعات على بيانات التدريب، ودالة، تعيد، عند إعطائها بيانات تدريب، مصفوفة من التسميات الصحيحة التي تتوافق مع التجميعات المختلفة. وبالنسبة للفئة، يمكن العثور على التسميات على بيانات التدريب في سمة “التسميات”.</p>
<aside class="topic">
<p class="topic-title">بيانات الإدخال</p>
<p>من المهم ملاحظة أن الخوارزميات المنفذة في هذه الوحدة يمكن أن تأخذ أنواعًا مختلفة من المصفوفات كإدخال. تقبل جميع الطرق مصفوفات البيانات القياسية ذات الشكل <code class="docutils literal notranslate"><span class="pre">(n_samples،</span> <span class="pre">n_features)</span></code>. يمكن الحصول على هذه المصفوفات من الفئات في الوحدة النمطية <a class="reference internal" href="../api/sklearn.feature_extraction.html#module-sklearn.feature_extraction" title="sklearn.feature_extraction"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.feature_extraction</span></code></a>. بالنسبة لـ <code class="xref py py-class docutils literal notranslate"><span class="pre">AffinityPropagation</span></code>، و:class:<code class="docutils literal notranslate"><span class="pre">SpectralClustering</span></code>، و:class:<code class="docutils literal notranslate"><span class="pre">DBSCAN</span></code>، يمكن أيضًا إدخال مصفوفات التشابه ذات الشكل <code class="docutils literal notranslate"><span class="pre">(n_samples،</span> <span class="pre">n_samples)</span></code>. يمكن الحصول على هذه المصفوفات من الدالات في الوحدة النمطية <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics.pairwise" title="sklearn.metrics.pairwise"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics.pairwise</span></code></a>.</p>
</aside>
<section id="id2">
<h2><span class="section-number">2.9.1. </span>نظرة عامة على طرق التجميع<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<figure class="align-center" id="id30">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_cluster_comparison.html"><img alt="../_images/sphx_glr_plot_cluster_comparison_001.png" src="../_images/sphx_glr_plot_cluster_comparison_001.png" style="width: 1050.0px; height: 650.0px;" />
</a>
<figcaption>
<p><span class="caption-text">مقارنة بين خوارزميات التجميع في scikit-learn</span><a class="headerlink" href="#id30" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>التجميع ذو الهندسة غير المسطحة مفيد عندما يكون للتجميعات شكل محدد، أي سطح غير مسطح، والمسافة الإقليدية القياسية ليست المقياس الصحيح. تنشأ هذه الحالة في الصفوف العلوية من الشكل أعلاه.</p>
<p>تُوصف نماذج المزيج الغاوسي، المفيدة للتجميع، في <span class="xref std std-ref">فصل آخر من الوثائق</span> المخصص لنماذج المزيج. يمكن اعتبار KMeans حالة خاصة من نموذج المزيج الغاوسي مع تساوي التباين لكل مكون.</p>
<p>طرق التجميع <span class="xref std std-term">الاستنتاج الاستقرائي</span> (على عكس طرق التجميع <span class="xref std std-term">الاستقرائي</span> ) ليست مصممة لتطبيقها على بيانات جديدة غير معروفة.</p>
<p id="k-means">K-means
خوارزمية :class: ‘KMeans’ تقوم بتجميع البيانات من خلال محاولة فصل العينات في مجموعات n ذات تباين متساوٍ، وتقليل معيار يعرف باسم “القصور الذاتي” أو مجموع المربعات داخل المجموعة (انظر أدناه). تتطلب هذه الخوارزمية تحديد عدد المجموعات. كما أنها تتناسب جيدًا مع الأعداد الكبيرة من العينات وقد تم استخدامها في مجموعة واسعة من مجالات التطبيق في العديد من المجالات المختلفة.</p>
<p>تقسم خوارزمية k-means مجموعة من N عينة X إلى K مجموعات غير متداخلة C، لكل منها متوسط μj لعينات المجموعة. عادة ما تسمى المتوسطات “مراكز” المجموعات؛ لاحظ أنها ليست، بشكل عام، نقاط من X، على الرغم من أنها موجودة في نفس المساحة.</p>
<p>تهدف خوارزمية K-means إلى اختيار مراكز تقلل من القصور الذاتي أو معيار مجموع المربعات داخل المجموعة:</p>
<p>يمكن التعرف على القصور الذاتي كمقاييس للتماسك الداخلي للمجموعات.</p>
<p>ولكنها تعاني من عدة عيوب:</p>
<ul class="simple">
<li><p>يفترض القصور الذاتي أن المجموعات محدبة ومتساوية الخواص، وهو ما لا يكون صحيحًا دائمًا. كما أنها تستجيب بشكل سيء للمجموعات الطويلة أو المنحنيات ذات الأشكال غير المنتظمة.</p></li>
<li><p>القصور الذاتي ليس مقياسًا معياريًا: كل ما نعرفه هو أن القيم الأقل هي الأفضل وأن الصفر هو الوضع الأمثل. ولكن في المساحات عالية الأبعاد جدًا، تميل المسافات الإقليدية إلى الانتفاخ (هذه هي حالة ما يسمى “لعنة الأبعاد”). يمكن التخفيف من هذه المشكلة وتسريع الحسابات من خلال تشغيل خوارزمية تقليل الأبعاد مثل :ref: ‘PCA’ قبل التجميع باستخدام k-means.</p></li>
</ul>
<p>يمكن الاطلاع على أوصاف أكثر تفصيلاً للمشكلات الموضحة أعلاه وكيفية معالجتها في الأمثلة :ref: ‘sphx_glr_auto_examples_cluster_plot_kmeans_assumptions.py’ و :ref: ‘sphx_glr_auto_examples_cluster_plot_kmeans_silhouette_analysis.py’.</p>
<p>يُشار إلى K-means غالبًا باسم خوارزمية Lloyd. وبشكل أساسي، تتكون الخوارزمية من ثلاث خطوات. تختار الخطوة الأولى المراكز الأولية، وتتمثل أبسط طريقة في اختيار k عينة من مجموعة البيانات X. بعد التهيئة، تتكون K-means من التكرار بين الخطوتين الأخريين. تقوم الخطوة الأولى بتعيين كل عينة إلى أقرب مركز لها. تقوم الخطوة الثانية بإنشاء مراكز جديدة عن طريق حساب المتوسط لجميع العينات المعينة لكل مركز سابق. يتم حساب الفرق بين المراكز القديمة والجديدة، وتكرر الخوارزمية هاتين الخطوتين الأخيرتين حتى تكون هذه القيمة أقل من عتبة معينة. وبعبارة أخرى، فإنها تكرر العملية حتى لا تتحرك المراكز بشكل كبير.</p>
<p>K-means مكافئ لخوارزمية التوقع الأقصى مع مصفوفة تباين صغيرة ومتساوية ومتعامدة.</p>
<p>يمكن أيضًا فهم الخوارزمية من خلال مفهوم مخططات Voronoi</p>
<p>يتم أولاً حساب مخطط Voronoi للنقاط باستخدام المراكز الحالية. يصبح كل جزء في مخطط Voronoi مجموعة منفصلة. ثانيًا، يتم تحديث المراكز إلى متوسط كل جزء. ثم تكرر الخوارزمية هذه العملية حتى يتم استيفاء معيار التوقف. عادة ما تتوقف الخوارزمية عندما يكون الانخفاض النسبي في دالة الهدف بين التكرارات أقل من قيمة التحمل المحددة. ولكن هذا ليس هو الحال في هذا التنفيذ: يتوقف التكرار عندما تتحرك المراكز بأقل من قيمة التحمل.</p>
<p>إذا تم منحها وقتًا كافيًا، فستتقارب K-means دائمًا، ولكن قد يكون ذلك عند حد أدنى محلي. يعتمد هذا إلى حد كبير على تهيئة المراكز. ونتيجة لذلك، يتم إجراء الحساب غالبًا عدة مرات، مع تهيئة مختلفة للمراكز. إحدى الطرق للمساعدة في معالجة هذه المشكلة هي مخطط تهيئة k-means++، والذي تم تنفيذه في scikit-learn (استخدم معلمة “init=’k-means++’”. يقوم هذا بإعداد المراكز لتكون متباعدة بشكل عام، مما يؤدي إلى نتائج أفضل من التهيئة العشوائية، كما هو موضح في المرجع. لمثال مفصل لمقارنة مخططات التهيئة المختلفة، راجع :ref: ‘sphx_glr_auto_examples_cluster_plot_kmeans_digits.py’.</p>
<p>يمكن أيضًا استخدام k-means++ بشكل مستقل لاختيار البذور لخوارزميات التجميع الأخرى، راجع :func: ‘sklearn.cluster.kmeans_plusplus’ للحصول على التفاصيل والاستخدام النموذجي.</p>
<p>تدعم الخوارزمية أوزان العينات، والتي يمكن إعطاؤها بواسطة معلمة “sample_weight”. يسمح ذلك بإعطاء وزن أكبر لبعض العينات عند حساب مراكز المجموعات وقيم القصور الذاتي. على سبيل المثال، فإن تعيين وزن 2 لعينة ما يعادل إضافة نسخة مكررة من تلك العينة إلى مجموعة البيانات X.</p>
<p>يمكن استخدام K-means في التكميم المتجه. يتم تحقيق ذلك باستخدام طريقة “التحويل” لنموذج مدرب من :class: ‘KMeans’. لمثال على تنفيذ التكميم المتجه على صورة، راجع :ref: ‘sphx_glr_auto_examples_cluster_plot_color_quantization.py’.</p>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><dl class="field-list simple">
<dt class="field-odd">ref<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘sphx_glr_auto_examples_cluster_plot_cluster_iris.py’: مثال على استخدام :class: ‘KMeans’ باستخدام مجموعة بيانات Iris</p>
</dd>
</dl>
</li>
<li><dl class="field-list simple">
<dt class="field-odd">ref<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘sphx_glr_auto_examples_text_plot_document_clustering.py’: تجميع المستندات باستخدام :class: ‘KMeans’ و :class: ‘MiniBatchKMeans’ بناءً على بيانات متفرقة</p>
</dd>
</dl>
</li>
</ul>
<section id="id3">
<h3><span class="section-number">2.9.1.1. </span>التوازي منخفض المستوى<a class="headerlink" href="#id3" title="Link to this heading">#</a></h3>
<p>يستفيد :class: ‘KMeans’ من التوازي القائم على OpenMP من خلال Cython. يتم معالجة أجزاء صغيرة من البيانات (256 عينة) بالتوازي، مما يؤدي أيضًا إلى تقليل استخدام الذاكرة. لمزيد من التفاصيل حول كيفية التحكم في عدد الخيوط، يرجى الرجوع إلى ملاحظاتنا حول :ref: ‘parallelism’.</p>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><dl class="field-list simple">
<dt class="field-odd">ref<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘sphx_glr_auto_examples_cluster_plot_kmeans_assumptions.py’: توضيح الحالات التي يؤدي فيها k-means بشكل بديهي والحالات التي لا يؤدي فيها بشكل بديهي</p>
</dd>
</dl>
</li>
<li><dl class="field-list simple">
<dt class="field-odd">ref<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘sphx_glr_auto_examples_cluster_plot_kmeans_digits.py’: تجميع الأرقام المكتوبة بخط اليد</p>
</dd>
</dl>
</li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">“k-means++: مزايا البذر بعناية”
&lt;<a class="reference external" href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf">http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf</a>&gt;
آرثر، ديفيد، وسيرجي فاسيلفيتسكي،
وقائع الندوة السنوية الثامنة عشرة ACM-SIAM حول الخوارزميات المنفصلة، جمعية الرياضيات الصناعية والتطبيقية (2007)</p></li>
</ul>
</div>
</details></section>
<section id="mini-batch-k-means">
<span id="mini-batch-kmeans"></span><h3><span class="section-number">2.9.1.2. </span>Mini Batch K-Means<a class="headerlink" href="#mini-batch-k-means" title="Link to this heading">#</a></h3>
<dl class="field-list simple">
<dt class="field-odd">class<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘MiniBatchKMeans’ هو متغير من :class: ‘KMeans’ خوارزمية</p>
</dd>
</dl>
<p>التي تستخدم الدفعات المصغرة لتقليل وقت الحساب، مع محاولة تحسين نفس دالة الهدف. الدفعات المصغرة هي مجموعات فرعية من بيانات الإدخال، يتم أخذ عينات عشوائية منها في كل تكرار تدريبي. تقلل هذه الدفعات المصغرة بشكل كبير من كمية الحسابات اللازمة للتقارب إلى حل محلي. على عكس الخوارزميات الأخرى التي تقلل من وقت التقارب لخوارزمية k-means، فإن mini-batch k-means ينتج نتائج أسوأ قليلاً فقط من الخوارزمية القياسية.</p>
<p>تتناوب الخوارزمية بين خطوتين رئيسيتين، مشابهتين لخوارزمية k-means الأساسية. في الخطوة الأولى، يتم رسم b عينة عشوائيًا من مجموعة البيانات لتشكيل دفعة مصغرة. ثم يتم تعيينها إلى أقرب مركز لها. في الخطوة الثانية، يتم تحديث المراكز. على عكس k-means، يتم ذلك على أساس كل عينة على حدة. بالنسبة لكل عينة في الدفعة المصغرة، يتم تحديث المركز المعين عن طريق أخذ المتوسط المتحرك للعينة وجميع العينات السابقة المعينة لذلك المركز. يؤدي هذا إلى تقليل معدل التغير للمركز بمرور الوقت. يتم تنفيذ هذه الخطوات حتى يتم الوصول إلى التقارب أو عدد محدد مسبقًا من التكرارات.</p>
<p>يتقارب :class: ‘MiniBatchKMeans’ بشكل أسرع من :class: ‘KMeans’، ولكن جودة النتائج أقل. في الممارسة العملية، يمكن أن يكون هذا الاختلاف في الجودة صغيرًا جدًا، كما هو موضح في المثال والمرجع المذكور.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_mini_batch_kmeans.html"><img alt="../_images/sphx_glr_plot_mini_batch_kmeans_001.png" src="../_images/sphx_glr_plot_mini_batch_kmeans_001.png" style="width: 800.0px; height: 300.0px;" />
</a>
</figure>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><dl class="field-list simple">
<dt class="field-odd">ref<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘sphx_glr_auto_examples_cluster_plot_mini_batch_kmeans.py’: مقارنة بين :class: ‘KMeans’ و :class: ‘MiniBatchKMeans’</p>
</dd>
</dl>
</li>
<li><dl class="field-list simple">
<dt class="field-odd">ref<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘sphx_glr_auto_examples_text_plot_document_clustering.py’: تجميع المستندات باستخدام :class: ‘KMeans’ و :class: ‘MiniBatchKMeans’ بناءً على بيانات متفرقة</p>
</dd>
</dl>
</li>
<li><dl class="field-list simple">
<dt class="field-odd">ref<span class="colon">:</span></dt>
<dd class="field-odd"><p>‘sphx_glr_auto_examples_cluster_plot_dict_face_patches.py’</p>
</dd>
</dl>
</li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">“K-Means التجميع على نطاق الويب”
&lt;<a class="reference external" href="https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf">https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf</a>&gt;
D. سكولي، وقائع المؤتمر الدولي التاسع عشر على World
الويب واسع النطاق (2010)</p></li>
</ul>
</div>
</details><p id="affinity-propagation">Affinity Propagation
ينشئ <code class="xref py py-class docutils literal notranslate"><span class="pre">AffinityPropagation</span></code> التجمعات عن طريق إرسال الرسائل بين أزواج العينات حتى التقارب. ثم يتم وصف مجموعة البيانات باستخدام عدد صغير من الأمثلة النموذجية، والتي يتم تحديدها على أنها الأكثر تمثيلاً للعينات الأخرى. وتمثل الرسائل المرسلة بين الأزواج ملاءمة عينة واحدة لتكون نموذجًا للآخر، يتم تحديثه استجابة للقيم من الأزواج الأخرى. يحدث هذا التحديث بشكل تكراري حتى يتم الوصول إلى التقارب، وعند هذه النقطة يتم اختيار النماذج النهائية، وبالتالي يتم إعطاء التجميع النهائي.</p>
<p>تقنية Affinity Propagation مثيرة للاهتمام لأنها تختار عدد التجمعات بناءً على البيانات المقدمة. ولهذا الغرض، هناك معياران مهمان هما: “التفضيل”، الذي يتحكم في عدد النماذج المستخدمة، و”معامل التخميد” الذي يقلل من أهمية رسائل المسؤولية والتوفر لتجنب الاهتزازات العددية عند تحديث هذه الرسائل.</p>
<p>الجانب السلبي الرئيسي لتقنية Affinity Propagation هو تعقيدها. فلخوارزمية تعقيد زمني من رتبة <span class="math notranslate nohighlight">\(O(N^2 T)\)</span>، حيث <span class="math notranslate nohighlight">\(N\)</span> هو عدد العينات و <span class="math notranslate nohighlight">\(T\)</span> هو عدد التكرارات حتى التقارب. علاوة على ذلك، فإن التعقيد الذاكري هو من رتبة <span class="math notranslate nohighlight">\(O(N^2)\)</span> إذا تم استخدام مصفوفة تشابه كثيفة، ولكنه قابل للتخفيض إذا تم استخدام مصفوفة تشابه مبعثرة. وهذا يجعل تقنية Affinity Propagation مناسبة أكثر لمجموعات البيانات الصغيرة والمتوسطة الحجم.</p>
<p>تنتمي الرسائل المرسلة بين النقاط إلى إحدى الفئتين التاليتين. الأولى هي المسؤولية <span class="math notranslate nohighlight">\(r(i, k)\)</span>، والتي تمثل الأدلة المتراكمة على أن العينة <span class="math notranslate nohighlight">\(k\)</span> يجب أن تكون نموذجًا للعينة <span class="math notranslate nohighlight">\(i\)</span>. والثانية هي التوفر <span class="math notranslate nohighlight">\(a(i, k)\)</span> الذي يمثل الأدلة المتراكمة على أن العينة <span class="math notranslate nohighlight">\(i\)</span> يجب أن تختار العينة <span class="math notranslate nohighlight">\(k\)</span> لتكون نموذجها، وتأخذ في الاعتبار القيم لجميع العينات الأخرى التي يجب أن تكون <span class="math notranslate nohighlight">\(k\)</span> نموذجًا لها. وبهذه الطريقة، يتم اختيار النماذج من قبل العينات إذا كانت (1) مشابهة بما فيه الكفاية للعديد من العينات و (2) اختارها العديد من العينات لتمثيل أنفسهم.</p>
<p>وبشكل أكثر رسمية، فإن مسؤولية عينة <span class="math notranslate nohighlight">\(k\)</span> لتكون نموذجًا للعينة <span class="math notranslate nohighlight">\(i\)</span> تعطى بالمعادلة التالية:</p>
<div class="math notranslate nohighlight">
\[r(i, k) \leftarrow s(i, k) - max [ a(i, k') + s(i, k') \forall k' \neq k ]\]</div>
<p>حيث <span class="math notranslate nohighlight">\(s(i, k)\)</span> هي درجة التشابه بين العينات <span class="math notranslate nohighlight">\(i\)</span> و <span class="math notranslate nohighlight">\(k\)</span>. وتُعطى قابلية العينة <span class="math notranslate nohighlight">\(k\)</span> لتكون نموذجًا للعينة <span class="math notranslate nohighlight">\(i\)</span> بالمعادلة التالية:</p>
<div class="math notranslate nohighlight">
\[a(i, k) \leftarrow min [0, r(k, k) + \sum_{i'~s.t.~i' \notin \{i, k\}}{r(i', k)}]\]</div>
<p>في البداية، يتم تعيين جميع القيم لـ <span class="math notranslate nohighlight">\(r\)</span> و <span class="math notranslate nohighlight">\(a\)</span> إلى الصفر، ويتم حساب كل منها حتى التقارب. وكما نوقش سابقًا، لتجنب الاهتزازات العددية عند تحديث الرسائل، يتم تقديم معامل التخميد <span class="math notranslate nohighlight">\(\lambda\)</span> إلى عملية التكرار على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[r_{t+1}(i, k) = \lambda\cdot r_{t}(i, k) + (1-\lambda)\cdot r_{t+1}(i, k)\]</div>
<div class="math notranslate nohighlight">
\[a_{t+Multiplier)(i, k) = \lambda\cdot a_{t}(i, k) + (1-\lambda)\cdot a_{t+1}(i, k)\]</div>
<p>حيث <span class="math notranslate nohighlight">\(t\)</span> تشير إلى مرات التكرار.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_affinity_propagation.html#sphx-glr-auto-examples-cluster-plot-affinity-propagation-py"><span class="std std-ref">Demo of affinity propagation clustering algorithm</span></a>: تقنية Affinity Propagation على مجموعة بيانات صناعية ثنائية الأبعاد مع 3 فئات</p></li>
<li><p><a class="reference internal" href="../auto_examples/applications/plot_stock_market.html#sphx-glr-auto-examples-applications-plot-stock-market-py"><span class="std std-ref">Visualizing the stock market structure</span></a>: تقنية Affinity Propagation على السلاسل الزمنية المالية للعثور على مجموعات من الشركات</p></li>
</ul>
</section>
</section>
<section id="mean-shift">
<span id="id4"></span><h2><span class="section-number">2.9.2. </span>Mean Shift<a class="headerlink" href="#mean-shift" title="Link to this heading">#</a></h2>
<p>يهدف التجميع باستخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">MeanShift</span></code> إلى اكتشاف “التكتلات” في كثافة سلسة من العينات. إنه خوارزمية تعتمد على المركزيد، تعمل عن طريق تحديث المرشحين لتكون المركزيد المتوسط للنقاط داخل منطقة معينة. يتم بعد ذلك تصفية هؤلاء المرشحين في مرحلة ما بعد المعالجة للقضاء على التكرارات القريبة لتشكيل المجموعة النهائية من المركزيد.</p>
<p>يتم ضبط موضع مرشحي المركزيد بشكل تكراري باستخدام تقنية تسمى “تسلق التل”، والتي تجد القيم القصوى المحلية لتقدير كثافة الاحتمالية. بالنظر إلى مرشح المركزيد <span class="math notranslate nohighlight">\(x\)</span> للتكرار <span class="math notranslate nohighlight">\(t\)</span>، يتم تحديث المرشح وفقًا للمعادلة التالية:</p>
<div class="math notranslate nohighlight">
\[x^{t+1} = x^t + m(x^t)\]</div>
<p>حيث <span class="math notranslate nohighlight">\(m\)</span> هي متجه “التحول المتوسط” الذي يتم حسابه لكل مركزيد ويشير إلى منطقة الزيادة القصوى في كثافة النقاط. ولحساب <span class="math notranslate nohighlight">\(m\)</span>، نقوم بتعريف <span class="math notranslate nohighlight">\(N(x)\)</span> على أنها مجموعة الجوار من العينات ضمن مسافة معينة حول <span class="math notranslate nohighlight">\(x\)</span>. ثم يتم حساب <span class="math notranslate nohighlight">\(m\)</span> باستخدام المعادلة التالية، مما يؤدي إلى تحديث المركزيد ليكون متوسط العينات داخل الجوار الخاص به:</p>
<div class="math notranslate nohighlight">
\[m(x) = \frac{1}{|N(x)|} \sum_{x_j \in N(x)}x_j - x\]</div>
<p>وبشكل عام، تعتمد معادلة <span class="math notranslate nohighlight">\(m\)</span> على دالة النواة المستخدمة لتقدير الكثافة. والصيغة العامة هي:</p>
<div class="math notranslate nohighlight">
\[m(x) = \frac{\sum_{x_j \in N(x)}K(x_j - x)x_j}{\sum_{x_j \in N(x)}K(x_j - x)} - x\]</div>
<p>في تنفيذنا، <span class="math notranslate nohighlight">\(K(x)\)</span> تساوي 1 إذا كانت <span class="math notranslate nohighlight">\(x\)</span> صغيرة بما فيه الكفاية وتساوي صفرًا في حال العكس. وبشكل فعال، تشير <span class="math notranslate nohighlight">\(K(y - x)\)</span> ما إذا كانت <span class="math notranslate nohighlight">\(y\)</span> في جوار <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>يحدد الخوارزم تلقائيًا عدد التجمعات، بدلاً من الاعتماد على معلمة “عرض النطاق الترددي”، التي تملي حجم المنطقة التي يجب البحث فيها. يمكن تعيين هذه المعلمة يدويًا، ولكن يمكن تقديرها باستخدام دالة “estimate_bandwidth” المقدمة، والتي يتم استدعاؤها إذا لم يتم تعيين عرض النطاق الترددي.</p>
<p>الخوارزمية ليست قابلة للتطوير بشكل كبير، حيث تتطلب عمليات بحث متعددة عن أقرب جار أثناء تنفيذ الخوارزمية. من المضمون أن تتقارب الخوارزمية، ومع ذلك، فإنها ستتوقف عن التكرار عندما يكون التغيير في المركزيد صغيرًا.</p>
<p>يتم تصنيف عينة جديدة عن طريق العثور على أقرب مركزيد لعينة معينة.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_mean_shift.html"><img alt="../_images/sphx_glr_plot_mean_shift_001.png" src="../_images/sphx_glr_plot_mean_shift_001.png" style="width: 320.0px; height: 240.0px;" />
</a>
</figure>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_mean_shift.html#sphx-glr-auto-examples-cluster-plot-mean-shift-py"><span class="std std-ref">A demo of the mean-shift clustering algorithm</span></a>: التجميع باستخدام Mean Shift على مجموعة بيانات صناعية ثنائية الأبعاد مع 3 فئات.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
</div>
</details><ul class="simple">
<li><p><a class="reference external" href="https://doi.org/10.1109/34.1000236">“Mean shift: A robust approach toward feature space analysis”</a> D. Comaniciu and P. Meer, <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (2002)</p></li>
</ul>
<p id="spectral-clustering">Spectral clustering
يؤدي <code class="xref py py-class docutils literal notranslate"><span class="pre">SpectralClustering</span></code> إلى تضمين منخفض الأبعاد لمصفوفة التشابه بين العينات، يليه تجميع، على سبيل المثال، بواسطة KMeans، لمكونات المتجهات الذاتية في الفضاء منخفض الأبعاد. إنه فعال بشكل خاص من الناحية الحسابية إذا كانت مصفوفة التشابه متفرقة ويتم استخدام محلل ‘amg’ لمشكلة القيمة الذاتية (ملاحظة، يتطلب محلل ‘amg’ تثبيت وحدة ‘pyamg &lt;<a class="github reference external" href="https://github.com/pyamg/pyamg">pyamg/pyamg</a>&gt;`_).</p>
<p>يتطلب الإصدار الحالي من SpectralClustering تحديد عدد التجميعات مسبقًا. يعمل بشكل جيد لعدد صغير من المجموعات، ولكن لا يُنصح به للعديد من المجموعات.</p>
<p>بالنسبة لمجموعتين، يحل SpectralClustering استرخاءًا محدبًا لمشكلة “التقطيعات المطبعنة &lt;<a class="reference external" href="https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf">https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf</a>&gt;`_” على الرسم البياني للتشابه: تقسيم الرسم البياني إلى قسمين بحيث يكون وزن الحواف المقطوعة صغيرًا مقارنة بأوزان الحواف داخل كل مجموعة. هذا المعيار مثير للاهتمام بشكل خاص عند العمل على الصور، حيث تكون عقد الرسم البياني بكسلًا، وتتم حسابات أوزان حواف الرسم البياني للتشابه باستخدام دالة تدرج الصورة.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_segmentation_toy.html"><img alt="noisy_img" src="../_images/sphx_glr_plot_segmentation_toy_001.png" style="width: 500.0px; height: 250.0px;" /></a> <a class="reference external" href="../auto_examples/cluster/plot_segmentation_toy.html"><img alt="segmented_img" src="../_images/sphx_glr_plot_segmentation_toy_002.png" style="width: 500.0px; height: 250.0px;" /></a></strong></p><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>تحويل المسافة إلى تشابهات جيدة التصرف</p>
<p>لاحظ أنه إذا لم تكن قيم مصفوفة التشابه الخاصة بك موزعة بشكل جيد، على سبيل المثال، بقيم سلبية أو بمصفوفة مسافة بدلاً من التشابه، فستكون المشكلة الطيفية غير قابلة للحل. في هذه الحالة، يُنصح بتطبيق تحويل على إدخالات المصفوفة. على سبيل المثال، في حالة مصفوفة مسافة موقعة، من الشائع تطبيق نواة حرارية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">similarity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">beta</span> <span class="o">*</span> <span class="n">distance</span> <span class="o">/</span> <span class="n">distance</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</pre></div>
</div>
<p>راجع الأمثلة لمثل هذا التطبيق.</p>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_segmentation_toy.html#sphx-glr-auto-examples-cluster-plot-segmentation-toy-py"><span class="std std-ref">Spectral clustering for image segmentation</span></a>: تجزئة الأجسام من خلفية ضبابية باستخدام التجميع الطيفي.</p></li>
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_coin_segmentation.html#sphx-glr-auto-examples-cluster-plot-coin-segmentation-py"><span class="std std-ref">Segmenting the picture of greek coins in regions</span></a>: التجميع الطيفي لتقسيم صورة العملات إلى مناطق.</p></li>
</ul>
<section id="id5">
<h3><span class="section-number">2.9.2.1. </span>استراتيجيات تعيين التسميات المختلفة<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p>يمكن استخدام استراتيجيات مختلفة لتعيين التسميات، والتي تتوافق مع
معلمة “assign_labels” من <code class="xref py py-class docutils literal notranslate"><span class="pre">SpectralClustering</span></code>. يمكن لاستراتيجية “kmeans” أن تتطابق مع التفاصيل الدقيقة، ولكن قد تكون غير مستقرة.</p>
<p>على وجه الخصوص، ما لم تتحكم في “random_state”، فقد لا يكون
قابلاً للتكرار من تشغيل إلى تشغيل، حيث يعتمد على التهيئة العشوائية.
البديل “discretize” استراتيجية قابلة للتكرار 100٪، ولكن يميل
إلى إنشاء قطع من الشكل حتى وجيومتري.
الخيار “cluster_qr” المضافة مؤخرًا هو بديل حتمي يميل إلى إنشاء
أفضل تقسيم مرئي على تطبيق المثال أدناه.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><code class="docutils literal notranslate"><span class="pre">assign_labels=&quot;kmeans&quot;</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">assign_labels=&quot;discretize&quot;</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">assign_labels=&quot;cluster_qr&quot;</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="../auto_examples/cluster/plot_coin_segmentation.html"><img alt="coin_kmeans" src="../_images/sphx_glr_plot_coin_segmentation_001.png" style="width: 175.0px; height: 175.0px;" /></a></p></td>
<td><p><a class="reference external" href="../auto_examples/cluster/plot_coin_segmentation.html"><img alt="coin_discretize" src="../_images/sphx_glr_plot_coin_segmentation_002.png" style="width: 175.0px; height: 175.0px;" /></a></p></td>
<td><p><a class="reference external" href="../auto_examples/cluster/plot_coin_segmentation.html"><img alt="coin_cluster_qr" src="../_images/sphx_glr_plot_coin_segmentation_003.png" style="width: 175.0px; height: 175.0px;" /></a></p></td>
</tr>
</tbody>
</table>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-4">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-4" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://people.eecs.berkeley.edu/~jordan/courses/281B-spring04/readings/yu-shi.pdf">“Multiclass spectral clustering”</a>
ستيلا إكس يو، جيانبو شي، 2003</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1093/imaiai/iay008">“Simple, direct, and efficient multi-way spectral clustering”</a>
أنيل داملي، فيكتور ميندن، ليكسينج يينج، 2019</p></li>
</ul>
</div>
</details></section>
<section id="spectral-clustering-graph">
<span id="id6"></span><h3><span class="section-number">2.9.2.2. </span>رسوم بيانية للتجميع الطيفي<a class="headerlink" href="#spectral-clustering-graph" title="Link to this heading">#</a></h3>
<p>يمكن أيضًا استخدام التجميع الطيفي لتقسيم الرسوم البيانية عبر تضميناتها الطيفية. في هذه الحالة، تكون مصفوفة التشابه هي مصفوفة المجاورة للرسم البياني، ويتم تهيئة SpectralClustering بـ <code class="docutils literal notranslate"><span class="pre">affinity='precomputed'</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">SpectralClustering</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sc</span> <span class="o">=</span> <span class="n">SpectralClustering</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">affinity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">assign_labels</span><span class="o">=</span><span class="s1">&#39;discretize&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sc</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">)</span>  
</pre></div>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-5">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-5" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1007/s11222-007-9033-z">“A Tutorial on Spectral Clustering”</a> Ulrike
von Luxburg، 2007</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1109/34.868688">“Normalized cuts and image segmentation”</a> Jianbo
Shi، Jitendra Malik، 2000</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/84a86a69315e994cfd1e0c7debb86d62d7bd1f44">“A Random Walks View of Spectral Segmentation”</a>
مارينا مايلا، جيانبو شي، 2001</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/796c5d6336fc52aa84db575fb821c78918b65f58">“On Spectral Clustering: Analysis and an algorithm”</a>
أندرو واي نج، مايكل آي جوردان، يائير وايس، 2001</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://arxiv.org/abs/1708.07481">“Preconditioned Spectral Clustering for Stochastic Block Partition
Streaming Graph Challenge”</a> ديفيد زهوزوناشفيلي، أندرو كنيازيف</p></li>
</ul>
</div>
</details><p id="hierarchical-clustering">التجميع الهرمي
التجميع الهرمي هي عائلة عامة من خوارزميات التجميع التي تقوم ببناء تجمعات متداخلة عن طريق دمجها أو تقسيمها بشكل متتالي. يتم تمثيل هذا التسلسل الهرمي للتجمعات على شكل شجرة (أو مخطط شجري). جذر الشجرة هو التجمع الفريد الذي يجمع جميع العينات، والأوراق هي التجمعات التي تحتوي على عينة واحدة فقط. لمزيد من التفاصيل، راجع صفحة ويكيبيديا <a class="reference external" href="https://en.wikipedia.org/wiki/Hierarchical_clustering">https://en.wikipedia.org/wiki/Hierarchical_clustering</a>.</p>
<p>تقوم كائن class: ‘AgglomerativeClustering’ بالتجميع الهرمي باستخدام نهج من الأسفل إلى الأعلى: تبدأ كل ملاحظة في تجمعها الخاص، ويتم دمج التجمعات معًا بشكل متتالي. تحدد معايير الربط المقياس المستخدم لاستراتيجية الدمج:</p>
<ul class="simple">
<li><p><strong>Ward</strong> تقلل من مجموع مربعات الاختلافات داخل جميع التجمعات. إنه نهج لتقليل التباين، وهو بهذا المعنى مشابه لدالة الهدف k-means ولكن تم التعامل معه باستخدام نهج تسلسلي هرمي.</p></li>
<li><p><strong>Maximum</strong> أو الربط الكامل يقلل المسافة القصوى بين الملاحظات في أزواج من التجمعات.</p></li>
<li><p><strong>Average linkage</strong> يقلل متوسط المسافات بين جميع الملاحظات في أزواج من التجمعات.</p></li>
<li><p><strong>Single linkage</strong> تقليل المسافة بين أقرب الملاحظات في أزواج من التجمعات.</p></li>
</ul>
<p>يمكن لـ class: ‘AgglomerativeClustering’ أيضًا أن يتوسع ليشمل عددًا كبيرًا من العينات عند استخدامه بشكل مشترك مع مصفوفة الاتصال، ولكنه مكلف من الناحية الحسابية عندما لا يتم إضافة أي قيود اتصال بين العينات: فهو ينظر في كل خطوة إلى جميع عمليات الدمج الممكنة.</p>
<p>يستخدم class: ‘FeatureAgglomeration’ التجميع التسلسلي لدمج الميزات التي تبدو متشابهة جدًا، مما يقلل عدد الميزات. إنه أداة لخفض الأبعاد، راجع ref: ‘data_reduction’.</p>
</section>
<section id="ward-complete-average-single-linkage">
<h3><span class="section-number">2.9.2.3. </span>أنواع مختلفة من الروابط: Ward وcomplete وaverage وsingle linkage<a class="headerlink" href="#ward-complete-average-single-linkage" title="Link to this heading">#</a></h3>
<p>يدعم class: ‘AgglomerativeClustering’ استراتيجيات الربط Ward وsingle وaverage وcomplete.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_linkage_comparison.html"><img alt="../_images/sphx_glr_plot_linkage_comparison_001.png" src="../_images/sphx_glr_plot_linkage_comparison_001.png" style="width: 589.1px; height: 623.5px;" />
</a>
<p>لدى التجميع التسلسلي سلوك “الغني يزداد ثراءً” الذي يؤدي إلى أحجام مجموعات غير متساوية. وفي هذا الصدد، فإن الربط الفردي هو الأسوأ، وWard يعطي أكثر الأحجام انتظامًا. ومع ذلك، لا يمكن تغيير الانجذاب (أو المسافة المستخدمة في التجميع) مع Ward، وبالتالي بالنسبة للمقاييس غير الإقليدية، فإن الربط المتوسط هو بديل جيد. يمكن حساب الربط الفردي، على الرغم من عدم متانته للبيانات الضجيج، بكفاءة كبيرة، وبالتالي يمكن أن يكون مفيدًا لتوفير التجميع الهرمي لمجموعات البيانات الأكبر. يمكن أيضًا أن يؤدي الربط الفردي أداءً جيدًا في البيانات غير الكروية.</p>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_digits_linkage.py’: استكشاف استراتيجيات الربط المختلفة في مجموعة بيانات حقيقية.</p></li>
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_linkage_comparison.py’: استكشاف استراتيجيات الربط المختلفة في مجموعات البيانات اللعبة.</p></li>
</ul>
</section>
<section id="id7">
<h3><span class="section-number">2.9.2.4. </span>تصور تسلسل هرمي للمجموعة<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>من الممكن تصور الشجرة التي تمثل الدمج الهرمي للمجموعات على شكل مخطط شجري. غالبًا ما يكون الفحص المرئي مفيدًا لفهم بنية البيانات، خاصة في حالة أحجام العينات الصغيرة.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_dendrogram.html"><img alt="auto_examples/cluster/images/sphpx_glr_plot_agglomerative_dendrogram_001.png" src="auto_examples/cluster/images/sphpx_glr_plot_agglomerative_dendrogram_001.png" />
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">/content/scikit-learn/doc/modules/clustering.rst</span>, line 444)</p>
<p>Cannot scale image!
  Could not get size from &quot;auto_examples/cluster/images/sphpx_glr_plot_agglomerative_dendrogram_001.png&quot;:
  [Errno 2] No such file or directory: 'auto_examples/cluster/images/sphpx_glr_plot_agglomerative_dendrogram_001.png'</p>
</aside>
</a>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_agglomerative_dendrogram.py’</p></li>
</ul>
</section>
<section id="id8">
<h3><span class="section-number">2.9.2.5. </span>إضافة قيود الاتصال<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>من الجوانب المهمة في class: ‘AgglomerativeClustering’ أنه يمكن إضافة قيود الاتصال إلى هذا الخوارزمية (يمكن دمج التجمعات المجاورة فقط معًا)، من خلال مصفوفة اتصال تحدد لكل عينة العينات المجاورة وفقًا لهيكل معين للبيانات. على سبيل المثال، في مثال swiss-roll أدناه، تمنع قيود الاتصال دمج النقاط التي لا تتواجد على swiss roll، وبالتالي تتجنب تكوين مجموعات تمتد عبر طيات متداخلة من swiss roll.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_ward_structured_vs_unstructured.html"><img alt="unstructured" src="../_images/sphx_glr_plot_ward_structured_vs_unstructured_001.png" style="width: 313.6px; height: 235.2px;" /></a> <a class="reference external" href="../auto_examples/cluster/plot_ward_structured_vs_unstructured.html"><img alt="structured" src="../_images/sphx_glr_plot_ward_structured_vs_unstructured_002.png" style="width: 313.6px; height: 235.2px;" /></a></strong></p><p>هذه القيود مفيدة لفرض بنية محلية معينة، ولكنها أيضًا تجعل الخوارزمية أسرع، خاصة عندما يكون عدد العينات كبيرًا.</p>
<p>يتم فرض قيود الاتصال عبر مصفوفة اتصال: مصفوفة scipy متفرقة تحتوي على عناصر فقط عند تقاطع صف وعمود مع مؤشرات مجموعة البيانات التي يجب أن تكون متصلة. يمكن بناء هذه المصفوفة من معلومات مسبقة: على سبيل المثال، قد ترغب في تجميع صفحات الويب عن طريق دمج الصفحات التي تحتوي على رابط يشير من واحدة إلى أخرى فقط. يمكن أيضًا تعلمه من البيانات، على سبيل المثال باستخدام sklearn.neighbors.kneighbors_graph لتقييد الدمج إلى أقرب جيران كما هو موضح في هذا المثال ref: ‘sphx_glr_auto_examples_cluster_plot_agglomerative_clustering.py’، أو باستخدام sklearn.feature_extraction.image.grid_to_graph للسماح فقط بدمج البكسلات المجاورة في صورة، كما هو الحال في مثال العملة ref: ‘sphx_glr_auto_examples_cluster_plot_coin_ward_segmentation.py’.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>قيود الاتصال مع الربط الفردي والمتوسط والكامل</p>
</div>
<p>يمكن أن تعزز قيود الاتصال وربط الربط الفردي أو الكامل أو المتوسط جانب “الغني يزداد ثراءً” في التجميع التسلسلي، خاصة إذا تم بناؤها باستخدام sklearn.neighbors.kneighbors_graph. في حد عدد صغير من التجمعات، فإنها تميل إلى إعطاء عدد قليل من المجموعات المشغولة بشكل كبير ومجموعات فارغة تقريبًا. (انظر المناقشة في ref: ‘sphx_glr_auto_examples_cluster_plot_agglomerative_clustering.py’). الربط الفردي هو أكثر خيارات الارتباط هشاشة فيما يتعلق بهذه المسألة.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_001.png" src="../_images/sphx_glr_plot_agglomerative_clustering_001.png" style="width: 380.0px; height: 152.0px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_002.png" src="../_images/sphx_glr_plot_agglomerative_clustering_002.png" style="width: 380.0px; height: 152.0px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_003.png" src="../_images/sphx_glr_plot_agglomerative_clustering_003.png" style="width: 380.0px; height: 152.0px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_004.png" src="../_images/sphx_glr_plot_agglomerative_clustering_004.png" style="width: 380.0px; height: 152.0px;" />
</a>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_coin_ward_segmentation.py’: تجميع Ward لتقسيم صورة العملات إلى مناطق.</p></li>
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_ward_structured_vs_unstructured.py’: مثال على خوارزمية Ward على swiss-roll، ومقارنة النهج المنظمة مقابل غير المنظمة.</p></li>
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_feature_agglomeration_vs_univariate_selection.py’: مثال على تقليل الأبعاد مع تجميع الميزات بناءً على التجميع الهرمي لـ Ward.</p></li>
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_agglomerative_clustering.py’</p></li>
</ul>
</section>
<section id="id9">
<h3><span class="section-number">2.9.2.6. </span>تغيير المقياس<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<p>يمكن استخدام الربط الفردي والمتوسط والكامل مع مجموعة متنوعة من المسافات (أو الانجذابات)، وخاصة المسافة الإقليدية (l2)، ومسافة مانهاتن (أو Cityblock، أو l1)، والمسافة التكوينية، أو أي مصفوفة انجذاب محسوبة مسبقًا.</p>
<ul class="simple">
<li><p>غالبًا ما تكون المسافة l1 جيدة للميزات النادرة، أو الضوضاء النادرة: أي أن العديد من الميزات تكون صفرية، كما هو الحال في تعدين النصوص باستخدام تكرارات الكلمات النادرة.</p></li>
<li><p>المسافة التكوينية مثيرة للاهتمام لأنها لا تتأثر بالقياسات العالمية للإشارة.</p></li>
</ul>
<p>تتمثل الإرشادات الخاصة باختيار المقياس في استخدام المقياس الذي يزيد المسافة بين العينات في فئات مختلفة، ويقلل ذلك داخل كل فئة.</p>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_metrics_005.png" src="../_images/sphx_glr_plot_agglomerative_clustering_metrics_005.png" style="width: 204.8px; height: 153.6px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_metrics_006.png" src="../_images/sphx_glr_plot_agglomerative_clustering_metrics_006.png" style="width: 204.8px; height: 153.6px;" />
</a>
<a class="reference external image-reference" href="../auto_examples/cluster/plot_agglomerative_clustering_metrics.html"><img alt="../_images/sphx_glr_plot_agglomerative_clustering_metrics_007.png" src="../_images/sphx_glr_plot_agglomerative_clustering_metrics_007.png" style="width: 204.8px; height: 153.6px;" />
</a>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p>ref: ‘sphx_glr_auto_examples_cluster_plot_agglomerative_clustering_metrics.py’</p></li>
</ul>
</section>
<section id="id10">
<h3><span class="section-number">2.9.2.7. </span>K-Means ثنائي القسمة<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<p id="bisect-k-means">class: ‘BisectingKMeans’ هو متغير تكراري من class: ‘KMeans’، باستخدام التجميع الهرمي التقسيمي. بدلاً من إنشاء جميع النقط المركزية مرة واحدة، يتم اختيار النقط المركزية تدريجيًا بناءً على تجميع سابق: يتم تقسيم مجموعة إلى مجموعتين جديدتين بشكل متكرر حتى يتم الوصول إلى عدد المجموعات المستهدفة.</p>
<p>class: ‘BisectingKMeans’ أكثر كفاءة من class: ‘KMeans’ عندما يكون عدد المجموعات كبيرًا لأنه يعمل فقط على جزء فرعي من البيانات في كل تقسيم بينما يعمل class: ‘KMeans’ دائمًا على مجموعة البيانات بالكامل.</p>
<p>على الرغم من أن class: ‘BisectingKMeans’ لا يمكنه الاستفادة من مزايا التهيئة “k-means++” حسب التصميم، إلا أنه سيظل ينتج نتائج مماثلة لـ ‘KMeans (init=”k-means++”)’ من حيث الخمول بتكاليف حسابية أقل، ومن المحتمل أن ينتج نتائج أفضل من ‘KMeans’ مع تهيئة عشوائية.</p>
<p>هذا المتغير أكثر كفاءة من التجميع التسلسلي إذا كان عدد المجموعات صغيرًا مقارنة بعدد نقاط البيانات.</p>
<p>هذا المتغير لا ينتج أيضًا مجموعات فارغة.</p>
<dl class="simple">
<dt>هناك استراتيجيتان لاختيار المجموعة التي سيتم تقسيمها:</dt><dd><ul class="simple">
<li><p>“bisecting_strategy=”largest_cluster”” يحدد المجموعة التي تحتوي على أكبر عدد من النقاط</p></li>
<li><p>“bisecting_strategy=”biggest_inertia”” يحدد المجموعة ذات أكبر عطالة (المجموعة ذات أكبر خطأ مربع داخلها)</p></li>
</ul>
</dd>
</dl>
<p>يؤدي الاختيار حسب أكبر عدد من نقاط البيانات في معظم الحالات إلى نتائج دقيقة مثل الاختيار حسب العطالة وهو أسرع (خاصة بالنسبة لعدد أكبر من نقاط البيانات، حيث قد يكون حساب الخطأ مكلفًا).</p>
<p>سيؤدي الاختيار حسب أكبر عدد من نقاط البيانات أيضًا إلى إنتاج مجموعات ذات أحجام متشابهة في حين أن K-Means معروف بإنتاج مجموعات ذات أحجام مختلفة.</p>
<p>يمكن رؤية الفرق بين K-Means ثنائي القسمة وK-Means العادي في المثال ref: ‘sphx_glr_auto_examples_cluster_plot_bisect_kmeans.py’.
بينما يميل خوارزم K-Means العادي إلى إنشاء مجموعات غير مرتبطة، فإن المجموعات من K-Means ثنائي القسمة منظمة جيدًا وتخلق تسلسل هرمي واضح.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-6">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-6" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">“مقارنة بين تقنيات تجميع المستندات”
<a class="reference external" href="http://www.philippe-fournier-viger.com/spmf/bisectingkmeans.pdf">http://www.philippe-fournier-viger.com/spmf/bisectingkmeans.pdf</a> مايكل
شتاينباخ، جورج كاريبيس وفيبين كومار، قسم علوم الكمبيوتر والهندسة، جامعة مينيسوتا (يونيو 2000)</p></li>
<li><p class="sd-card-text">“تحليل أداء خوارزميات K-Means وBisecting K-Means في بيانات سجل الويب”
<a class="reference external" href="https://ijeter.everscience.org/Manuscripts/Volume-4/Issue-8/Vol-4-issue-8-M-23.pdf">https://ijeter.everscience.org/Manuscripts/Volume-4/Issue-8/Vol-4-issue-8-M-23.pdf</a>
K.Abirami and Dr.P.Mayilvahanan، المجلة الدولية لتقنيات الاختراق (IJETER) المجلد 4، العدد 8، (أغسطس 2016)</p></li>
<li><p class="sd-card-text">“خوارزمية Bisecting K-means استنادًا إلى K-valued Self-determining و
تحسين مركز التجميع ”
<a class="reference external" href="http://www.jcomputers.us/vol13/jcp1306-01.pdf">http://www.jcomputers.us/vol13/jcp1306-01.pdf</a> جيان دي، شينيو جو مدرسة
التحكم في الكمبيوتر وهندسة الكمبيوتر، جامعة شمال الصين للكهرباء،
باودينغ، خبي، الصين (أغسطس 2017)</p></li>
</ul>
</div>
</details><p id="dbscan">DBSCAN
يرى خوارزم <code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code> التجمعات على أنها مناطق ذات كثافة عالية تفصلها مناطق ذات كثافة منخفضة. وبسبب هذا الرأي العام إلى حد ما، يمكن أن تكون التجمعات التي يجدُها DBSCAN ذات أشكال مختلفة، على عكس k-means الذي يفترض أن التجمعات ذات شكل محدب. والمكون المركزي لخوارزم DBSCAN هو مفهوم <em>العينات الأساسية</em>، والتي هي عينات موجودة في مناطق ذات كثافة عالية. وبالتالي، فإن التجمع هو مجموعة من العينات الأساسية، وكل منها قريب من الآخر (يتم قياسه بواسطة بعض مقاييس المسافة) ومجموعة من العينات غير الأساسية القريبة من عينة أساسية (ولكنها ليست عينات أساسية بنفسها). هناك معياران للخوارزمية، وهما <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> و <code class="docutils literal notranslate"><span class="pre">eps</span></code>، اللذان يحددان رسميًا ما نعنيه عندما نقول <em>كثيف</em>. تشير القيمة الأعلى لـ <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> أو القيمة الأدنى لـ <code class="docutils literal notranslate"><span class="pre">eps</span></code> إلى كثافة أعلى ضرورية لتشكيل تجمع.</p>
<p>وبشكل أكثر رسمية، نُعرِّف العينة الأساسية على أنها عينة في مجموعة البيانات بحيث يوجد <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> من العينات الأخرى ضمن مسافة <code class="docutils literal notranslate"><span class="pre">eps</span></code>، والتي يتم تعريفها على أنها <em>جيران</em> العينة الأساسية. وهذا يخبرنا بأن العينة الأساسية موجودة في منطقة كثيفة من فضاء المتجهات. والتجمع هو مجموعة من العينات الأساسية التي يمكن بناؤها عن طريق أخذ عينة أساسية بشكل متكرر، وإيجاد جميع جيرانها من العينات الأساسية، وإيجاد جميع جيران تلك العينات الأساسية، وهكذا. كما أن للتجمع مجموعة من العينات غير الأساسية، والتي هي عينات مجاورة لعينة أساسية في التجمع ولكنها ليست عينات أساسية بنفسها. وبداهةً، توجد هذه العينات على أطراف التجمع.</p>
<p>أي عينة أساسية هي جزء من تجمع، بحكم التعريف. وأي عينة ليست عينة أساسية، وتبعد مسافة لا تقل عن <code class="docutils literal notranslate"><span class="pre">eps</span></code> عن أي عينة أساسية، تعتبر من قبل الخوارزمية قيمة شاذة.</p>
<p>في حين أن معيار <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> يتحكم بشكل أساسي في مدى تسامح الخوارزمية مع الضوضاء (قد يكون من المستحسن زيادة هذا المعيار في مجموعات البيانات الضخمة والمليئة بالضوضاء)، فإن معيار <code class="docutils literal notranslate"><span class="pre">eps</span></code> <em>حاسم لاختيار القيمة المناسبة</em> لمجموعة البيانات ووظيفة المسافة ولا يمكن عادةً تركه بالقيمة الافتراضية. فهو يتحكم في الجوار المحلي للنقاط. فعندما تكون القيمة المختارة صغيرة جدًا، لن يتم تجميع معظم البيانات على الإطلاق (وسيتم تصنيفها على أنها “-1” للضوضاء). وعندما تكون القيمة المختارة كبيرة جدًا، فإنها تتسبب في دمج التجمعات القريبة في تجمع واحد، وفي النهاية يتم إرجاع مجموعة البيانات بأكملها كتجمع واحد. وقد نوقشت بعض قواعد الاختيار لهذا المعيار في الأدبيات، على سبيل المثال، استنادًا إلى انحناء في رسم المسافات الأقرب للجيران (كما هو موضح في المراجع أدناه).</p>
<p>في الشكل أدناه، يشير اللون إلى عضوية التجمع، مع وجود دوائر كبيرة تشير إلى العينات الأساسية التي وجدتها الخوارزمية. والدوائر الصغيرة هي عينات غير أساسية لا تزال جزءًا من تجمع. علاوة على ذلك، يتم الإشارة إلى القيم الشاذة بالنقاط السوداء أدناه.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_dbscan.html"><img alt="dbscan_results" src="../_images/sphx_glr_plot_dbscan_002.png" style="width: 320.0px; height: 240.0px;" /></a></strong></p><p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py"><span class="std std-ref">Demo of DBSCAN clustering algorithm</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التنفيذ">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التنفيذ<a class="headerlink" href="#التنفيذ" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
</div>
</details><p>خوارزمية DBSCAN حتمية، وتولد دائمًا نفس التجمعات عندما يتم إعطاؤها نفس البيانات بنفس الترتيب. ومع ذلك، قد تختلف النتائج عندما يتم تقديم البيانات بترتيب مختلف. أولاً، على الرغم من أن العينات الأساسية ستُعين دائمًا في نفس التجمعات، إلا أن تسميات تلك التجمعات ستعتمد على الترتيب الذي يتم فيه العثور على تلك العينات في البيانات. ثانيًا والأهم من ذلك، أن التجمعات التي يتم تعيين العينات غير الأساسية لها قد تختلف اعتمادًا على ترتيب البيانات. وهذا يحدث عندما تكون المسافة بين عينة غير أساسية وعينتين أساسيتين في تجمعين مختلفين أقل من <code class="docutils literal notranslate"><span class="pre">eps</span></code>. وبحسب عدم المساواة المثلثية، يجب أن تكون هاتان العينتان الأساسيتان متباعدتين بمسافة أكبر من <code class="docutils literal notranslate"><span class="pre">eps</span></code>، أو ستكونان في نفس التجمع. ويتم تعيين العينة غير الأساسية إلى التجمع الذي يتم إنشاؤه أولاً في تمرير عبر البيانات، وبالتالي ستعتمد النتائج على ترتيب البيانات.</p>
<p>يستخدم التنفيذ الحالي أشجار الكرة والأشجار kd لتحديد جوار النقاط، مما يتجنب حساب مصفوفة المسافة الكاملة (كما كان يتم في إصدارات scikit-learn السابقة للإصدار 0.14). ويتم الاحتفاظ بإمكانية استخدام المقاييس المخصصة؛ للتفاصيل، راجع <code class="xref py py-class docutils literal notranslate"><span class="pre">NearestNeighbors</span></code>.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="استهلاك-الذاكرة-لأحجام-العينات-الكبيرة">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">استهلاك الذاكرة لأحجام العينات الكبيرة<a class="headerlink" href="#استهلاك-الذاكرة-لأحجام-العينات-الكبيرة" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
</div>
</details><p>هذا التنفيذ غير فعال في استخدام الذاكرة بشكل افتراضي لأنه يقوم ببناء مصفوفة تشابه ثنائية كاملة في حالة عدم إمكانية استخدام الأشجار kd أو أشجار الكرة (على سبيل المثال، مع المصفوفات المتناثرة). وستستهلك هذه المصفوفة <span class="math notranslate nohighlight">\(n^2\)</span> من الفاصلات العائمة. وهناك آليتان للالتفاف حول هذا الأمر:</p>
<ul class="simple">
<li><p>استخدام تجميع <a class="reference internal" href="#optics"><span class="std std-ref">OPTICS</span></a> بالاقتران مع طريقة <code class="docutils literal notranslate"><span class="pre">extract_dbscan</span></code>. يحسب تجميع OPTICS أيضًا مصفوفة ثنائية كاملة، ولكنه يحتفظ بصف واحد فقط في الذاكرة في كل مرة (تعقيد الذاكرة n).</p></li>
<li><p>يمكن حساب مخطط الجوار الإشعاعي المتناثر مسبقًا بطريقة فعالة من حيث الذاكرة، ويمكن تشغيل DBSCAN فوق هذا المخطط باستخدام <code class="docutils literal notranslate"><span class="pre">metric='precomputed'</span></code>. راجع <code class="xref py py-meth docutils literal notranslate"><span class="pre">sklearn.neighbors.NearestNeighbors.radius_neighbors_graph</span></code>.</p></li>
<li><p>يمكن ضغط مجموعة البيانات، إما عن طريق إزالة المكررات الدقيقة إذا كانت موجودة في بياناتك، أو عن طريق استخدام BIRCH. بعد ذلك، سيكون لديك عدد صغير نسبيًا من الممثلين لعدد كبير من النقاط. يمكنك بعد ذلك توفير <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> عند ملاءمة DBSCAN.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-7">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-7" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
</div>
</details><ul class="simple">
<li><p><a class="reference external" href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf">A Density-Based Algorithm for Discovering Clusters in Large Spatial
Databases with Noise</a>
Ester, M., H. P. Kriegel, J. Sander, and X. Xu, In Proceedings of the 2nd
International Conference on Knowledge Discovery and Data Mining, Portland, OR,
AAAI Press, pp. 226-231. 1996</p></li>
<li><p><a class="reference external" href="https://doi.org/10.1145/3068335">DBSCAN revisited, revisited: why and how you should (still) use DBSCAN.</a> Schubert, E., Sander, J., Ester, M., Kriegel, H. P., &amp; Xu,
X. (2017). In ACM Transactions on Database Systems (TODS), 42(3), 19.</p></li>
</ul>
</section>
</section>
<section id="hdbscan">
<span id="id11"></span><h2><span class="section-number">2.9.3. </span>HDBSCAN<a class="headerlink" href="#hdbscan" title="Link to this heading">#</a></h2>
<p>يمكن اعتبار خوارزم <code class="xref py py-class docutils literal notranslate"><span class="pre">HDBSCAN</span></code> امتدادًا لخوارزم <code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">OPTICS</span></code>. وعلى وجه التحديد، يفترض <code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code> أن معيار التجميع (أي متطلبات الكثافة) <em>متجانس عالميًا</em>. وبعبارة أخرى، قد يجد <code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code> صعوبة في التقاط التجمعات ذات الكثافات المختلفة بنجاح. ويخفف <code class="xref py py-class docutils literal notranslate"><span class="pre">HDBSCAN</span></code> من هذا الافتراض ويستكشف جميع مقاييس الكثافة الممكنة عن طريق بناء تمثيل بديل لمشكلة التجميع.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>تم تكييف هذا التنفيذ من التنفيذ الأصلي لخوارزمية HDBSCAN، <a class="reference external" href="https://github.com/scikit-learn-contrib/hdbscan">scikit-learn-contrib/hdbscan</a> استنادًا إلى <a class="reference internal" href="#lj2017" id="id12"><span>[LJ2017]</span></a>.</p>
</div>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_hdbscan.html#sphx-glr-auto-examples-cluster-plot-hdbscan-py"><span class="std std-ref">Demo of HDBSCAN clustering algorithm</span></a></p></li>
</ul>
<section id="id13">
<h3><span class="section-number">2.9.3.1. </span>مخطط إمكانية الوصول المتبادل<a class="headerlink" href="#id13" title="Link to this heading">#</a></h3>
<p>يحدد HDBSCAN أولاً <span class="math notranslate nohighlight">\(d_c(x_p)\)</span>، <em>المسافة الأساسية</em> لعينة <span class="math notranslate nohighlight">\(x_p\)</span>، على أنها المسافة إلى أقرب جار <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> لها، بما في ذلك نفسها. على سبيل المثال، إذا كان <code class="docutils literal notranslate"><span class="pre">min_samples=5</span></code> وكانت <span class="math notranslate nohighlight">\(x_*\)</span> هي أقرب جار خامس لـ <span class="math notranslate nohighlight">\(x_p\)</span>، فإن المسافة الأساسية هي:</p>
<div class="math notranslate nohighlight">
\[d_c(x_p)=d(x_p, x_*).\]</div>
<p>بعد ذلك، يحدد <span class="math notranslate nohighlight">\(d_m(x_p, x_q)\)</span>، <em>المسافة القابلة للوصول المتبادلة</em> لنقطتين <span class="math notranslate nohighlight">\(x_p, x_q\)</span>، على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[d_m(x_p, x_q) = \max\{d_c(x_p), d_c(x_q), d(x_p, x_q)\}\]</div>
<p>يسمح لنا هذان المفهومان ببناء <em>مخطط إمكانية الوصول المتبادل</em> <span class="math notranslate nohighlight">\(G_{ms}\)</span> المحدد لاختيار ثابت من <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> عن طريق ربط كل عينة <span class="math notranslate nohighlight">\(x_p\)</span> مع رأس من المخطط، وبالتالي تكون الحواف بين النقطتين <span class="math notranslate nohighlight">\(x_p, x_q\)</span> هي المسافة القابلة للوصول المتبادل <span class="math notranslate nohighlight">\(d_m(x_p, x_q)\)</span> بينهما. ويمكننا بناء مجموعات فرعية من هذا المخطط، والتي يُشار إليها بالرمز <span class="math notranslate nohighlight">\(G_{ms,\varepsilon}\)</span>، عن طريق إزالة أي حواف ذات قيمة أكبر من <span class="math notranslate nohighlight">\(\varepsilon\)</span>: من المخطط الأصلي. يتم في هذه المرحلة وضع علامة على أي نقاط تكون مسافتها الأساسية أقل من <span class="math notranslate nohighlight">\(\varepsilon\)</span>: على أنها ضوضاء. بعد ذلك، يتم تجميع النقاط المتبقية عن طريق إيجاد المكونات المتصلة لهذا المخطط المُقَلَّم.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>إن إيجاد المكونات المتصلة لمخطط مُقَلَّم <span class="math notranslate nohighlight">\(G_{ms,\varepsilon}\)</span> يعادل تشغيل DBSCAN* مع <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> و <span class="math notranslate nohighlight">\(\varepsilon\)</span>. DBSCAN* هو نسخة معدلة قليلاً من DBSCAN مذكورة في <a class="reference internal" href="#cm2013" id="id14"><span>[CM2013]</span></a>.</p>
</div>
</section>
<section id="id15">
<h3><span class="section-number">2.9.3.2. </span>التجميع الهرمي<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<p>يمكن اعتبار HDBSCAN خوارزمية تقوم بتنفيذ التجميع DBSCAN* عبر جميع القيم <span class="math notranslate nohighlight">\(\varepsilon\)</span>. وكما ذُكر سابقًا، فإن هذا يعادل إيجاد المكونات المتصلة لمخططات إمكانية الوصول المتبادل لجميع قيم <span class="math notranslate nohighlight">\(\varepsilon\)</span>. وللقيام بذلك بكفاءة، يستخرج HDBSCAN أولاً شجرة تغطية دنيا (MST) من مخطط إمكانية الوصول المتبادل المتصل بالكامل، ثم يقطع حواف الشجرة ذات الأوزان الأعلى بشكل جشع. وفيما يلي مخطط عام لخوارزمية HDBSCAN:</p>
<ol class="arabic simple">
<li><p>استخراج شجرة تغطية دنيا (MST) من <span class="math notranslate nohighlight">\(G_{ms}\)</span>.</p></li>
<li><p>توسيع شجرة التغطية الدنيا عن طريق إضافة “حافة ذاتية” لكل رأس، مع وزن يساوي المسافة الأساسية للعينة الأساسية.</p></li>
<li><p>قم بتطبيق تسمية تجمع واحدة على شجرة التغطية الدنيا.</p></li>
<li><p>إزالة الحافة ذات الوزن الأكبر من شجرة التغطية الدنيا (يتم إزالة التعادل في نفس الوقت).</p></li>
<li><p>قم بتعيين تسميات التجمعات للمكونات المتصلة التي تحتوي على نقاط نهاية الحافة التي تمت إزالتها الآن. إذا لم يكن للمكون أي حواف على الأقل، يتم بدلاً من ذلك تعيين تسمية “null” له لوضع علامة عليه على أنه ضوضاء.</p></li>
<li><p>كرر الخطوتين 4 و5 حتى لا تكون هناك مكونات متصلة متبقية.</p></li>
</ol>
<p>وبالتالي، فإن HDBSCAN قادر على الحصول على جميع التقسيمات الممكنة التي يمكن تحقيقها بواسطة DBSCAN* لقيمة ثابتة من <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> بطريقة هرمية. وهذا يسمح لـ HDBSCAN بإجراء التجميع عبر كثافات متعددة، وبالتالي لم يعد بحاجة إلى إعطاء <span class="math notranslate nohighlight">\(\varepsilon\)</span> كمعيار. وبدلاً من ذلك، فإنه يعتمد فقط على اختيار <code class="docutils literal notranslate"><span class="pre">min_samples</span></code>، والذي يميل إلى أن يكون معيارًا أكثر متانة.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/cluster/plot_hdbscan.html"><img alt="hdbscan_ground_truth" src="../_images/sphx_glr_plot_hdbscan_005.png" style="width: 750.0px; height: 300.0px;" /></a></strong></p><p class="centered">
<strong><a class="reference internal" href="auto_examples/cluster/images/sphx_glr_plot_hdbscan_007.png:target,../auto_examples/cluster/plot_hdbscan.html"><img alt="hdbscan_results" src="auto_examples/cluster/images/sphx_glr_plot_hdbscan_007.png:target,../auto_examples/cluster/plot_hdbscan.html" /></a></strong></p><p>يمكن تحسين HDBSCAN بمعيار إضافي هو <code class="docutils literal notranslate"><span class="pre">min_cluster_size</span></code> الذي يحدد أنه أثناء التجميع الهرمي، يتم اعتبار المكونات التي تحتوي على عدد من العينات أقل من <code class="docutils literal notranslate"><span class="pre">minimum_cluster_size</span></code> على أنها ضوضاء. وفي الممارسة العملية، يمكن تعيين <code class="docutils literal notranslate"><span class="pre">minimum_cluster_size</span> <span class="pre">=</span> <span class="pre">min_samples</span></code> لربط المعيارين وتبسيط مساحة المعايير.</p>
<aside class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<span class="docutils literal">/content/scikit-learn/doc/modules/clustering.rst</span>, line 669)</p>
<p>Cannot scale image!
  Could not get size from &quot;auto_examples/cluster/images/sphx_glr_plot_hdbscan_007.png:target,../auto_examples/cluster/plot_hdbscan.html&quot;:
  [Errno 2] No such file or directory: 'auto_examples/cluster/images/sphx_glr_plot_hdbscan_007.png:target,../auto_examples/cluster/plot_hdbscan.html'</p>
</aside>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="cm2013" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id14">CM2013</a><span class="fn-bracket">]</span></span>
<p>Campello, R.J.G.B., Moulavi, D., Sander, J. (2013). Density-Based
Clustering Based on Hierarchical Density Estimates. In: Pei, J., Tseng, V.S.,
Cao, L., Motoda, H., Xu, G. (eds) Advances in Knowledge Discovery and Data
Mining. PAKDD 2013. Lecture Notes in Computer Science(), vol 7819. Springer,
Berlin, Heidelberg. <a class="reference external" href="https://doi.org/10.1007/978-3-642-37456-2_14">Density-Based Clustering Based on Hierarchical
Density Estimates</a></p>
</div>
<div class="citation" id="lj2017" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id12">LJ2017</a><span class="fn-bracket">]</span></span>
<p>L. McInnes and J. Healy, (2017). Accelerated Hierarchical Density
Based Clustering. In: IEEE International Conference on Data Mining Workshops
(ICDMW), 2017, pp. 33-42. <a class="reference external" href="https://doi.org/10.1109/ICDMW.2017.12">Accelerated Hierarchical Density Based
Clustering</a></p>
</div>
</div>
<p id="optics">OPTICS
ترجمة النص المنسق بتنسيق RST إلى اللغة العربية:</p>
<p>خوارزمية OPTICS <code class="xref py py-class docutils literal notranslate"><span class="pre">OPTICS</span></code> تشترك في العديد من أوجه التشابه مع خوارزمية <code class="xref py py-class docutils literal notranslate"><span class="pre">DBSCAN</span></code>، ويمكن اعتبارها تعميما لخوارزمية DBSCAN التي تُرخي متطلب “إبسيلون - epsilon” من قيمة واحدة إلى نطاق من القيم. والفرق الرئيسي بين DBSCAN وOPTICS هو أن خوارزمية OPTICS تبني مخطط “الوصول - reachability” reachability، والذي يعيّن لكل عينة مسافة “الوصول - reachability” وقيمة ضمن خاصية “ترتيب - ordering” للعنقود؛ ويتم تعيين هاتين الخاصيتين عندما يتم ضبط النموذج، ويتم استخدامهما لتحديد عضوية العنقود. إذا تم تشغيل خوارزمية OPTICS بالقيمة الافتراضية “غير المنتهية - infinity” المحددة لبارامتر “ماكس إبسيلون - max_eps”، فيمكن حينها إجراء استخراج العنقود على طريقة DBSCAN بشكل متكرر في زمن خطي لأي قيمة “إبسيلون - epsilon” باستخدام طريقة “كلستر أوبتكس دي بي سكان - cluster_optics_dbscan”. ويؤدي تعيين “ماكس إبسيلون - max_eps” إلى قيمة أقل إلى الحصول على أزمنة تشغيل أقصر، ويمكن اعتبارها نصف القطر الأقصى للجوار من كل نقطة للعثور على نقاط أخرى يمكن الوصول إليها.</p>
<p>تسمح مسافات “الوصول - reachability” التي تولدها خوارزمية OPTICS باستخراج العنقود متغير الكثافة ضمن مجموعة بيانات واحدة. وكما هو موضح في المخطط أعلاه، فإن الجمع بين مسافات “الوصول - reachability” وترتيب مجموعة البيانات ينتج مخطط “الوصول - reachability”، حيث يمثل المحور Y كثافة النقاط، ويتم ترتيب النقاط بحيث تكون النقاط القريبة متجاورة. وتنتج عملية “قطع” مخطط “الوصول - reachability” عند قيمة واحدة نتائج مشابهة لخوارزمية DBSCAN؛ حيث يتم تصنيف جميع النقاط أعلى “القطع - cut” كضجيج، وكل مرة يكون فيها انقطاع عند القراءة من اليسار إلى اليمين تشير إلى عنقود جديد. وتنظر عملية استخراج العنقود الافتراضية في خوارزمية OPTICS إلى المنحدرات الحادة داخل المخطط للعثور على العناقيد، ويمكن للمستخدم تحديد ما يعتبر منحدرًا حادًا باستخدام بارامتر “كسي - xi”. وهناك أيضًا إمكانيات أخرى للتحليل على المخطط نفسه، مثل إنشاء تمثيلات هرمية للبيانات من خلال مخططات “الوصول - reachability” الشجرية، ويمكن الوصول إلى تسلسل العناقيد الذي تكشفه الخوارزمية من خلال بارامتر “كلستر هايراركي - cluster_hierarchy”. وقد تم تلوين المخطط أعلاه برموز لونية بحيث تتطابق ألوان العنقود في الفضاء ثنائي الأبعاد مع عناقيد المقاطع الخطية في مخطط “الوصول - reachability”. لاحظ أن العنقودين الأزرق والأحمر متجاورين في مخطط “الوصول - reachability”، ويمكن تمثيلهما هرميًا كأطفال لعنقود أبوي أكبر.</p>
<p>الأمثلة:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_optics.html#sphx-glr-auto-examples-cluster-plot-optics-py"><span class="std std-ref">Demo of OPTICS clustering algorithm</span></a></p></li>
</ul>
<p>المقارنة مع DBSCAN:</p>
<p>النتائج من طريقة “كلستر أوبتكس دي بي سكان - cluster_optics_dbscan” في خوارزمية OPTICS وخوارزمية DBSCAN متشابهة جدًا، ولكنها ليست متطابقة دائمًا؛ وتحديدًا، في تسمية نقاط المحيط والضجيج. ويرجع ذلك جزئيًا إلى أن أولى العينات من كل منطقة كثيفة تتم معالجتها بواسطة خوارزمية OPTICS يكون لها قيمة “وصول - reachability” كبيرة بينما تكون قريبة من نقاط أخرى في منطقتها، وبالتالي يتم تصنيفها في بعض الأحيان كضجيج بدلاً من نقاط محيطية. ويؤثر ذلك على النقاط المجاورة عندما يتم اعتبارها مرشحة ليتم تصنيفها كنقاط محيطية أو ضجيج.</p>
<p>لاحظ أنه بالنسبة لأي قيمة واحدة من “إبسيلون - epsilon”، فإن خوارزمية DBSCAN تميل إلى أن يكون لها زمن تشغيل أقصر من خوارزمية OPTICS؛ ومع ذلك، بالنسبة للتشغيلات المتكررة عند قيم “إبسيلون - epsilon” المتغيرة، فقد يتطلب تشغيل واحد من خوارزمية OPTICS وقت تشغيل تراكمي أقل من خوارزمية DBSCAN. ومن المهم أيضًا ملاحظة أن إخراج خوارزمية OPTICS يكون قريبًا من خوارزمية DBSCAN فقط إذا كانت قيمتا “إبسيلون - epsilon” و”ماكس إبسيلون - max_eps” قريبتين.</p>
<p>التعقيد الحسابي:</p>
<p>تُستخدم أشجار الفهرسة المكانية لتجنب حساب مصفوفة المسافة الكاملة، والسماح باستخدام الذاكرة بكفاءة على مجموعات كبيرة من العينات. ويمكن توفير مقاييس المسافة المختلفة عبر كلمة “متريك - metric”.</p>
<p>بالنسبة لمجموعات البيانات الكبيرة، يمكن الحصول على نتائج مماثلة (ولكنها ليست متطابقة) عبر <code class="xref py py-class docutils literal notranslate"><span class="pre">HDBSCAN</span></code>. ويتم تنفيذ خوارزمية HDBSCAN على عدة خيوط، ولديها تعقيد زمني أفضل من خوارزمية OPTICS، على حساب أسوأ في مقياس الذاكرة. وبالنسبة لمجموعات البيانات الكبيرة للغاية التي تستنفد ذاكرة النظام باستخدام خوارزمية HDBSCAN، فإن خوارزمية OPTICS ستحافظ على مقياس ذاكرة <span class="math notranslate nohighlight">\(n\)</span> (على عكس <span class="math notranslate nohighlight">\(n^2\)</span>)؛ ومع ذلك، فمن المحتمل أن تكون هناك حاجة لضبط بارامتر “ماكس إبسيلون - max_eps” لتقديم حل في وقت معقول.</p>
<p>المرجع:</p>
<ul class="simple">
<li><p>“OPTICS: ordering points to identify the clustering structure.” Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel, and Jörg Sander. In ACM Sigmod Record, vol. 28, no. 2, pp. 49-60. ACM, 1999.</p></li>
</ul>
<p>BIRCH:</p>
<p>تبني خوارزمية <code class="xref py py-class docutils literal notranslate"><span class="pre">Birch</span></code> شجرة تسمى شجرة ميزات التجميع Clustering Feature Tree (CFT) للبيانات المعطاة. ويتم بشكل أساسي ضغط البيانات إلى مجموعة من عقد ميزات التجميع Clustering Feature nodes (CF Nodes). ولعقد CF عدد من العناقيد الفرعية تسمى عناقيد ميزات التجميع الفرعية Clustering Feature subclusters (CF Subclusters)، ويمكن أن يكون لعناقيد CF الفرعية هذه الموجودة في عقد CF غير الطرفية عقد CF كأطفال.</p>
<p>تحتفظ عناقيد CF الفرعية بالمعلومات الضرورية للتجميع والتي تمنع الحاجة إلى الاحتفاظ بمجموعة البيانات الكاملة في الذاكرة. وتشمل هذه المعلومات:</p>
<ul class="simple">
<li><p>عدد العينات في العناقيد الفرعية.</p></li>
<li><p>المجموع الخطي - وهو متجه متعدد الأبعاد يحمل مجموع جميع العينات.</p></li>
<li><p>مجموع المربعات - مجموع القيم مربعة للمعيار L2 لجميع العينات.</p></li>
<li><p>المركز - لتجنب إعادة حساب المجموع الخطري / عدد العينات.</p></li>
<li><p>القيمة مربعة للمعيار لمراكز العناقيد الفرعية.</p></li>
</ul>
<p>لدى خوارزمية BIRCH معاملان، العتبة وعامل التفرع. ويحد عامل التفرع من عدد العناقيد الفرعية في العقدة، وتحد العتبة من المسافة بين العينة الداخلة والعناقيد الفرعية الموجودة.</p>
<p>يمكن اعتبار هذه الخوارزمية مثالاً على طريقة تقليل البيانات، حيث تقلل البيانات المدخلة إلى مجموعة من العناقيد الفرعية التي يتم الحصول عليها مباشرة من أوراق شجرة CFT. ويمكن معالجة هذه البيانات المخفضة بشكل أكبر من خلال تغذيتها في مجمع عناقيد عالمي. ويمكن تعيين هذا المجمع العنقودي العالمي بواسطة “إن كلسترز - n_clusters”. إذا تم تعيين “إن كلسترز - n_clusters” إلى None، فسيتم قراءة العناقيد الفرعية من الأوراق مباشرة، وإلا فإن خطوة التجميع العنقودي العالمي تقوم بتسمية هذه العناقيد الفرعية إلى عناقيد عالمية (تسميات)، ويتم تعيين العينات إلى التسمية العالمية لأقرب عنقود فرعي.</p>
<p>وصف الخوارزمية:</p>
<ul class="simple">
<li><p>يتم إدخال عينة جديدة في جذر شجرة CF والتي هي عقدة CF. ثم يتم دمجها مع العناقيد الفرعية لجذر الشجرة، والتي يكون لها أصغر نصف قطر بعد الدمج، مع مراعاة شروط العتبة وعامل التفرع. إذا كان للعنقود الفرعي أي عقدة طفل، فيتم تكرار ذلك حتى يصل إلى ورقة. بعد العثور على أقرب عنقود فرعي في الورقة، يتم تحديث خصائص هذا العنقود الفرعي والعنقود الفرعي الأبوي بشكل متكرر.</p></li>
<li><p>إذا كان نصف قطر العنقود الفرعي الناتج عن دمج العينة الجديدة وأقرب عنقود فرعي أكبر من مربع العتبة وإذا كان عدد العناقيد الفرعية أكبر من عامل التفرع، فيتم تخصيص مساحة مؤقتة لهذه العينة الجديدة. ويتم أخذ أبعد عنقودين فرعيين وتقسيم العناقيد الفرعية إلى مجموعتين على أساس المسافة بين هاتين العنقودين الفرعيين.</p></li>
<li><p>إذا كانت لعقدة الانقسام الفرعي هذه عنقود فرعي أبوي وكان هناك مجال لعنقود فرعي جديد، فيتم تقسيم الأب إلى اثنين. إذا لم يكن هناك مجال، فيتم تقسيم هذه العقدة مرة أخرى إلى اثنين وتستمر العملية بشكل متكرر حتى تصل إلى الجذر.</p></li>
</ul>
<p>BIRCH أو MiniBatchKMeans:</p>
<ul class="simple">
<li><p>لا تتوسع خوارزمية BIRCH جيدًا إلى البيانات عالية الأبعاد. وكقاعدة عامة، إذا كان “إن فيجاز - n_features” أكبر من عشرين، فمن الأفضل عمومًا استخدام MiniBatchKMeans.</p></li>
<li><p>إذا كان عدد مثيلات البيانات بحاجة إلى التخفيض، أو إذا كان المرء يريد عددًا كبيرًا من العناقيد الفرعية كخطوة ما قبل المعالجة أو خلاف ذلك، فإن خوارزمية BIRCH أكثر فائدة من MiniBatchKMeans.</p></li>
</ul>
<p>كيفية استخدام “بارشال فيت - partial_fit”:</p>
<p>لتجنب حساب التجميع العالمي، يُنصح المستخدم بما يلي لكل مكالمة من “بارشال فيت - partial_fit”:</p>
<ol class="arabic simple">
<li><p>قم بتعيين “إن كلسترز - n_clusters” إلى None في البداية.</p></li>
<li><p>قم بتدريب جميع البيانات من خلال عدة مكالمات إلى “بارشال فيت - partial_fit”.</p></li>
<li><p>قم بتعيين “إن كلسترز - n_clusters” إلى قيمة مطلوبة باستخدام “برك.سيت بارامز(إن كلسترز=إن كلسترز)”.</p></li>
<li><p>قم أخيرًا بمكالمة “بارشال فيت - partial_fit” بدون وسائط، أي “برك.بارشال فيت()” والتي تقوم بالتجميع العنقودي العالمي.</p></li>
</ol>
<p>المراجع:</p>
<ul class="simple">
<li><p>Tian Zhang, Raghu Ramakrishnan, Maron Livny BIRCH: An efficient data clustering method for large databases. <a class="reference external" href="https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf">https://www.cs.sfu.ca/CourseCentral/459/han/papers/zhang96.pdf</a></p></li>
<li><p>Roberto Perdisci JBirch - Java implementation of BIRCH clustering algorithm <a class="reference external" href="https://code.google.com/archive/p/jbirch">https://code.google.com/archive/p/jbirch</a></p></li>
</ul>
<p>تقييم أداء التجميع:
تقييم أداء خوارزمية التجميع ليس بسيطًا مثل عد الأخطاء أو الدقة والاستدعاء لخوارزمية تصنيف إشرافية. على وجه الخصوص، يجب ألا يأخذ أي مقياس تقييم القيم المطلقة لعلامات التجميع في الاعتبار، ولكن بدلاً من ذلك، ما إذا كان هذا التجميع يحدد عمليات فصل البيانات المشابهة لبعض مجموعات الفئات الأساسية أو التي تفي ببعض الافتراضات بحيث يكون الأعضاء الذين ينتمون إلى نفس الفئة أكثر تشابهاً من أعضاء الفئات المختلفة وفقًا لبعض مقاييس التشابه.</p>
<p><strong>مؤشر راند</strong></p>
<p>نظرًا لمعرفة تعيينات الفئات الأساسية “labels_true” وتعيينات خوارزمية التجميع الخاصة بنا لنفس العينات “labels_pred”، فإن مؤشر راند (المعدل أو غير المعدل) هو دالة تقيس تشابه التعيينين، مع تجاهل التباديل:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.66...</span>
</pre></div>
</div>
<p>لا يضمن مؤشر راند الحصول على قيمة قريبة من 0.0 لعملية تسمية عشوائية. ويصحح مؤشر راند المعدل هذا الاحتمال ويعطي خط الأساس هذا.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.24...</span>
</pre></div>
</div>
<p>كما هو الحال مع جميع مقاييس التجميع، يمكنك تبديل 0 و1 في التسميات المتوقعة، وإعادة تسمية 2 إلى 3، والحصول على نفس النتيجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.24...</span>
</pre></div>
</div>
<p>علاوة على ذلك، كل من rand_score و adjusted_rand_score <strong>متناظران</strong>: لا يؤدي تبديل الحجة إلى تغيير النتائج. وبالتالي يمكن استخدامها كإجراءات <strong>توافقية</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="n">labels_true</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="n">labels_true</span><span class="p">)</span>
<span class="go">0.24...</span>
</pre></div>
</div>
<p>يتم تسجيل التسمية المثالية على أنها 1.0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="n">labels_true</span><span class="p">[:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>يكون للعلامات التي تتفق بشكل ضعيف (على سبيل المثال، التسميات المستقلة) درجات أقل، وبالنسبة لمؤشر راند المعدل، ستكون النتيجة سلبية أو قريبة من الصفر. ومع ذلك، بالنسبة لمؤشر راند غير المعدل، ستكون النتيجة أقل، ولكنها لن تكون بالضرورة قريبة من الصفر.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.39...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_rand_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">-0.07...</span>
</pre></div>
</div>
<p><strong>المزايا:</strong></p>
<ul class="simple">
<li><p><strong>قابلية التفسير</strong>: يتناسب مؤشر راند غير المعدل مع عدد أزواج العينات التي تحمل نفس التسميات في كل من “labels_pred” و”labels_true”، أو تكون مختلفة في كليهما.</p></li>
<li><p><strong>يحصل تعيين التسميات العشوائية (الموحدة) على مؤشر راند معدل قريب من 0.0</strong> لأي قيمة من “n_clusters” و”n_samples” (وهو ما لا يحدث مع مؤشر راند غير المعدل أو مقياس V، على سبيل المثال).</p></li>
<li><p><strong>النطاق المحدد</strong>: تشير القيم المنخفضة إلى التسميات المختلفة، وتشير مؤشرات التجميع المتشابهة إلى مؤشر راند مرتفع (معدل أو غير معدل)، و1.0 هو نتيجة التطابق المثالي. ويتراوح النطاق من [0، 1] لمؤشر راند غير المعدل ومن [-0.5، 1] لمؤشر راند المعدل.</p></li>
<li><p><strong>لا يتم إجراء أي افتراض حول بنية التجميع</strong>: يمكن استخدام مؤشر راند (المعدل أو غير المعدل) لمقارنة جميع أنواع خوارزميات التجميع، ويمكن استخدامه لمقارنة خوارزميات التجميع مثل k-means التي تفترض أشكال كتل متساوية الخواص مع نتائج خوارزميات التجميع الطيفي التي يمكنها العثور على مجموعات ذات أشكال “مطوية”.</p></li>
</ul>
<p><strong>العيوب:</strong></p>
<ul>
<li><p>على عكس القصور الذاتي، يتطلب مؤشر راند (المعدل أو غير المعدل) <strong>معرفة الفئات الأساسية</strong> التي نادرًا ما تكون متاحة في الممارسة العملية أو تتطلب تعيينًا يدويًا بواسطة معلّمي البيانات (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p>
<p>ومع ذلك، يمكن أيضًا استخدام مؤشر راند (المعدل أو غير المعدل) ككتلة بناء في إعداد غير خاضع للإشراف لمؤشر توافقي يمكن استخدامه لاختيار نموذج التجميع (TODO).</p>
</li>
<li><p><strong>يكون مؤشر راند غير المعدل قريبًا من 1.0</strong> حتى إذا اختلفت التجميعات نفسها بشكل كبير. ويمكن فهم ذلك عند تفسير مؤشر راند على أنه دقة تسمية أزواج العناصر الناتجة عن التجميعات: في الممارسة العملية، غالبًا ما تكون هناك أغلبية من أزواج العناصر التي يتم تعيينها لعلامة “مختلفة” في كل من التجميع المتوقع والتجميع الأساسي، مما يؤدي إلى نسبة عالية من علامات الأزواج المتفقة، والتي تؤدي بعد ذلك إلى نتيجة عالية.</p></li>
</ul>
<p><strong>أمثلة:</strong></p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html#sphx-glr-auto-examples-cluster-plot-adjusted-for-chance-measures-py"><span class="std std-ref">Adjustment for chance in clustering performance evaluation</span></a>: تحليل تأثير حجم مجموعة البيانات على قيمة مقاييس التجميع للتعيينات العشوائية.</p></li>
</ul>
<p><strong>الصيغة الرياضية:</strong></p>
<p>إذا كانت C هي تعيين فئة أساسية وK هي التجميع، دعنا نحدد a وb كما يلي:</p>
<ul class="simple">
<li><p>a، عدد أزواج العناصر الموجودة في نفس المجموعة في C وفي نفس المجموعة في K</p></li>
<li><p>b، عدد أزواج العناصر الموجودة في مجموعات مختلفة في C وفي مجموعات مختلفة في K</p></li>
</ul>
<p>يعطى مؤشر راند غير المعدل بعد ذلك بما يلي:</p>
<div class="math notranslate nohighlight">
\[\text{RI} = \frac{a + b}{C_2^{n_{samples}}}\]</div>
<p>حيث <span class="math notranslate nohighlight">\(C_2^{n_{samples}}\)</span> هو العدد الإجمالي لأزواج العناصر الممكنة في مجموعة البيانات. لا يهم إذا تم إجراء الحساب على أزواج مرتبة أو غير مرتبة طالما تم إجراء الحساب بشكل متسق.</p>
<p>ومع ذلك، لا يضمن مؤشر راند أن التعيينات العشوائية للتسميات ستحصل على قيمة قريبة من الصفر (خاصة إذا كان عدد التجميعات بنفس ترتيب الحجم مثل عدد العينات).</p>
<p>للتخفيف من هذا التأثير، يمكننا خصم القيمة المتوقعة لـ RI <span class="math notranslate nohighlight">\(E[\text{RI}]\)</span> لتعيينات التسميات العشوائية من خلال تعريف مؤشر راند المعدل كما يلي:</p>
<div class="math notranslate nohighlight">
\[\text{ARI} = \frac{\text{RI} - E[\text{RI}]}{\max(\text{RI}) - E[\text{RI}]}\]</div>
<p><strong>المراجع:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://link.springer.com/article/10.1007%2FBF01908075">مقارنة التقسيمات</a> L. Hubert and P.
Arabie، مجلة التصنيف 1985</p></li>
<li><p><a class="reference external" href="https://psycnet.apa.org/record/2004-17801-007">خصائص مؤشر راند المعدل لهبرت-أرابيا</a> D. Steinley، الأساليب النفسية 2004</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index">صفحة ويكيبيديا لمؤشر راند</a></p></li>
<li><p><a class="reference external" href="https://doi.org/10.1007/s11634-022-00491-w">مؤشر راند المعدل الأدنى لتجميعين بحجم معين، 2022، J. E. Chacón and A. I. Rastrojo</a></p></li>
</ul>
<p><strong>الدرجات المستندة إلى معلومات متبادلة</strong>
فيما يلي ترجمة لنص RST باللغة العربية مع اتباع التعليمات المذكورة:</p>
<p>نظرًا لمعرفة تعيينات فئة الحقيقة الأرضية <code class="docutils literal notranslate"><span class="pre">labels_true</span></code> وتعيينات خوارزمية التجميع الخاصة بنا لنفس العينات <code class="docutils literal notranslate"><span class="pre">labels_pred</span></code>، فإن <strong>معلومات التبادل</strong> هي دالة تقيس <strong>الاتفاق</strong> بين التعيينين، مع تجاهل التباديل. هناك نسختان معيّرتان مختلفتان من هذا المقياس، <strong>معلومات التبادل المطبعي (NMI)</strong> و <strong>معلومات التبادل المعدلة (AMI)</strong>. غالبًا ما يتم استخدام NMI في الأدبيات، بينما تم اقتراح AMI مؤخرًا وهو <strong>معياري ضد الصدفة</strong>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">0.22504...</span>
</pre></div>
</div>
<p>يمكنك تبديل 0 و 1 في التسميات المتوقعة، وإعادة تسمية 2 إلى 3 والحصول على نفس النتيجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">0.22504...</span>
</pre></div>
</div>
<p>جميع الدوال <code class="xref py py-func docutils literal notranslate"><span class="pre">mutual_info_score</span></code>، و <code class="xref py py-func docutils literal notranslate"><span class="pre">adjusted_mutual_info_score</span></code>، و <code class="xref py py-func docutils literal notranslate"><span class="pre">normalized_mutual_info_score</span></code> متماثلة: لا يؤدي تبديل الحجة إلى تغيير النتيجة. وبالتالي، يمكن استخدامها كـ <strong>إجراء توافقي</strong>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_pred</span><span class="p">,</span> <span class="n">labels_true</span><span class="p">)</span>  
<span class="go">0.22504...</span>
</pre></div>
</div>
<p>يتم تسجيل التسمية المثالية على أنها 1.0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="n">labels_true</span><span class="p">[:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">1.0</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">normalized_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">1.0</span>
</pre></div>
</div>
<p>هذا لا ينطبق على <code class="docutils literal notranslate"><span class="pre">mutual_info_score</span></code>، مما يجعل الحكم عليه أكثر صعوبة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">0.69...</span>
</pre></div>
</div>
<p>تكون التسميات السيئة (على سبيل المثال، التسميات المستقلة) ذات درجات غير موجبة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>  
<span class="go">-0.10526...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p><strong>تعيينات التسميات العشوائية (الموحدة) لها نتيجة AMI قريبة من 0.0</strong> لأي
قيمة من <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> و <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> (وهو ما لا يحدث في حالة معلومات التبادل الخام أو مقياس V على سبيل المثال).</p></li>
<li><p><strong>الحد الأعلى 1</strong>: تشير القيم القريبة من الصفر إلى أن تعييني التسمية مستقلان إلى حد كبير، في حين تشير القيم القريبة من واحد إلى وجود اتفاق كبير. علاوة على ذلك، تشير AMI التي تساوي 1 بالضبط إلى أن تعييني التسمية متساويان (مع أو بدون تبديل).</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul>
<li><p>على عكس القصور الذاتي، <strong>تتطلب المقاييس المستندة إلى معلومات التبادل معرفة</strong> بفئات الحقيقة الأرضية في حين أنها غير متوفرة عمليًا أو تتطلب تعيينًا يدويًا بواسطة الملاحظين البشريين (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p>
<p>ومع ذلك، يمكن أيضًا أن تكون المقاييس المستندة إلى معلومات التبادل مفيدة في الإعداد غير الخاضع للإشراف ككتلة بناء لمؤشر توافقي يمكن استخدامه لاختيار نموذج التجميع.</p>
</li>
<li><p>NMI و MI غير معدلين ضد الصدفة.</p></li>
</ul>
</aside>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html#sphx-glr-auto-examples-cluster-plot-adjusted-for-chance-measures-py"><span class="std std-ref">Adjustment for chance in clustering performance evaluation</span></a>: تحليل
تأثير حجم مجموعة البيانات على قيمة مقاييس التجميع لتعيينات عشوائية. يتضمن هذا المثال أيضًا مؤشر Rand المعدل.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">لنفترض تعييني تسمية (لنفس الأشياء N)، <span class="math notranslate nohighlight">\(U\)</span> و <span class="math notranslate nohighlight">\(V\)</span>. إن إنتروبيا الخاصة بهما هي مقدار عدم اليقين لمجموعة التقسيم، والتي يتم تحديدها على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[H(U) = - \sum_{i=1}^{|U|}P(i)\log(P(i))\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(P(i) = |U_i| / N\)</span> هو احتمال أن يقع كائن تم اختياره عشوائيًا من <span class="math notranslate nohighlight">\(U\)</span> في الفئة <span class="math notranslate nohighlight">\(U_i\)</span>. وبالمثل بالنسبة لـ <span class="math notranslate nohighlight">\(V\)</span>:</p>
<div class="math notranslate nohighlight">
\[H(V) = - \sum_{j=1}^{|V|}P'(j)\log(P'(j))\]</div>
<p class="sd-card-text">مع <span class="math notranslate nohighlight">\(P'(j) = |V_j| / N\)</span>. يتم حساب معلومات التبادل (MI) بين <span class="math notranslate nohighlight">\(U\)</span>
و <span class="math notranslate nohighlight">\(V\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\text{MI}(U, V) = \sum_{i=1}^{|U|}\sum_{j=1}^{|V|}P(i, j)\log\left(\frac{P(i,j)}{P(i)P'(j)}\right)\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(P(i, j) = |U_i \cap V_j| / N\)</span> هو احتمال أن يقع كائن
تم اختياره عشوائيًا في كل من الفئتين <span class="math notranslate nohighlight">\(U_i\)</span> و <span class="math notranslate nohighlight">\(V_j\)</span>.</p>
<p class="sd-card-text">ويمكن التعبير عنه أيضًا بصيغة عدد عناصر المجموعة:</p>
<div class="math notranslate nohighlight">
\[\text{MI}(U, V) = \sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \frac{|U_i \cap V_j|}{N}\log\left(\frac{N|U_i \cap V_j|}{|U_i||V_j|}\right)\]</div>
<p class="sd-card-text">يتم تعريف معلومات التبادل المطبعي على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\text{NMI}(U, V) = \frac{\text{MI}(U, V)}{\text{mean}(H(U), H(V))}\]</div>
<p class="sd-card-text">هذه القيمة من معلومات التبادل والمتغير المطبعي أيضًا غير معدلة للصدفة، ومن المحتمل أن تزيد مع زيادة عدد التسميات المختلفة
(التجمعات)، بغض النظر عن الكمية الفعلية “معلومات التبادل” بين تعيينات التسمية.</p>
<p class="sd-card-text">يمكن حساب القيمة المتوقعة لمعلومات التبادل باستخدام المعادلة التالية <a class="reference internal" href="#veb2009" id="id19"><span>[VEB2009]</span></a>. في هذه المعادلة، <span class="math notranslate nohighlight">\(a_i = |U_i|\)</span> (عدد
العناصر في <span class="math notranslate nohighlight">\(U_i\)</span>) و <span class="math notranslate nohighlight">\(b_j = |V_j|\)</span> (عدد العناصر في
<span class="math notranslate nohighlight">\(V_j\)</span>).</p>
<div class="math notranslate nohighlight">
\[E[\text{MI}(U,V)]=\sum_{i=1}^{|U|} \sum_{j=1}^{|V|} \sum_{n_{ij}=(a_i+b_j-N)^+
}^{\min(a_i, b_j)} \frac{n_{ij}}{N}\log \left( \frac{ N.n_{ij}}{a_i b_j}\right)
\frac{a_i!b_j!(N-a_i)!(N-b_j)!}{N!n_{ij}!(a_i-n_{ij})!(b_j-n_{ij})!
(N-a_i-b_j+n_{ij})!}\]</div>
<p class="sd-card-text">باستخدام القيمة المتوقعة، يمكن بعد ذلك حساب معلومات التبادل المعدلة باستخدام صيغة مشابهة لتلك الخاصة بمؤشر Rand المعدل:</p>
<div class="math notranslate nohighlight">
\[\text{AMI} = \frac{\text{MI} - E[\text{MI}]}{\text{mean}(H(U), H(V)) - E[\text{MI}]}\]</div>
<p class="sd-card-text">بالنسبة لمعلومات التبادل المطبعي ومعلومات التبادل المعدلة، تكون القيمة المعيارية عادةً عبارة عن متوسط <em>عام</em> لإنتروبيا كل تجميع. توجد العديد من المتوسطات العامة، ولا توجد قواعد صارمة لتفضيل أحدها على الآخر. يتم اتخاذ القرار أساسًا على أساس كل مجال على حدة؛ على سبيل المثال، في اكتشاف المجتمع، يكون المتوسط الحسابي هو الأكثر شيوعًا. يوفر كل أسلوب معياري “سلوكيات مماثلة نوعيًا” <a class="reference internal" href="#yat2016" id="id20"><span>[YAT2016]</span></a>. في تنفيذنا، يتم التحكم في ذلك بواسطة معلمة <code class="docutils literal notranslate"><span class="pre">average_method</span></code>.</p>
<p class="sd-card-text">أطلق فينه وآخرون. (2010) أسماءً على المتغيرات NMI و AMI حسب طريقة المتوسط المستخدمة <a class="reference internal" href="#veb2010" id="id21"><span>[VEB2010]</span></a>. إن متوسطي ‘sqrt’ و ‘sum’ هما المتوسطان الهندسي والعددي؛ نستخدم هذه الأسماء الأكثر شيوعًا.</p>
<p class="rubric">المراجع</p>
<ul class="simple">
<li><p class="sd-card-text">Strehl, Alexander, and Joydeep Ghosh (2002). “Cluster ensembles - a
knowledge reuse framework for combining multiple partitions”. Journal of
Machine Learning Research 3: 583-617. <a class="reference external" href="http://strehl.com/download/strehl-jmlr02.pdf">doi:10.1162/153244303321897735</a>.</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Mutual_Information">Wikipedia entry for the (normalized) Mutual Information</a></p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Adjusted_Mutual_Information">Wikipedia entry for the Adjusted Mutual Information</a></p></li>
</ul>
<div role="list" class="citation-list">
<div class="citation" id="veb2009" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">VEB2009</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Vinh, Epps, and Bailey, (2009). “Information theoretic measures
for clusterings comparison”. Proceedings of the 26th Annual International
Conference on Machine Learning - ICML ‘09. <a class="reference external" href="https://dl.acm.org/citation.cfm?doid=1553374.1553511">doi:10.1145/1553374.1553511</a>. ISBN
9781605585161.</p>
</div>
<div class="citation" id="veb2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id21">VEB2010</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Vinh, Epps, and Bailey, (2010). “Information Theoretic Measures
for Clusterings Comparison: Variants, Properties, Normalization and
Correction for Chance”. JMLR
&lt;<a class="reference external" href="https://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf">https://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf</a>&gt;</p>
</div>
<div class="citation" id="yat2016" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">YAT2016</a><span class="fn-bracket">]</span></span>
<p class="sd-card-text">Yang, Algesheimer, and Tessone, (2016). “A comparative analysis
of community detection algorithms on artificial networks”. Scientific
Reports 6: 30750. <a class="reference external" href="https://www.nature.com/articles/srep30750">doi:10.1038/srep30750</a>.</p>
</div>
</div>
</div>
</details><p id="homogeneity-completeness">Homogeneity, completeness and V-measure
بالنظر إلى معرفة تعيينات فئة الحقيقة الأرضية للعينات، من الممكن تحديد بعض المقاييس البديهية باستخدام تحليل الإنتروبيا الشرطي.</p>
<p>على وجه الخصوص، يحدد روزنبرغ وهيرشبرغ (2007) الهدفين المرغوبين التاليين لأي تعيين عنقودي:</p>
<ul class="simple">
<li><p><strong>التجانس</strong>: تحتوي كل عنقود على أعضاء من فئة واحدة فقط.</p></li>
<li><p><strong>الاكتمال</strong>: يتم تعيين جميع أعضاء فئة معينة إلى نفس العنقود.</p></li>
</ul>
<p>يمكننا تحويل هذين المفهومين إلى درجات: “درجة التجانس” و”درجة الاكتمال”. كلاهما محدود من الأسفل بـ 0.0 ومن الأعلى بـ 1.0 (الأعلى أفضل):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">homogeneity_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.66...</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">completeness_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.42...</span>
</pre></div>
</div>
<p>متوسطهما التوافقي يسمى <strong>V-measure</strong> يتم حسابه بواسطة:func:<code class="docutils literal notranslate"><span class="pre">v_measure_score</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.51...</span>
</pre></div>
</div>
<p>صيغة هذه الدالة هي كما يلي:</p>
<div class="math notranslate nohighlight">
\[v = \frac{(1 + \beta) \times \text{homogeneity} \times \text{completeness}}{(\beta \times \text{homogeneity} + \text{completeness})}\]</div>
<p>القيمة الافتراضية لـ <code class="docutils literal notranslate"><span class="pre">beta</span></code> هي 1.0، ولكن لاستخدام قيمة أقل من 1 لـ beta:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="go">0.54...</span>
</pre></div>
</div>
<p>سيتم إعطاء وزن أكبر للتجانس، واستخدام قيمة أكبر من 1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">v_measure_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.8</span><span class="p">)</span>
<span class="go">0.48...</span>
</pre></div>
</div>
<p>سيتم إعطاء وزن أكبر للاكتمال.</p>
<p>في الواقع، V-measure مكافئ لمعلومات التماثل (NMI)
نوقش أعلاه، مع كون دالة التجميع هي المتوسط الحسابي <a class="reference internal" href="#b2011" id="id22"><span>[B2011]</span></a>.</p>
<p>يمكن حساب التجانس والاكتمال وV-measure في نفس الوقت باستخدام:func:<code class="docutils literal notranslate"><span class="pre">homogeneity_completeness_v_measure</span></code> كما يلي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">homogeneity_completeness_v_measure</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">(0.66..., 0.42..., 0.51...)</span>
</pre></div>
</div>
<p>تعيين التجميع التالي أفضل قليلاً، لأنه
متجانس ولكنه غير مكتمل:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">homogeneity_completeness_v_measure</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">(1.0, 0.68..., 0.81...)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">v_measure_score</span></code> هو <strong>متناظر</strong>: يمكن استخدامه لتقييم
<strong>الاتفاق</strong> بين تعيينين مستقلين على نفس مجموعة البيانات.</p>
<p>هذه ليست الحالة:func:<code class="docutils literal notranslate"><span class="pre">completeness_score</span></code> و:func:<code class="docutils literal notranslate"><span class="pre">homogeneity_score</span></code>: كلاهما محدودان بالعلاقة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">homogeneity_score</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">==</span> <span class="n">completeness_score</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p><strong>الدرجات المحدودة</strong>: 0.0 هو الأسوأ، 1.0 هو الدرجة الكاملة.</p></li>
<li><p>التفسير البديهي: يمكن تحليل التجميع بدرجة V-measure سيئة
<strong>من الناحية النوعية من حيث التجانس والاكتمال</strong> ليشعر بشكل أفضل بنوع ‘الأخطاء’ التي يرتكبها التعيين.</p></li>
<li><p><strong>لا يتم إجراء أي افتراض بشأن بنية العنقود</strong>: يمكن استخدامه لمقارنة
خوارزميات التجميع مثل k-means والتي تفترض أشكال كتل متساوية الخواص
مع نتائج خوارزميات التجميع الطيفي التي يمكنها العثور على عنقود مع
الأشكال “المطوية”.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul>
<li><p>المقاييس المقدمة سابقًا <strong>غير معيارية فيما يتعلق
التسمية العشوائية</strong>: وهذا يعني أنه اعتمادًا على عدد العينات،
العنقوديات وفئات الحقيقة الأرضية، لن يؤدي التسمية العشوائية تمامًا إلى
دائمًا نفس القيم للتجانس والاكتمال وبالتالي V-measure. على وجه الخصوص <strong>لن يؤدي التسمية العشوائية إلى درجات صفر خاصة عندما يكون عدد العنقود كبيرًا</strong>.</p>
<p>يمكن تجاهل هذه المشكلة بأمان عندما يكون عدد العينات أكثر من ألف
وعدد العنقود أقل من 10. <strong>بالنسبة لأحجام العينات الأصغر أو عدد أكبر من العنقود، من الآمن استخدام مؤشر معدّل مثل مؤشر Rand المعدل (ARI)</strong>.</p>
</li>
</ul>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html"><img alt="../_images/sphx_glr_plot_adjusted_for_chance_measures_001.png" src="../_images/sphx_glr_plot_adjusted_for_chance_measures_001.png" style="width: 640.0px; height: 480.0px;" />
</a>
</figure>
<ul class="simple">
<li><p>هذه المقاييس <strong>تتطلب معرفة الفئات الحقيقية</strong>
في حين أنها غير متوفرة عملياً على الإطلاق أو تتطلب تعيينًا يدويًا بواسطة الملاحظين البشريين (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p></li>
</ul>
</aside>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_adjusted_for_chance_measures.html#sphx-glr-auto-examples-cluster-plot-adjusted-for-chance-measures-py"><span class="std std-ref">Adjustment for chance in clustering performance evaluation</span></a>: تحليل
تأثير حجم مجموعة البيانات على قيمة مقاييس التجميع لل
التعيينات العشوائية.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية-2">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية-2" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يتم إعطاء درجات التجانس والاكتمال رسميًا بواسطة:</p>
<div class="math notranslate nohighlight">
\[h = 1 - \frac{H(C|K)}{H(C)}\]</div>
<div class="math notranslate nohighlight">
\[c = 1 - \frac{H(K|C)}{H(K)}\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(H(C|K)\)</span> هو <strong>إنتروبيا شرطي للفئات بالنظر إلى
تعيينات العنقود</strong> وهو معطى بواسطة:</p>
<div class="math notranslate nohighlight">
\[H(C|K) = - \sum_{c=1}^{|C|} \sum_{k=1}^{|K|} \frac{n_{c,k}}{n}
\cdot \log\left(\frac{n_{c,k}}{n_k}\right)\]</div>
<p class="sd-card-text">و:math:<code class="docutils literal notranslate"><span class="pre">H(C)</span></code> هو <strong>إنتروبيا الفئات</strong> وهو معطى بواسطة:</p>
<div class="math notranslate nohighlight">
\[H(C) = - \sum_{c=1}^{|C|} \frac{n_c}{n} \cdot \log\left(\frac{n_c}{n}\right)\]</div>
<p class="sd-card-text">مع:math:<code class="docutils literal notranslate"><span class="pre">n</span></code> هو العدد الإجمالي للعينات،<span class="math notranslate nohighlight">\(n_c\)</span> و:math:<code class="docutils literal notranslate"><span class="pre">n_k</span></code> عدد
العينات التي تنتمي على التوالي إلى الفئة:math:<code class="docutils literal notranslate"><span class="pre">c</span></code> والمجموعة
<span class="math notranslate nohighlight">\(k\)</span>، وأخيرًا:math:<code class="docutils literal notranslate"><span class="pre">n_{c،k}</span></code> عدد العينات من الفئة
<span class="math notranslate nohighlight">\(c\)</span> المعينة للمجموعة:math:<code class="docutils literal notranslate"><span class="pre">k</span></code>.</p>
<p class="sd-card-text">يتم تحديد <strong>إنتروبيا شرطي للعنقود بالنظر إلى الفئة</strong> <span class="math notranslate nohighlight">\(H(K|C)\)</span> و
<strong>إنتروبيا العنقود</strong><span class="math notranslate nohighlight">\(H(K)\)</span> يتم تعريفها بطريقة متماثلة.</p>
<p class="sd-card-text">عرّف روزنبرغ وهيرشبرغ كذلك <strong>V-measure</strong> على أنه <strong>متوسط التوافقي
من التجانس والاكتمال</strong>:</p>
<div class="math notranslate nohighlight">
\[v = 2 \cdot \frac{h \cdot c}{h + c}\]</div>
</div>
</details><p class="rubric">المراجع</p>
<ul class="simple">
<li><p><a class="reference external" href="https://aclweb.org/anthology/D/D07/D07-1043.pdf">V-Measure: A conditional entropy-based external cluster evaluation measure</a> Andrew Rosenberg and Julia
Hirschberg, 2007</p></li>
</ul>
<div role="list" class="citation-list">
<div class="citation" id="b2011" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id22">B2011</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="http://www.cs.columbia.edu/~hila/hila-thesis-distributed.pdf">Identification and Characterization of Events in Social Media</a>, Hila
Becker, PhD Thesis.</p>
</div>
</div>
</section>
<section id="fowlkes-mallows-scores">
<span id="id23"></span><h3><span class="section-number">2.9.3.3. </span>Fowlkes-Mallows scores<a class="headerlink" href="#fowlkes-mallows-scores" title="Link to this heading">#</a></h3>
<p>يمكن استخدام مؤشر Fowlkes-Mallows (<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.fowlkes_mallows_score</span></code>) عندما تكون فئة الحقيقة الأرضية
تعيينات العينات معروفة. يتم تعريف Fowlkes-Mallows score FMI على أنه المتوسط الهندسي
الدقة والاستدعاء الزوجي:</p>
<div class="math notranslate nohighlight">
\[\text{FMI} = \frac{\text{TP}}{\sqrt{(\text{TP} + \text{FP}) (\text{TP} + \text{FN})}}\]</div>
<p>حيث “TP” هو عدد <strong>الإيجابيات الحقيقية</strong> (أي عدد
أزواج النقاط التي تنتمي إلى نفس العنقود في كل من التسميات الحقيقية والمتوقعة)، “FP” هو عدد
<strong>الإيجابيات الخاطئة</strong> (أي عدد أزواج النقاط التي تنتمي إلى نفس العنقود في التسميات الحقيقية وليس
في التسميات المتوقعة) و “FN” هو عدد <strong>السلبيات الخاطئة</strong> (أي عدد
أزواج النقاط التي تنتمي إلى نفس العنقود في التسميات المتوقعة وليس في التسميات الحقيقية).</p>
<p>يتراوح الدرجات من 0 إلى 1. تشير القيمة المرتفعة إلى تشابه جيد
بين عنقودين.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.47140...</span>
</pre></div>
</div>
<p>يمكنك تبديل 0 و 1 في التسميات المتوقعة، وإعادة تسمية 2 إلى 3 والحصول
نفس النتيجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.47140...</span>
</pre></div>
</div>
<p>يتم تقييم التسمية المثالية بـ 1.0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="n">labels_true</span><span class="p">[:]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>التسميات السيئة (على سبيل المثال، التسميات المستقلة) لها درجات صفرية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">labels_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fowlkes_mallows_score</span><span class="p">(</span><span class="n">labels_true</span><span class="p">,</span> <span class="n">labels_pred</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p><strong>تعيينات التسميات العشوائية (المتساوية) لها درجة FMI قريبة من 0.0</strong> ل أي
قيمة لـ “n_clusters” و “n_samples” (وهو ما لا يحدث مع معلومات التماثل الخام أو V-measure على سبيل المثال).</p></li>
<li><p><strong>محدد أعلى عند 1</strong>: تشير القيم القريبة من الصفر إلى أن تعييني التسمية
مستقلان إلى حد كبير، في حين تشير القيم القريبة من واحد إلى وجود اتفاق كبير. علاوة على ذلك، تشير قيم FMI التي تساوي 0 بالضبط إلى أن تعييني التسمية
مستقلة تمامًا، وتشير FMI التي تساوي 1 بالضبط إلى أن تعييني التسمية متساويان (مع أو بدون تبديل).</p></li>
<li><p><strong>لا يتم إجراء أي افتراض بشأن بنية العنقود</strong>: يمكن استخدامه لمقارنة
خوارزميات التجميع مثل k-means والتي تفترض أشكال كتل متساوية الخواص
مع نتائج خوارزميات التجميع الطيفي التي يمكنها العثور على عنقود مع
الأشكال “المطوية”.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>على عكس القصور الذاتي، <strong>تتطلب المقاييس المستندة إلى FMI معرفة
الفئات الحقيقية</strong> في حين أنها غير متوفرة عملياً على الإطلاق أو تتطلب
تعيينًا يدويًا بواسطة الملاحظين البشريين (كما هو الحال في إعداد التعلم الخاضع للإشراف).</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-8">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-8" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">E. B. Fowkles and C. L. Mallows, 1983. “A method for comparing two
hierarchical clusterings”. Journal of the American Statistical Association.
<a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1983.10478008">https://www.tandfonline.com/doi/abs/10.1080/01621459.1983.10478008</a></p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Fowlkes-Mallows_index">Wikipedia entry for the Fowlkes-Mallows Index</a></p></li>
</ul>
</div>
</details></section>
<section id="silhouette-coefficient">
<span id="id24"></span><h3><span class="section-number">2.9.3.4. </span>معامل التشابه<a class="headerlink" href="#silhouette-coefficient" title="Link to this heading">#</a></h3>
<p>إذا كانت التسميات الحقيقية غير معروفة، يجب إجراء التقييم باستخدام
النموذج نفسه. معامل التشابه
(<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.silhouette_score</span></code>)
هو مثال على هذا التقييم، حيث درجة أعلى من معامل التشابه
يرتبط بنموذج مع عنقود محددة بشكل أفضل. يتكون معامل التشابه من
درجتان:</p>
<ul class="simple">
<li><p><strong>أ</strong>: متوسط المسافة بين عينة وجميع النقاط الأخرى في نفس
الفئة.</p></li>
<li><p><strong>ب</strong>: متوسط المسافة بين عينة وجميع النقاط الأخرى في
<em>العنقود التالي الأقرب</em>.</p></li>
</ul>
<p>معامل التشابه <em>s</em> لعينة واحدة هو ثم يعطى كما يلي:</p>
<div class="math notranslate nohighlight">
\[s = \frac{b - a}{max(a، b)}\]</div>
<p>معامل التشابه لمجموعة من العينات هو متوسط معامل التشابه لكل عينة.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>في الاستخدام العادي، يتم تطبيق معامل التشابه على نتائج
تحليل التجميع.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans_model</span><span class="o">.</span><span class="n">labels_</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="go">0.55...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>الدرجة محددة بين -1 لعنقود غير صحيحة و +1 لعنقود كثيفة للغاية. تشير الدرجات القريبة من الصفر إلى تداخل العنقود.</p></li>
<li><p>تكون الدرجة أعلى عندما تكون العنقود كثيفة ومتباعدة بشكل جيد، وهو ما</p></li>
</ul>
<p>يرتبط بالمفهوم القياسي للعنقود.</p>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>معامل التشابه أعلى عمومًا للعنقود محدبة الشكل أكثر من مفاهيم العنقود الأخرى، مثل</p></li>
</ul>
<p>العنقود المستندة إلى الكثافة مثل تلك
التي تم الحصول عليها من خلال DBSCAN.</p>
</aside>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py"><span class="std std-ref">Selecting the number of clusters with silhouette analysis on KMeans clustering</span></a> : في
يتم استخدام تحليل التشابه في هذا المثال لاختيار قيمة مثالية
لـ n_clusters.</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-9">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-9" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Peter J. Rousseeuw (1987). <a class="reference external" href="https://doi.org/10.1016/0377-0427(87)90125-7">“Silhouettes: a Graphical Aid to the
Interpretation and Validation of Cluster Analysis”</a>.
الرياضيات الحاسوبية والتطبيقية 20: 53-65.</p></li>
</ul>
</div>
</details><p id="calinski-harabasz-index">إذا لم تكن علامات الحقيقة الأرضية معروفة، فيمكن استخدام مؤشر Calinski-Harabasz (sklearn.metrics.calinski_harabasz_score) - المعروف أيضًا باسم معيار نسبة التباين - لتقييم النموذج، حيث تشير درجة Calinski-Harabasz الأعلى إلى نموذج بمجموعات محددة بشكل أفضل.</p>
<p>المؤشر هو نسبة مجموع التشتت بين المجموعات والتشتت داخل المجموعة لجميع المجموعات (حيث يُعرَّف التشتت على أنه مجموع المسافات المربعة):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>في الاستخدام العادي، يتم تطبيق مؤشر Calinski-Harabasz على نتائج تحليل التجميع:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans_model</span><span class="o">.</span><span class="n">labels_</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="go">561.59...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>تكون النتيجة أعلى عندما تكون المجموعات كثيفة ومتباعدة بشكل جيد، وهو ما يتعلق بالمفهوم القياسي للمجموعة.</p></li>
<li><p>النتيجة سريعة الحساب.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>مؤشر Calinski-Harabasz أعلى بشكل عام للمجموعات المحدبة من مفاهيم المجموعات الأخرى، مثل المجموعات المستندة إلى الكثافة مثل تلك التي تم الحصول عليها من خلال DBSCAN.</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية-3">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية-3" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">لمجموعة من البيانات E بحجم n_E والتي تم تجميعها في k مجموعات، يتم تعريف نتيجة Calinski-Harabasz s على أنها نسبة متوسط التشتت بين المجموعات والتشتت داخل المجموعة:</p>
<div class="math notranslate nohighlight">
\[s = \frac{\mathrm{tr}(B_k)}{\mathrm{tr}(W_k)} \times \frac{n_E - k}{k - 1}\]</div>
<p class="sd-card-text">حيث mathrm{tr} (B_k) هو أثر مصفوفة التشتت بين المجموعات و mathrm{tr} (W_k) هو أثر مصفوفة التشتت داخل المجموعة المحددة بواسطة:</p>
<div class="math notranslate nohighlight">
\[W_k = \sum_{q=1}^k \sum_{x \in C_q} (x - c_q) (x - c_q)^T\]</div>
<div class="math notranslate nohighlight">
\[B_k = \sum_{q=1}^k n_q (c_q - c_E) (c_q - c_E)^T\]</div>
<p class="sd-card-text">مع C_q مجموعة من النقاط في المجموعة q، c_q مركز المجموعة q، c_E مركز E، و n_q عدد النقاط في المجموعة q.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-10">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-10" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Caliński، T.، وHarabasz، J. (1974). “طريقة الشجيرات لتحليل التجميع”.
<a class="reference external" href="https://doi.org/10.1080/03610927408827101">اتصالات في Statistics-theory and Methods 3: 1-27</a>.</p></li>
</ul>
</div>
</details></section>
<section id="davies-bouldin-index">
<span id="id25"></span><h3><span class="section-number">2.9.3.5. </span>مؤشر ديفيز-بولدين<a class="headerlink" href="#davies-bouldin-index" title="Link to this heading">#</a></h3>
<p>إذا لم تكن علامات الحقيقة الأرضية معروفة، فيمكن استخدام مؤشر ديفيز-بولدين (sklearn.metrics.davies_bouldin_score) لتقييم النموذج، حيث تشير قيمة مؤشر ديفيز-بولدين الأقل إلى نموذج بفصل أفضل بين المجموعات.</p>
<p>يشير هذا المؤشر إلى “التشابه” المتوسط بين المجموعات، حيث يكون التشابه مقياسًا يقارن المسافة بين المجموعات بحجم المجموعات نفسها.</p>
<p>الصفر هو أقل نتيجة ممكنة. تشير القيم الأقرب إلى الصفر إلى تقسيم أفضل.</p>
<p>في الاستخدام العادي، يتم تطبيق مؤشر ديفيز-بولدين على نتائج تحليل التجميع على النحو التالي:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">davies_bouldin_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">davies_bouldin_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="go">0.666...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>حساب ديفيز-بولدين أبسط من حساب نتائج Silhouette.</p></li>
<li><p>يعتمد المؤشر فقط على الكميات والسمات المتأصلة في مجموعة البيانات حيث يستخدم حسابه فقط المسافات النقطية.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>مؤشر ديفيز-بولدين أعلى بشكل عام للمجموعات المحدبة من مفاهيم المجموعات الأخرى، مثل المجموعات المستندة إلى الكثافة مثل تلك التي تم الحصول عليها من DBSCAN.</p></li>
<li><p>يقتصر استخدام مسافة المركز النصفي مقياس المسافة على الفضاء الإقليدي.</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الصيغة-الرياضية-4">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الصيغة الرياضية<a class="headerlink" href="#الصيغة-الرياضية-4" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يتم تعريف المؤشر على أنه متوسط التشابه بين كل مجموعة C_i لـ i=1، …، k وأكثرها تشابهاً C_j. في سياق هذا المؤشر، يتم تعريف التشابه على أنه مقياس <a href="#id31"><span class="problematic" id="id32">R_</span></a> {ij} الذي يوازن بين:</p>
<ul class="simple">
<li><p class="sd-card-text">s_i، المسافة المتوسطة بين كل نقطة من المجموعة i ومركز المجموعة - المعروف أيضًا باسم قطر المجموعة.</p></li>
<li><p class="sd-card-text"><a href="#id33"><span class="problematic" id="id34">d_</span></a> {ij}، المسافة بين مراكز المجموعات i وj.</p></li>
</ul>
<p class="sd-card-text">يمكن إجراء اختيار بسيط لبناء <a href="#id35"><span class="problematic" id="id36">R_</span></a> {ij} بحيث يكون غير سالب ومتناظر:</p>
<div class="math notranslate nohighlight">
\[R_{ij} = \frac{s_i + s_j}{d_{ij}}\]</div>
<p class="sd-card-text">ثم يتم تعريف مؤشر ديفيز-بولدين على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[DB = \frac{1}{k} \sum_{i=1}^k \max_{i \neq j} R_{ij}\]</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-11">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-11" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">ديفيز، ديفيد إل؛ بولدين، دونالد دبليو (1979). <a class="reference external" href="https://doi.org/10.1109/TPAMI.1979.4766909">“مقياس فصل المجموعة”</a> معاملات IEEE على أنماط التحليل والذكاء الآلي. PAMI-1 (2): 224-227.</p></li>
<li><p class="sd-card-text">Halkidi، Maria؛ Batistakis، Yannis؛ Vazirgiannis، Michalis (2001). <a class="reference external" href="https://doi.org/10.1023/A:1012801612483">“On
تقنيات التحقق من صحة التجميع “</a> مجلة أنظمة المعلومات الذكية، 17 (2-3)، 107-145.</p></li>
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Davies-Bouldin_index">إدخال ويكيبيديا لمؤشر ديفيز-بولدين</a>.</p></li>
</ul>
</div>
</details></section>
<section id="contingency-matrix">
<span id="id27"></span><h3><span class="section-number">2.9.3.6. </span>مصفوفة الاحتمالية<a class="headerlink" href="#contingency-matrix" title="Link to this heading">#</a></h3>
<p>تقدم مصفوفة الاحتمالية (sklearn.metrics.cluster.contingency_matrix) تقارير عن تقاطع التوافقية لكل زوج من المجموعات الحقيقية/المتوقعة.
توفر مصفوفة الاحتمالية إحصائيات كافية لجميع مقاييس التجميع حيث تكون العينات مستقلة ومتطابقة التوزيع ولا تحتاج إلى حساب بعض الحالات غير المجمّعة.</p>
<p>فيما يلي مثال:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">contingency_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contingency_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">array([[2, 1, 0],</span>
<span class="go">       [0, 1, 2]])</span>
</pre></div>
</div>
<p>يشير الصف الأول من مصفوفة الإخراج إلى وجود ثلاث عينات تكون المجموعة الحقيقية لها هي “a”. منهم، اثنان في المجموعة المتوقعة 0، واحدة في 1، ولا شيء في 2. ويشير الصف الثاني إلى وجود ثلاث عينات تكون مجموعتها الحقيقية هي “b”. منهم، لا يوجد شيء في المجموعة المتوقعة 0، واحدة في 1 واثنتان في 2.</p>
<p>تعد مصفوفة الارتباك للتصنيف (<span class="xref std std-ref">confusion_matrix</span>) مصفوفة احتمالية مربعة حيث يتوافق ترتيب الصفوف والأعمدة مع قائمة الفئات.</p>
<aside class="topic">
<p class="topic-title">المزايا:</p>
<ul class="simple">
<li><p>يسمح بفحص انتشار كل مجموعة حقيقية عبر المجموعات المتوقعة والعكس بالعكس.</p></li>
<li><p>يتم استخدام جدول الاحتمالية المحسوب عادةً في حساب إحصائية التشابه (مثل الآخرين المدرجة في هذه الوثيقة) بين التجميعين.</p></li>
</ul>
</aside>
<aside class="topic">
<p class="topic-title">العيوب:</p>
<ul class="simple">
<li><p>من السهل تفسير مصفوفة الاحتمالية لعدد صغير من المجموعات، ولكن يصبح من الصعب تفسيرها لعدد كبير من المجموعات.</p></li>
<li><p>لا يوفر مقياسًا واحدًا لاستخدامه كهدف لتحسين التجميع.</p></li>
</ul>
</aside>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-12">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-12" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Contingency_table">إدخال ويكيبيديا لمصفوفة الاحتمالية</a></p></li>
</ul>
</div>
</details></section>
<section id="pair-confusion-matrix">
<span id="id29"></span><h3><span class="section-number">2.9.3.7. </span>مصفوفة الارتباك الزوجي<a class="headerlink" href="#pair-confusion-matrix" title="Link to this heading">#</a></h3>
<p>مصفوفة الارتباك الزوجي
(<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.cluster.pair_confusion_matrix</span></code>) هي مصفوفة تشابه 2x2</p>
<div class="math notranslate nohighlight">
\[\begin{split}C = \left[\begin{matrix}
C_{00} &amp; C_{01} \\
C_{10} &amp; C_{11}
\end{matrix}\right]\end{split}\]</div>
<p>بين تجميعين يتم حسابهما عن طريق مراعاة جميع أزواج العينات وعد الأزواج التي يتم تعيينها في نفس المجموعة أو في مجموعات مختلفة
في التجميعات الحقيقية والمتوقعة.</p>
<p>يحتوي على الإدخالات التالية:</p>
<p><span class="math notranslate nohighlight">\(C_{00}\)</span> : عدد الأزواج الذين لا تجمعهم كل من التجميعات معًا</p>
<p><span class="math notranslate nohighlight">\(C_{10}\)</span> : عدد الأزواج الذين تجمعهم التسمية الحقيقية للتجميع معًا ولكن التجميع الآخر لا يجمعهم معًا</p>
<p><span class="math notranslate nohighlight">\(C_{01}\)</span> : عدد الأزواج الذين لا تجمعهم التسمية الحقيقية للتجميع معًا ولكن التجميع الآخر يجمعهم معًا</p>
<p><span class="math notranslate nohighlight">\(C_{11}\)</span> : عدد الأزواج الذين تجمعهم كل من التجميعات معًا</p>
<p>مع مراعاة زوج من العينات التي يتم تجميعها معًا إيجابية، ثم كما هو الحال في التصنيف الثنائي، يكون عدد السلبيات الحقيقية هو
<span class="math notranslate nohighlight">\(C_{00}\)</span>، والسلبيات الخاطئة هي <span class="math notranslate nohighlight">\(C_{10}\)</span>، والإيجابيات الحقيقية هي <span class="math notranslate nohighlight">\(C_{11}\)</span> والإيجابيات الخاطئة هي <span class="math notranslate nohighlight">\(C_{01}\)</span>.</p>
<p>تكون التسميات المطابقة تمامًا لها جميع الإدخالات غير الصفرية على
التشخيص بغض النظر عن قيم التسميات الفعلية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics.cluster</span> <span class="kn">import</span> <span class="n">pair_confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">array([[8, 0],</span>
<span class="go">       [0, 4]])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">array([[8, 0],</span>
<span class="go">       [0, 4]])</span>
</pre></div>
</div>
<p>قد تكون التسميات التي تقوم بتعيين جميع أعضاء الفصل إلى نفس المجموعات
مكتملة ولكنها قد لا تكون دائمًا نقية، وبالتالي يتم معاقبتها، ولديها بعض الإدخالات غير الصفرية خارج القطر:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="go">array([[8, 2],</span>
<span class="go">       [0, 2]])</span>
</pre></div>
</div>
<p>المصفوفة غير متماثلة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([[8, 0],</span>
<span class="go">       [2, 2]])</span>
</pre></div>
</div>
<p>إذا تم تقسيم أعضاء الفصل تمامًا عبر مجموعات مختلفة، فإن
التعيين غير مكتمل تمامًا، وبالتالي فإن المصفوفة لها جميع الإدخالات القطري
الصفر:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pair_confusion_matrix</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">array([[ 0,  0],</span>
<span class="go">       [12,  0]])</span>
</pre></div>
</div>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع-13">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع-13" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://doi.org/10.1007/BF01908075">“مقارنة التقسيمات”</a> L. Hubert and P. Arabie،
مجلة التصنيف 1985</p></li>
</ul>
</div>
</details></section>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="manifold.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2.3. </span>تعلم المنوال</p>
      </div>
    </a>
    <a class="right-next"
       href="biclustering.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">&lt;no title&gt;</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2.9.1. نظرة عامة على طرق التجميع</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">2.9.1.1. التوازي منخفض المستوى</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mini-batch-k-means">2.9.1.2. Mini Batch K-Means</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-shift">2.9.2. Mean Shift</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">2.9.2.1. استراتيجيات تعيين التسميات المختلفة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#spectral-clustering-graph">2.9.2.2. رسوم بيانية للتجميع الطيفي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ward-complete-average-single-linkage">2.9.2.3. أنواع مختلفة من الروابط: Ward وcomplete وaverage وsingle linkage</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">2.9.2.4. تصور تسلسل هرمي للمجموعة</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">2.9.2.5. إضافة قيود الاتصال</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">2.9.2.6. تغيير المقياس</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">2.9.2.7. K-Means ثنائي القسمة</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hdbscan">2.9.3. HDBSCAN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">2.9.3.1. مخطط إمكانية الوصول المتبادل</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">2.9.3.2. التجميع الهرمي</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fowlkes-mallows-scores">2.9.3.3. Fowlkes-Mallows scores</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#silhouette-coefficient">2.9.3.4. معامل التشابه</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#davies-bouldin-index">2.9.3.5. مؤشر ديفيز-بولدين</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#contingency-matrix">2.9.3.6. مصفوفة الاحتمالية</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pair-confusion-matrix">2.9.3.7. مصفوفة الارتباك الزوجي</a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/modules/clustering.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License).
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>