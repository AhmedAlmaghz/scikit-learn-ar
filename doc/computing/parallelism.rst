التفرع، وإدارة الموارد، والتهيئة
بالتوازي
================

يقوم بعض مقدري ومرافق scikit-learn بتوازي العمليات المكلفة باستخدام
عدة أنوية معالجة مركزية.

اعتمادًا على نوع المُقدِّر، وأحيانًا على قيم معلمات البناء، يتم ذلك
إما:

- باستخدام التوازي عالي المستوى عبر `joblib <https://joblib.readthedocs.io/en/latest/>`_.
- باستخدام التوازي منخفض المستوى عبر OpenMP، المستخدم في كود C أو Cython.
- باستخدام التوازي منخفض المستوى عبر BLAS، الذي تستخدمه NumPy وSciPy للعمليات العامة على المصفوفات.

تتحكم معلمة ``n_jobs`` للمقدّرات دائمًا في مقدار التوازي الذي يديره
joblib (العمليات أو الخيوط اعتمادًا على backend joblib). يتحكم
دائمًا التوازي على مستوى الخيوط الذي يديره OpenMP في كود Cython
الخاص بـ scikit-learn أو مكتبات BLAS & LAPACK التي تستخدمها عمليات
NumPy وSciPy المستخدمة في scikit-learn بواسطة متغيرات البيئة أو
`threadpoolctl` كما هو موضح أدناه. لاحظ أن بعض المقدرات يمكنها
الاستفادة من جميع أنواع التوازي الثلاثة في نقاط مختلفة من أساليب
التدريب والتنبؤ الخاصة بها.

نوضح هذه الأنواع الثلاثة من التوازي في الأقسام الفرعية التالية بمزيد
من التفاصيل.

التوازي عالي المستوى مع joblib
-----------------------------

عندما يستخدم التنفيذ الأساسي joblib، يمكن التحكم في عدد العمال
(الخيوط أو العمليات) التي يتم تشغيلها بالتوازي عبر معلمة
``n_jobs``.

.. note::

    التوثيق الحالي لموقع (و كيفية) حدوث التوازي في المقدرات التي
    تستخدم joblib عن طريق تحديد ``n_jobs`` ضعيف حاليًا. يرجى مساعدتنا
    من خلال تحسين وثائقنا والتعامل مع `القضية 14228
    <https://github.com/scikit-learn/scikit-learn/issues/14228>`_!

يمكن لـ joblib دعم كل من المعالجة المتعددة والتعددية المتعددة.
يعتمد اختيار joblib لتشغيل خيط أو عملية على **backend** الذي يستخدمه.

يعتمد scikit-learn بشكل عام على backend ``loky``، وهو backend
الافتراضي لـ joblib. Loky هو backend معالجة متعددة. عند إجراء
معالجة متعددة، لتجنب ازدواجية الذاكرة في كل عملية (التي ليست
معقولة مع مجموعات البيانات الكبيرة)، سيقوم joblib بإنشاء `memmap
<https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html>`_
يمكن لجميع العمليات مشاركته، عندما تكون البيانات أكبر من 1 ميجابايت.

في بعض الحالات المحددة (عندما يقوم الكود الذي يتم تشغيله بالتوازي
بإصدار GIL)، سيشير scikit-learn إلى ``joblib`` بأن backend
متعدد الخيوط مفضل.

كمستخدم، يمكنك التحكم في backend الذي سيستخدمه joblib (بغض النظر
عن ما يوصي به scikit-learn) باستخدام مدير السياق::

    from joblib import parallel_backend

    with parallel_backend('threading', n_jobs=2):
        # Your scikit-learn code here

يرجى الرجوع إلى `وثائق joblib
<https://joblib.readthedocs.io/en/latest/parallel.html#thread-based-parallelism-vs-process-based-parallelism>`_
لمزيد من التفاصيل.

من الناحية العملية، يعتمد ما إذا كان التوازي مفيدًا لتحسين وقت
التشغيل على العديد من العوامل. عادة ما يكون من الجيد إجراء
تجارب بدلاً من افتراض أن زيادة عدد العمال أمر جيد دائمًا. في بعض
الحالات، قد يكون من الضار جدًا للأداء تشغيل نسخ متعددة من بعض
المقدرات أو الوظائف بالتوازي (راجع الإفراط في الاشتراك أدناه).

التوازي منخفض المستوى مع OpenMP
-------------------------------

يتم استخدام OpenMP لتوازي الكود المكتوب في Cython أو C، معتمدًا
على التعددية المتعددة بشكل حصري. بشكل افتراضي، ستستخدم
التطبيقات التي تستخدم OpenMP أكبر عدد ممكن من الخيوط، أي عدد
الخيوط مثل الأنوية المنطقية.

يمكنك التحكم في العدد الدقيق للخيوط المستخدمة إما:

- عبر متغير البيئة ``OMP_NUM_THREADS``، على سبيل المثال عند:
  تشغيل نص برمجي Python:

  .. prompt:: bash $

      OMP_NUM_THREADS=4 python my_script.py

- أو عبر `threadpoolctl` كما هو موضح بواسطة `قطعة من التوثيق
  <https://github.com/joblib/threadpoolctl/#setting-the-maximum-size-of-thread-pools>`_.

الروتينات المتوازية NumPy وSciPy من المكتبات الرقمية
-------------------------------------------------

يعتمد scikit-learn بشكل كبير على NumPy وSciPy، والتي تستدعي داخليًا
روتينات الجبر الخطي متعدد الخيوط (BLAS & LAPACK) المنفذة في
مكتبات مثل MKL أو OpenBLAS أو BLIS.

يمكنك التحكم في العدد الدقيق للخيوط التي تستخدمها BLAS لكل مكتبة
باستخدام متغيرات البيئة، وهي:

- ``MKL_NUM_THREADS`` يحدد عدد الخيوط التي تستخدمها MKL،
- ``OPENBLAS_NUM_THREADS`` يحدد عدد الخيوط التي تستخدمها OpenBLAS
- ``BLIS_NUM_THREADS`` يحدد عدد الخيوط التي تستخدمها BLIS

لاحظ أن تنفيذ BLAS & LAPACK يمكن أن يتأثر أيضًا بـ
``OMP_NUM_THREADS``. للتحقق مما إذا كان هذا هو الحال في بيئتك،
يمكنك فحص كيفية تأثر عدد الخيوط المستخدمة بشكل فعال بواسطة
تلك المكتبات عند تشغيل الأمر التالي في bash أو zsh terminal
لقيم مختلفة من ``OMP_NUM_THREADS``:

.. prompt:: bash $

    OMP_NUM_THREADS=2 python -m threadpoolctl -i numpy scipy

.. note::

    في وقت الكتابة (2022)، ترتبط حزم NumPy وSciPy الموزعة على
    pypi.org (أي تلك المثبتة عبر ``pip install``) وعلى قناة
    conda-forge (أي تلك المثبتة عبر ``conda install --channel
    conda-forge``) بـ OpenBLAS، في حين أن حزم NumPy وSciPy
    الموزعة على قناة "الافتراضيات" conda من Anaconda.org (أي
    تلك المثبتة عبر ``conda install``) ترتبط بشكل افتراضي بـ MKL.


الإفراط في الاشتراك: تشغيل عدد كبير جدًا من الخيوط
---------------------------------------------

من المستحسن عمومًا تجنب استخدام عدد كبير من العمليات أو الخيوط
أكثر من عدد وحدات المعالجة المركزية على الآلة. يحدث الإفراط في
الاشتراك عندما يقوم البرنامج بتشغيل عدد كبير جدًا من الخيوط في
نفس الوقت.

لنفترض أن لديك آلة بها 8 وحدات معالجة مركزية. ضع في اعتبارك حالة
تقوم فيها بتشغيل :class:`~sklearn.model_selection.GridSearchCV`
(متعددة العمليات باستخدام joblib) مع ``n_jobs=8`` على
:class:`~sklearn.ensemble.HistGradientBoostingClassifier`
(متعددة الخيوط باستخدام OpenMP). ستقوم كل مثيل من
:class:`~sklearn.ensemble.HistGradientBoostingClassifier` بتشغيل 8
خيوط (نظرًا لأن لديك 8 وحدات معالجة مركزية). هذا ما مجموعه
``8 * 8 = 64`` خيط، مما يؤدي إلى الإفراط في اشتراك الخيوط لموارد
وحدة المعالجة المركزية الفعلية وبالتالي إلى وقت انتظار الجدولة.

يمكن أن ينشأ الإفراط في الاشتراك بنفس الطريقة تمامًا مع الروتينات
المتوازية من MKL أو OpenBLAS أو BLIS المضمنة في مكالمات joblib.

بدءًا من ``joblib >= 0.14``، عندما يتم استخدام backend ``loky``
(وهو الافتراضي)، سيخبر joblib عملياته الفرعية بالحد من عدد
الخيوط التي يمكنها استخدامها، لتجنب الإفراط في الاشتراك. في
الممارسة العملية، تستخدم joblib حيلة لإخبار العمليات باستخدام
``max_threads = n_cpus // n_jobs``، عبر متغير البيئة المقابل
لها. العودة إلى مثالنا أعلاه، نظرًا لأن backend joblib من
:class:`~sklearn.model_selection.GridSearchCV` هو ``loky``،
فستتمكن كل عملية من استخدام خيط واحد فقط بدلاً من 8، وبالتالي
تخفيف مشكلة الإفراط في الاشتراك.

لاحظ أن:

- سيأخذ الإعداد اليدوي لأحد متغيرات البيئة (``OMP_NUM_THREADS``،
  ``MKL_NUM_THREADS``، ``OPENBLAS_NUM_THREADS``، أو
  ``BLIS_NUM_THREADS``) الأسبقية على ما يحاول joblib القيام به.
  سيكون العدد الإجمالي للخيوط هو ``n_jobs * <LIB>_NUM_THREADS``.
  لاحظ أن تحديد هذا الحد سيؤثر أيضًا على حساباتك في العملية
  الرئيسية، والتي ستستخدم فقط ``<LIB>_NUM_THREADS``. يعرض joblib
  مدير سياق للتحكم الدقيق في عدد الخيوط في عماله (راجع وثائق
  joblib المرتبطة أدناه).
- عندما يتم تكوين joblib لاستخدام backend ``threading``، لا توجد
  آلية لتجنب الإفراط في الاشتراك عند استدعاء مكتبات أصلية
  متوازية في الخيوط التي يديرها joblib.
- جميع مقدرات scikit-learn التي تعتمد صراحةً على OpenMP في كود
  Cython الخاص بها تستخدم دائمًا `threadpoolctl` داخليًا لتعديل
  أعداد الخيوط التي تستخدمها OpenMP ومكالمات BLAS المضمنة
  تلقائيًا لتجنب الإفراط في الاشتراك.

ستجد تفاصيل إضافية حول تخفيف joblib من الإفراط في الاشتراك في
`توثيق joblib
<https://joblib.readthedocs.io/en/latest/parallel.html#avoiding-over-subscription-of-cpu-resources>`_.

ستجد تفاصيل إضافية حول التوازي في مكتبات بايثون الرقمية في
`هذه الوثيقة من توماس جيه فان <https://thomasjpfan.github.io/parallelism-python-libraries-design/>`_.

مفاتيح التكوين
واجهة برمجة التطبيقات (API) الخاصة بلغة بايثون
..............................................

يمكن استخدام :func: `sklearn.set_config` و :func: `sklearn.config_context` لتغيير معلمات التكوين التي تتحكم في جوانب التوازي.

.. _environment_variable:

المتغيرات البيئية
...................

يجب تعيين متغيرات البيئة هذه قبل استيراد سكيت-ليرن.

`SKLEARN_ASSUME_FINITE`
~~~~~~~~~~~~~~~~~~~~~~~

يحدد القيمة الافتراضية لحجة `assume_finite` للدالة :func: `sklearn.set_config`.

`SKLEARN_WORKING_MEMORY`
~~~~~~~~~~~~~~~~~~~~~~~~

يحدد القيمة الافتراضية لحجة `working_memory` للدالة :func: `sklearn.set_config`.

`SKLEARN_SEED`
~~~~~~~~~~~~~~

يحدد بذرة مولد الأرقام العشوائية العالمي عند تشغيل الاختبارات، من أجل إمكانية إعادة الإنتاج.

ملاحظة: من المتوقع أن تعمل اختبارات سكيت-ليرن بشكل حتمي مع البذر الصريح لنسخ RNG الخاصة بها بدلاً من الاعتماد على مولدات RNG الخاصة بمكتبة نومبي أو بايثون القياسية للتأكد من أن نتائج الاختبار مستقلة عن ترتيب تنفيذ الاختبار. ومع ذلك، قد تنسى بعض الاختبارات استخدام البذر الصريح، وهذه المتغيرات هي طريقة للتحكم في الحالة الأولية لنسخ Singleton المذكورة أعلاه.

`SKLEARN_TESTS_GLOBAL_RANDOM_SEED`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

يتحكم في بذر مولد الأرقام العشوائية المستخدمة في الاختبارات التي تعتمد على الفيصلة `global_random_seed`.

يجب أن تمر جميع الاختبارات التي تستخدم هذا الفيصلة بالعقد الذي يجب أن تنجح بشكل حتمي لأي قيمة بذرة من 0 إلى 99.

في الإنشاءات الليلية لـ CI، يتم سحب متغير البيئة `SKLEARN_TESTS_GLOBAL_RANDOM_SEED` بشكل عشوائي في النطاق المذكور أعلاه، وسيتم تشغيل جميع الاختبارات ذات الفيصلة لهذه البذرة المحددة. الهدف هو التأكد من أن CI الخاص بنا، مع مرور الوقت، سيقوم بتشغيل جميع الاختبارات باستخدام بذور مختلفة مع الحفاظ على مدة الاختبار لتشغيل واحد لمجموعة الاختبارات الكاملة محدودة. سيتحقق هذا من أن تأكيدات الاختبارات المكتوبة لاستخدام هذا الفيصلة لا تعتمد على قيمة بذرة معينة.

يتم تحديد نطاق قيم البذور المقبولة بـ [0، 99] لأنه غالبًا ما يكون من المستحيل كتابة اختبار يمكن أن يعمل لأي بذرة ممكنة ونريد تجنب وجود اختبارات تفشل بشكل عشوائي في CI.

القيم الصالحة لـ `SKLEARN_TESTS_GLOBAL_RANDOM_SEED`:

- `SKLEARN_TESTS_GLOBAL_RANDOM_SEED="42"`: تشغيل الاختبارات باستخدام بذرة ثابتة تبلغ 42
- `SKLEARN_TESTS_GLOBAL_RANDOM_SEED="40-42"`: تشغيل الاختبارات بجميع البذور بين 40 و 42
- `SKLEARN_TESTS_GLOBAL_RANDOM_SEED="all"`: تشغيل الاختبارات بجميع البذور بين 0 و 99. قد يستغرق هذا وقتًا طويلاً: استخدمه فقط لاختبارات فردية، وليس لمجموعة الاختبارات الكاملة!

إذا لم يتم تعيين المتغير، يتم استخدام 42 كبذرة عالمية بطريقة حتمية. يضمن هذا أنه، بشكل افتراضي، تكون مجموعة اختبارات سكيت-ليرن حتمية قدر الإمكان لتجنب تعطيل مُحافظي حزم الطرف الثالث الودودين. وبالمثل، لا ينبغي تعيين هذا المتغير في تكوين CI لطلبات السحب للتأكد من أن مساهمينا الودودين ليسوا أول من يواجه تراجعًا في الحساسية للبذور في اختبار لا علاقة له بالتغييرات في طلب السحب الخاص بهم. من المتوقع أن يكون مُحافظو سكيت-ليرن الذين يراقبون نتائج الإنشاءات الليلية فقط منزعجين من هذا.

عند كتابة دالة اختبار جديدة تستخدم هذا الفيصلة، يرجى استخدام الأمر التالي للتأكد من أنها تمر بشكل حتمي لجميع البذور المقبولة على جهازك المحلي:

.. prompt:: bash $

    SKLEARN_TESTS_GLOBAL_RANDOM_SEED="all" pytest -v -k test_your_test_name

`SKLEARN_SKIP_NETWORK_TESTS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى قيمة غير صفرية، يتم تخطي الاختبارات التي تحتاج إلى الوصول إلى الشبكة. عندما لا يتم تعيين متغير البيئة هذا، يتم تخطي الاختبارات التي تحتاج إلى الشبكة.

`SKLEARN_RUN_FLOAT32_TESTS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى '1'، يتم أيضًا تشغيل الاختبارات التي تستخدم الفيصلة `global_dtype` على بيانات float32.

عندما لا يتم تعيين متغير البيئة هذا، يتم تشغيل الاختبارات فقط على بيانات float64.

`SKLEARN_ENABLE_DEBUG_CYTHON_DIRECTIVES`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى قيمة غير صفرية، يتم تعيين المشتق `Cython`، `boundscheck`، إلى `True`. هذا مفيد في العثور على الأخطاء.

`SKLEARN_BUILD_ENABLE_DEBUG_SYMBOLS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

عندما يتم تعيين متغير البيئة هذا إلى قيمة غير صفرية، سيتم تضمين رموز التصحيح في ملحقات C المترجمة. يتم تكوين رموز التصحيح لأنظمة POSIX فقط.

`SKLEARN_PAIRWISE_DIST_CHUNK_SIZE`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

يحدد هذا متغير حجم الجزء الذي سيتم استخدامه بواسطة التطبيقات الأساسية لـ `PairwiseDistancesReductions`. القيمة الافتراضية هي `256` والتي ثبت أنها كافية على معظم الآلات.

قد يرغب المستخدمون الذين يبحثون عن أفضل أداء في ضبط هذا المتغير باستخدام قوى 2 للحصول على أفضل سلوك توازي لأجهزتهم، خاصة فيما يتعلق بأحجام ذاكرة التخزين المؤقت الخاصة بهم.

`SKLEARN_WARNINGS_AS_ERRORS`
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

يتم استخدام متغير البيئة هذا لتحويل التحذيرات إلى أخطاء في الاختبارات وبناء الوثائق.

يحدد بعض مدمجي CI (Continuous Integration) `SKLEARN_WARNINGS_AS_ERRORS=1`، على سبيل المثال للتأكد من أننا نلتقط تحذيرات الإلغاء التدريجي من تبعياتنا ونقوم بتكييف شفرتنا وفقًا لذلك.

لتشغيله محليًا باستخدام نفس إعداد "التحذيرات كأخطاء" كما هو الحال في عمليات بناء CI هذه، يمكنك تحديد `SKLEARN_WARNINGS_AS_ERRORS=1`.

بشكل افتراضي، لا يتم تحويل التحذيرات إلى أخطاء. هذا هو الحال إذا لم يتم تعيين `SKLEARN_WARNINGS_AS_ERRORS`، أو إذا كان `SKLEARN_WARNINGS_AS_ERRORS=0`.

يستخدم هذا المتغير البيئي مرشحات تحذير محددة لتجاهل بعض التحذيرات، حيث إن التحذيرات تنشأ أحيانًا من مكتبات الطرف الثالث ولا يمكننا فعل الكثير بشأنها. يمكنك الاطلاع على مرشحات التحذير في دالة `_get_warnings_filters_info_list` في `sklearn/utils/_testing.py`.

ملاحظة: بالنسبة لبناء الوثائق، يتحقق `SKLEARN_WARNING_AS_ERRORS=1` من أن بناء الوثائق، وعلى وجه التحديد تشغيل الأمثلة، لا ينتج عنه أي تحذيرات. يختلف هذا عن حجة `-W` لبرنامج `sphinx-build` التي تلتقط تحذيرات بناء الجملة في ملفات rst.