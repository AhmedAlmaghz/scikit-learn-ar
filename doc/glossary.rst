هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي:

.. currentmodule:: sklearn

.. _glossary:

=========================================
معجم المصطلحات الشائعة وعناصر واجهة برمجة التطبيقات
=========================================

يهدف هذا المعجم إلى تقديم تمثيل قاطع للاتفاقيات الضمنية والصريحة المطبقة في Scikit-learn وواجهة برمجة التطبيقات الخاصة به، مع توفير مرجع للمستخدمين والمساهمين. يصف هذا المعجم المفاهيم ويربطها إما بواجهة برمجة التطبيقات المقابلة لها أو بال أجزاء الأخرى ذات الصلة من التوثيق. من خلال الربط بمصطلحات المعجم من مرجع واجهة برمجة التطبيقات ودليل المستخدم، يمكننا تقليل التكرار وعدم الاتساق.

نبدأ بإدراج المفاهيم العامة (وأية مفاهيم لم تناسب مكانًا آخر)، ولكن يتم سرد مجموعات أكثر تحديدًا من المصطلحات ذات الصلة أدناه: :ref:`glossary_estimator_types`, :ref:`glossary_target_types`, :ref:`glossary_methods`, :ref:`glossary_parameters`, :ref:`glossary_attributes`, :ref:`glossary_sample_props`.

مفاهيم عامة

    
    (ملاحظة: لم يتم ترجمة المصطلحات والمفاهيم العامة نظراً لعدم وجود سياق محدد لها في النص الأصلي. يمكن ترجمتها عند توفر سياق محدد لها في النص.)

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي:

================

.. glossary::

    1d
    1d array
        مصفوفة أحادية البعد. وهي مصفوفة NumPy التي يكون طول ``.shape`` الخاص بها 1.
        وتعتبر متجهًا.

    2d
    2d array
        مصفوفة ثنائية البعد. وهي مصفوفة NumPy التي يكون طول ``.shape`` الخاص بها 2.
        غالبًا ما تمثل مصفوفة.

    API
        يشير إلى كل من الواجهات *الخاصة* للتقديرات المنفذة في Scikit-learn والاتفاقيات *العامة* عبر أنواع التقديرات كما هو موصوف في هذا المسرد و: ref: `نظرة عامة على واجهة برمجة التطبيقات في وثائق المساهمين <api_overview>`_.

        الواجهات الخاصة التي تشكل واجهة برمجة التطبيقات العامة لـ Scikit-learn موثقة إلى حد كبير في :ref:`api_ref`. ومع ذلك، فإننا نعتبر بشكل غير رسمي أي شيء واجهة برمجة تطبيقات عامة إذا لم تبدأ أي من المعرفات المطلوبة للوصول إليها بحرف ``_``. نحن نحاول بشكل عام الحفاظ على: term: `التوافق مع الإصدارات السابقة` لجميع الكائنات في واجهة برمجة التطبيقات العامة.

        واجهة برمجة التطبيقات الخاصة، بما في ذلك الوظائف والوحدات النمطية والأساليب التي تبدأ بحرف ``_``، غير مضمونة أن تكون مستقرة.

    array-like
        تنسيق البيانات الأكثر شيوعًا لـ *المدخلات* في تقديرات ووظائف Scikit-learn، array-like هو أي نوع كائن ستنتج عنه: func: `numpy.asarray` مجموعة ذات شكل مناسب (عادةً ما تكون 1 أو 2 أبعاد) من النوع المناسب (عادة رقمي).

        وهذا يشمل:

        * مصفوفة NumPy
        * قائمة من الأرقام
        * قائمة من قوائم الأرقام بطول ثابت k
        * `pandas.DataFrame` مع جميع الأعمدة الرقمية
        * `pandas.Series` رقمية

        ويستثني:

        * :term:`sparse matrix`
        * مصفوفة متفرقة
        * أداة تكرار
        * أداة توليد

        لاحظ أن *المخرجات* من تقديرات ووظائف Scikit-learn (مثل التنبؤات) يجب أن تكون بشكل عام صفائف أو مصفوفات متفرقة، أو قوائم منها (كما في مخرجات ``predict_proba`` متعددة المخرجات :class:`tree.DecisionTreeClassifier`). التقدير الذي تُرجع فيه ``predict()`` قائمة أو `pandas.Series` غير صالح.

    attribute
    attributes
        نحن نستخدم في الغالب سمة للإشارة إلى كيفية تخزين معلومات النموذج على المُقدّر أثناء التركيب. أي سمة عامة مخزنة على مثيل المُقدّر مطلوب أن تبدأ بحرف أبجدي وتنتهي بشرطة سفلية واحدة إذا تم تعيينها في: term: `fit` أو: term: `partial_fit`. هذه هي ما تم توثيقه ضمن توثيق *السّمات* للمُقدّر. المعلومات المخزنة في السمات تكون عادةً إما: إحصائيات كافية تستخدم للتنبؤ أو التحويل؛ مخرجات :term:`transductive` مثل: term:`labels_` أو: term:`embedding_`؛ أو بيانات تشخيصية، مثل: term:`feature_importances_`.
        السمات الشائعة مدرجة :ref:`أسفل <glossary_attributes>`.

        قد تحتوي السمة العامة على نفس الاسم مثل: term:`parameter` مُنشئ، مع إضافة ``_``. يتم استخدامه لتخزين إصدار معتمد أو مقدر من إدخال المستخدم. على سبيل المثال، يتم إنشاء: class:`decomposition.PCA` باستخدام معلمة ``n_components``. من هذا، جنبًا إلى جنب مع المعلمات الأخرى والبيانات، يقدر PCA السمة ``n_components_``.

        يمكن أيضًا تعيين سمات خاصة إضافية مستخدمة في التنبؤ/التحويل/إلخ عند التركيب. تبدأ هذه السمات بشرطة سفلية واحدة ولا يضمن الوصول العام إليها أن تكون مستقرة.

        السمة العامة على مثيل المُقدّر التي لا تنتهي بشرطة سفلية يجب أن تكون القيمة المخزنة وغير المعدلة لـ: term:`parameter` ``__init__`` بنفس الاسم. بسبب هذا التماثل، يتم توثيق هذه السمات تحت توثيق *المعلمات* للمُقدّر.

    backwards compatibility
        نحاول بشكل عام الحفاظ على التوافق مع الإصدارات السابقة (أي قد يتم توسيع الواجهات والسلوكيات ولكن لا يتم تغييرها أو إزالتها) من إصدار إلى آخر، ولكن هذا يأتي مع بعض الاستثناءات:

        واجهة برمجة التطبيقات العامة فقط
            قد يتم تغيير سلوك الكائنات التي تم الوصول إليها من خلال المعرفات الخاصة (تلك التي تبدأ بـ ``_``) بشكل تعسفي بين الإصدارات.
        كما هو موثق
            سنفترض بشكل عام أن المستخدمين قد التزموا بأنواع المعلمات ونطاقاتها الموثقة. إذا طلبت التوثيق قائمة وأعطى المستخدم tuple، فإننا لا نضمن سلوكًا ثابتًا من إصدار إلى آخر.
        الإهمال
            قد تتغير السلوكيات بعد فترة :term:`deprecation` (عادةً ما تكون طولها إصدارين). يتم إصدار التحذيرات باستخدام وحدة :mod:`warnings` من Python.
        وسائط الكلمات الرئيسية
            قد نفترض أحيانًا أن جميع المعلمات الاختيارية (بخلاف X و y إلى: term:`fit` والطرق المماثلة) يتم تمريرها كوسائط كلمات رئيسية فقط ويمكن إعادة ترتيبها موضعيًا.
        إصلاح الأخطاء والتحسينات
            قد تغير إصلاحات الأخطاء - وأحيانًا أقل - التحسينات سلوك المُقدّرين، بما في ذلك تنبؤات نموذج مُدرّب على نفس البيانات و: term:`random_state`. عندما يحدث هذا، نحاول ملاحظة ذلك بوضوح في سجل التغيير.
        التسلسل
            لا نؤكد أن إزالة العقبات من مُقدّر في إصدار واحد ستسمح له بأن يتم إلغاء عقبه إلى نموذج مكافئ في الإصدار اللاحق. (بالنسبة إلى المُقدّرين في حزمة sklearn، نصدر تحذيرًا عند محاولة إلغاء العقبات هذا، حتى لو كان قد ينجح.) انظر: ref:`persistence_limitations`.
        :func:`utils.estimator_checks.check_estimator`
            نقدم ضمانات توافق محدودة مع الإصدارات السابقة لفحوصات المُقدّر: قد نضيف متطلبات إضافية على المُقدّرين الذين تم اختبارهم باستخدام هذه الوظيفة، وعادة ما يكون ذلك عندما كانت هذه المتطلبات مفترضة بشكل غير رسمي ولكن لم يتم اختبارها رسميًا.

    

على الرغم من هذا العقد غير الرسمي مع مستخدمينا، يتم توفير البرنامج كما هو، كما هو منصوص عليه في الترخيص. عندما يؤدي إصدار ما عن طريق الخطأ إلى إدخال تغييرات غير متوافقة مع الإصدارات السابقة، فإن هذه التغييرات تُعرف باسم "تراجعات البرنامج".

callable (قابل للاستدعاء)
    وظيفة أو صنف أو كائن ينفذ طريقة "__call__"؛ أي شيء يُرجع القيمة True عند تمريره كحجة للدالة callable().

categorical feature (الميزة الفئوية)
    الميزة الفئوية أو الاسمية هي ميزة لها مجموعة محدودة من القيم المنفصلة عبر مجموعة البيانات. يتم تمثيلها عادة كأعمدة من الأعداد الصحيحة أو السلاسل. سيرفض معظم مقدري scikit-learn السلاسل، وسيتم التعامل مع الأعداد الصحيحة على أنها ترتيبية أو ذات قيمة عددية. لاستخدامها مع معظم مقدري scikit-learn، يجب ترميز الميزات الفئوية بشكل أحادي. الاستثناءات البارزة تشمل النماذج القائمة على الأشجار مثل الغابات العشوائية ونماذج التدرج المعزز، التي تعمل بشكل أفضل وأسرع مع الميزات الفئوية المشفرة بالأعداد الصحيحة الترتيبية. تساعد الدالة OrdinalEncoder في تشفير الميزات الفئوية النصية كأعداد صحيحة ترتيبية، ويمكن استخدام الدالة OneHotEncoder لترميز الميزات الفئوية بشكل أحادي. انظر أيضًا preprocessing_categorical_features ومكتبة categorical-encoding لأدوات تتعلق بترميز الميزات الفئوية.

clone (استنساخ)
cloned (تم استنساخه)
    لنسخ مثيل مقدر وإنشاء مثيل جديد بنفس المعلَمات، ولكن دون أي سِمات مثبَتة، باستخدام الدالة clone.

    عند استدعاء "fit"، عادة ما يقوم المقدّر الفوقي باستنساخ مثيل المقدّر المغلف قبل تركيب المثيل المستنسخ. (تتضمن الاستثناءات، لأسباب تاريخية، Pipeline و FeatureUnion.)

    إذا كانت معلمة "random_state" للمقدّر عددًا صحيحًا (أو إذا لم يكن للمقدّر معلمة "random_state")، فإن استنساخًا دقيقًا سيعاد: سيعطي الاستنساخ والمقدّر الأصلي نفس النتائج بالضبط. بخلاف ذلك، يتم إرجاع استنساخ إحصائي: قد ينتج الاستنساخ نتائج مختلفة عن المقدّر الأصلي. يمكن العثور على مزيد من التفاصيل في randomness.

common tests (الاختبارات الشائعة)
    يشير هذا إلى الاختبارات التي يتم إجراؤها على كل فئة مقدر تقريبًا في Scikit-learn للتحقق من أنها تلتزم باتفاقيات واجهة برمجة التطبيقات الأساسية. وهي متاحة للاستخدام الخارجي من خلال الدالة check_estimator، مع وجود معظم التنفيذ في "sklearn/utils/estimator_checks.py".

    ملاحظة: يتم حاليًا ترميز بعض الاستثناءات لنظام الاختبار الشائع في المكتبة، لكننا نأمل في استبدال ذلك بوضع علامات على السلوكيات الاستثنائية في المقدّر باستخدام علامات المقدّر الدلالية.

cross-fitting (الملاءمة المتقاطعة)
cross fitting (الملاءمة المتقاطعة)
    طريقة إعادة أخذ عينات تقسم البيانات بشكل تكراري إلى مجموعات متبادلة متبادلة بشكل متبادل لتناسب مرحلتين. خلال المرحلة الأولى، تمكّن المجموعات الفرعية المتبادلة المتبادلة بشكل متبادل من حساب التنبؤات أو التحويلات على البيانات التي لم يتم رؤيتها أثناء التدريب. ثم تُستخدم البيانات المحسوبة في المرحلة الثانية. الهدف هو تجنب جعل أي مبالغة في المرحلة الأولى تؤدي إلى تحيز في توزيع بيانات الإدخال في المرحلة الثانية.
    لأمثلة عن استخدامه، انظر: TargetEncoder و StackingClassifier و StackingRegressor و CalibratedClassifierCV.

cross-validation (التحقق المتقاطع)
cross validation (التحقق المتقاطع)
    طريقة إعادة أخذ عينات تقوم بشكل تكراري بتقسيم البيانات إلى مجموعات فرعية "تدريب" و "اختبار" متبادلة بشكل متبادل حتى يمكن تقييم أداء النموذج على البيانات غير المرئية. هذا يحافظ على البيانات لأنه يتجنب الحاجة إلى الاحتفاظ بمجموعة بيانات "التحقق"، ويأخذ في الاعتبار التباين حيث يتم إجراء جولات متعددة من التحقق المتقاطع بشكل عام.
    انظر دليل المستخدم cross_validation لمزيد من التفاصيل.

deprecation (الإهمال)
    نستخدم الإهمال لخرق تأكيداتنا المتعلقة بالتوافق مع الإصدارات السابقة ببطء، وعادة ما يكون ذلك من أجل:

    * تغيير القيمة الافتراضية للمعلمة؛ أو
    * إزالة معلمة أو سمة أو طريقة أو فئة، وما إلى ذلك.

    سنصدر عادةً تحذيرًا عند استخدام عنصر مهمل، على الرغم من أنه قد تكون هناك قيود على ذلك. على سبيل المثال، سنرفع تحذيرًا عندما يقوم شخص ما بتعيين معلمة تم إهمالها، ولكن قد لا نقوم بذلك عند وصوله إلى السمة المعلمة على مثيل المقدّر.

    انظر دليل المساهمين contributing_deprecation.

dimensionality (الأبعاد)
    قد يُستخدم للإشارة إلى عدد الميزات (أي n_features)، أو الأعمدة في مصفوفة ميزات ثنائية الأبعاد.
    ومع ذلك، تُستخدم الأبعاد أيضًا للإشارة إلى طول شكل صفيف NumPy، لتمييز صفيف أحادي البعد عن مصفوفة ثنائية الأبعاد.

docstring (نص التوثيق)
    توثيق مضمن لوحدة نمطية أو صنف أو دالة وما إلى ذلك، عادةً في الشفرة كحبل في بداية تعريف الكائن، ويمكن الوصول إليه كسمة "__doc__" للكائن.

    نحاول الالتزام بـ PEP257، واتباع اتفاقيات NumpyDoc.

علامة التحتية المزدوجة

    كتابة علامة التحتية المزدوجة
        عند تحديد أسماء البارامترات للمُقدِّرات المتداخلة، يمكن استخدام ``__`` للفصل بين الأصل والفرع في بعض السياقات. الاستخدام الأكثر شيوعًا هو عند تعيين البارامترات من خلال ميتا-مُقدّر مع :term:`set_params` وبالتالي في تحديد شبكة بحث في :ref:`parameter search <grid_search>`. راجع :term:`parameter`.
        يتم استخدامه أيضًا في :meth:`pipeline.Pipeline.fit` لتمرير :term:`sample properties` إلى طرق ``fit`` الخاصة بالمُقدِّرات في خط الأنابيب.

    dtype
    نوع البيانات
        تفترض مصفوفات NumPy نوع بيانات متجانس في جميع الأنحاء، متاح في السمة ``.dtype`` للمصفوفة (أو المصفوفة المتفرقة). نحن نفترض بشكل عام أنواع بيانات بسيطة لبيانات scikit-learn: float أو integer.
        قد ندعم أنواع بيانات الكائن أو السلسلة للمصفوفات قبل الترميز أو المتجه. مقدراتنا لا تعمل مع مصفوفات الهيكل، على سبيل المثال.

        قد تقدم وثائقنا أحيانًا معلومات حول دقة dtype، مثل `np.int32` ، `np.int64` ، إلخ. عندما يتم توفير الدقة، فإنها تشير إلى نوع بيانات NumPy. إذا تم استخدام دقة عشوائية، فستشير الوثائق إلى النوع `integer` أو `floating`.
        لاحظ أنه في هذه الحالة، يمكن أن تعتمد الدقة على النظام الأساسي. يشير النوع `numeric` إلى قبول كل من `integer` و `floating`.

        عندما يتعلق الأمر بالاختيار بين نوع البيانات 64 بت (أي `np.float64` و `np.int64`) ونوع البيانات 32 بت (أي `np.float32` و `np.int32`)، فإن الأمر يتعلق بموازنة بين الكفاءة والدقة. تقدم أنواع 64 بت نتائج أكثر دقة نظرًا لخطأ الفاصلة العائمة الأقل، ولكنها تتطلب مزيدًا من الموارد الحسابية، مما يؤدي إلى عمليات أبطأ وزيادة استخدام الذاكرة. من ناحية أخرى، تعد أنواع 32 بت بتسريع العمليات وتقليل استهلاك الذاكرة، ولكنها تقدم خطأ أكبر في الفاصلة العائمة. تعتمد تحسينات الكفاءة على التحسين على مستوى أدنى مثل المتجهية، الإرسال المتعدد للتعليمات الفردية (SIMD)، أو تحسين ذاكرة التخزين المؤقت ولكن بشكل حاسم على توافق الخوارزمية قيد الاستخدام.

        على وجه التحديد، يجب أن يأخذ اختيار الدقة في الاعتبار ما إذا كانت الخوارزمية المستخدمة يمكنها الاستفادة الفعالة من `np.float32`. يتم تشفير بعض الخوارزميات، وخاصة بعض طرق التقليل، حصريًا لـ `np.float64`، مما يعني أنه حتى إذا تم تمرير `np.float32`، فإنه يؤدي إلى تحويل تلقائي إلى `np.float64`. هذا لا ينفي التوفير الحسابي المقصود فحسب، بل يؤدي أيضًا إلى زيادة الحمل، مما يجعل العمليات مع `np.float32` أبطأ بشكل غير متوقع وتستهلك المزيد من الذاكرة بسبب خطوة التحويل الإضافية هذه.

    كتابة البطة
        نحاول تطبيق `كتابة البطة <https://en.wikipedia.org/wiki/Duck_typing>`_ لتحديد كيفية التعامل مع بعض قيم الإدخال (على سبيل المثال، التحقق مما إذا كان مُقدّر معين عبارة عن مُصنف).  وهذا يعني، نتجنب استخدام ``isinstance`` حيثما أمكن، ونعتمد على وجود أو عدم وجود سمات لتحديد سلوك الكائن.  يلزم بعض الدقة عند اتباع هذا النهج:

        * بالنسبة لبعض المُقدِّرين، قد تكون السمة متاحة فقط بمجرد :term:`fitted`.  على سبيل المثال، لا يمكننا تحديد مسبقًا ما إذا كان :term:`predict_proba` متاحًا في بحث شبكي حيث تتضمن الشبكة التبديل بين مُنبئ احتمالي وغير احتمالي في الخطوة الأخيرة من خط الأنابيب.  في ما يلي، لا يمكننا تحديد ما إذا كان ``clf`` احتماليًا إلا بعد تركيبه على بعض البيانات::

              >>> from sklearn.model_selection import GridSearchCV
              >>> from sklearn.linear_model import SGDClassifier
              >>> clf = GridSearchCV(SGDClassifier(),
              ...                    param_grid={'loss': ['log_loss', 'hinge']})

          هذا يعني أنه يمكننا فقط التحقق من سمات كتابة البطة بعد التثبيت، وأنه يجب أن نكون حذرين لجعل :term:`meta-estimators` لا تقدم سمات إلا وفقًا لحالة المُقدّر الأساسي بعد التثبيت.

        * التحقق مما إذا كانت السمة موجودة (باستخدام ``hasattr``) بشكل عام بنفس تكلفة الحصول على السمة (``getattr`` أو نقطة التدوين).  في بعض الحالات، قد يكون الحصول على السمة مكلفًا بالفعل (على سبيل المثال، بالنسبة لبعض عمليات التنفيذ الخاصة بـ :term:`feature_importances_`، مما قد يشير إلى أن هذا خطأ في تصميم واجهة برمجة التطبيقات).  لذلك يجب تجنب الكود الذي يحتوي على ``hasattr`` متبوعًا بـ ``getattr``؛ يُفضل استخدام ``getattr`` داخل كتلة try-except.

        * لتحديد بعض جوانب توقعات المُقدّر أو الدعم لميزة معينة، نستخدم :term:`estimator tags` بدلاً من كتابة البطة.

    الإيقاف المبكر
        يتكون هذا من إيقاف طريقة تحسين تكرارية قبل تقارب خسارة التدريب، لتجنب الإفراط في التجهيز. يتم ذلك بشكل عام عن طريق مراقبة درجة التعميم على مجموعة التحقق. عند توفره، يتم تنشيطه من خلال المعامل ``early_stopping`` أو عن طريق ضبط :term:`n_iter_no_change` موجب.

    مثيل المُقدّر
        نستخدم أحيانًا هذه المصطلحات للتمييز بين فئة :term:`estimator` وحالة مُنشأة. على سبيل المثال، في ما يلي، ``cls`` هي فئة مُقدّر، بينما ``est1`` و ``est2`` هما مثيلان::

            cls = RandomForestClassifier
            est1 = cls()
            est2 = RandomForestClassifier()

    أمثلة
        نحاول تقديم أمثلة عن الاستخدام الأساسي لمعظم الوظائف والفئات في واجهة برمجة التطبيقات:
    
    (ملحوظة: ليس هناك محتوى تحت هذا العنوان في النص الأصلي)

  هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية دون ترجمة:

    * كاختبارات doctests في سلاسل التعليقات التوضيحية الخاصة بهم (أي داخل كود مكتبة ``sklearn/`` نفسه).
    * كأمثلة في :ref:`معرض الأمثلة <general_examples>` الذي يتم عرضه (باستخدام `sphinx-gallery <https://sphinx-gallery.readthedocs.io/>`_) من النصوص البرمجية في دليل ``examples/``، والتي توضح الميزات أو المعلمات الرئيسية للمقدر/الدالة. يجب أيضًا الإشارة إلى هذه من دليل المستخدم.
    * أحيانًا في :ref:`دليل المستخدم <user_guide>` (المبني من ``doc/``) إلى جانب وصف فني للمقدر.

    تجريبي
        الأداة التجريبية قابلة للاستخدام بالفعل ولكن واجهة برمجة التطبيقات العامة الخاصة بها، مثل قيم المعلمات الافتراضية أو السمات المفروضة، لا تزال عرضة للتغيير في الإصدارات المستقبلية دون سياسة التحذير المعتادة :term:`deprecation`.

    معيار التقييم
    معايير التقييم
        تمنح معايير التقييم مقياسًا لأداء النموذج. قد نستخدم هذا المصطلح بشكل خاص للإشارة إلى الدوال في :mod:`~sklearn.metrics` (دون اعتبار :mod:`~sklearn.metrics.pairwise`)، على النقيض من طريقة :term:`score` وواجهة برمجة التطبيقات :term:`scoring` المستخدمة في التحقق المتبادل. انظر :ref:`model_evaluation`.

        تقبل هذه الوظائف عادةً حقيقة أساسية (أو البيانات الأولية حيث تقوم المقياس بتقييم التجمعات دون حقيقة أساسية) وتوقعًا، سواء كان ناتج :term:`predict` (``y_pred``)، أو :term:`predict_proba` (``y_proba``)، أو أي دالة تسجيل عشوائية بما في ذلك :term:`decision_function` (``y_score``). عادةً ما يتم تسمية الدوال لتنتهي بـ ``_score`` إذا كان الدرجة الأكبر تشير إلى نموذج أفضل، و ``_loss`` إذا كانت الدرجة الأقل تشير إلى نموذج أفضل. هذا التنوع في الواجهة يبرر واجهة برمجة التطبيقات للتسجيل.

        لاحظ أن بعض المقيمات يمكنها حساب المقاييس غير المضمنة في :mod:`~sklearn.metrics` وتكون خاصة بالمقدر، ولا سيما احتمالات النموذج.

    وسوم المقيم
        ميزة مقترحة (مثل :issue:`8022`) يوصف من خلالها قدرات المقيم من خلال مجموعة من الوسوم الدلالية. سيتيح ذلك بعض سلوكيات وقت التشغيل بناءً على فحص المقيم، ولكنه يسمح أيضًا باختبار كل مقيم للثوابت المناسبة مع استثناءه من :term:`common tests` الأخرى.

        يتم حاليًا تحديد بعض جوانب وسوم المقيم من خلال :term:`duck typing` للطرق مثل ``predict_proba`` ومن خلال بعض السمات الخاصة على كائنات المقيم:

        .. glossary::

            ``_estimator_type``
                يحدد هذا السمة ذات القيمة النصية المقيم على أنه مقيم، أو مقيم، وما إلى ذلك. يتم تعيينه بواسطة برامج mixins مثل :class:`base.ClassifierMixin`، ولكن يجب اعتماده بشكل أكثر صراحة على :term:`meta-estimator`. يجب عادةً التحقق من قيمته عن طريق أداة مساعدة مثل :func:`base.is_classifier`.

        لمزيد من المعلومات التفصيلية، انظر :ref:`estimator_tags`.

    ميزة
    الميزات
    متجه الميزة
        بشكل مجرد، الميزة هي دالة (بالمعنى الرياضي) ترسم كائنًا مُعطى إلى كمية رقمية أو فئوية. يستخدم مصطلح "الميزات" أيضًا للإشارة إلى هذه الكميات، باعتبارها العناصر الفردية للمتجه الذي يمثل العينة. في مصفوفة بيانات، يتم تمثيل الميزات كأعمدة: يحتوي كل عمود على نتيجة تطبيق دالة ميزة على مجموعة من العينات.

        في مكان آخر تُعرف الميزات بالسمات أو العناصر التنبؤية أو العناصر الارتدادية أو المتغيرات المستقلة.

        تفترض جميع المقيمات تقريبًا في Scikit-learn أن الميزات رقمية، ومتناهية وغير مفقودة، حتى عندما يكون لها مجالات وتوزيعات مختلفة من الناحية الدلالية (فئوية، ترتيبية، ذات قيمة عددية، ذات قيمة حقيقية، متقطعة). انظر أيضًا :term:`categorical feature` و :term:`missing values`.

        يشير ``n_features`` إلى عدد الميزات في مجموعة بيانات.

    التثبيت
        استدعاء :term:`fit` (أو :term:`fit_transform`، :term:`fit_predict`، إلخ.) على مقيم.

    مثبت
        حالة المقيم بعد :term:`fitting`.

        لا توجد إجراءات تقليدية للتحقق مما إذا كان المقيم مثبتًا. ومع ذلك، فإن المقيم الذي لم يتم تثبيته:

        * يجب أن يثير :class:`exceptions.NotFittedError` عندما يتم استدعاء طريقة توقع (:term:`predict`، :term:`transform`، إلخ.). (:func:`utils.validation.check_is_fitted` يستخدم داخليًا لهذا الغرض.)
        * يجب ألا يكون لديه أي :term:`attributes` تبدأ بحرف أبجدي وتنتهي بشرطة سفلية. (لاحظ أنه قد لا يزال موجودًا على الفصل، ولكن يجب أن ترجع hasattr قيمة False)

    الدالة
        نوفر واجهات الدالة المخصصة للعديد من الخوارزميات، بينما توفر فئات :term:`estimator` واجهة أكثر تناسقًا.

        على وجه الخصوص، قد يوفر Scikit-learn واجهة دالة تناسب نموذجًا لبعض البيانات وتعيد معلمات النموذج المستفادة، كما في :func:`linear_model.enet_path`. بالنسبة للنماذج التلقائية، يعيد هذا أيضًا التضمين أو تسميات المجموعات، كما في :func:`manifold.spectral_embedding` أو :func:`cluster.dbscan`. توفر العديد من محولات المعالجة المسبقة أيضًا واجهة دالة، تشبه إلى حد بعيد الاتصال بـ :term:`fit_transform`، كما في :func:`preprocessing.maxabs_scale`. يجب على المستخدمين توخي الحذر لتجنب :term:`data leakage` عند استخدام هذه الدوال المكافئة لـ ``fit_transform``.

لا يوجد لدينا سياسة صارمة حول متى يتم توفير نماذج الدوال للتقديرات أم لا، ولكن يجب على المشرفين مراعاة الاتساق مع الواجهات الحالية، وما إذا كان توفير دالة سيؤدي إلى إبعاد المستخدمين عن أفضل الممارسات (بالنسبة لتسرب البيانات، وما إلى ذلك).

معرض
    انظر: أمثلة.

فرط معامل
    انظر: معامل.

إحلال
    تتطلب معظم خوارزميات التعلم الآلي أن مدخلاتها لا تحتوي على قيم مفقودة، ولن تعمل إذا تم انتهاك هذا الشرط. يشار إلى الخوارزميات التي تحاول ملء (أو إحلال) القيم المفقودة على أنها خوارزميات إحلال.

قابل للفهرسة
    تشبه المصفوفة أو المصفوفة المتفرقة أو إطار البيانات في pandas أو التسلسل (عادةً قائمة).

استقراء
    يبني التعلم الآلي الاستقرائي (على النقيض من الترانسديكسي) نموذجًا لبعض البيانات التي يمكن تطبيقها بعد ذلك على حالات جديدة. معظم مقدري Scikit-learn هو استقرائي، مع طرق للتنبؤ و/أو التحويل.

Joblib
    مكتبة بايثون (https://joblib.readthedocs.io) تُستخدم في Scikit-learn لتسهيل التوازي البسيط والتخزين المؤقت. يتم توجيه Joblib نحو العمل بكفاءة مع صفائف Numpy، مثل من خلال استخدام تعيين الذاكرة. انظر: التوازي للحصول على مزيد من المعلومات.

مصفوفة مؤشر التسمية
    التنسيق المستخدم لتمثيل بيانات متعددة العلامات، حيث يتوافق كل صف من صفيف ثنائي الأبعاد أو مصفوفة متفرقة مع عينة، ويتوافق كل عمود مع فئة، وكل عنصر هو 1 إذا كانت العينة موصوفة بالفئة و 0 إن لم يكن كذلك.

تسرب
    مشكلة في التحقق المتقاطع حيث يمكن المبالغة في تقدير أداء التعميم نظرًا لأن معرفة بيانات الاختبار تم تضمينها عن غير قصد في تدريب نموذج. هذا خطر، على سبيل المثال، عند تطبيق محول على المجموعة الكاملة من البيانات بدلاً من كل جزء تدريب في تقسيم التحقق المتقاطع.

نهدف إلى توفير واجهات (مثل sklearn.pipeline و sklearn.model_selection) تحمي المستخدم من تسرب البيانات.

تعيين الذاكرة
    استراتيجية كفاءة الذاكرة التي تحتفظ بالبيانات على القرص بدلاً من نسخها في الذاكرة الرئيسية. يمكن إنشاء خرائط الذاكرة للمصفوفات التي يمكن قراءتها أو كتابتها أو كليهما، وذلك باستخدام numpy.memmap. عند استخدام Joblib لعمليات متوازية في Scikit-learn، فقد يقوم تلقائيًا بتعيين الذاكرة للمصفوفات الكبيرة لتقليل النفقات العامة لتكرار الذاكرة في المعالجة المتعددة.

القيم المفقودة
    لا يعمل معظم مقدري Scikit-learn مع القيم المفقودة. عندما يفعلون (مثل في impute.SimpleImputer)، NaN هو التمثيل المفضل للقيم المفقودة في صفائف float. إذا كان صفيف الاعداد الصحيحة dtype، فلا يمكن تمثيل NaN. لهذا السبب، نسمح بتحديد قيمة "missing_values" أخرى عند إجراء عملية إحلال أو يمكن إجراء التعلم في مساحة الاعداد الصحيحة. البيانات غير المسماة هي حالة خاصة من القيم المفقودة في الهدف.

``n_features``
    عدد الميزات.

``n_outputs``
    عدد المخرجات في الهدف.

``n_samples``
    عدد العينات.

``n_targets``
    مرادف لـ n_outputs.

وثائق السرد
    اسم مستعار لإرشادات المستخدم، أي الوثائق المكتوبة في "doc/modules/". على عكس مرجع API المتوفر من خلال الوثائق، تهدف إرشادات المستخدم إلى:

    * مجموعات الأدوات التي توفرها Scikit-learn معًا مواضيعيًا أو من حيث الاستخدام،
    * تحفيز سبب استخدام شخص ما لكل أداة معينة، وغالبًا من خلال المقارنة،
    * تقديم أوصاف بديهية وفنية للأدوات،
    * تقديم أو ربط أمثلة لاستخدام الميزات الرئيسية للأداة.

np
    اختصار لـ Numpy بسبب عبارة الاستيراد التقليدية::

        import numpy as np

التعلم عبر الإنترنت
    حيث يتم تحديث النموذج بشكل متكرر عن طريق تلقي كل مجموعة من الأهداف الحقيقية بعد وقت قصير من إصدار التوقعات على المجموعة المقابلة من البيانات. بشكل أساسي، يجب أن يكون النموذج قابلاً للاستخدام للتنبؤ بعد كل دفعة. انظر partial_fit.

خارج النواة
    إستراتيجية كفاءة حيث لا يتم تخزين جميع البيانات في الذاكرة الرئيسية في وقت واحد، عادةً عن طريق إجراء التعلم على مجموعات البيانات. انظر partial_fit.

المخرجات
    متغيرات كمية / تصنيفية فردية لكل عينة في الهدف. على سبيل المثال، في تصنيف متعدد القوائم، يتوافق كل تسمية محتملة مع إخراج ثنائي. وتسمى أيضا الاستجابات، المهام أو الأهداف.
    انظر multiclass multioutput و continuous multioutput.

زوج
    تتكون من عنصرين.

المعامل
    نستخدم في الغالب "معامل" للإشارة إلى جوانب التقدير التي يمكن تحديدها في بنائها. على سبيل المثال، ``max_depth`` و ``random_state`` هي معاملات RandomForestClassifier.
    يتم تخزين المعلمات لمُنشئ التقدير دون تغيير كسمات على مثيل التقدير، وتبدأ بشكل تقليدي بحرف أبجدي وتنتهي بحرف أبجدي رقمي. يتم وصف معلمات مُنشئ كل مقيم في docstring للمقدر.

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع مراعاة عدم ترجمة الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

نحن لا نستخدم المعلمات بالمعنى الإحصائي، حيث تكون المعلمات قيمًا تحدد نموذجًا ويمكن تقديرها من البيانات. ما نسميه المعلمات قد يكون ما يسميه الإحصائيون هايبرباراميترز للنموذج: جوانب لتكوين بنية النموذج التي غالبًا لا يتم تعلمها مباشرة من البيانات. ومع ذلك، تُستخدم معلماتنا أيضًا لوصف عمليات النمذجة التي لا تؤثر على النموذج المتعلم، مثل ``n_jobs`` للتحكم في التوازي.

عند الحديث عن معلمات "ميتا-مقدر" (meta-estimator)، قد نشمل أيضًا معلمات المقـدِّرات التي يلتف حولها الميتا-مقدر. عادةً، يتم الإشارة إلى هذه المعلمات المتداخلة باستخدام "علامة تحتيّة مزدوجة" (``__``) لفصل بين المقدِّر-كمعلمة ومعلمته. بالتالي، ``clf = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=3))`` لديه معلمة عميقة ``estimator__max_depth`` ذات قيمة ``3``، والتي يمكن الوصول إليها عبر ``clf.estimator.max_depth`` أو ``clf.get_params()['estimator__max_depth']``.

يمكن استرداد قائمة المعلمات وقيمها الحالية من "مثيل المقدِّر" (estimator instance) باستخدام طريقة ``get_params`` الخاصة به.

بين الإنشاء والتركيب، يمكن تعديل المعايير باستخدام ``set_params``. لتمكين ذلك، لا يتم عادةً التحقق من صحة المعلمات أو تغييرها عند إنشاء المقدِّر، أو عندما يتم تعيين كل معلمة. يتم تنفيذ التحقق من صحة المعلمات عندما يتم استدعاء ``fit``.

يتم إدراج المعلمات الشائعة :ref:`أسفل <glossary_parameters>`.

مقياس زوجي (pairwise metric)
مقاييس زوجية (pairwise metrics)

بمعناه الواسع، يحدد المقياس الزوجي وظيفة لقياس التشابه أو الاختلاف بين عينتين (مع تمثيل كل منهما عادةً كـ "متجه ميزة"). نحن نقدم بشكل خاص تنفيذات لمقاييس المسافة (وكذلك المقاييس غير الصحيحة مثل مسافة كوزين) من خلال ``metrics.pairwise_distances``، ولمعاملات النواة (وهي فئة مقيدة من دوال التشابه) في ``metrics.pairwise.pairwise_kernels``. يمكن لهذه الوظائف حساب مصفوفات المسافة الزوجية التي تكون متماثلة وبالتالي تخزن البيانات بشكل زائد.

انظر أيضًا :term:`precomputed` و :term:`metric`.

لاحظ أننا نعتمد على عمليات تنفيذ من ``scipy.spatial.distance`` لمعظم مقاييس المسافة، ولكن قد نعيد التنفيذ من أجل الكفاءة في سياقنا. يتم استخدام واجهة ``metrics.DistanceMetric`` لتنفيذ مقاييس المسافة للتكامل مع البحث الفعال للجيران.

pd
    اختصار لـ `Pandas <https://pandas.pydata.org>`_ بسبب عبارة الاستيراد التقليدية::

        import pandas as pd

محسوب مسبقًا (precomputed)

حيث تعتمد الخوارزميات على :term:`مقاييس زوجية`، ويمكن حسابها من المقاييس الزوجية وحدها، غالبًا ما نسمح للمستخدم بتحديد أن :term:`X` المقدمة موجودة بالفعل في مساحة التشابه (أو الاختلاف) الزوجية، بدلاً من أن تكون في مساحة ميزة. أي، عند تمريرها إلى :term:`fit`، تكون مصفوفة مربعة ومتناسقة، مع كل متجه يشير إلى التشابه (أو الاختلاف) لكل عينة، وعند تمريرها إلى طرق التنبؤ/التحويل، كل صف يتوافق مع عينة اختبار وكل عمود يتوافق مع عينة تدريب.

عادةً ما يتم الإشارة إلى استخدام X المحسوب مسبقًا عن طريق تعيين معلمة ``metric``، أو ``affinity``، أو ``kernel`` إلى السلسلة 'precomputed'. إذا كان هذا هو الحال، يجب على المقدِّر تعيين علامة `pairwise` للمقدِّر على أنها True.

مستطيل (rectangular)

البيانات التي يمكن تمثيلها كمصفوفة مع :term:`عينات` على المحور الأول ومجموعة ثابتة ونهائية من :term:`الميزات` على المحور الثاني تسمى مستطيلة.

هذا المصطلح يستبعد العينات ذات البنى غير المتجهية، مثل النص، أو صورة بحجم عشوائي، أو سلسلة زمنية بطول عشوائي، أو مجموعة من المتجهات، وما إلى ذلك. الغرض من :term:`المُجهِّز` هو إنشاء أشكال مستطيلة من مثل هذه البيانات.

عينة (sample)
عينات (samples)

نستخدم هذا المصطلح عادةً كاسم للإشارة إلى متجه ميزة واحد. في أماكن أخرى، تسمى العينة حالة أو نقطة بيانات أو ملاحظة. يشير ``n_samples`` إلى عدد العينات في مجموعة بيانات، وهو عدد الصفوف في مصفوفة البيانات :term:`X`.

خاصية العينة (sample property)
خصائص العينة (sample properties)

خاصية العينة هي بيانات لكل عينة (مثل مجموعة من الطول n_samples) يتم تمريرها إلى طريقة مقدِّر أو وظيفة مماثلة، إلى جانب ولكن متميزة من :term:`الميزات` (``X``) و :term:`الهدف` (``y``). المثال الأبرز هو :term:`sample_weight`؛ انظر الآخرين في :ref:`glossary_sample_props`.

اعتبارًا من الإصدار 0.19، ليس لدينا نهج ثابت للتعامل مع خصائص العينة وتوجيهها في :term:`meta-estimators`، على الرغم من استخدام معلمات ``fit_params`` بشكل متكرر.

scikit-learn-contrib

مكان لنشر مكتبات متوافقة مع Scikit-learn مصرح بها بشكل عام من قبل مطوري النواة ومجتمع المساهمة، ولكن لا يتم صيانتها بواسطة فريق مطوري النواة. انظر https://scikit-learn-contrib.github.io.

فيما يلي ترجمة النص بتنسيق RST إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

اقتراحات تحسين scikit-learn
    SLEP
    SLEPs
        يتم إجراء التغييرات على مبادئ API والتغييرات على التبعيات أو الإصدارات المدعومة عبر :ref:`SLEP <slep>` وتتبع عملية اتخاذ القرار الموضحة في :ref:`governance`.
        بالنسبة لجميع التصويتات، يجب أن يكون الاقتراح قد تم الإعلان عنه ومناقشته قبل التصويت. يجب أن يكون هذا الاقتراح وثيقة موحدة، في شكل "اقتراح تحسين Scikit-Learn" (SLEP)، وليس نقاشًا طويلاً حول مشكلة ما. يجب تقديم SLEP كطلب سحب إلى `اقتراحات التحسين <https://scikit-learn-enhancement-proposals.readthedocs.io>`_ باستخدام `قالب SLEP <https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep_template.html>`_.

    نصف خاضع للإشراف
    التعلم النصفي الخاضع للإشراف
    semisupervised
        التعلم حيث يتوفر التنبؤ المتوقع (التسمية أو الحقيقة الأرضية) فقط لبعض العينات المقدمة كبيانات تدريب عند :term:`fitting` النموذج.  نطبق بشكل تقليدي التسمية ``-1`` على العينات :term:`غير المسماة` في التصنيف شبه الخاضع للإشراف.

    المصفوفة المتفرقة
    الرسم البياني المتفرق
        تمثيل للبيانات العددية ثنائية الأبعاد أكثر كفاءة في استخدام الذاكرة من مصفوفة NumPy الكثيفة المقابلة حيث تكون جميع العناصر تقريبًا صفرًا. نستخدم إطار عمل :mod:`scipy.sparse`، والذي يوفر العديد من تمثيلات البيانات المتفرقة الأساسية، أو *التنسيقات*.
        بعض التنسيقات أكثر كفاءة من غيرها لمهام معينة، وعندما يوفر تنسيق معين فائدة خاصة، فإننا نحاول توثيق هذه الحقيقة في أوصاف معلمات Scikit-learn.

        تفرق بعض تنسيقات المصفوفات المتفرقة (لا سيما CSR و CSC و COO و LIL) بين الأصفار *الصريحة* و *الضمنية*. الأصفار الصريحة مخزنة (أي أنها تستهلك ذاكرة في صفيف ``data``) في بنية البيانات، بينما تتوافق الأصفار الضمنية مع كل عنصر غير معرف بخلاف ذلك في التخزين الصريح.

        يتم استخدام دلالتين للمصفوفات المتفرقة في Scikit-learn:

        دلالات المصفوفة
            يتم تفسير المصفوفة المتفرقة كمصفوفة مع تفسير الأصفار الضمنية والصريحة على أنها الرقم 0.  هذا هو التفسير الأكثر شيوعًا، على سبيل المثال عند استخدام المصفوفات المتفرقة لمصفوفات الميزات أو :term:`multilabel indicator matrices`.
        دلالات الرسم البياني
            كما هو الحال مع :mod:`scipy.sparse.csgraph`، يتم تفسير الأصفار الصريحة على أنها الرقم 0، ولكن الأصفار الضمنية تشير إلى قيمة مقنعة أو مفقودة، مثل غياب الحافة بين رؤوسين من الرسم البياني، حيث يشير وجود قيمة صريحة إلى وزن الحافة. يتم اعتماد هذا التفسير لتمثيل الترابط في التجمعات، في تمثيلات أقرب الجوار (على سبيل المثال :func:`neighbors.kneighbors_graph`)، ولتمثيل المسافات المحسوبة مسبقًا حيث تكون هناك حاجة فقط إلى المسافات في حي كل نقطة.

        عند العمل مع المصفوفات المتفرقة، نفترض أنها متفرقة لسبب وجيه، ونحاول تجنب كتابة التعليمات البرمجية التي تكثف المصفوفة المتفرقة المقدمة من المستخدم، بدلاً من الحفاظ على التفرق أو رفع خطأ إذا كان ذلك غير ممكن (على سبيل المثال، إذا لم يقم مقدر ما / لا يدعم المصفوفات المتفرقة).

    بدون حالة
        يكون المقدّر بدون حالة إذا لم يقم بتخزين أي معلومات يتم الحصول عليها أثناء :term:`fit`. يمكن أن تكون هذه المعلومات إما معلمات تم تعلمها أثناء :term:`fit` أو إحصائيات تم حسابها من بيانات التدريب. يكون المقدّر بدون حالة إذا لم يكن لديه :term:`attributes` بخلاف تلك التي تم تعيينها في `__init__`. يؤدي استدعاء :term:`fit` لهذه المقادير إلى التحقق من صحة :term:`attributes` العامة التي تم تمريرها في `__init__` فقط.

    تحت الإشراف
    التعلم الخاضع للإشراف
        التعلم حيث يكون التنبؤ المتوقع (التسمية أو الحقيقة الأرضية) متاحًا لكل عينة عند :term:`fitting` النموذج، كمقدمة :term:`y`.  هذا هو النهج المتبع في :term:`classifier` أو :term:`regressor` من بين مقدرين آخرين.

    الهدف
    الأهداف
        *المتغير التابع* في التعلم :term:`supervised` (و :term:`semisupervised`)، يتم تمريره ك :term:`y` إلى طريقة :term:`fit` للمقدر.  يُعرف أيضًا باسم *المتغير التابع*، *متغير النتيجة*، *متغير الاستجابة*، *الحقيقة الأرضية* أو *التسمية*. يعمل Scikit-learn مع أهداف لها بنية بسيطة: فئة من مجموعة محدودة، رقم حقيقي ذو قيمة محدودة، فئات متعددة، أو أرقام متعددة. انظر :ref:`glossary_target_types`.

    التعميم
    استقرائي
        طريقة التعلم الآلي الاستقرائية (على النقيض من :term:`transductive`) مصممة لنمذجة مجموعة بيانات محددة، ولكن ليس لتطبيق هذا النموذج على بيانات غير مرئية.  تتضمن الأمثلة :class:`manifold.TSNE`، :class:`cluster.AgglomerativeClustering` و :class:`neighbors.LocalOutlierFactor`.

    غير مسمى
    بيانات غير مسماة
        عينات ذات حقيقة أرضية غير معروفة عند التجهيز؛ بشكل مكافئ، :term:`missing values` في :term:`target`.  انظر أيضًا :term:`semisupervised` و :term:`unsupervised` learning.

    غير خاضع للإشراف
    التعلم غير الخاضع للإشراف
        التعلم حيث لا يتوفر التنبؤ المتوقع (التسمية أو الحقيقة الأرضية) لكل عينة عند :term:`fitting` النموذج، كما هو الحال في :term:`clusterers` و :term:`outlier detectors`.  تتجاهل المقادير غير الخاضعة للإشراف أي :term:`y` تم تمريرها إلى :term:`fit`.

.. _glossary_estimator_types:

واجهات برمجة التطبيقات للمقدرين وأنواع المقدرين
    

(ملاحظة: لم يتم ترجمة القسم الأخير "واجهات برمجة التطبيقات للمقدرين وأنواع المقدرين" لأنه لا يحتوي على أي نص للترجمة.)

  هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية دون ترجمة:

    ==============================

    .. glossary::

        classifier
        classifiers
            مُصنِّف مُشرف (أو شبه مُشرف) مع مجموعة محدودة من القيم المنفصلة الممكنة للمخرجات.

            يدعم المُصنِّف نمذجة بعض الأهداف الثنائية، أو متعددة الفئات، أو متعددة التسميات، أو متعددة الفئات متعددة المخرجات. داخل سكيت-ليرن، تدعم جميع المُصنِّفات التصنيف متعدد الفئات، بشكل افتراضي باستخدام استراتيجية واحد مقابل البقية على مشكلة التصنيف الثنائي.

            يجب أن يخزن المُصنِّف سمة :term:`classes_` بعد التجهيز، وعادة ما يرث من :class:`base.ClassifierMixin`، والذي يضبط سمة :term:`_estimator_type`.

            يمكن تمييز المُصنِّف عن غيره من المقدِّرين باستخدام :func:`~base.is_classifier`.

            يجب أن يحقق المُصنِّف:

            * :term:`fit`
            * :term:`predict`
            * :term:`score`

            قد يكون من المناسب أيضًا تحقيق :term:`decision_function`، :term:`predict_proba` و :term:`predict_log_proba`.

        clusterer
        clusterers
            مقدِّر غير مُشرف مع مجموعة محدودة من القيم المنفصلة لمخرجاته.

            عادةً ما يخزن collector سمة :term:`labels_` بعد التجهيز، ويجب أن يفعل ذلك إذا كان :term:`transductive`.

            يجب أن يحقق clusterer:

            * :term:`fit`
            * :term:`fit_predict` إذا كان :term:`transductive`
            * :term:`predict` إذا كان :term:`inductive`

        density estimator
            تقدير غير مُشرف لوظيفة كثافة الاحتمال للإدخال. من التقنيات شائعة الاستخدام:

            * :ref:`kernel_density` - يستخدم دالة نواة، يتم التحكم فيها بواسطة معامل عرض النطاق الترددي لتمثيل الكثافة؛
            * :ref:`Gaussian mixture <mixture>` - يستخدم خليطًا من نماذج غاوسية لتمثيل الكثافة.

        estimator
        estimators
            كائن يدير تقدير وفك تشفير النموذج. يتم تقدير النموذج كدالة حتمية لـ:

            * :term:`parameters` المقدمة في بناء الكائن أو مع :term:`set_params`؛
            * الحالة العشوائية العالمية :mod:`numpy.random` إذا تم تعيين معلمات :term:`random_state` للمقدِّر على None؛ و
            * أي بيانات أو :term:`sample properties` تم تمريرها إلى أحدث نداء لـ :term:`fit`، :term:`fit_transform` أو :term:`fit_predict`، أو بيانات مماثلة تم تمريرها في سلسلة من المكالمات لـ :term:`partial_fit`.

            يتم تخزين النموذج المقدر في سمات :term:`attributes` العامة والخاصة على مثيل المقدِّر، مما يسهل فك التشفير من خلال طرق التنبؤ والتحويل.

            يجب أن يوفر المقدِّرون طريقة :term:`fit`، ويجب أن يوفر :term:`set_params` و :term:`get_params`، على الرغم من أنه يتم توفيرها عادةً عن طريق الوراثة من :class:`base.BaseEstimator`.

            قد تتوفر الوظيفة الأساسية لبعض المقدِّرين أيضًا كـ :term:`function`.

        feature extractor
        feature extractors
            محول يأخذ الإدخال حيث لا يتم تمثيل كل عينة ككائن :term:`array-like` ذي طول ثابت، وينتج كائن :term:`array-like` من :term:`features` لكل عينة (وبالتالي كائن array-like ثنائي الأبعاد لمجموعة من العينات). بمعنى آخر، فإنه (بشكل ضائع) يرسم تمثيل بيانات غير مستطيلة في بيانات :term:`rectangular`.

            يجب أن يحقق مستخرج الميزات على الأقل:

            * :term:`fit`
            * :term:`transform`
            * :term:`get_feature_names_out`

        meta-estimator
        meta-estimators
        metaestimator
        metaestimators
            مقدِّر يأخذ مقدِّرًا آخر كمعامل. أمثلة تشمل :class:`pipeline.Pipeline`، :class:`model_selection.GridSearchCV`، :class:`feature_selection.SelectFromModel` و :class:`ensemble.BaggingClassifier`.

            في طريقة :term:`fit` لمقدِّر ميتا، يجب استنساخ أي مقدِّرين موجودين قبل تجهيزهم (على الرغم من أنه FIXME: Pipeline و FeatureUnion لا يفعلان ذلك حاليًا). استثناء لذلك هو أن المقدِّر قد يوثق صراحة أنه يقبل مقدِّرًا مجهزًا مسبقًا (على سبيل المثال باستخدام ``prefit=True`` في :class:`feature_selection.SelectFromModel`). مشكلة معروفة في هذا هي أن المقدِّر المجهز مسبقًا سوف يفقد نموذجه إذا تم استنساخ المقدِّر الفوقي. يجب استدعاء ``fit`` لمقدِّر ميتا قبل التنبؤ، حتى إذا تم تجهيز جميع المقدِّرين الموجودين مسبقًا.

            في الحالات التي تكون فيها السلوكيات الأساسية لمقدِّر ميتا (على سبيل المثال تطبيق :term:`predict` أو :term:`transform`) هي وظائف لطرق التنبؤ / التحويل للمقدِّر الأساسي (أو مقدِّرين أساسيين متعددين)، يجب أن يوفر المقدِّر الفوقي على الأقل الطرق القياسية التي يوفرها المقدِّر الأساسي. قد لا يكون من الممكن تحديد الطرق التي يوفرها المقدِّر الأساسي حتى يتم تركيب المقدِّر الفوقي (انظر أيضًا :term:`duck typing`)، والتي قد تساعد :func:`utils.metaestimators.available_if`. يجب أن يوفر أيضًا (أو يعدل) علامة :term:`estimator tags` و سمة :term:`classes_` التي يوفرها المقدِّر الأساسي.

            يجب أن يكون المقدِّرون الفوقيون حذرين في التحقق من صحة البيانات بأقل قدر ممكن قبل تمريرها إلى مقدِّر أساسي. هذا يوفر وقت الحساب، وقد يسمح، على سبيل المثال، للمقدِّر الأساسي بالعمل بسهولة مع البيانات التي ليست :term:`rectangular`.

        outlier detector
        outlier detectors
            تنبؤ ثنائي غير مُشرف والذي ينمذج التمييز بين العينات الأساسية والبعيدة.

            يجب أن يحقق مراقب الشذوذ:

            * :term:`fit`
            * :term:`fit_predict` إذا كان :term:`transductive`
            * :term:`predict` إذا كان :term:`inductive`

    
    (ملاحظة: لم يتم ترجمة المصطلحات داخل الأقواس المعقوفة لأنها رموز خاصة أو معادلات رياضية أو روابط أو تاجات أو شفرات برمجية.)

يستطيع كاشف الشذوذ الاستقرائي أيضًا تنفيذ دالة اتخاذ القرار `decision_function` لإعطاء درجة طبيعية للعينات الداخلية حيث أن الشواذ لها درجة أقل من ٠. قد توفر `score_samples` درجة غير طبيعية لكل عينة.

predictor
predictors
مقدر `estimator` يدعم `predict` و/أو `fit_predict`. يشمل هذا المصنف `classifier`، والانحدار `regressor`، وكاشف الشذوذ `outlier detector`، والمجمع `clusterer`.

في الإحصاء، يشير "predictors" إلى الميزات `features`.

regressor
regressors
مقدر `predictor` مُشرف (أو شبه مُشرف) مع قيم إخراج مستمرة `continuous`.

عادةً ما يرث المنحدر من `base.RegressorMixin`، والذي يضبط سمة `_estimator_type`.

يمكن التمييز بين المنحدر والمقدرين الآخرين باستخدام `~base.is_regressor`.

يجب على المنحدر تنفيذ:

* `fit`
* `predict`
* `score`

transformer
transformers
مقدر يدعم `transform` و/أو `fit_transform`. قد لا ينفذ المحول `transformer` الناقلي البحت، مثل `manifold.TSNE`، `transform`.

vectorizer
vectorizers
انظر مستخلص الميزة `feature extractor`.

هناك واجهات برمجية إضافية خاصة بمجموعة صغيرة من المقدرين، مثل:

cross-validation splitter
CV splitter
cross-validation generator
فئة من الفئات غير المقدرة المستخدمة لتقسيم مجموعة البيانات إلى سلسلة من الأجزاء المنظمة للاختبار والتدريب (انظر المراجعة الت組みانية `cross_validation`)، من خلال توفير طرق `split` و `get_n_splits`. لاحظ أنه على عكس المقدرين، ليس لديهم طرق `fit` ولا يقدمون `set_params` أو `get_params`. يمكن إجراء التحقق من الصحة في `__init__`.

cross-validation estimator
مقدر له قدرات مدمجة على المراجعة الت組みانية لاختيار أفضل الوسيطات الفائقة تلقائيًا (انظر دليل المستخدم `<grid_search>`). بعض الأمثلة عن المقدرين مع المراجعة الت組みانية هي `ElasticNetCV <linear_model.ElasticNetCV>` و `LogisticRegressionCV <linear_model.LogisticRegressionCV>`. يطلق على المقدرين مع المراجعة الت組みانية اسم `EstimatorCV` وتميل إلى أن تكون مكافئة تقريبًا لـ `GridSearchCV(Estimator(), ...)`. ميزة استخدام مقدر مع المراجعة الت組みانية على فئة `estimator` الكنسية مع `<grid_search>` هي أنه يمكنها الاستفادة من إعادة استخدام النتائج المحسوبة مسبقًا في الخطوات السابقة لعملية المراجعة الت組みانية. يؤدي هذا بشكل عام إلى تحسينات في السرعة. استثناء هو فئة `RidgeCV <linear_model.RidgeCV>`، والتي يمكن أن تؤدي بدلاً من ذلك المراجعة الت組みانية بكفاءة. بشكل افتراضي، سيتم إعادة تركيب كل هذه المقدرين، بصرف النظر عن `RidgeCV <linear_model.RidgeCV>` مع المراجعة الت組みانية، على مجموعة بيانات التدريب الكاملة بعد العثور على أفضل مجموعة من الوسيطات الفائقة.

scorer
كائن قابل للاستدعاء غير مقدر يقيم مقدرًا على بيانات الاختبار المحددة، مع إرجاع رقم. على عكس مقاييس التقييم `evaluation metrics`، يجب أن يتوافق الرقم الأكبر الذي تم إرجاعه مع درجة *أفضل*. انظر `<scoring_parameter>`.

أمثلة إضافية:

* `metrics.DistanceMetric`
* `gaussian_process.kernels.Kernel`
* `tree.Criterion`

 Metadata Routing

    

(ملاحظة: لم أقم بترجمة المصطلحات المحددة بحرف المائل لأنها تعبر عن مفاهيم ومصطلحات متخصصة في علوم البيانات والبرمجة.)

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي:

================

.. glossary::

    consumer
        كائن يستهلك :term:`metadata`. عادة ما يكون هذا الكائن :term:`estimator` أو :term:`scorer` أو :term:`CV splitter`. استهلاك البيانات الفوقية يعني استخدامها في العمليات الحسابية، مثل استخدام :term:`sample_weight` لحساب نوع معين من الدرجات. كون الكائن مستهلكًا لا يعني أنه يتلقى دائمًا بيانات فوقية معينة، بل يعني أنه يمكنه استخدامها إذا تم توفيرها.

    metadata
        البيانات التي ترتبط ببيانات :term:`X` و :term:`y` المحددة، ولكنها ليست جزءًا مباشرًا من البيانات، مثل :term:`sample_weight` أو :term:`groups`، ويتم تمريرها إلى كائنات وطرق مختلفة، مثل :term:`scorer` أو :term:`CV splitter`.

    router
        كائن يقوم بتوجيه البيانات الفوقية إلى :term:`consumers <consumer>`. عادة ما يكون هذا الكائن :term:`meta-estimator`، مثل :class:`~pipeline.Pipeline` أو :class:`~model_selection.GridSearchCV`. يمكن أن يكون بعض الموجهين مستهلكين أيضًا. يحدث هذا على سبيل المثال عندما يستخدم المقدر الفوقي :term:`groups` المعطى، كما أنه يمرره إلى بعض الكائنات الفرعية الخاصة به، مثل :term:`CV splitter`.

يرجى الرجوع إلى :ref:`Metadata Routing User Guide <metadata_routing>` للمزيد من المعلومات.

.. _glossary_target_types:

انواع الأهداف

    

فيما يلي ترجمة النص بتنسيق RST إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

===========

.. glossary::

    binary
        مشكلة تصنيف مكونة من فئتين. يمكن تمثيل الهدف الثنائي كمشكلة :term:`multiclass` ولكن مع فئتين فقط. يتم تمثيل دالة القرار الثنائية كمصفوفة أحادية البعد.

        من الناحية الدلالية، غالبًا ما تعتبر إحدى الفئتين الفئة "الإيجابية". ما لم يتم تحديد خلاف ذلك (على سبيل المثال باستخدام :term:`pos_label` في :term:`evaluation metrics`)، فإننا نعتبر تسمية الفئة ذات القيمة الأكبر (رقميًا أو أبجديًا) الفئة الإيجابية: من التسميات [0، 1]، 1 هي الفئة الإيجابية؛ من [1، 2]، 2 هي الفئة الإيجابية؛ من ['no'، 'yes']، 'yes' هي الفئة الإيجابية؛ من ['no'، 'YES']، 'no' هي الفئة الإيجابية. هذا يؤثر على نتائج :term:`decision_function`، على سبيل المثال.

        لاحظ أن مجموعة بيانات مأخوذة من ``y`` متعددة الفئات أو ``y`` مستمر قد تبدو ثنائية.

        ستعيد :func:`~utils.multiclass.type_of_target` 'binary' للمدخلات الثنائية، أو مصفوفة مماثلة مع وجود فئة واحدة فقط.

    continuous
        مشكلة انحدار حيث يكون هدف كل عينة رقمًا عشريًا محدودًا ممثلاً كمصفوفة أحادية البعد من الأرقام العشرية (أو đôi khi أعداد صحيحة).

        ستعيد :func:`~utils.multiclass.type_of_target` 'continuous' للمدخلات المستمرة، ولكن إذا كانت البيانات كلها أعدادًا صحيحة، فسيتم التعرف عليها على أنها 'multiclass'.

    continuous multioutput
    continuous multi-output
    multioutput continuous
    multi-output continuous
        مشكلة انحدار حيث يتكون هدف كل عينة من ``n_outputs`` :term:`outputs` ، وكل منها رقم عشري محدود، لعدد صحيح ثابت ``n_outputs > 1`` في مجموعة بيانات معينة.

        يتم تمثيل أهداف المخرجات المتعددة المستمرة كمخرجات :term:`continuous` متعددة، مكدسة أفقيًا في مصفوفة من الشكل ``(n_samples، n_outputs)``.

        ستعيد :func:`~utils.multiclass.type_of_target` 'continuous-multioutput' لمدخلات المخرجات المتعددة المستمرة، ولكن إذا كانت البيانات كلها أعدادًا صحيحة، فسيتم التعرف عليها على أنها 'multiclass-multioutput'.

    multiclass
    multi-class
        مشكلة تصنيف تتكون من أكثر من فئتين. يمكن تمثيل هدف متعدد الفئات كمصفوفة أحادية البعد من السلاسل أو الأعداد الصحيحة. يتم قبول متجه العمود ثنائي الأبعاد للأعداد الصحيحة (أي إخراج واحد في مصطلحات :term:`multioutput`) أيضًا.

        نحن لا ندعم رسميًا الكائنات القابلة للترتيب والقابلة للتجزئة الأخرى كملصقات للفئة، حتى لو حدث أن عملت تقديرات عند إعطاء أهداف تصنيف من هذا النوع.

        لتصنيف شبه خاضع للإشراف، يجب أن تحتوي العينات :term:`unlabeled` على التسمية الخاصة -1 في ``y``.

        ضمن scikit-learn، تدعم جميع التقديرات التي تدعم التصنيف الثنائي أيضًا التصنيف متعدد الفئات، باستخدام One-vs-Rest افتراضيًا.

        يساعد :class:`preprocessing.LabelEncoder` في توحيد أهداف متعددة الفئات كأعداد صحيحة.

        ستعيد :func:`~utils.multiclass.type_of_target` 'multiclass' للمدخلات متعددة الفئات. قد يرغب المستخدم أيضًا في التعامل مع مدخلات 'binary' بشكل مماثل لـ 'multiclass'.

    multiclass multioutput
    multi-class multi-output
    multioutput multiclass
    multi-output multi-class
        مشكلة تصنيف حيث يتكون هدف كل عينة من ``n_outputs`` :term:`outputs` ، كل منها ملصق فئة، لعدد صحيح ثابت ``n_outputs > 1`` في مجموعة بيانات معينة. يحتوي كل ناتج على مجموعة ثابتة من الفئات المتاحة، ويتم وضع علامة على كل عينة بفئة لكل ناتج. يمكن أن يكون الناتج ثنائي أو متعدد الفئات، وفي الحالة التي تكون فيها جميع المخرجات ثنائية، يكون الهدف هو :term:`multilabel`.

        تمثل أهداف إخراج متعدد الفئات متعددة الفئات كأهداف :term:`multiclass` متعددة، مكدسة أفقيًا في مصفوفة من الشكل ``(n_samples، n_outputs)``.

        XXX: من أجل البساطة، قد لا ندعم دائمًا تسميات الفئة السلسلة للعديد من الفئات متعددة المخرجات، ويجب استخدام تسميات الفئة الصحيحة.

        يوفر :mod:`~sklearn.multioutput` تقديرات تقدر مشكلات الإخراج المتعدد باستخدام العديد من التقديرات أحادية الإخراج. قد لا يمثل هذا بشكل كامل الاعتماد بين الإخراج المختلفة، والتي قد تؤديها الطرق التي تتعامل مع حالة الإخراج المتعدد بشكل أصلي (مثل أشجار القرار، والجيران الأقرب، والشبكات العصبية) بشكل أفضل.

        ستعيد :func:`~utils.multiclass.type_of_target` 'multiclass-multioutput' لمدخلات متعددة الإخراج متعددة الفئات.

    multilabel
    multi-label
        هدف إخراج متعدد الفئات حيث يكون كل ناتج هو :term:`binary`. يمكن تمثيل هذا كمصفوفة ثنائية الأبعاد (كثيفة) أو مصفوفة متفرقة من الأعداد الصحيحة، بحيث يكون كل عمود هدفًا ثنائيًا منفصلاً، حيث يتم الإشارة إلى التسميات الإيجابية بـ 1 وعادةً ما تكون التسميات السلبية -1 أو 0. لا يتم دعم الأهداف متعددة التسميات المتفرقة في كل مكان يتم فيه دعم أهداف متعددة التسميات الكثيفة.

        من الناحية الدلالية، يمكن اعتبار الهدف متعدد التسميات مجموعة من التسميات لكل عينة. بينما لا يتم استخدامه داخليًا، يتم توفير :class:`preprocessing.MultiLabelBinarizer` كأداة مساعدة للتحويل من تمثيل قائمة المجموعات إلى مصفوفة ثنائية الأبعاد أو مصفوفة متفرقة. يؤدي الترميز الأحادي للهدف متعدد الفئات باستخدام :class:`preprocessing.LabelBinarizer` إلى تحويله إلى مشكلة متعددة التسميات.

        ستعيد :func:`~utils.multiclass.type_of_target` 'multilabel-indicator' لمدخلات متعددة التسميات، سواء كانت متفرقة أو كثيفة.

    multioutput
    multi-output
        هدف حيث تحتوي كل عينة على تسميات تصنيف / انحدار متعددة. انظر :term:`multiclass multioutput` و :term:`continuous multioutput`. نحن لا ندعم حاليًا نمذجة أهداف التصنيف والانحدار المختلطة.

.. _glossary_methods:

الأساليب

    

هذا هو نص RST الذي تم ترجمته إلى اللغة العربية.

.. glossary::

    ``decision_function``
        في جهاز تصنيف أو كاشف شاذة مجهز، يتوقع درجة "ناعمة" لكل عينة بالنسبة لكل فئة، بدلاً من التوقع "الصلب" للفئة الذي ينتجه ``predict``. مدخله عادةً يكون بعض البيانات المرصودة، ``X``.

        إذا لم يكن المقدّر مجهزًا بالفعل، فإن استدعاء هذه الطريقة يجب أن يرفع استثناء ``exceptions.NotFittedError``.

        اتفاقيات الإخراج:

        تصنيف ثنائي
            مصفوفة أحادية البعد، حيث تشير القيم الأكبر من الصفر بشكل صارم إلى الفئة الإيجابية (أي الفئة الأخيرة في ``classes_``).
        تصنيف متعدد الفئات
            مصفوفة ثنائية الأبعاد، حيث يكون الحد الأقصى لصفها هو الفئة المتوقعة. يتم ترتيب الأعمدة وفقًا لـ ``classes_``.
        تصنيف متعدد التسميات
            يتسم Scikit-learn بعدم التناسق في تمثيل دالات القرار ``multilabel``. قد يتم تمثيله بإحدى طريقتين:

            - قائمة من المصفوفات ثنائية الأبعاد، كل مصفوفة من الشكل: (``n_samples``، 2)، كما هو الحال في المخرجات متعددة الفئات متعددة المخرجات. تكون القائمة بطول ``n_labels``.

            - مصفوفة ثنائية الأبعاد واحدة من الشكل (``n_samples``، ``n_labels``)، مع كل "عمود" في المصفوفة المقابلة لقرارات التصنيف الثنائي الفردية. هذا مطابق لتنسيق التصنيف متعدد الفئات، على الرغم من أن دلالاته تختلف: ينبغي تفسيره، كما هو الحال في الحالة الثنائية، عن طريق التردد عند 0.

        تصنيف متعدد المخرجات
            قائمة المصفوفات ثنائية الأبعاد، المقابلة لكل دالة قرار متعددة الفئات.
        كشف الشذوذ
            مصفوفة أحادية البعد، حيث تشير القيمة الأكبر من أو تساوي الصفر إلى قيمة داخلية.

    ``fit``
        تتوفر طريقة ``fit`` في كل جهاز تقدير. وعادة ما تتخذ بعض ``عينات`` ``X``، ``أهداف`` ``y`` إذا كان النموذج خاضع للإشراف، وربما غيرها من ``خصائص العينة`` مثل ``sample_weight``. يجب أن:

        * يمسح أي ``سمات`` سابقة مخزنة على جهاز التقدير، ما لم يتم استخدام ``warm_start``؛
        * التحقق من صحة أي ``معلمات`` وتفسيرها، ويفضل أن يرفع خطأ إذا كانت غير صالحة؛
        * التحقق من صحة بيانات الإدخال؛
        * تقدير وتخزين سمات النموذج من المعلمات المقدرة والبيانات المقدمة؛ و
        * إعادة جهاز التقدير المجهز الآن لتسهيل تكديس الأسلوب.

        تصف :ref:`glossary_target_types` التنسيقات الممكنة لـ ``y``.

    ``fit_predict``
        يستخدم بشكل خاص بالنسبة للمقدرين ``غير خاضعين للإشراف``، ``التحولي``، وهذا يجهز النموذج ويعيد التوقعات (على غرار ``predict``) على بيانات التدريب. في المجمعين، يتم تخزين هذه التنبؤات أيضًا في سمة ``labels_``، وعادة ما يكون إخراج ``.fit_predict(X)`` مكافئًا لـ ``.fit(X).predict(X)``.
        المعلمات لـ ``fit_predict`` هي نفسها كما هي في ``fit``.

    ``fit_transform``
        طريقة على ``المحولات`` التي تجهز المقدّر وتعيد بيانات التدريب المحولة. يأخذ المعلمات كما في ``fit`` وينبغي أن يكون إخراجها نفس الشكل كما هو الحال في استدعاء ``.fit(X, ...).transform(X)``. هناك حالات نادرة مع ذلك حيث لا تقوم ``.fit_transform(X, ...)`` و``.fit(X, ...).transform(X)`` بإرجاع نفس القيمة، حيث تحتاج بيانات التدريب إلى أن تتم معالجتها بشكل مختلف (بسبب مزج النماذج في المجموعات المكدسة، على سبيل المثال؛ يجب توثيق مثل هذه الحالات بوضوح).
        قد يوفر المحولون ``التحوليون`` أيضًا ``fit_transform`` ولكن ليس ``transform``.

        أحد الأسباب لتنفيذ ``fit_transform`` هو أن تنفيذ ``fit`` و``transform`` بشكل منفصل سيكون أقل كفاءة من تنفيذهما معًا. يوفر :class:`base.TransformerMixin` تنفيذًا افتراضيًا، مما يوفر واجهة متسقة عبر المحولات حيث يتم أو لا يتم تخصص ``fit_transform``.

        في التعلم ``الاستقرائي`` - حيث الهدف هو تعلم نموذج معمم يمكن تطبيقه على بيانات جديدة - يجب على المستخدمين الانتباه إلى عدم تطبيق ``fit_transform`` على مجموعة البيانات بالكامل (أي بيانات التدريب والاختبار معًا) قبل مزيد من النمذجة، لأن هذا يؤدي إلى ``تسرب البيانات``.

    ``get_feature_names_out``
        بشكل أساسي لـ ``مستخرجات الميزات``، ولكن يتم استخدامه أيضًا للمحولات الأخرى لتوفير أسماء سلسلة لكل عمود في مخرجات طريقة ``transform`` للمقدّر.  يُخرج مصفوفة من السلاسل وقد يأخذ مصفوفة تشبه السلاسل كمدخل، تتوافق مع أسماء الأعمدة المدخلة التي يمكن منها إنشاء أسماء الأعمدة المخرجة.  إذا لم يتم تمرير `input_features`، فسيتم استخدام سمة `feature_names_in_`. إذا لم يتم تعريف سمة `feature_names_in_`، فسيتم تسمية الأسماء المدخلة بـ `[x0, x1, ..., x(n_features_in_ - 1)]`.

    ``get_n_splits``
        على ``قاسم CV`` (ليس مقدّرًا)، يعيد عدد العناصر التي قد يحصل عليها المرء إذا قام بالتكرار من خلال قيمة الإرجاع لـ ``split`` بالنظر إلى نفس المعلمات.  يأخذ نفس المعلمات كالانقسام.

    ``get_params``
        يحصل على جميع ``المعلمات``، وقيمها، التي يمكن تعيينها باستخدام ``set_params``.  يمكن استخدام معلمة ``deep``، عند تعيينها إلى False لإعادة تلك المعلمات فقط بما في ذلك عدم ``__``، أي عدم الإحالة عبر المقدّرين المضمنين.

  هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية دون ترجمة:

    معظم المقدرات تعتمد التعريف من :class:`base.BaseEstimator`، والذي يعتمد ببساطة على البارامترات المعرفة لـ ``__init__``. :class:`pipeline.Pipeline`، من بين آخرين، يعيد تنفيذ ``get_params`` ليعلن عن المقدرات المسماة في بارامترات ``steps`` الخاصة به كمقدرات بحد ذاتها.

    ``partial_fit``
        يسهل تركيب المقدّر بطريقة متصلة بالإنترنت. على عكس ``fit``، فإن استدعاء ``partial_fit`` بشكل متكرر لا يؤدي إلى مسح النموذج، بل يقوم بتحديثه بالبيانات المقدمة. الجزء من البيانات
        المقدم إلى ``partial_fit`` قد يسمى مجموعة صغيرة. يجب أن تكون كل مجموعة صغيرة ذات شكل متسق، إلخ. في المقدرات التكرارية، غالبًا ما يؤدي ``partial_fit`` تكرارًا واحدًا فقط.

        يمكن أيضًا استخدام ``partial_fit`` للتعلم :term:`out-of-core`، على الرغم من أنه عادة ما يقتصر على الحالة التي يمكن فيها إجراء التعلم عبر الإنترنت، أي أن النموذج يمكن استخدامه بعد كل ``partial_fit`` ولا توجد معالجة منفصلة مطلوبة لإكمال النموذج. :class:`cluster.Birch` يدخل الاتفاقية التي تنص على أن استدعاء ``partial_fit(X)`` سينتج نموذجًا غير مكتمل، ولكن يمكن إكمال النموذج عن طريق استدعاء ``partial_fit()`` أي دون تمرير مجموعة صغيرة أخرى.

        بشكل عام، لا يجوز تعديل بارامترات المقدّر بين استدعاءات ``partial_fit``، على الرغم من أن ``partial_fit`` يجب أن يقوم بالتحقق منها وكذلك مجموعة البيانات الصغيرة الجديدة. في المقابل، يتم استخدام ``warm_start`` لتركيب نفس المقدّر بشكل متكرر بنفس البيانات ولكن بارامترات مختلفة.

        مثل ``fit``، يجب أن يعيد ``partial_fit`` كائن المقدّر.

        لإزالة النموذج، يجب إنشاء مقدر جديد، على سبيل المثال مع :func:`base.clone`.

        ملحوظة: استخدام ``partial_fit`` بعد ``fit`` يؤدي إلى سلوك غير محدد.

    ``predict``
        يقوم بعمل توقع لكل عينة، عادة ما يأخذ :term:`X` فقط كمدخل (ولكن انظر تحت اتفاقيات إخراج المقدر أدناه). في :term:`classifier` أو :term:`regressor`، يكون هذا التوقع في نفس مساحة الهدف المستخدمة في التركيب (مثل واحد من {'red', 'amber', 'green'} إذا كانت ``y`` في التركيب تتكون من هذه السلاسل). على الرغم من هذا، حتى عندما تكون ``y`` المارة إلى :term:`fit` عبارة عن قائمة أو صفيف آخر، يجب أن يكون إخراج ``predict`` دائمًا صفيفًا أو مصفوفة متفرقة. في :term:`clusterer` أو :term:`outlier detector` يكون التوقع رقمًا صحيحًا.

        إذا لم يكن المقدّر :term:`fitted` بالفعل، فإن استدعاء هذه الطريقة يجب أن يرفع :class:`exceptions.NotFittedError`.

        اتفاقيات الإخراج:

        classifier
            صفيف من الشكل ``(n_samples,)`` أو ``(n_samples, n_outputs)``. يمكن تمثيل بيانات :term:`multilabel` كمصفوفة متفرقة إذا تم استخدام مصفوفة متفرقة في التركيب. يجب أن يكون كل عنصر واحدًا من القيم في سمة :term:`classes_` للمصنف.

        clusterer
            صفيف من الشكل ``(n_samples,)`` حيث تكون كل قيمة من 0 إلى ``n_clusters - 1`` إذا كانت العينة متجمعة، و -1 إذا لم تكن العينة متجمعة، كما هو الحال في :func:`cluster.dbscan`.

        outlier detector
            صفيف من الشكل ``(n_samples,)`` حيث تكون كل قيمة -1 لشاذ و 1 بخلاف ذلك.

        regressor
            صفيف رقمي من الشكل ``(n_samples,)``، عادة ما يكون float64. تحتوي بعض المقدرات على خيارات إضافية في طريقة ``predict`` الخاصة بها، مما يسمح لها بإرجاع الانحراف المعياري (``return_std=True``) أو التباين (``return_cov=True``) بالنسبة إلى القيمة المتوقعة. في هذه الحالة، تكون قيمة الإرجاع عبارة عن صفيف من التوبلات المقابلة لـ (متوسط التوقع، الانحراف المعياري، التباين) كما هو مطلوب.

    ``predict_log_proba``
        اللوغاريتم الطبيعي لإخراج :term:`predict_proba`، مقدم لتسهيل الثبات العددي.

    ``predict_proba``
        طريقة في :term:`classifiers` و:term:`clusterers` التي يمكنها إرجاع تقديرات الاحتمالات لكل فئة/تجمع. مدخله عادة ما يكون بيانات ملاحظة فقط، :term:`X`.

        إذا لم يكن المقدّر :term:`fitted` بالفعل، فإن استدعاء هذه الطريقة يجب أن يرفع :class:`exceptions.NotFittedError`.

        اتفاقيات الإخراج تشبه تلك الخاصة بـ :term:`decision_function` باستثناء حالة التصنيف :term:`binary`، حيث يتم إخراج عمود لكل فئة (بينما يخرج ``decision_function`` صفيفًا أحادي البعد). للتنبؤات الثنائية ومتعددة الصفوف، يجب أن تضيف كل صف إلى 1.

        مثل الطرق الأخرى، يجب أن يكون ``predict_proba`` موجودًا فقط عندما يمكن للمقدر تقديم تنبؤات احتمالية (انظر :term:`duck typing`). هذا يعني أن وجود الطريقة قد يعتمد على بارامترات المقدّر (مثل :class:`linear_model.SGDClassifier`) أو بيانات التدريب (مثل :class:`model_selection.GridSearchCV`) وقد تظهر فقط بعد التركيب.

    ``score``
        طريقة على المقدّر، عادة ما تكون :term:`predictor`، والذي يقيم تنبؤاته على مجموعة بيانات معينة، ويعيد درجة رقمية واحدة. يجب أن تشير قيمة الإرجاع الأكبر إلى تنبؤات أفضل؛ الدقة المستخدمة للمصنفات و R^2 للمقدّرات بشكل افتراضي.

        إذا لم يكن المقدّر :term:`fitted` بالفعل، فإن استدعاء هذه الطريقة يجب أن يرفع :class:`exceptions.NotFittedError`.

        تنفذ بعض المقدرات وظيفة نقاط مخصصة للمقدّر، وغالبًا ما تكون احتمالية البيانات بموجب النموذج.

"score\_samples"

طريقة تُرجع نتيجة لكل عينة مُعطاة. يتنوع التعريف الدقيق لـ"النتيجة" من فئة إلى أخرى. في حالة تقدير الكثافة، يمكن أن يكون نموذج الكثافة اللوغاريتمية على البيانات، وفي حالة اكتشاف الشذوذ، يمكن أن يكون عكس عامل الشذوذ في البيانات.

إذا لم يكن المقدّر قد تم تركيبه بالفعل، فإن استدعاء هذه الطريقة يجب أن يرفع خطأ `exceptions.NotFittedError`.

"set\_params"

متوفر في أي مقدّر، يأخذ الوسائط الأساسية المقابلة للمفاتيح في `get_params`. يتم توفير قيمة جديدة لكل منها لتعيينه بحيث أن استدعاء `get_params` بعد `set_params` سيعكس المعلمات (`parameters`) المتغيرة. تستخدم معظم المقدّرات التنفيذ في `base.BaseEstimator`، والذي يتعامل مع المعلمات المتداخلة ويعيّن المعلمة كسمات على المقدّر. تتم إعادة كتابة الطريقة في `pipeline.Pipeline` والمقدّرات ذات الصلة.

"split"

على أداة تفريق تقاطع التحقق (`CV splitter`) (وليس مقدّرًا)، تقبل هذه الطريقة المعلمات (`X`, `y`, `groups`)، حيث قد تكون جميعها اختيارية، وتعيد تكرارًا على أزواج `(train_idx, test_idx)`. كل من `{train,test}_idx` هو مصفوفة أحادية البعد، مع قيم من 0 إلى `X.shape[0] - 1` من أي طول، بحيث لا تظهر أي قيم في كل من بعض `train_idx` و `test_idx` المقابل لها.

"transform"

في محول (`transformer`)، يحول الإدخال، عادةً فقط `X`، إلى بعض المساحات المحولة (يُشار إليها تقليديًا باسم `Xt`). الناتج هو مصفوفة أو مصفوفة متفرقة بطول `n_samples` وبعدد ثابت من الأعمدة بعد التركيب (`fitting`).

إذا لم يكن المقدّر قد تم تركيبه بالفعل، فإن استدعاء هذه الطريقة يجب أن يرفع خطأ `exceptions.NotFittedError`.

المعلمات (`Parameters`)

(لا يوجد نص للترجمة في هذا القسم)

فيما يلي ترجمة النص بتنسيق RST إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

==========

تستخدم أسماء المعلمات الشائعة هذه، بشكل محدد في بناء المقدّر (انظر مفهوم :term:`parameter`)، وأحيانًا تظهر أيضًا كمعلمات للوظائف أو بُناة غير مقدرين.

.. glossary::

    ``class_weight``
        تُستخدم لتحديد أوزان العينة عند تركيب المصنفات كدالة لفئة :term:`target`. إذا تم دعم :term:`sample_weight` وإعطاؤها، يتم ضربها بمساهمة ``class_weight``. بالمثل، عند استخدام ``class_weight`` في مهام :term:`multioutput` (بما في ذلك :term:`multilabel`)، يتم ضرب الأوزان عبر المخرجات (أي أعمدة ``y``).

        بشكل افتراضي، يكون لجميع العينات وزن متساوٍ بحيث يتم ترجيح الفئات بشكل فعال حسب انتشارها في بيانات التدريب. يمكن تحقيق ذلك بشكل صريح باستخدام ``class_weight={label1: 1, label2: 1, ...}`` لجميع تسميات الفئة.

        بشكل أكثر عمومية، يتم تحديد ``class_weight`` كقاموس يرسم تسميات الفئة على الأوزان (``{class_label: weight}``)، بحيث يتم إعطاء كل عينة من الفئة المسماة هذا الوزن.

        يمكن استخدام ``class_weight='balanced'`` لإعطاء جميع الفئات وزنًا متساويًا عن طريق إعطاء كل عينة وزنًا يتعلق عكسيًا بانتشار فئتها في بيانات التدريب: ``n_samples / (n_classes * np.bincount(y))``. سيتم استخدام أوزان الفئة بشكل مختلف اعتمادًا على الخوارزمية: بالنسبة للنماذج الخطية (مثل SVM الخطي أو الانحدار اللوجستي)، ستغير أوزان الفئة دالة الخسارة عن طريق ترجيح خسارة كل عينة بوزن فئتها. بالنسبة للخوارزميات المستندة إلى الشجرة، سيتم استخدام أوزان الفئة لمعايرة معيار الانقسام. **ملحوظة** ومع ذلك، أن هذا إعادة التوازن لا يأخذ وزن العينات في كل فئة في الاعتبار.

        بالنسبة لتصنيف المخرجات المتعددة، يتم استخدام قائمة من القواميس لتحديد الأوزان لكل ناتج. على سبيل المثال، بالنسبة لتصنيف متعدد التسميات من أربع فئات، يجب أن تكون الأوزان ``[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}]`` بدلاً من ``[{1:1}, {2:5}, {3:1}, {4:1}]``.

        يتم التحقق من صحة معلمة ``class_weight`` وتفسيرها باستخدام :func:`utils.class_weight.compute_class_weight`.

    ``cv``
        يحدد استراتيجية تقسيم التحقق المتقاطع، كما هو مستخدم في إجراءات التحقق المتقاطع. ``cv`` متاح أيضًا في مقدرين مثل :class:`multioutput.ClassifierChain` أو :class:`calibration.CalibratedClassifierCV` التي تستخدم تنبؤات مقدر واحد كبيانات تدريب لآخر، حتى لا تفرط في ملاءمة الإشراف على التدريب.

        المدخلات الممكنة لـ ``cv`` هي عادةً:

        - عدد صحيح، يحدد عدد الطيات في التحقق المتقاطع K-fold. سيكون K-fold طبقياً على الفئات إذا كان المقدّر مصنفًا (يتم تحديده بواسطة :func:`base.is_classifier`) وقد تمثل :term:`targets` مشكلة تصنيف ثنائية أو متعددة الفئات (ولكن ليس متعددة المخرجات) (يتم تحديدها بواسطة :func:`utils.multiclass.type_of_target`).
        - مثيل :term:`cross-validation splitter`. راجع :ref:`User Guide <cross_validation>` for splitters available within Scikit-learn.
        - تكرار ينتج تقسيمات التدريب / الاختبار.

        مع بعض الاستثناءات (خاصة عندما لا يكون استخدام التحقق المتقاطع على الإطلاق خيارًا)، يكون الافتراضي هو 5 أضعاف.

        يتم التحقق من صحة قيم ``cv`` وتفسيرها باستخدام :func:`model_selection.check_cv`.

    ``kernel``
        يحدد دالة النواة التي سيتم استخدامها بواسطة خوارزميات طريقة النواة. على سبيل المثال، لدى كل من المقدر :class:`svm.SVC` و :class:`gaussian_process.GaussianProcessClassifier` معلمة ``kernel`` التي تأخذ اسم النواة المطلوب استخدامها كـ string أو دالة نواة قابلة للاستدعاء تُستخدم لحساب مصفوفة النواة. لمزيد من الإشارة ، راجع :ref:`kernel_approximation` و :ref:`gaussian_process` أدلة المستخدم.

    ``max_iter``
        بالنسبة للمقدر الذي يشمل التحسين التكراري، يحدد هذا الحد الأقصى لعدد التكرارات التي يجب إجراؤها في :term:`fit`. إذا تم تشغيل ``max_iter`` تكرارات دون التقارب، يجب رفع :class:`exceptions.ConvergenceWarning`. لاحظ أن تفسير "تكرار واحد" غير متسق عبر المقدرين: بعضها، ولكن ليس جميعها، يستخدمه ليعني عصرًا واحدًا (أي اجتياز كل عينة في البيانات).

        FIXME ربما ينبغي أن يكون لدينا بعض الاختبارات المشتركة حول العلاقة بين ConvergenceWarning و max_iter.

    ``memory``
        يستخدم بعض المقدرين :class:`joblib.Memory` لتخزين الحلول الجزئية أثناء التركيب. وبالتالي، عندما يتم استدعاء ``fit`` مرة أخرى، تم تذكير تلك الحلول الجزئية ويمكن إعادة استخدامها.

        يمكن تحديد معلمة ``memory`` كسلسلة ذات مسار إلى دليل، أو يمكن استخدام مثيل :class:`joblib.Memory` (أو كائن بواجهة مماثلة، أي طريقة ``cache``).

        يتم التحقق من صحة قيم ``memory`` وتفسيرها باستخدام :func:`utils.validation.check_memory`.

    ``metric``
        كمعلمة، هذا هو المخطط لتحديد المسافة بين نقطتي بيانات. انظر :func:`metrics.pairwise_distances`. في الممارسة العملية، بالنسبة لبعض الخوارزميات، قد يتم استخدام مقياس المسافة غير الصحيح (الذي لا يطيع عدم المساواة في المثلث، مثل مسافة كوزين).

        XXX: يستخدم التجميد الهرمي ``affinity`` بهذا المعنى.

        نستخدم *metric* أيضًا للإشارة إلى :term:`evaluation metrics`، لكننا نتجنب استخدام هذا المعنى كاسم معلمة.

    ``n_components``
        عدد الميزات التي يجب أن يحولها :term:`transformer` الإخراج إليها. انظر :term:`components_` للحالة الخاصة للإسقاط الشبيه.

    

```n_iter_no_change```
    عدد التكرارات بدون تحسين يجب الانتظار قبل إيقاف الإجراء التكراري. يُعرف هذا أيضًا بمعلمة "الصبر". يتم استخدامه عادةً مع "الإيقاف المبكر" لتجنب التوقف مبكرًا.

```n_jobs```
    يتم استخدام هذا المعلمة لتحديد عدد العمليات أو الخيوط المتزامنة التي يجب استخدامها للروتينات المتوازية مع joblib.

    ```n_jobs``` هو عدد صحيح، يحدد الحد الأقصى لعدد العمال المتزامنين. إذا تم إعطاء 1، فلن يتم استخدام أي توازي joblib على الإطلاق، وهو أمر مفيد لاستكشاف الأخطاء وإصلاحها. إذا تم تعيينه على -1، يتم استخدام جميع وحدات المعالجة المركزية. لـ ```n_jobs``` أقل من -1، يتم استخدام (n_cpus + 1 + n_jobs). على سبيل المثال مع ```n_jobs=-2``، يتم استخدام جميع وحدات المعالجة المركزية باستثناء واحدة.

    القيمة الافتراضية لـ ```n_jobs``` هي None، مما يعني "غير محدد"؛ سيتم تفسيرها عمومًا على أنها ```n_jobs=1``، ما لم يحدد سياق الخلفية الحالي لـ :class:`joblib.Parallel` خلاف ذلك.

    لاحظ أنه حتى إذا كان ```n_jobs=1``، فقد يتم استخدام التوازي على مستوى منخفض (عبر Numpy و OpenMP) في بعض التكوينات.

    لمزيد من التفاصيل حول استخدام ``joblib`` وتفاعلاته مع scikit-learn، يرجى الرجوع إلى :ref:`parallelism notes <parallelism>`.

```pos_label```
    قيمة يجب ترميز التسميات الإيجابية بها في مشاكل التصنيف الثنائي التي لا يتم فيها افتراض الفئة الإيجابية. عادةً ما تكون هذه القيمة مطلوبة لحساب مقاييس التقييم غير المتماثلة مثل الدقة والاسترجاع.

```random_state```
    عندما يكون التوزيع العشوائي جزءًا من خوارزمية Scikit-learn، يمكن توفير معلمة ``random_state`` للتحكم في مولد الأرقام العشوائية المستخدم. لاحظ أن وجود ``random_state`` وحده لا يعني أنه يتم دائمًا استخدام التوزيع العشوائي، لأنه قد يعتمد على تعيين معلمة أخرى، مثل ``shuffle``.

    ستؤثر القيمة المارة على قابلية إعادة إنتاج النتائج التي تعيدها الدالة (:term:`fit`، :term:`split`، أو أي دالة أخرى مثل :func:`~sklearn.cluster.k_means`). يمكن أن تكون قيمة `random_state`:

    None (افتراضي)
        استخدم مثيل الحالة العشوائية العالمية من :mod:`numpy.random`.
        ستعيد استدعاء الدالة عدة مرات استخدام نفس المثيل، وستنتج نتائج مختلفة.

    عدد صحيح
        استخدم مولد أرقام عشوائي جديد زرعه العدد الصحيح المحدد.
        سيؤدي استخدام عدد صحيح إلى إنتاج نفس النتائج عبر مكالمات مختلفة.
        ومع ذلك، قد يكون من المفيد التحقق من أن نتائجك مستقرة عبر عدد من البذور العشوائية المختلفة المميزة. البذور العشوائية الصحيحة الشائعة هي 0 و `42
        <https://en.wikipedia.org/wiki/Answer_to_the_Ultimate_Question_of_Life%2C_the_Universe%2C_and_Everything>`_.
        يجب أن تكون القيم الصحيحة في النطاق `[0، 2 ** 32 - 1]`.

    مثيل :class:`numpy.random.RandomState`
        استخدم حالة عشوائية مقدمة، مما يؤثر فقط على المستخدمين الآخرين
        نفس مثيل الحالة العشوائية. سيعيد استدعاء الدالة عدة مرات استخدام نفس المثيل، وسيؤدي ذلك إلى نتائج مختلفة.

    يتم استخدام :func:`utils.check_random_state` داخليًا للتحقق من صحة ``random_state`` المدخلة وإرجاع مثيل :class:`~numpy.random.RandomState`.

    لمزيد من التفاصيل حول كيفية التحكم في عشوائية كائنات scikit-learn وتجنب المزالق الشائعة، يمكنك الرجوع إلى :ref:`randomness`.

```scoring```
    يحدد وظيفة الدرجة التي يجب تعظيمها (عادةً بواسطة :ref:`cross validation <cross_validation>`)، أو - في بعض الحالات - وظائف الدرجة المتعددة التي يجب الإبلاغ عنها. يمكن أن تكون وظيفة الدرجة سلسلة يقبلها :func:`metrics.get_scorer` أو :term:`scorer` قابل للاستدعاء، ولا يجب الخلط بينها وبين :term:`evaluation metric`، نظرًا لأن الأخير يحتوي على واجهة برمجة تطبيقات أكثر تنوعًا.  يمكن أيضًا ضبط ``scoring`` على None، وفي هذه الحالة يتم استخدام طريقة :term:`score` للمقدر.  انظر :ref:`scoring_parameter` في دليل المستخدم.

    حيث يمكن تقييم مقاييس متعددة، يمكن إعطاء ``scoring`` إما كقائمة من السلاسل الفريدة، أو قاموس بأسماء كمفاتيح وقابلة للاستدعاء كقيم أو قابل للاستدعاء يعيد قاموسًا. لاحظ أن هذا لا يحدد وظيفة الدرجة التي يجب تعظيمها، ويمكن استخدام معلمة أخرى مثل ``refit`` لهذا الغرض.

    يتم التحقق من صحة معلمة ``scoring`` وتفسيرها باستخدام :func:`metrics.check_scoring`.

```verbose```
    لا تتم معالجة التسجيل بشكل متسق للغاية في Scikit-learn في الوقت الحالي، ولكن عندما يتم توفيره كخيار، عادةً ما يتوفر المعلمة ``verbose`` لاختيار عدم التسجيل (تعيين إلى False). يجب أن تمكن أي قيمة صحيحة بعض التسجيل، ولكن قد تكون هناك حاجة إلى أعداد صحيحة أكبر (على سبيل المثال أعلى من 10) للغة الكاملة.  يتم عادةً طباعة السجلات الكلامية إلى المخرجات القياسية.
    لا ينبغي أن تنتج أدوات التقدير أي مخرجات على الإخراج القياسي مع إعداد ``verbose`` الافتراضي.

```warm_start```

    عند تركيب مقدر مرارًا وتكرارًا على نفس مجموعة البيانات، ولكن بالنسبة لقيم متعددة (مثل إيجاد القيمة التي تزيد من الأداء كما في :ref:`grid search <grid_search>`)، قد يكون من الممكن إعادة استخدام جوانب النموذج المستفادة من القيمة المعلمة السابقة ،
    توفير الوقت.  عندما يكون ``warm_start`` صحيحًا، يتم استخدام :term:`fitted` الحالية
    :term:`attributes` لتبدأ النموذج الجديد
    في مكالمة لاحقة إلى :term:`fit`.

    لاحظ أن هذا لا ينطبق إلا على بعض النماذج وبعض
    المعلمات، وحتى بعض أوامر قيم المعلمة. بشكل عام، هناك
    تفاعل بين ``warm_start`` والمعلمة التي تتحكم في عدد التكرارات
    من المقدّر.

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية كما هي:

بالنسبة للمقدرات المستوردة من :mod:`~sklearn.ensemble`، سيتفاعل ``warm_start`` مع ``n_estimators`` أو ``max_iter``. بالنسبة لهذه النماذج، فإن عدد التكرارات، المبلغ عنها عبر ``len(estimators_)`` أو ``n_iter_``، يتوافق مع إجمالي عدد المقدرات/التكرارات المتعلمة منذ تهيئة النموذج. وبالتالي، إذا كان النموذج قد تم تهيئته بالفعل باستخدام `N` من المقدرات، وتمت استدعاء `fit` مع تعيين ``n_estimators`` أو ``max_iter`` إلى `M`، فسيقوم النموذج بتدريب `M - N` من المقدرات الجديدة.

تتصرف النماذج الأخرى، التي عادةً ما تستخدم الحلول القائمة على التدرج، بشكل مختلف. إنها جميعًا تعرض معلمة ``max_iter``. يتوافق ``n_iter_`` المبلغ عنه مع عدد التكرارات المنفذة أثناء آخر استدعاء لـ ``fit`` ولن يتجاوز ``max_iter``. وبالتالي، نحن لا نأخذ في الاعتبار حالة المقدّر منذ التهيئة.

تحافظ :term:`partial_fit` أيضًا على النموذج بين الاستدعاءات، ولكنها تختلف: مع ``warm_start``، تتغير المعلمات وتبقى البيانات (أكثر أو أقل) ثابتة عبر استدعاءات ``fit``؛ مع ``partial_fit``، تتغير الدفعة الصغيرة من البيانات وتبقى معلمات النموذج ثابتة.

هناك حالات تريد فيها استخدام ``warm_start`` للتناسب مع بيانات مختلفة ولكنها ذات صلة وثيقة. على سبيل المثال، قد يناسب المرء في البداية مجموعة فرعية من البيانات، ثم يضبط معلمات البحث على مجموعة البيانات الكاملة. للتصنيف، يجب أن تتضمن جميع البيانات في تسلسل استدعاءات ``warm_start`` لـ ``fit`` عينات من كل فئة.

.. _glossary_attributes:

السمات

(ملاحظة: لم يتم ترجمة الرابط ``:term:`partial_fit``` لأنه يشير إلى مصطلح محدد في إطار عمل sklearn وقد لا يكون له ترجمة مباشرة إلى اللغة العربية.)

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

==========

انظر مفهوم :term:`attribute`.

.. glossary::

    ``classes_``
        قائمة تسميات الفئات المعروفة لـ :term:`classifier`، والتي تربط كل تسمية برقم فهرس يُستخدم في تمثيل النموذج أو الناتج لدينا. على سبيل المثال، المصفوفة الناتجة من :term:`predict_proba` لها أعمدة متوافقة مع ``classes_``. بالنسبة لـ :term:`multi-output` classifiers، يجب أن تكون ``classes_`` عبارة عن قائمة من القوائم، مع قائمة فئات لكل ناتج. لكل ناتج، يجب فرز الفئات (رقميًا أو أبجديًا للحروف).

        غالبًا ما تتم إدارة ``classes_`` وتعيينها للمؤشرات باستخدام :class:`preprocessing.LabelEncoder`.

    ``components_``
        مصفوفة تحويل مماسي من الشكل ``(n_components, n_features)`` المستخدمة في العديد من المحولات الخطية :term:`transformers` حيث :term:`n_components` هو عدد ميزات الإخراج و:term:`n_features` هو عدد ميزات الإدخال.

        انظر أيضًا :term:`components_` وهو سمة مشابهة للتنبؤات الخطية.

    ``coef_``
        مصفوفة الوزن/المعامل لنموذج خطي معمم :term:`predictor`، من الشكل ``(n_features,)`` للتصنيف الثنائي والانحدار أحادي الإخراج، ``(n_classes, n_features)``للتصنيف متعدد الفئات و``(n_targets, n_features)`` للانحدار متعدد الإخراج. لاحظ أن هذا لا يتضمن مصطلح التقاطع (أو التحيز)، والذي يتم تخزينه في ``intercept_``.

        عند توفرها، لا يتم عادةً توفير ``feature_importances_`` أيضًا، ولكن يمكن حسابها كمعيار لكل ميزة في ``coef_``.

        انظر أيضًا :term:`components_` وهو سمة مشابهة للمحولات الخطية.

    ``embedding_``
        تضمين لبيانات التدريب في تقديرات :ref:`manifold learning <manifold>`، مع الشكل ``(n_samples, n_components)``، مطابقًا لإخراج :term:`fit_transform`. انظر أيضًا :term:`labels_`.

    ``n_iter_``
        عدد التكرارات التي تم إجراؤها بالفعل عند تركيب مقدر تكراري قد يتوقف عند التقارب. انظر أيضًا :term:`max_iter`.

    ``feature_importances_``
        متجه من الشكل ``(n_features,)`` متوفر في بعض :term:`predictors` لتوفير مقياس نسبي لأهمية كل ميزة في تنبؤات النموذج.

    ``labels_``
        متجه يحتوي على تسمية الكتلة لكل عينة من بيانات التدريب في :term:`clusterers`، مطابق لإخراج :term:`fit_predict`. انظر أيضًا :term:`embedding_`.

.. _glossary_sample_props:

خصائص البيانات والعينات
==========================

انظر مفهوم :term:`sample property`.

.. glossary::

    ``groups``
        تُستخدم في إجراءات التحقق المتقاطع لتحديد العينات المرتبطة ببعضها.
        كل قيمة هي مُعرّف بحيث، في :term:`CV splitter` الداعم، قد لا تظهر العينات من بعض قيم ``groups`` في كل من مجموعة التدريب ومجموعة الاختبار المقابلة لها.
        انظر :ref:`group_cv`.

    ``sample_weight``
        وزن نسبي لكل عينة. بشكل بديهي، إذا كانت جميع الأوزان أعدادًا صحيحة، فإن نموذجًا أو نتيجة مرجحة يجب أن تكون مكافئة لتلك المحسوبة عند تكرار العينة لعدد المرات المحددة في الوزن. يمكن تحديد الأوزان كأرقام عشرية، بحيث تكون أوزان العينات عادةً ما تكون مكافئة حتى عامل توسيع موجب ثابت.

        FIXME: هل هذا التفسير هو الحال دائمًا في الواقع العملي؟ ليس لدينا اختبارات شائعة.

        تدعم بعض التقديرات، مثل أشجار القرار، الأوزان السالبة.
        FIXME: قد لا يتم اختبار هذه الميزة أو عدم وجودها أو توثيقها في العديد من التقديرات.

        هذا ليس هو الحال تمامًا عندما تفكر معلمات أخرى للنموذج في عدد العينات في منطقة ما، كما هو الحال مع ``min_samples`` في :class:`cluster.DBSCAN`. في هذه الحالة، يصبح عدد العينات إلى مجموع أوزانها.

        في التصنيف، يمكن أيضًا تحديد أوزان العينات كدالة للفئة باستخدام :term:`class_weight` estimator :term:`parameter`.

    ``X``
        يدل على البيانات التي يتم ملاحظتها في وقت التدريب والتنبؤ، وتستخدم كمتغيرات مستقلة في التعلم. الحرف كبير للإشارة إلى أنه عادة ما يكون مصفوفة (انظر :term:`rectangular`). عندما تكون مصفوفة، يمكن تمثيل كل عينة بواسطة متجه :term:`feature`، أو متجه :term:`precomputed` (عدم) تشابه مع كل عينة تدريب. قد لا تكون ``X`` مصفوفة، وقد تتطلب :term:`feature extractor` أو :term:`pairwise metric` لتحويلها إلى مصفوفة قبل تعلم النموذج.

    ``Xt``
        اختصار لـ "transformed :term:`X`".

    ``y``
    ``Y``
        يدل على البيانات التي قد يتم ملاحظتها في وقت التدريب كمتغير تابع في التعلم، ولكن غير متوفر في وقت التنبؤ، وعادة ما يكون :term:`target` للتنبؤ. يمكن أن يكون الترميز كبيرًا للإشارة إلى أنه مصفوفة، تمثل أهداف :term:`multi-output`، على سبيل المثال؛ ولكن عادةً ما نستخدم ``y`` وأحيانًا نفعل ذلك حتى عندما تكون مخرجات متعددة مفترضة.
