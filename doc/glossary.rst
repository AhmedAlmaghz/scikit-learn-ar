هذا القاموس يهدف إلى تمثيل واضح للاتفاقيات الضمنية والصريحة المطبقة في Scikit-learn وواجهة برمجة التطبيقات (API) الخاصة بها، مع توفير مرجع للمستخدمين والمساهمين على حد سواء. ويهدف إلى وصف المفاهيم وتفصيل واجهة برمجة التطبيقات (API) المقابلة أو توفير رابط إلى أجزاء أخرى ذات صلة من الوثائق التي تفعل ذلك. من خلال الربط إلى إدخالات القاموس من مرجع واجهة برمجة التطبيقات (API) ودليل المستخدم، يمكننا تقليل التكرار وعدم الاتساق.

نبدأ بإدراج المفاهيم العامة (وأي مفاهيم لم تناسب الأقسام الأخرى)، ولكن هناك مجموعات أكثر تحديدًا من المصطلحات ذات الصلة مدرجة أدناه: :ref: `glossary_estimator_types`، :ref: `glossary_target_types`، :ref: `glossary_methods`، :ref: `glossary_parameters`، :ref: `glossary_attributes`، :ref: `glossary_sample_props`.

المفاهيم العامة:
================

.. glossary::

    1d
    1d array
        مصفوفة أحادية البعد. مصفوفة NumPy التي يكون لخاصية ".shape" فيها طول 1.
        متجه.

    2d
    2d array
        مصفوفة ثنائية الأبعاد. مصفوفة NumPy التي يكون لخاصية ".shape" فيها طول 2.
        غالبًا ما تمثل مصفوفة.

    API
        يشير إلى كل من الواجهات *المحددة* للمُقدِّرات المُنفَّذة في
        Scikit-learn و*الاتفاقيات العامة* عبر أنواع المُقدِّرات كما هو موصوف في
        هذا المسرد و:ref:`نظرة عامة في وثائق المساهمين <api_overview>`.

        يتم توثيق واجهات محددة تشكل واجهة برمجة التطبيقات العامة لـ Scikit-learn
        بشكل أساسي في :ref:`api_ref`. ومع ذلك، فإننا نعتبر بشكل غير رسمي أي شيء
        كجزء من واجهة برمجة التطبيقات العامة إذا لم يبدأ أي من المعرفات المطلوبة
        للوصول إليه بشرطة سفلية "". نحاول بشكل عام الحفاظ على :term:`التوافق
        مع الإصدارات السابقة` لجميع الكائنات في واجهة برمجة التطبيقات العامة.

        لا يُضمن استقرار واجهة برمجة التطبيقات الخاصة، بما في ذلك الوظائف
        والوحدات والطرق التي تبدأ بشرطة سفلية "".

    array-like
        تنسيق البيانات الأكثر شيوعًا لـ *الإدخال* إلى مُقدِّرات ووظائف
        Scikit-learn، يمكن أن يكون array-like أي نوع كائن ينتج عنه مصفوفة
        بالشكل المناسب (عادة أحادية أو ثنائية الأبعاد) من النوع المناسب (عادة
        رقمي) عند تمريره إلى الدالة :func:`numpy.asarray`.

        يشمل ذلك:

        * مصفوفة NumPy
        * قائمة من الأرقام
        * قائمة من القوائم ذات الطول k من الأرقام لبعض الطول الثابت k
        * :class:`pandas.DataFrame` مع أعمدة رقمية فقط
        * سلسلة رقمية من فئة :class:`pandas.Series`

        يستبعد ذلك:

        * :term:`مصفوفة متفرقة`
        * مصفوفة متفرقة
        * مُولِّد
        * مُنشئ

        ملاحظة: يجب أن تكون *النتائج* من مُقدِّرات ووظائف Scikit-learn (مثل
        التنبؤات) بشكل عام مصفوفات أو مصفوفات متفرقة، أو قوائم منها (كما هو
        الحال في فئة :class:`tree.DecisionTreeClassifier` متعددة الإخراج
        ``predict_proba``). لا يُعتبر المُقدِّر صالحًا إذا أعادت دالة
        ``predict()`` الخاصة به قائمة أو `pandas.Series`.

    attribute
    attributes
        نستخدم مصطلح attribute في الغالب للإشارة إلى كيفية تخزين معلومات النموذج
        على مُقدِّر أثناء التجهيز. يجب أن يبدأ أي attribute عام مخزن على
        مثيل المُقدِّر بحرف أبجدي وينتهي بشرطة سفلية واحدة إذا تم تعيينه في
        :term:`fit` أو :term:`partial_fit`. يتم توثيق هذه الأنواع من
        attributes في قسم *Attributes* الخاص بالـمُقدِّر. عادةً ما تكون
        المعلومات المخزنة في attributes إما إحصائيات كافية تُستخدم للتنبؤ أو
        التحويل؛ أو مخرجات :term:`transductive` مثل :term:`labels_` أو
        :term:`embedding_`; أو بيانات تشخيصية، مثل :term:`feature_importances_`.
        ترد قائمة بالـ attributes الشائعة :ref:`أدناه <glossary_attributes>`.

        قد يكون للـ attribute العام نفس اسم معلمة الباني، مع إضافة شرطة سفلية.
        ويُستخدم هذا لتخزين نسخة تم التحقق منها أو تقديرها من إدخال المستخدم.
        على سبيل المثال، يتم إنشاء :class:`decomposition.PCA` بمعلمة
        "n_components". ومن ذلك، إلى جانب معلمات وبيانات أخرى، يُقدِّر PCA
        attribute "n_components_".

        قد يتم أيضًا تعيين attributes خاصة إضافية تُستخدم في
        التنبؤ/التحويل/إلخ. أثناء التجهيز. تبدأ هذه الأنواع من attributes
        بشرطة سفلية واحدة ولا يُضمن استقرارها للوصول العام.

        يجب أن يكون أي attribute عام على مثيل المُقدِّر لا ينتهي بشرطة سفلية
        القيمة المخزنة، وغير المعدلة، لمعلمة "مُنشئ" بنفس الاسم. نظرًا لهذا
        التكافؤ، يتم توثيق هذه الأنواع من الـ attributes في قسم *Parameters*
        الخاص بالمُقدِّر.

    backwards compatibility
        نحاول بشكل عام الحفاظ على التوافق مع الإصدارات السابقة (أي أنه يمكن
        توسيع الواجهات والسلوكيات، ولكن لا يمكن تغييرها أو إزالتها) من إصدار
        إلى آخر، ولكن مع بعض الاستثناءات:

        واجهة برمجة التطبيقات العامة فقط
            قد يتغير سلوك الكائنات التي يتم الوصول إليها من خلال معرفات خاصة
            (تلك التي تبدأ بشرطة سفلية "") بشكل تعسفي بين الإصدارات.
        كما هو موثق
            سنفترض بشكل عام أن المستخدمين قد التزموا بأنواع المعلمات والنطاقات
            الموثقة. إذا طلبت الوثائق قائمة وقدم المستخدم مجموعة، فلا نضمن
            سلوكًا متسقًا من إصدار إلى آخر.
        الإلغاء التدريجي
            قد تتغير السلوكيات بعد فترة :term:`الإلغاء التدريجي` (عادة ما تكون
            إصدارين). يتم إصدار التحذيرات باستخدام وحدة :mod:`warnings` في
            بايثون.
        معلمات الكلمات الرئيسية
            قد نفترض في بعض الأحيان أن جميع المعلمات الاختيارية (باستثناء X
            وy إلى :term:`fit` والطرق المماثلة) يتم تمريرها كمعلمات كلمات رئيسية
            فقط وقد يتم إعادة ترتيبها بشكل متكرر.
        إصلاح الأخطاء والتحسينات
            قد يؤدي إصلاح الأخطاء، وفي بعض الأحيان التحسينات، إلى تغيير سلوك
            المُقدِّرات، بما في ذلك تنبؤات مُقدِّر تم تدريبه على نفس البيانات
            و:term:`random_state`. عندما يحدث هذا، نحاول الإشارة إليه بوضوح في
            سجل التغييرات.
        التخزين
            لا نقدم أي ضمانات بأن تخزين مُقدِّر في إصدار ما سيسمح بفك تخزينه
            إلى نموذج مكافئ في الإصدار التالي. (بالنسبة للمُقدِّرات في حزمة
            sklearn، نقوم بإصدار تحذير عند محاولة فك التخزين، حتى لو كان
            من المحتمل أن يعمل). راجع :ref:`persistence_limitations`.
        :func:`utils.estimator_checks.check_estimator`
            نقدم ضمانات محدودة للتوافق مع الإصدارات السابقة لفحوصات المُقدِّرات:
            قد نضيف متطلبات إضافية على المُقدِّرات التي تم اختبارها باستخدام
            هذه الدالة، وعادةً ما تكون هذه المتطلبات مفترضة بشكل غير رسمي ولكن
            لم يتم اختبارها بشكل رسمي.

        على الرغم من هذا العقد غير الرسمي مع مستخدمينا، يتم توفير البرنامج كما
        هو، كما هو مذكور في الترخيص. عندما يتسبب إصدار ما عن غير قصد في
        تغييرات غير متوافقة مع الإصدارات السابقة، يُعرف ذلك باسم تراجعات
        البرامج.

    callable
        دالة أو فئة أو كائن ينفذ طريقة ``__call__``؛ أي شيء يعيد القيمة True
        عندما يتم تمريره كوسيط للدالة `callable()
        <https://docs.python.org/3/library/functions.html#callable>`_.

    categorical feature
        ميزة تصنيفية أو اسمية لها مجموعة محدودة من القيم المنفصلة عبر
        مجموعة البيانات. يتم تمثيل هذه الميزات عادةً كأعمدة من الأرقام أو
        السلاسل النصية. سيرفض معظم مُقدِّرات scikit-learn السلاسل النصية،
        وسيتم التعامل مع الأرقام على أنها ترتيبية أو ذات قيم عددية. ولاستخدامها
        مع معظم المُقدِّرات، يجب ترميز المتغيرات التصنيفية بطريقة الترميز
        one-hot encoding. ومن الاستثناءات الملحوظة النماذج الشجرية مثل الغابات
        العشوائية ونماذج التعزيز التدريجي التي غالبًا ما تعمل بشكل أفضل وأسرع
        مع المتغيرات التصنيفية المشفرة بالأرقام الصحيحة.
        تساعد الفئة :class:`~sklearn.preprocessing.OrdinalEncoder` في ترميز
        الميزات التصنيفية ذات القيم النصية كأعداد صحيحة ترتيبية، ويمكن استخدام
        الفئة :class:`~sklearn.preprocessing.OneHotEncoder` لترميز المتغيرات
        التصنيفية بطريقة one-hot encoding.
        راجع أيضًا :ref:`preprocessing_categorical_features` وحزمة
        `categorical-encoding
        <https://github.com/scikit-learn-contrib/category_encoders>`_ للأدوات
        ذات الصلة بترميز الميزات التصنيفية.

    clone
    cloned
        لنسخ مثيل :term:`estimator` وإنشاء مثيل جديد له نفس :term:`parameters`،
        ولكن بدون أي :term:`attributes` مجهزة، باستخدام
        :func:`~sklearn.base.clone`.

        عندما يتم استدعاء ``fit``، عادةً ما يقوم :term:`meta-estimator` باستنساخ
        مثيل المُقدِّر المُغلَّف قبل تجهيز مثيل المُقدِّر المستنسخ. (تُعد
        :class:`~pipeline.Pipeline` و:class:`~pipeline.FeatureUnion` استثناءات
        لهذا، لأسباب متعلقة بالإرث).

        إذا كانت معلمة "random_state" للمُقدِّر عبارة عن عدد صحيح (أو إذا لم
        يكن للمُقدِّر معلمة "random_state")، فسيتم إرجاع *نسخة مطابقة تمامًا*.
        وإلا، فسيتم إرجاع *نسخة إحصائية*، والتي قد تعطي نتائج مختلفة عن
        المُقدِّر الأصلي. يمكن العثور على مزيد من التفاصيل في :ref:`randomness`.

    common tests
        يشير هذا إلى الاختبارات التي يتم تشغيلها على كل فئة تقريبًا في
        Scikit-learn للتحقق من امتثالها لاتفاقيات واجهة برمجة التطبيقات
        الأساسية. وهي متاحة للاستخدام الخارجي من خلال
        :func:`utils.estimator_checks.check_estimator`، مع معظم التنفيذ في
        ``sklearn/utils/estimator_checks.py``.

        ملاحظة: هناك بعض الاستثناءات لنظام الاختبار الشائع المرمز حاليًا في
        المكتبة، ولكن نأمل أن نستبدل ذلك عن طريق وضع علامة على السلوكيات
        الاستثنائية للمُقدِّر باستخدام علامات :term:`estimator tags` الدلالية.

    cross-fitting
    cross fitting
        طريقة إعادة أخذ العينات التي تقسم البيانات بشكل تكراري إلى أقسام
        حصرية بشكل متبادل لتجهيز مرحلتين. خلال المرحلة الأولى، تمكّن الأقسام
        الحصرية بشكل متبادل من حساب التنبؤات أو التحويلات على بيانات غير
        مرئية أثناء التدريب. يتم بعد ذلك استخدام البيانات المحسوبة في المرحلة
        الثانية. الهدف من ذلك هو تجنب حدوث أي تحيز في توزيع بيانات الإدخال
        للمرحلة الثانية بسبب الإفراط في التجهيز في المرحلة الأولى.
        للحصول على أمثلة على استخدامها، راجع: :class:`~preprocessing.TargetEncoder`،
        و:class:`~ensemble.StackingClassifier`، و:class:`~ensemble.StackingRegressor`،
        و:class:`~calibration.CalibratedClassifierCV`.

    cross-validation
    cross validation
        طريقة إعادة أخذ العينات التي تقسم البيانات بشكل تكراري إلى أقسام
        حصرية بشكل متبادل لـ "التدريب" و"الاختبار" بحيث يمكن تقييم أداء
        النموذج على بيانات غير مرئية. يحافظ هذا على البيانات ويتجنب الحاجة إلى
        الاحتفاظ بمجموعة بيانات "التحقق" ويحسب التباين حيث يتم إجراء عدة جولات
        من التحقق من الصحة بشكل عام.
        راجع :ref:`User Guide <cross_validation>` لمزيد من التفاصيل.

    deprecation
        نستخدم الإلغاء التدريجي لانتهاك ضمانات :term:`التوافق مع الإصدارات
        السابقة` الخاصة بنا تدريجيًا، وعادةً لتغيير:

        * القيمة الافتراضية لمعلمة ما؛ أو
        * إزالة معلمة أو attribute أو طريقة أو فئة، إلخ.

        سنصدر عادةً تحذيرًا عند استخدام عنصر تم إلغاؤه تدريجيًا، على الرغم
        من أنه قد تكون هناك قيود على ذلك. على سبيل المثال، سنقوم بإصدار
        تحذير عندما يحدد المستخدم معلمة تم إلغاؤها تدريجيًا، ولكن قد لا
        نقوم بذلك عندما يصل المستخدم إلى attribute تلك المعلمة على مثيل
        المُقدِّر.

        راجع :ref:`Contributors' Guide <contributing_deprecation>`.

    dimensionality
        قد يُستخدم هذا المصطلح للإشارة إلى عدد :term:`الميزات` (أي
        :term:`n_features`)، أو أعمدة مصفوفة الميزات ثنائية الأبعاد.
        ومع ذلك، يتم أيضًا استخدام الأبعاد للإشارة إلى طول شكل مصفوفة NumPy،
        مما يميز مصفوفة أحادية البعد عن مصفوفة ثنائية الأبعاد.

    docstring
        الوثائق المدمجة لوحدة أو فئة أو دالة، إلخ، عادةً ما تكون في الكود
        كسلسلة في بداية تعريف الكائن، ويمكن الوصول إليها كـ attribute
        ``__doc__`` للكائن.

        نحاول الالتزام بـ `PEP257
        <https://www.python.org/dev/peps/pep-0257/>`_، واتباع `اتفاقيات NumpyDoc
        <https://numpydoc.readthedocs.io/en/latest/format.html>`_.
علامة التسطير المزدوجة

علامة التسطير المزدوجة
    علامة التسطير المزدوجة
        عند تحديد أسماء المعلمات لمقدّري التداخل، يمكن استخدام "__" لفصل
    بين الوالد والطفل في بعض السياقات. الاستخدام الأكثر شيوعًا هو عند
    تعيين المعلمات من خلال أداة تقدير البيانات الوصفية باستخدام
    :term: `set_params` وبالتالي في تحديد شبكة بحث في
    :ref: `grid_search`. راجع :term: `parameter`.
    كما يتم استخدامه في :meth: `pipeline.Pipeline.fit` لمرور
    :term: `sample properties` إلى أساليب "fit" للمقدّرين في
    الأنابيب.

نوع البيانات
نوع البيانات
    تفترض مصفوفات NumPy نوع بيانات متجانس في جميع أنحاء، وهو متاح في
    سمة `.dtype` لمصفوفة (أو مصفوفة متقطعة). نفترض عمومًا أنواع بيانات بسيطة
    لبيانات scikit-learn: float أو integer.
    قد ندعم أنواع بيانات الكائنات أو السلاسل قبل الترميز أو التحويل إلى
    شكل ناقلات. لا تعمل أدواتنا التقديرية مع صفائف struct، على سبيل
    المثال.

    يمكن أن توفر وثائقنا في بعض الأحيان معلومات حول دقة dtype، على سبيل
    المثال. `np.int32`، `np.int64`، إلخ. عندما يتم توفير الدقة، فإنه يشير
    إلى نوع بيانات NumPy. إذا تم استخدام دقة عشوائية، فستشير الوثائق إلى
    نوع بيانات `integer` أو `floating`.
    لاحظ أنه في هذه الحالة، يمكن أن تكون الدقة خاصة بالمنصة.
    يشير نوع البيانات `numeric` إلى قبول كل من `integer` و`floating`.

    عندما يتعلق الأمر بالاختيار بين نوع بيانات 64 بت (أي `np.float64` و
    `np.int64`) ونوع بيانات 32 بت (أي `np.float32` و `np.int32`)، فإنه
    يتلخص في المقايضة بين الكفاءة والدقة. توفر أنواع 64 بت نتائج أكثر
    دقة بسبب خطأ النقطة العائمة الأقل، ولكنها تتطلب المزيد من الموارد
    الحسابية، مما يؤدي إلى عمليات أبطأ واستخدام ذاكرة أكبر. على النقيض
    من ذلك، تعد أنواع 32 بت بتعزيز سرعة التشغيل وتقليل استهلاك الذاكرة،
    ولكنها تقدم خطأ أكبر في النقطة العائمة. تعتمد تحسينات الكفاءة على
    مستوى أدنى من التحسين مثل التجهيز المتجهي، أو التعليمات الفردية
    المتعددة الإرسال (SIMD)، أو تحسين الذاكرة المؤقتة ولكن بشكل حاسم على
    توافق الخوارزمية قيد الاستخدام.

    على وجه التحديد، يجب أن يراعي اختيار الدقة ما إذا كانت الخوارزمية
    المستخدمة يمكنها الاستفادة بشكل فعال من `np.float32`. بعض الخوارزميات،
    خاصة بعض طرق التبسيط، مبرمجة حصريًا لـ `np.float64`، مما يعني أنه
    حتى إذا تم تمرير `np.float32`، فإنه يؤدي إلى تحويل تلقائي مرة أخرى
    إلى `np.float64`. لا يؤدي هذا فقط إلى إلغاء التوفير الحسابي المقصود،
    ولكنه أيضًا يقدم عبئًا إضافيًا، مما يجعل العمليات باستخدام
    `np.float32` أبطأ بشكل غير متوقع وأكثر كثافة في استخدام الذاكرة
    بسبب خطوة التحويل الإضافية هذه.

الكتابة بأسلوب البط
    نحاول تطبيق `duck typing
    <https://en.wikipedia.org/wiki/Duck_typing>`_ لتحديد كيفية
    التعامل مع بعض قيم الإدخال (على سبيل المثال، التحقق مما إذا كان
    أداة تقدير البيانات الوصفية معينة هي أداة لتصنيف البيانات). أي،
    نتجنب استخدام "isinstance" حيثما أمكن، ونعتمد على وجود أو عدم وجود
    سمات لتحديد سلوك كائن. مطلوب بعض الدقة عند اتباع هذا النهج:

    * بالنسبة لبعض أدوات تقدير البيانات الوصفية، قد لا تكون السمة متاحة
      حتى يتم تركيبها. على سبيل المثال، لا يمكننا مسبقًا تحديد ما إذا كان
      :term: `predict_proba` متاحًا في بحث الشبكة حيث تتضمن الشبكة
      التناوب بين أداة لتصنيف البيانات التنبؤية وغير التنبؤية في الخطوة
      الأخيرة من الأنبوب. في ما يلي، لا يمكننا تحديد ما إذا كان "clf"
      أداة لتصنيف البيانات التنبؤية إلا بعد تركيبه على بعض البيانات::

          >>> from sklearn.model_selection import GridSearchCV
          >>> from sklearn.linear_model import SGDClassifier
          >>> clf = GridSearchCV(SGDClassifier(),
          ...                    param_grid={'loss': ['log_loss', 'hinge']})

      هذا يعني أنه يمكننا التحقق فقط من سمات الكتابة بأسلوب البط بعد
      التركيب، ويجب أن نكون حذرين لجعل أدوات تقدير البيانات الوصفية
      لا تقدم سوى سمات وفقًا لحالة أداة التقدير الأساسية بعد التركيب.

    * التحقق مما إذا كانت السمة موجودة (باستخدام "hasattr") مكلف بشكل
      عام مثل الحصول على السمة (``getattr`` أو ترميز النقطة). في بعض
      الحالات، قد يكون الحصول على السمة مكلفًا بالفعل (على سبيل المثال،
      لبعض تطبيقات :term: `feature_importances_``، والتي قد تشير إلى
      وجود عيب في تصميم واجهة برمجة التطبيقات). لذا يجب تجنب الكود الذي
      يقوم بـ "hasattr" متبوعًا بـ "getattr"؛ يُفضل "getattr" داخل كتلة
      "try-except".

    * لتحديد بعض جوانب توقعات أداة تقدير البيانات الوصفية أو دعمها
      لبعض الميزات، نستخدم :term: `estimator tags` بدلاً من الكتابة
      بأسلوب البط.

التوقف المبكر
    يتكون هذا من إيقاف طريقة تحسين تكرارية قبل تقارب فقد التدريب، لتجنب
    الإفراط في التجهيز. يتم ذلك بشكل عام عن طريق مراقبة نتيجة التعميم
    على مجموعة التحقق من الصحة. عندما تكون متاحة، يتم تنشيطها من خلال
    معلمة "early_stopping" أو عن طريق تعيين :term: `n_iter_no_change`
    إيجابية.

مثيل أداة التقدير
    نستخدم هذه المصطلحات أحيانًا للتمييز بين فئة أداة تقدير البيانات
    الوصفية ومثيلها المُنشأ. على سبيل المثال، في ما يلي، "cls" هي فئة
    أداة تقدير البيانات الوصفية، في حين أن "est1" و "est2" هما مثيلان::

        cls = RandomForestClassifier
        est1 = cls()
        est2 = RandomForestClassifier()

أمثلة
    نحاول تقديم أمثلة على الاستخدام الأساسي لمعظم الوظائف والفئات في
    واجهة برمجة التطبيقات:

    * كاختبارات توثيق في وثائقهم (أي داخل كود "sklearn/" نفسه).
    * كأمثلة في :ref: `example gallery <general_examples>`
      تم تقديمها (باستخدام `sphinx-gallery
      <https://sphinx-gallery.readthedocs.io/>`_) من النصوص في دليل
      "examples/"، والتي توضح الميزات أو المعلمات الرئيسية لأداة
      تقدير البيانات الوصفية/الوظيفة. يجب أيضًا الإشارة إليها من دليل
      المستخدم.
    * في بعض الأحيان في :ref: `User Guide <user_guide>` (المبني من
      "doc/") إلى جانب وصف تقني لأداة تقدير البيانات الوصفية.

تجريبي
    تعد الأداة التجريبية قابلة للاستخدام بالفعل، ولكن واجهة برمجة
    التطبيقات العامة الخاصة بها، مثل قيم المعلمات الافتراضية أو
    السمات المجهزة، لا تزال عرضة للتغيير في الإصدارات المستقبلية
    دون سياسة تحذير الإلغاء التدريجي المعتادة.

مقياس التقييم
مقاييس التقييم
    توفر مقاييس التقييم مقياسًا لكيفية أداء النموذج. قد نستخدم هذا المصطلح
    على وجه التحديد للإشارة إلى الوظائف الموجودة في
    :mod: `~sklearn.metrics` (باستثناء :mod: `~sklearn.metrics.pairwise`)،
    على عكس طريقة :term: `score` وواجهة برمجة تطبيقات التقييم المستخدمة
    في التحقق من صحة التقاطع. راجع :ref: `model_evaluation`.

    تقبل هذه الوظائف عادةً الحقيقة الأرضية (أو البيانات الخام حيث
    تقيم المترية التجميع دون حقيقة أرضية) وتوقعًا، سواء كان ناتج
    :term: `predict` (``y_pred``)، أو :term: `predict_proba`
    (``y_proba``)، أو دالة تسجيل درجات تعسفية بما في ذلك
    :term: `decision_function` (``y_score``).
    يتم تسمية الوظائف عادةً بحيث تنتهي بـ ``_score`` إذا كان ارتفاع
    النتيجة يشير إلى نموذج أفضل، و ``_loss`` إذا كانت النتيجة الأقل
    تشير إلى نموذج أفضل. تدعو هذه التنوع في واجهة برمجة التطبيقات إلى
    واجهة برمجة تطبيقات التقييم.

    لاحظ أن بعض أدوات تقدير البيانات الوصفية يمكنها حساب المقاييس التي
    لا تُدرج في :mod: `~sklearn.metrics` وهي خاصة بأداة تقدير البيانات
    الوصفية، ولا سيما احتمالات النموذج.

علامات أداة تقدير البيانات الوصفية
    ميزة مقترحة (على سبيل المثال: :issue: `8022`) والتي يتم من خلالها
    وصف قدرات أداة تقدير البيانات الوصفية من خلال مجموعة من العلامات
    الدلالية. سيمكن ذلك بعض سلوكيات وقت التشغيل بناءً على فحص أداة
    تقدير البيانات الوصفية، ولكنه يسمح أيضًا باختبار كل أداة تقدير
    بيانات وصفية لثوابت مناسبة مع استثنائها من الاختبارات
    :term: `common tests` الأخرى.

    يتم تحديد بعض جوانب علامات أداة تقدير البيانات الوصفية حاليًا من
    خلال :term: `duck typing` لأساليب مثل "predict_proba" ومن خلال
    بعض السمات الخاصة على كائنات أداة تقدير البيانات الوصفية:

    .. glossary::

        ``_estimator_type``
            تحدد هذه السمة ذات القيمة النصية أداة تقدير البيانات الوصفية
            على أنها أداة لتصنيف البيانات أو أداة للتنبؤ بالبيانات، إلخ.
            يتم تعيينه بواسطة المزج مثل :class: `base.ClassifierMixin`،
            ولكنه يحتاج إلى تبنيه بشكل أكثر صراحةً على أداة تقدير
            بيانات وصفية ذات مستوى أعلى. يجب التحقق من قيمته عادةً عن
            طريق مساعد مثل :func: `base.is_classifier`.

    للحصول على معلومات أكثر تفصيلاً، راجع :ref: `estimator_tags`.

سمة
سمات
متجه السمات
    من الناحية المجردة، السمة هي دالة (بالمعنى الرياضي) تقوم بتعيين كائن
    تمت معاينته إلى كمية رقمية أو فئة. يُعرف "الميزة" أيضًا باسم
    الكميات، كونها العناصر الفردية لمتجه يمثل عينة. في مصفوفة
    البيانات، يتم تمثيل الميزات كأعمدة: يحتوي كل عمود على نتيجة
    تطبيق دالة ميزة على مجموعة من العينات.

    تُعرف الميزات في أماكن أخرى باسم السمات أو عوامل التنبؤ أو
    عوامل التنبؤ أو المتغيرات المستقلة.

    يفترض معظم أدوات تقدير البيانات الوصفية في scikit-learn أن
    الميزات رقمية ومحدودة وغير مفقودة، حتى عندما تكون لها مجالات
    وتوزيعات دلالية متميزة (فئوية أو ترتيبية أو ذات قيمة عددية أو
    ذات قيمة حقيقية أو فاصلة). راجع أيضًا :term: `categorical feature`
    و :term: `missing values`.

    يشير ``n_features`` إلى عدد الميزات في مجموعة بيانات.

التجهيز
    استدعاء :term: `fit` (أو :term: `fit_transform`، :term:
    `fit_predict`، إلخ.) على أداة تقدير البيانات الوصفية.

مجهزة
    حالة أداة تقدير البيانات الوصفية بعد :term: `fitting`.

    لا يوجد إجراء تقليدي للتحقق مما إذا كانت أداة تقدير البيانات
    الوصفية مجهزة. ومع ذلك، يجب أن ترفع أداة تقدير البيانات الوصفية
    التي لم يتم تجهيزها:

    * :class: `exceptions.NotFittedError` عند استدعاء طريقة التنبؤ
      (:term: `predict`، :term: `transform`، إلخ.).
      (:func: `utils.validation.check_is_fitted` مستخدم داخليًا
      لهذا الغرض.)
    * لا ينبغي أن يكون لها أي :term: `attributes` التي تبدأ بحرف أبجدي
      وتنتهي بشرطة سفلية. (لاحظ أنه قد يكون هناك لا يزال وصفًا
      للسمة على الفئة، ولكن يجب أن تعيد "hasattr" القيمة False)

وظيفة
    نوفر واجهات وظيفية مخصصة للعديد من الخوارزميات، في حين أن فئات
    :term: `estimator` توفر واجهة أكثر اتساقًا.

    على وجه الخصوص، قد توفر Scikit-learn واجهة وظيفية تقوم بتناسب نموذج
    مع بعض البيانات وإرجاع معلمات التعلم، كما هو الحال في
    :func: `linear_model.enet_path`. بالنسبة للنماذج الاستقرائية،
    فإنه يعيد أيضًا التضمين أو تسميات التجميع، كما هو الحال في
    :func: `manifold.spectral_embedding` أو :func: `cluster.dbscan`.
    توفر العديد من المحولات التمهيدية أيضًا واجهة وظيفية، تشبه
    استدعاء :term: `fit_transform`، كما هو الحال في
    :func: `preprocessing.maxabs_scale`. يجب أن يكون المستخدمون حذرين
    لتجنب :term: `data leakage` عند الاستفادة من هذه الوظائف
    المكافئة لـ "fit_transform".

    ليس لدينا سياسة صارمة بشأن متى أو متى لا نوفر أشكال الوظائف لأدوات
    تقدير البيانات الوصفية، ولكن يجب على المشرفين مراعاة الاتساق مع
    واجهات موجودة، وما إذا كان توفير وظيفة سيؤدي بالمستخدمين إلى
    الابتعاد عن أفضل الممارسات (من حيث تسرب البيانات، إلخ.).

معرض
    راجع :term: `examples`.

معلمة فائقة
معلمة فائقة
    راجع :term: `parameter`.
impute

imputation

تتطلب معظم خوارزميات التعلم الآلي أن تكون مدخلاتها خالية من القيم المفقودة، ولن تعمل إذا تم انتهاك هذا الشرط. والخوارزميات التي تحاول ملء (أو استنباط) القيم المفقودة يشار إليها بخوارزميات الاستنباط.

indexable

صفيف أو مصفوفة متفرقة أو إطار بيانات Pandas أو تسلسل (عادة ما يكون قائمة).

induction

inductive

التعلم الاستقرائي (على النقيض من التعلم بالاستقراء): يقوم ببناء نموذج لبعض البيانات التي يمكن بعد ذلك تطبيقها على حالات جديدة. معظم التقديرات في Scikit-learn استقرائية، ولديها طرق "توقع" و/أو "تحويل".

joblib

مكتبة بايثون (https://joblib.readthedocs.io) المستخدمة في Scikit-learn لتسهيل الموازاة والتخزين المؤقت البسيطين. يهدف Joblib إلى العمل بكفاءة مع صفائف Numpy، مثل استخدام memory mapping. راجع parallelism لمزيد من المعلومات.

label indicator matrix

multilabel indicator matrix

multilabel indicator matrices

تنسيق يستخدم لتمثيل البيانات متعددة التصنيفات، حيث يتوافق كل صف في مصفوفة ثنائية الأبعاد أو مصفوفة متفرقة مع عينة، وكل عمود مع فئة، وكل عنصر يساوي 1 إذا تم تصنيف العينة بالصنف و 0 إذا لم يتم ذلك.

leakage

data leakage

مشكلة في التحقق المتقاطع حيث يمكن المبالغة في تقدير الأداء العام حيث تم تضمين معرفة بيانات الاختبار عن غير قصد في تدريب نموذج. هذا احتمال، على سبيل المثال، عند تطبيق محول على مجموعة البيانات بأكملها بدلاً من كل جزء تدريب في انقسام التحقق المتقاطع.

نحن نهدف إلى توفير واجهات (مثل sklearn.pipeline و sklearn.model_selection) التي تحمي المستخدم من تسرب البيانات.

memmapping

memory map

memory mapping

استراتيجية كفاءة الذاكرة التي تبقي البيانات على القرص بدلاً من نسخها إلى الذاكرة الرئيسية. يمكن إنشاء خرائط الذاكرة للمصفوفات التي يمكن قراءتها أو كتابتها أو كليهما، باستخدام numpy.memmap. عند استخدام joblib لموازاة العمليات في Scikit-learn، فقد يقوم تلقائيًا بتعيين مصفوفات كبيرة إلى الذاكرة للحد من Overhead ازدواجية الذاكرة في المعالجة المتعددة.

missing values

لا تعمل معظم تقديرات Scikit-learn مع القيم المفقودة. عندما يفعلون ذلك (على سبيل المثال، في طريقة imputation.SimpleImputer)، NaN هو التمثيل المفضل للقيم المفقودة في صفائف float. إذا كان نوع البيانات في المصفوفة هو integer، فلا يمكن تمثيل NaN. لهذا السبب، ندعم تحديد قيمة "missing_values" أخرى عندما يمكن إجراء الاستنباط أو التعلم في مساحة الأعداد الصحيحة. البيانات غير المُعنونة هي حالة خاصة من القيم المفقودة في الهدف.

n_features

عدد الميزات.

n_outputs

عدد الإخراج في الهدف.

n_samples

عدد العينات.

n_targets

مرادف لـ n_outputs.

narrative docs

narrative documentation

مرادف لـ User Guide، أي الوثائق المكتوبة في doc/modules/. على عكس مرجع واجهة برمجة التطبيقات المقدم من خلال docstrings، يهدف دليل المستخدم إلى:

- تجميع الأدوات التي يوفرها Scikit-learn معًا حسب الموضوع أو من حيث الاستخدام.
- توضيح سبب استخدام شخص ما لكل أداة معينة، غالبًا من خلال المقارنة.
- تقديم أوصاف بديهية وتقنية للأدوات.
- توفير أو ربط أمثلة على استخدام الميزات الرئيسية لأداة ما.

np

مختصر لـ Numpy بسبب عبارة الاستيراد التقليدية:

import numpy as np

online learning

حيث يتم تحديث النموذج بشكل تكراري من خلال تلقي كل دفعة من بيانات ground truth الهدف قريبًا بعد إجراء تنبؤات على دفعة مناظرة من البيانات. يجب أن يكون النموذج قابلًا للاستخدام للتنبؤ بعد كل دفعة. راجع partial_fit.

out-of-core

استراتيجية كفاءة حيث لا يتم تخزين جميع البيانات في الذاكرة الرئيسية مرة واحدة، وعادة ما يتم ذلك عن طريق إجراء التعلم على دفعات من البيانات. راجع partial_fit.

outputs

متغيرات فردية لكل عينة في الهدف. على سبيل المثال، في التصنيف متعدد التصنيفات، يتوافق كل تصنيف محتمل مع إخراج ثنائي. يُطلق عليها أيضًا الاستجابات أو المهام أو الأهداف. راجع multiclass multioutput و continuous multioutput.

pair

زوج من طول اثنين.

parameter

params

نستخدم في الغالب مصطلح "معلمة" للإشارة إلى جوانب المحلل التي يمكن تحديدها في بنائه. على سبيل المثال، max_depth و random_state هي معلمات طريقة ensemble.RandomForestClassifier. يتم تخزين معلمات مُنشئ المحلل دون تعديل كسمات على مثيل المحلل، وتبدأ تقليديًا بحرف أبجدي وتنتهي بحرف أبجدي رقمي. يتم وصف معلمات كل محلل في docstring الخاص به.

لا نستخدم المعلمات بالمعنى الإحصائي، حيث تكون المعلمات هي القيم التي تحدد نموذجًا ويمكن تقديرها من البيانات. ما نسميه معلمات قد يكون ما يسميه الإحصائيون المعلمات الفائقة للنموذج: جوانب تكوين بنية النموذج التي غالبًا ما لا يتم تعلمها مباشرة من البيانات. ومع ذلك، فإن معلماتنا تُستخدم أيضًا لوصف عمليات النمذجة التي لا تؤثر على النموذج المُتعلم، مثل n_jobs للتحكم في الموازية.

عند التحدث عن معلمات محلل علوي، فقد نكون أيضًا ندرج معلمات المحللين المضمنين بواسطة المحلل العلوي. عادةً، يتم الإشارة إلى هذه المعلمات المضمنة باستخدام علامة تسطير مزدوجة (__) للفصل بين المحلل كمعلمة ومعلمته. وبالتالي، فإن clf = BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=3)) لها معلمة عميقة باسم "estimator__max_depth" بقيمة "3"، والتي يمكن الوصول إليها باستخدام clf.estimator.max_depth أو clf.get_params()['estimator__max_depth'].

يمكن استرداد قائمة المعلمات وقيمها الحالية من مثيل المحلل باستخدام طريقة get_params الخاصة به.

بين البناء والتجهيز، يمكن تعديل المعلمات باستخدام set_params. لتمكين ذلك، لا يتم عادةً التحقق من صحة المعلمات أو تعديلها عندما يتم بناء المحلل، أو عندما يتم تعيين كل معلمة. يتم تنفيذ التحقق من صحة المعلمة عند استدعاء fit.

يتم سرد المعلمات الشائعة أدناه.

pairwise metric

pairwise metrics

بالمعنى الواسع، تحدد المترية الزوجية دالة لقياس التشابه أو الاختلاف بين عيناتين (يمثل كل منهما عادةً متجه ميزة). نقدم بشكل خاص تطبيقات لمقاييس المسافة (بالإضافة إلى المقاييس غير الصحيحة مثل مسافة جيب التمام) من خلال metrics.pairwise_distances، ولوظائف النواة (فئة مقيدة من وظائف التشابه) في metrics.pairwise.pairwise_kernels. يمكن أن تحسب هذه المصفوفات مصفوفة المسافات الزوجية التي تكون متماثلة وبالتالي تخزين البيانات بشكل مكرر.

راجع أيضًا precomputed و metric.

ملاحظة: بالنسبة لمعظم مقاييس المسافة، نعتمد على التطبيقات من scipy.spatial.distance، ولكن قد نعيد التنفيذ من أجل الكفاءة في سياقنا. يستخدم metrics.DistanceMetric واجهة لتنفيذ مقاييس المسافة للتكامل مع البحث عن الجيران بكفاءة.

pd

مختصر لـ Pandas بسبب عبارة الاستيراد التقليدية:

import pandas as pd

precomputed

حيث تعتمد الخوارزميات على المقاييس الزوجية، ويمكن حسابها من المقاييس الزوجية وحدها، فنحن غالبًا ما نسمح للمستخدم بتحديد أن X المقدم موجود بالفعل في مساحة التشابه (الاختلاف)، بدلاً من مساحة الميزة. أي أنه عند تمريره إلى fit، يكون عبارة عن مصفوفة مربعة متماثلة، حيث يشير كل متجه إلى التشابه (الاختلاف) مع كل عينة، وعند تمريره إلى طرق التنبؤ/التحويل، يتوافق كل صف مع عينة اختبار وكل عمود مع عينة تدريب.

يتم الإشارة إلى استخدام X مسبقًا عادةً عن طريق تعيين معلمة "metric" أو "affinity" أو "kernel" إلى سلسلة "precomputed". إذا كان الأمر كذلك، فيجب على المحلل تعيين علامة المحلل الزوجي كـ True.

rectangular

البيانات التي يمكن تمثيلها كمصفوفة مع عينات على المحور الأول ومجموعة ثابتة ومحدودة من الميزات على المحور الثاني تسمى مستطيلة.

يستبعد هذا المصطلح العينات ذات البنى غير المتجهية، مثل النص أو الصورة ذات الحجم التعسفي أو سلسلة زمنية ذات طول تعسفي أو مجموعة من المتجهات، وما إلى ذلك. الغرض من vectorizer هو إنتاج أشكال مستطيلة من هذه البيانات.

sample

samples

عادةً ما نستخدم هذا المصطلح كاسم للإشارة إلى متجه ميزة واحد. في مكان آخر، يُطلق على العينة اسم instance أو data point أو observation. يشير n_samples إلى عدد العينات في مجموعة البيانات، وهو عدد الصفوف في مصفوفة البيانات X.

sample property

sample properties

تعد خاصية العينة بيانات لكل عينة (على سبيل المثال، مصفوفة بطول n_samples) يتم تمريرها إلى طريقة المحلل أو دالة مماثلة، إلى جانب ولكن بشكل منفصل عن الميزات (X) والهدف (y). المثال الأكثر بروزًا هو sample_weight؛ راجع الآخرين في glossary_sample_props.

اعتبارًا من الإصدار 0.19، ليس لدينا نهج متسق للتعامل مع خصائص العينة وتوجيهها في المحللين العلويين، على الرغم من أنه يتم غالبًا استخدام معلمة "fit_params".

scikit-learn-contrib

مكان لنشر المكتبات المتوافقة مع Scikit-learn التي يصرح بها مطورو النواة ومجتمع المساهمين بشكل عام، ولكن لا تتم صيانتها بواسطة فريق مطوري النواة.

راجع https://scikit-learn-contrib.github.io.

scikit-learn enhancement proposals

SLEP

SLEPs

تحدث التغييرات على مبادئ واجهة برمجة التطبيقات والتغييرات على التبعيات أو الإصدارات المدعومة من خلال SLEP وتتبع عملية صنع القرار الموضحة في governance.

بالنسبة لجميع الأصوات، يجب أن يكون الاقتراح قد تم طرحه للمناقشة قبل التصويت. يجب أن يكون هذا الاقتراح وثيقة موحدة، في شكل "اقتراح تحسين Scikit-Learn" (SLEP)، بدلاً من مناقشة طويلة حول مشكلة ما. يجب تقديم SLEP كطلب سحب إلى https://scikit-learn-enhancement-proposals.readthedocs.io باستخدام نموذج SLEP.

semi-supervised

semi-supervised learning

semisupervised

التعلم حيث يكون التنبؤ المتوقع (التصنيف أو الحقيقة الأرضية) متاحًا فقط لبعض العينات المقدمة كبيانات تدريب عند تناسب النموذج. نطبق تقليديًا التسمية "-1" على العينات غير المُعنونة في التصنيف شبه الخاضع للإشراف.
النص المترجم إلى اللغة العربية: 

مصفوفة متفرقة

-   رسم بياني متفرق: تمثيل للبيانات الرقمية ثنائية الأبعاد أكثر كفاءة في الذاكرة
    من المصفوفة الكثيفة المناظرة حيث تكون جميع العناصر تقريبًا صفرًا. نستخدم
    إطار العمل scipy.sparse، والذي يوفر عدة تمثيلات أساسية للبيانات المتفرقة،
    أو "التنسيقات". بعض التنسيقات أكثر كفاءة من غيرها لمهمام معينة، وعندما
    يوفر تنسيق معين فائدة خاصة، نحاول توثيق هذه الحقيقة في أوصاف معلمات
    Scikit-learn.

-   تفرق بعض تنسيقات المصفوفة (خاصة CSR وCSC وCOO وLIL) بين الأصفار *الضمنية*
    و*الصريحة*. الأصفار الصريحة مخزنة (أي أنها تستهلك الذاكرة في مصفوفة
    "البيانات") في بنية البيانات، بينما تشير الأصفار الضمنية إلى كل عنصر غير
    محدد بخلاف ذلك في التخزين الصريح.

-   يتم استخدام دلالتين للمصفوفات المتناثرة في Scikit-learn:

    -   دلالة المصفوفة: يتم تفسير المصفوفة المتناثرة على أنها مصفوفة مع
        تفسير الأصفار الضمنية والصريحة على أنها الرقم 0. هذا هو التفسير
        المعتمد في معظم الأحيان، على سبيل المثال، عندما يتم استخدام المصفوفات
        المتناثرة لمصفوفات الميزات أو مصفوفات مؤشرات التصنيف المتعدد.

    -   دلالة الرسم البياني: كما هو الحال مع scipy.sparse.csgraph، يتم تفسير
        الأصفار الصريحة على أنها الرقم 0، ولكن تشير الأصفار الضمنية إلى قيمة
        مقنعة أو مفقودة، مثل غياب حافة بين رأسين في رسم بياني، حيث يشير
        قيمة صريحة إلى وزن الحافة. يتم اعتماد هذا التفسير لتمثيل الاتصال
        في التجميع، وفي تمثيلات الأحياء الأقرب (على سبيل المثال،
        neighbors.kneighbors_graph)، ولمسافات المحسوبة مسبقًا حيث تكون
        المسافات المطلوبة فقط في حي كل نقطة.

-   عند العمل مع المصفوفات المتناثرة، نفترض أنها متناثرة لسبب وجيه، ونتجنب
    كتابة كود يقوم بتكثيف مصفوفة متفرقة مقدمة من المستخدم، بدلاً من الحفاظ على
    التفرق أو إثارة خطأ إذا لم يكن ذلك ممكنًا (أي إذا لم يدعم/لم يتمكن
    المُقدر من دعم المصفوفات المتناثرة).

-   عديم الحالة: يكون المُقدر عديم الحالة إذا لم يقم بتخزين أي معلومات يتم
    الحصول عليها أثناء التهيئة. يمكن أن تكون هذه المعلومات إما معلمات تم
    تعلمها أثناء التهيئة أو إحصاءات محسوبة من بيانات التدريب. يكون المُقدر
    عديم الحالة إذا لم يكن لديه أي سمات بخلاف تلك المحددة في init. ستعمل
    مكالمة التهيئة لهذه المقدرات فقط على التحقق من السمات العامة التي تم
    تمريرها في init.

-   مشرف: التعلم الخاضع للإشراف

-   التعلم الخاضع للإشراف: التعلم حيث يكون التنبؤ المتوقع (التصنيف أو الحقيقة
    الأرضية) متاحًا لكل عينة عند تناسب النموذج، ويتم توفيره على أنه y. هذا
    هو النهج المتبع في مصنف أو مرجع، من بين مقدرات أخرى.

-   الهدف: الهدف في التعلم الخاضع للإشراف (ونصف الخاضع للإشراف)، والذي يتم
    تمريره كـ y إلى طريقة التهيئة للمُقدر. يُعرف أيضًا باسم المتغير التابع،
    أو متغير النتائج، أو متغير الاستجابة، أو الحقيقة الأرضية أو التصنيف.
    يعمل Scikit-learn مع الأهداف ذات البنية الدنيا: فئة من مجموعة محدودة،
    أو رقم حقيقي محدود، أو فئات متعددة، أو أرقام متعددة. راجع
    glossary_target_types.

-   الاستقراء: الاستقراء (على عكس الاستقراء) هو طريقة للتعلم الآلي مصممة
    لنمذجة مجموعة بيانات محددة، ولكن ليس لتطبيق هذا النموذج على البيانات
    غير المرئية. تشمل الأمثلة manifold.TSNE وcluster.AgglomerativeClustering
    وneighbors.LocalOutlierFactor.

-   غير معنون: بيانات غير معنونة لها حقيقة أرضية غير معروفة عند التهيئة؛
    أي ما يعادل القيم المفقودة في الهدف. راجع أيضًا التعلم نصف الخاضع
    للإشراف وغير الخاضع للإشراف.

-   غير خاضع للإشراف: التعلم غير الخاضع للإشراف

-   التعلم غير الخاضع للإشراف: التعلم حيث لا يتوفر التنبؤ المتوقع (التصنيف
    أو الحقيقة الأرضية) لكل عينة عند تناسب النموذج، كما هو الحال في
    التجميعات وأجهزة الكشف عن الأخطاء. تتجاهل المقدرات غير الخاضعة للإشراف
    أي y يتم تمريرها إلى التهيئة.

-   أنواع المقدرات: واجهات برمجة تطبيقات الفصل وأنواع المقدرات
بالتأكيد! فيما يلي ترجمة للنص المحدد بتنسيق ReStructuredText إلى اللغة العربية:

==============================

.. glossary::

    classifier
    classifiers
        مصنف إشرافي (أو شبه إشرافي) يستخدم مجموعة محدودة من القيم المخرجة الممكنة المنفصلة.

        يدعم المصنف النمذجة لبعض الأهداف الثنائية أو متعددة الفئات أو متعددة التصنيفات أو متعددة الفئات والمتعددة المخرجات. وفي scikit-learn، تدعم جميع المصنفات التصنيف متعدد الفئات، مع التخلف إلى استخدام استراتيجية one-vs-rest عبر مشكلة التصنيف الثنائية.

        يجب على المصنفات تخزين سمة classes_ بعد التجهيز، وعادة ما ترث من base.ClassifierMixin، والتي تحدد سمة _estimator_type الخاصة بها.

        يمكن التمييز بين المصنف والمقدرات الأخرى باستخدام base.is_classifier.

        يجب على المصنف تنفيذ:

        * التجهيز
        * التنبؤ
        * النتيجة

        قد يكون من المناسب أيضًا تنفيذ decision_function، وpredict_proba، وpredict_log_proba.

    clusterer
    clusterers
        مصنف غير إشرافي بقيم إخراج منفصلة محدودة.

        عادة ما يقوم المجمع بتخزين العلامات labels_ بعد التجهيز، ويجب أن يفعل ذلك إذا كان استقرائيًا.

        يجب على المجمع تنفيذ:

        * التجهيز
        * fit_predict إذا كان استقرائيًا
        * التنبؤ إذا كان استقرائيًا

    density estimator
        تقدير غير إشرافي لتوزيع الاحتمالية الكثيفة للإدخال. تقنيات الاستخدام الشائعة هي:

        * kernel_density - يستخدم دالة kernel، يتحكم فيها معامل عرض النطاق لتمثيل الكثافة؛
        * مزيج غاوسي - يستخدم مزيجًا من نماذج غاوس لتمثيل الكثافة.

    estimator
    estimators
        كائن يدير تقدير وفك تشفير نموذج. يتم تقدير النموذج كدالة محددة من:

        * المعلمات المقدمة في إنشاء الكائن أو باستخدام set_params؛
        * حالة التعشيش العشوائي العالمي إذا كانت معلمة random_state للمصنف مضبوطة على None؛ و
        * أي بيانات أو خصائص عينة تم تمريرها إلى آخر مكالمة إلى التجهيز أو fit_transform أو fit_predict، أو البيانات التي تم تمريرها بالمثل في تسلسل من الاستدعاءات إلى partial_fit.

        يتم تخزين النموذج المقدر في سمات عامة وخاصة على مثيل المقدر، مما يسهل فك التشفير من خلال طرق التنبؤ والتحويل.

        يجب أن توفر المقدرات طريقة التجهيز، ويجب أن توفر set_params وget_params، على الرغم من أن هذه عادة ما يتم توفيرها عن طريق الوراثة من base.BaseEstimator.

        قد تكون الوظيفة الأساسية لبعض المقدرات متاحة أيضًا كدالة.

    feature extractor
    feature extractors
        محول يأخذ الإدخال حيث لا يتم تمثيل كل عينة ككائن يشبه المصفوفة بطول ثابت، وينتج كائن يشبه المصفوفة من الميزات لكل عينة (وبالتالي مصفوفة ثنائية الأبعاد لمجموعة من العينات). بمعنى آخر، فإنه (فقدان البيانات) يُمَثِّل بيانات غير مستطيلة إلى بيانات مستطيلة.

        يجب أن تقوم مستخلصات الميزات بتنفيذ على الأقل:

        * التجهيز
        * التحويل
        * get_feature_names_out

    meta-estimator
    meta-estimators
    metaestimator
    metaestimators
        مقدر يأخذ مقدرًا آخر كمعلمة. تشمل الأمثلة pipeline.Pipeline، وmodel_selection.GridSearchCV، وfeature_selection.SelectFromModel، وensemble.BaggingClassifier.

        في طريقة التجهيز الخاصة بالمقدر الفوقي، يجب استنساخ أي مقدرات مضمنة قبل تجهيزها (على الرغم من أن Pipeline وFeatureUnion لا تفعلان ذلك حاليًا). والاستثناء من ذلك هو أن المقدر قد يوثق صراحة أنه يقبل مقدرًا مُجهزًا مسبقًا (على سبيل المثال، باستخدام "prefit=True" في feature_selection.SelectFromModel). إحدى المشكلات المعروفة في ذلك هي أن المقدر المُجهز مسبقًا سيفقد نموذجه إذا تم استنساخ المقدر الفوقي. يجب استدعاء "التجهيز" في المقدر الفوقي قبل التنبؤ، حتى إذا تم تجهيز جميع المقدرات المضمنة مسبقًا.

        في الحالات التي تكون فيها السلوكيات الأساسية للمقدر الفوقي (على سبيل المثال، تنفيذ التنبؤ أو التحويل) عبارة عن دالات لطرق التنبؤ/التحويل الخاصة بمقدر *أساسي* (أو مقدرات أساسية متعددة)، يجب أن يوفر المقدر الفوقي على الأقل الطرق القياسية التي يوفرها المقدر الأساسي. قد لا يكون من الممكن تحديد الطرق التي يوفرها المقدر الأساسي حتى يتم تجهيز المقدر الفوقي (انظر أيضًا: الاستدلال بالبطة)، والتي قد تساعد فيها utils.metaestimators.available_if. يجب أن يوفر أيضًا (أو يعدل) علامات المقدر وسمة classes_ التي يوفرها المقدر الأساسي.

        يجب أن يكون المقدرون الفوقيون حذرين للتحقق من صحة البيانات بشكل أقل قدر ممكن قبل تمريرها إلى مقدر أساسي. يوفر ذلك وقت الحساب، وقد يسمح، على سبيل المثال، للمقدر الأساسي بالعمل بسهولة مع البيانات التي لا تكون مستطيلة.

    outlier detector
    outlier detectors
        مصنف غير إشرافي ثنائي يُمَثِّل التمييز بين العينات الأساسية والشاذة.

        يجب على كاشف الشذوذ تنفيذ:

        * التجهيز
        * fit_predict إذا كان استقرائيًا
        * التنبؤ إذا كان استقرائيًا

        قد يقوم كاشف الشذوذ الاستقرائي أيضًا بتنفيذ decision_function لإعطاء درجة عادية حيث تكون النتيجة أقل من 0. قد توفر score_samples درجة غير معيارية لكل عينة.

    predictor
    predictors
        مقدر يدعم التنبؤ و/أو fit_predict. ويشمل ذلك المصنف، والمرجع، وكاشف الشذوذ، والمجمع.

        في الإحصاءات، يشير "المتغيرات" إلى الميزات.

    regressor
    regressors
        مصنف إشرافي (أو شبه إشرافي) بقيم إخراج مستمرة.

        عادة ما يرث المرجعون من base.RegressorMixin، والتي تحدد سمة _estimator_type الخاصة بهم.

        يمكن التمييز بين المرجع والمقدرات الأخرى باستخدام base.is_regressor.

        يجب أن ينفذ المرجع:

        * التجهيز
        * التنبؤ
        * النتيجة

    transformer
    transformers
        مقدر يدعم التحويل و/أو fit_transform. قد لا يقوم المحول الاستقرائي النقي، مثل manifold.TSNE، بتنفيذ "التحويل".

    vectorizer
    vectorizers
        راجع مستخرج الميزة.

هناك واجهات برمجة تطبيقات أخرى تتعلق بعائلة صغيرة من المقدرات، مثل:

.. glossary::

    cross-validation splitter
    CV splitter
    cross-validation generator
        عائلة من الفئات غير المقدرة المستخدمة لتقسيم مجموعة من البيانات إلى تسلسل من أجزاء التدريب والاختبار (راجع: cross_validation)، من خلال توفير طرق الانقسام وget_n_splits.
        لاحظ أنه على عكس المقدرات، لا تحتوي هذه الفئات على طرق التجهيز ولا توفر set_params أو get_params.
        قد يتم تنفيذ التحقق من صحة المعلمات في "__init__".

    cross-validation estimator
        مقدر له قدرات مدمجة للتحقق من صحة التقاطع لاختيار أفضل فرط المعلمات تلقائيًا (راجع: الدليل الإرشادي للمستخدم <grid_search>). بعض الأمثلة على المقدرات المتقاطعة هي ElasticNetCV <linear_model.ElasticNetCV> وLogisticRegressionCV <linear_model.LogisticRegressionCV>.
        يتم تسمية المقدرات المتقاطعة باسم "EstimatorCV" وتميل إلى أن تكون مكافئة تقريبًا لـ "GridSearchCV(Estimator(), ...)".
        تتمثل ميزة استخدام مقدر متقاطع بدلاً من فئة المقدر القياسية إلى جانب البحث الشبكي <grid_search> في أنه يمكنها الاستفادة من إعادة الاستخدام عن طريق إعادة استخدام النتائج المحسوبة مسبقًا في الخطوات السابقة لعملية التحقق من صحة التقاطع. يؤدي ذلك بشكل عام إلى تحسينات في السرعة. والاستثناء هو فئة RidgeCV <linear_model.RidgeCV>، والتي يمكنها بدلاً من ذلك إجراء التحقق من صحة Leave-One-Out (LOO) بكفاءة. بشكل افتراضي، سيتم إعادة تدريب جميع هذه المقدرات، باستثناء RidgeCV <linear_model.RidgeCV> مع LOO-CV، على مجموعة البيانات التدريبية الكاملة بعد العثور على أفضل مجموعة من فرط المعلمات.

    scorer
        كائن غير مقدر قابل للاستدعاء يقوم بتقييم مقدر على بيانات الاختبار المعطاة، ويعيد رقمًا. على عكس مقاييس التقييم، يجب أن يقابل العدد المرتجع الأكبر درجة *أفضل*.
        راجع: scoring_parameter.

أمثلة أخرى:

* metrics.DistanceMetric
* gaussian_process.kernels.Kernel
* "tree.Criterion"

.. _glossary_metadata_routing:

توجيه البيانات الوصفية
================

.. glossary::

    consumer
        كائن يستهلك البيانات الوصفية. هذا الكائن هو عادةً مقدر أو مسجل نقاط أو مُقسِّم CV. يعني استهلاك البيانات الوصفية استخدامها في الحسابات، على سبيل المثال، استخدام sample_weight لحساب نوع معين من النتيجة. لا يعني كونك مستهلكًا أن الكائن يتلقى دائمًا بيانات وصفية معينة، بل يعني أنه يمكنه استخدامها إذا تم توفيرها.

    metadata
        بيانات تتعلق ببيانات X وy المعطاة، ولكنها ليست جزءًا مباشرًا من البيانات، على سبيل المثال sample_weight أو groups، ويتم تمريرها إلى كائنات وطرق مختلفة، على سبيل المثال إلى مسجل نقاط أو مُقسِّم CV.

    router
        كائن يقوم بتوجيه البيانات الوصفية إلى المستهلكين. هذا الكائن هو عادةً مقدر فائق، على سبيل المثال pipeline.Pipeline أو model_selection.GridSearchCV.
        يمكن أن يكون بعض الموجهين أيضًا مستهلكين. يحدث هذا، على سبيل المثال، عندما يستخدم المقدر الفائق المجموعات المعطاة، ويقوم أيضًا بتمريرها إلى بعض كائناته الفرعية، مثل مُقسِّم CV.

يرجى الرجوع إلى: الدليل الإرشادي للمستخدم لتوجيه البيانات الوصفية <metadata_routing> للحصول على مزيد من المعلومات.

.. _glossary_target_types:

أنواع الأهداف
===============

.. glossary::

    binary
        هي مشكلة تصنيف تتكون من فئتين. يمكن تمثيل الهدف الثنائي على أنه مشكلة متعددة الفئات :term: ولكن مع وجود علامتين فقط. يتم تمثيل دالة القرار الثنائية كمصفوفة أحادية البعد.

        من الناحية الدلالية، غالبًا ما تعتبر إحدى الفئتين "إيجابية".
        ما لم يُحدد خلاف ذلك (على سبيل المثال، باستخدام :term: `pos_label` في
        :term: `مقاييس التقييم`)، فإننا نعتبر فئة العلامات ذات القيمة الأكبر (رقميًا أو أبجديًا) على أنها الفئة الإيجابية:
        من العلامات [0، 1]، 1 هي الفئة الإيجابية؛ من [1، 2]، 2 هي الفئة الإيجابية؛ من ['no'، 'yes']، 'yes' هي الفئة الإيجابية؛ من ['no'، 'YES']،
        'no' هي الفئة الإيجابية. يؤثر هذا على إخراج :term: `decision_function`، على سبيل المثال.

        لاحظ أن مجموعة البيانات التي تم أخذ عينات منها من فئة متعددة "y" أو "y" مستمرة
        قد يبدو ثنائي.

        :func: `~ utils.multiclass.type_of_target` سوف يعيد 'binary' لـ
        إدخال ثنائي، أو مصفوفة مماثلة مع وجود فئة واحدة فقط.

    continuous
        مشكلة ارتجاع حيث يكون هدف كل عينة رقمًا عائمًا محدودًا يتم تمثيله كمصفوفة أحادية البعد من النقاط العائمة (أو في بعض الأحيان ints).

        :func: `~ utils.multiclass.type_of_target` سوف يعيد 'continuous' لـ
        إدخال مستمر، ولكن إذا كانت البيانات كلها أعداد صحيحة، فسيتم تحديدها على أنها 'multiclass'.

    continuous multioutput
    continuous multi-output
    multioutput continuous
    multi-output continuous
        مشكلة ارتجاع حيث يتكون هدف كل عينة من "n_outputs"
        :term: `outputs`، كل منها رقم عائم محدود، لـ
        عدد صحيح ثابت "n_outputs> 1" في مجموعة بيانات معينة.

        يتم تمثيل الأهداف المستمرة متعددة الإخراج على أنها متعددة
        أهداف مستمرة :term:، مكدسة أفقيًا في مصفوفة
        الشكل "(n_samples، n_outputs)".

        :func: `~ utils.multiclass.type_of_target` سوف يعيد
        'continuous-multioutput' لإدخال مستمر متعدد الإخراج، ولكن إذا كانت
        البيانات كلها أعداد صحيحة، فسيتم تحديدها على أنها
        'multiclass-multioutput'.

    multiclass
    multi-class
        مشكلة تصنيف تتكون من أكثر من فئتين. يمكن تمثيل الهدف متعدد الفئات على أنه مصفوفة أحادية البعد من
        السلاسل أو الأعداد الصحيحة. يتم أيضًا قبول متجه عمود ثنائي الأبعاد (أي
        إخراج واحد في مصطلحات :term: `multioutput`).

        لا ندعم رسميًا كائنات أخرى قابلة للترتيب وقابلة للتجزئة كعلامات فئات، حتى إذا كان من المحتمل أن تعمل التقديرات عند إعطائها
        أهداف التصنيف من هذا النوع.

        للتصنيف شبه المُشرف، يجب أن تحتوي العينات "غير المُوسومة" على العلامة الخاصة -1 في "y".

        في scikit-learn، تدعم جميع التقديرات التي تدعم التصنيف الثنائي
        التصنيف متعدد الفئات أيضًا، باستخدام One-vs-Rest بشكل افتراضي.

        تساعد :class: `preprocessing.LabelEncoder` على توحيد الأهداف متعددة الفئات كأعداد صحيحة.

        :func: `~ utils.multiclass.type_of_target` سوف يعيد 'multiclass' لـ
        إدخال متعدد الفئات. قد يرغب المستخدم أيضًا في التعامل مع إدخال 'binary'
        بشكل متطابق مع 'multiclass'.

    multiclass multioutput
    multi-class multi-output
    multioutput multiclass
    multi-output multi-class
        مشكلة تصنيف حيث يتكون هدف كل عينة من
        "n_outputs" :term: `outputs`، كل منها تسمية فئة، لـ
        عدد صحيح ثابت "n_outputs> 1" في مجموعة بيانات معينة. يحتوي كل إخراج على
        مجموعة ثابتة من الفئات المتاحة، ويتم وضع علامة على كل عينة باستخدام
        فئة لكل إخراج. قد يكون الإخراج ثنائيًا أو متعدد الفئات، وفي
        في الحالة التي تكون فيها جميع الإخراج ثنائية، يكون الهدف
        :term: `multilabel`.

        يتم تمثيل الأهداف متعددة الفئات متعددة الإخراج على أنها متعددة
        أهداف متعددة الفئات :term:، مكدسة أفقيًا في مصفوفة
        الشكل "(n_samples، n_outputs)".

        XXX: من أجل البساطة، قد لا ندعم دائمًا تسميات الفئات السلسلة
        للأهداف متعددة الفئات متعددة الإخراج، ويجب استخدام تسميات الفئات الصحيحة.

        يوفر :mod: `~ sklearn.multioutput` التقديرات التي تقدر مشكلات الإخراج المتعددة
        باستخدام العديد من التقديرات ذات الإخراج الفردي. قد لا يراعي هذا تمامًا
        الاعتماد على الإخراج المختلف، والذي قد تقوم به الطرق التي تتعامل بشكل طبيعي مع
        حالة الإخراج المتعدد (مثل أشجار القرار، والجيران الأقرب، والشبكات العصبية) بشكل أفضل.

        :func: `~ utils.multiclass.type_of_target` سوف يعيد
        'multiclass-multioutput' لإدخال متعدد الفئات متعدد الإخراج.

    multilabel
    multi-label
        :term: `multiclass multioutput` target حيث يكون كل إخراج
        :term: `binary`. قد يتم تمثيل هذا على أنه مصفوفة ثنائية الأبعاد (كثيفة) أو
        مصفوفة متفرقة من الأعداد الصحيحة، بحيث يكون كل عمود هدفًا ثنائيًا منفصلاً، حيث يتم الإشارة إلى العلامات الإيجابية بـ 1 والعلامات السلبية
        عادة -1 أو 0. لا يتم دعم الأهداف متعددة التصنيفات المتناثرة في كل مكان
        حيث يتم دعم الأهداف متعددة التصنيفات الكثيفة.

        من الناحية الدلالية، يمكن اعتبار الهدف متعدد التصنيفات على أنه مجموعة من التصنيفات
        لكل عينة. في حين أنه لا يستخدم داخليًا،
        :class: `preprocessing.MultiLabelBinarizer` يتم توفيرها كمرفق للتحويل من
        تمثيل قائمة المجموعات إلى مصفوفة ثنائية الأبعاد أو مصفوفة متفرقة. يؤدي الترميز الساخن لهدف متعدد الفئات باستخدام
        :class: `preprocessing.LabelBinarizer` يحوله إلى مشكلة متعددة التصنيفات.

        :func: `~ utils.multiclass.type_of_target` سوف يعيد
        'multilabel-indicator' لإدخال متعدد التصنيفات، سواء كان متفرقًا أو كثيفًا.

    multioutput
    multi-output
        هدف يحتوي على عدة تسميات تصنيف/ارتجاع لكل عينة. راجع :term: `multiclass multioutput` و: term: `continuous
        multioutput`. لا ندعم حاليًا نمذجة الأهداف المختلطة
        التصنيف والارتداد.

.. _glossary_methods:

الأساليب
يسرد هذا القاموس المصطلحات المستخدمة في الوثائق المرجعية لـ scikit-learn، ويصف معناها في سياق المكتبة.

.. glossary::

    ``decision_function``
        في :term:`classifier` أو :term:`outlier detector` المناسب، يتنبأ بـ "soft"
        النتيجة لكل عينة فيما يتعلق بكل فئة، بدلاً من التنبؤ "الصعب"
        التنبؤ التصنيفي الذي ينتجه :term:`predict`. عادةً ما يكون الإدخال
        فقط بعض البيانات الملاحظة، :term:`X`.

        إذا لم يكن المثمن مناسبًا بالفعل، فيجب أن يؤدي استدعاء هذه الطريقة
        إلى رفع :class:`exceptions.NotFittedError`.

        اتفاقيات الإخراج:

        التصنيف الثنائي
            مصفوفة أحادية البعد، حيث تشير القيم التي تزيد عن الصفر بشكل صارم
            إلى الفئة الإيجابية (أي الفئة الأخيرة في :term:`classes_`).
        التصنيف متعدد الفئات
            مصفوفة ثنائية الأبعاد، حيث يكون الحد الأقصى للجدول هو الفئة المتوقعة.
            يتم ترتيب الأعمدة وفقًا لـ :term:`classes_`.
        التصنيف متعدد التصنيفات
            لا يتسق Scikit-learn في تمثيله لـ :term:`multilabel`
            وظائف القرار. قد يتم تمثيله بطريقتين:

            - قائمة من المصفوفات ثنائية الأبعاد، حيث تكون كل مصفوفة من الشكل:
              ('n_samples'، 2)، كما هو الحال في التصنيف متعدد الفئات متعدد الإخراج.
              القائمة هي من طول 'n_labels'.

            - مصفوفة ثنائية الأبعاد واحدة من الشكل ('n_samples'، 'n_labels')، مع
              يتم تمثيل كل "عمود" في المصفوفة بقرارات التصنيف الثنائية الفردية.
              هذا مطابق لتنسيق التصنيف متعدد الفئات، على الرغم من اختلاف الدلالات:
              يجب تفسيره، كما هو الحال في الحالة الثنائية، عن طريق العتبة عند
              0.

        التصنيف متعدد الإخراج
            قائمة من المصفوفات ثنائية الأبعاد، المقابلة لكل وظيفة قرار متعددة الفئات.
        كشف الشذوذ
            مصفوفة أحادية البعد، حيث تشير قيمة أكبر من أو تساوي الصفر
            إلى قيمة شاذة.

    ``fit``
        يتم توفير طريقة "fit" في كل مثمن. عادة ما يأخذ بعض
        :term:`samples` ``X``، :term:`targets` ``y`` إذا كان النموذج مشرفًا،
        وربما خصائص العينة الأخرى مثل :term:`sample_weight`. يجب أن:

        * مسح أي :term:`attributes` المخزنة مسبقًا على المثمن، ما لم
          :term:`warm_start` مستخدمة؛
        * التحقق من صحة وتفسير أي :term:`parameters`، ويفضل رفع خطأ
          إذا كانت غير صالحة؛
        * التحقق من صحة بيانات الإدخال؛
        * تقدير وتخزين سمات النموذج من المعلمات المقدرة
          وبيانات مقدمة؛ و
        * إرجاع المثمن المناسب الآن لتسهيل تسلسل الطريقة.

        :ref:`glossary_target_types` يصف التنسيقات الممكنة لـ "y".

    ``fit_predict``
        تستخدم بشكل خاص لمقدرات :term:`unsupervised`، :term:`transductive`
        ، تناسب هذه الطريقة النموذج وتعيد التوقعات (مشابهة
        :term:`predict`) على بيانات التدريب. في التجميع، يتم أيضًا تخزين هذه التوقعات
        في :term:`labels_` السمة، ويكون إخراج "fit_predict(X)" عادةً
        مكافئًا لـ ".fit(X).predict(X)".
        تكون معلمات "fit_predict" هي نفسها الخاصة بـ "fit".

    ``fit_transform``
        طريقة في :term:`transformers` التي تناسب المثمن وتعيد
        بيانات التدريب المحولة. يأخذ المعلمات كما هو الحال في :term:`fit`
        يجب أن يكون شكل الإخراج هو نفسه كما هو الحال عند استدعاء ".fit(X،
        ...).transform(X)". ومع ذلك، هناك حالات نادرة حيث
        "fit_transform(X، ...)" و ".fit(X، ...).transform(X)"
        لا تعيد نفس القيمة، حيث يجب التعامل مع بيانات التدريب بشكل مختلف
        (بسبب مزج النماذج في المجموعات المكدسة، على سبيل المثال؛
        يجب توثيق مثل هذه الحالات بوضوح).
        قد توفر المحولات :term:`Transductive <transductive>` أيضًا
        ``fit_transform`` ولكن ليس :term:`transform`.

        أحد أسباب تنفيذ "fit_transform" هو أن إجراء "fit"
        و "transform" بشكل منفصل سيكون أقل كفاءة من معًا.
        يوفر :class:`base.TransformerMixin` تنفيذًا افتراضيًا،
        توفير واجهة متسقة عبر المحولات حيث "fit_transform"
        يتم أو لا يتم التخصص.

        في التعلم :term:`inductive` - حيث يتمثل الهدف في تعلم نموذج معمم
        يمكن تطبيقه على بيانات جديدة - يجب أن يكون المستخدمون حذرين
        لا تطبق "fit_transform" على مجموعة البيانات بأكملها
        (أي بيانات التدريب واختبار معًا) قبل إجراء المزيد من النمذجة، كما هو الحال
        يؤدي ذلك إلى :term:`data leakage`.

    ``get_feature_names_out``
        في المقام الأول لمستخلصات الميزات، ولكن أيضًا
        من قبل المحولات الأخرى لتوفير أسماء السلاسل لكل عمود في
        إخراج طريقة التحويل الخاصة بالمثمن. ينتج مصفوفة من السلاسل
        قد يأخذ كإدخال مصفوفة تشبه السلسلة المقابلة
        أسماء أعمدة الإدخال التي يمكن استخدامها لتوليد أسماء أعمدة الإخراج.
        إذا لم يتم تمرير 'input_features'، فسيتم استخدام السمة
        `feature_names_in_`. إذا لم يتم تحديد السمة
        `feature_names_in_`، فسيتم تسمية أسماء الإدخال
        '[x0، x1، ...، x(n_features_in_ - 1)]'.

    ``get_n_splits``
        على :term:`CV splitter` (ليس مثمنًا)، يعيد عدد العناصر التي سيتم الحصول عليها
        إذا تم التكرار خلال قيمة الإرجاع لـ :term:`split`
        يتم تمرير نفس المعلمات. تأخذ نفس المعلمات مثل الانقسام.

    ``get_params``
        يحصل على جميع :term:`parameters`، وقيمها، التي يمكن تعيينها باستخدام
        :term:`set_params`. يمكن استخدام معلمة "عميقة" عند الإعداد
        إلى False للعودة فقط إلى تلك المعلمات التي لا تحتوي على "__"، أي
        ليس بسبب الاستدلال غير المباشر عبر المثمنات المحتواة.

        يعتمد معظم المقدرين التعريف من :class:`base.BaseEstimator`،
        الذي يعتمد ببساطة المعلمات المحددة لـ "__init__".
        يعيد :class:`pipeline.Pipeline`، من بين أمور أخرى، تعريف "get_params"
        للإعلان عن المقدرات المسماة في معلمة "الخطوات" الخاصة بها
        أنفسهم كمعلمات.

    ``partial_fit``
        يسهل تناسب المثمن بطريقة عبر الإنترنت. على عكس "fit"،
        لا يؤدي استدعاء "partial_fit" بشكل متكرر إلى مسح النموذج، ولكنه
        تحديثه بالبيانات المقدمة. قد يُطلق على جزء البيانات
        المقدمة إلى "partial_fit" اسم مصغر.
        يجب أن يكون لكل مصغر نفس الشكل، إلخ. في المقدرات التكرارية،
        غالبًا ما يؤدي "partial_fit" إلى تنفيذ تكرار واحد فقط.

        قد يتم استخدام "partial_fit" أيضًا للتعلم :term:`out-of-core`،
        على الرغم من أنه يقتصر عادةً على الحالة التي يمكن فيها إجراء التعلم عبر الإنترنت، أي
        يمكن استخدام النموذج بعد كل "partial_fit" وليس هناك
        معالجة منفصلة مطلوبة لإنهاء النموذج.
        يقدم :class:`cluster.Birch` الاتفاقية التي تنص على أن استدعاء
        "partial_fit(X)" سينتج عنه نموذج غير نهائي، ولكن
        يمكن نهائي النموذج عن طريق استدعاء "partial_fit()" أي
        بدون تمرير مصغر آخر.

        بشكل عام، يجب ألا يتم تعديل معلمات المثمن بين الاستدعاءات
        إلى "partial_fit"، على الرغم من أنه يجب أن يتحقق منها
        وكذلك مصغر البيانات الجديد. على النقيض من ذلك، "warm_start"
        يتم استخدامه لتناسب نفس المثمن بنفس البيانات
        ولكن مع اختلاف المعلمات.

        مثل "fit"، يجب أن تعيد "partial_fit" كائن المقدر.

        لتنظيف النموذج، يجب إنشاء مثمن جديد، على سبيل المثال
        مع :func:`base.clone`.

        ملاحظة: يؤدي استخدام "partial_fit" بعد "fit" إلى سلوك غير محدد.

    ``predict``
        يقوم بتنبؤ لكل عينة، وعادة ما يأخذ فقط :term:`X` كإدخال (ولكن راجع
        اتفاقيات إخراج المُرجع أدناه). في :term:`classifier` أو
        :term:`regressor`، يكون هذا التنبؤ في نفس
        مساحة الهدف المستخدمة في التجهيز (على سبيل المثال، واحدة من {'red'، 'amber'، 'green'} إذا
        كانت "y" في التجهيز تتكون من هذه السلاسل). على الرغم من ذلك، حتى عندما
        "y" التي تم تمريرها إلى :term:`fit` قائمة أو مصفوفة تشبه أخرى،
        يجب أن يكون إخراج "predict" مصفوفة أو مصفوفة متفرقة دائمًا. في
        :term:`clusterer` أو :term:`outlier detector` التنبؤ هو
        عدد صحيح.

        إذا لم يكن المثمن مناسبًا بالفعل، فيجب أن يؤدي استدعاء هذه الطريقة
        إلى رفع :class:`exceptions.NotFittedError`.

        اتفاقيات الإخراج:

        المصنف
            مصفوفة من الشكل "(n_samples،)" "(n_samples، n_outputs)".
            قد يتم تمثيل بيانات :term:`Multilabel <multilabel>` كمصفوفة متفرقة إذا
            تم استخدام مصفوفة متفرقة في التجهيز. يجب أن يكون كل عنصر
            واحدة من القيم الموجودة في سمة "classes_" الخاصة بالمصنف
            السمة.

        التجميع
            مصفوفة من الشكل "(n_samples،)" حيث تكون كل قيمة من 0 إلى
            "n_clusters - 1" إذا تم تجميع العينة المقابلة،
            و -1 إذا لم يتم تجميع العينة، كما هو الحال في
            :func:`cluster.dbscan`.

        كاشف الشذوذ
            مصفوفة من الشكل "(n_samples،)" حيث تكون كل قيمة -1 لشذوذ و 1 خلاف ذلك.

        المُرجع
            مصفوفة رقمية من الشكل "(n_samples،)"، عادةً float64.
            تحتوي بعض المُرجعات على خيارات إضافية في طريقة "predict" الخاصة بها،
            السماح لهم بإرجاع الانحراف المعياري (``return_std=True``)
            أو التباين (``return_cov=True``) فيما يتعلق بالقيمة المتوقعة.
            في هذه الحالة، تكون قيمة الإرجاع عبارة عن مجموعة من المصفوفات
            (التنبؤ، std، cov) كما هو مطلوب.

    ``predict_log_proba``
        اللوغاريتم الطبيعي لإخراج :term:`predict_proba`، المقدم
        لتسهيل الاستقرار العددي.

    ``predict_proba``
        طريقة في :term:`classifiers` و :term:`clusterers` التي يمكن
        إرجاع تقديرات الاحتمالية لكل class/cluster. عادة ما يكون الإدخال
        فقط بعض البيانات الملاحظة، :term:`X`.

        إذا لم يكن المثمن مناسبًا بالفعل، فيجب أن يؤدي استدعاء هذه الطريقة
        إلى رفع :class:`exceptions.NotFittedError`.

        اتفاقيات الإخراج مثل تلك الخاصة بـ :term:`decision_function` باستثناء
        في حالة التصنيف الثنائي، حيث يتم إخراج عمود لكل فئة (بينما
        ينتج "decision_function" مصفوفة أحادية البعد). للتنبؤات الثنائية والمتعددة الفئات،
        يجب أن يضيف كل صف إلى 1.

        مثل الطرق الأخرى، يجب ألا يكون "predict_proba" موجودًا إلا عندما
        يمكن للمثمن إجراء تنبؤات احتمالية (انظر :term:`duck typing`).
        هذا يعني أن وجود الطريقة قد يعتمد على معلمات المثمن (على سبيل المثال في
        :class:`linear_model.SGDClassifier`) أو بيانات التدريب (على سبيل المثال في
        :class:`model_selection.GridSearchCV`) وقد لا يظهر إلا بعد التجهيز.

    ``score``
        طريقة في المثمن، عادةً ما تكون :term:`predictor`، والتي تقيم
        تنبؤاته على مجموعة بيانات معينة، وتعيد نتيجة رقمية واحدة.
        يجب أن يشير ناتج القيمة الأكبر إلى تنبؤات أفضل؛ يتم استخدام الدقة للتصنيفات و
        R^2 للمرجعيات بشكل افتراضي.

        إذا لم يكن المثمن مناسبًا بالفعل، فيجب أن يؤدي استدعاء هذه الطريقة
        إلى رفع :class:`exceptions.NotFittedError`.

        يقوم بعض المقدرين بتنفيذ دالة تقييم مخصصة خاصة بالمثمن،
        غالبًا ما يكون احتمال البيانات وفقًا للنموذج.

    ``score_samples``
        طريقة تعيد درجة لكل عينة معينة. يعتمد التعريف الدقيق لـ
        *درجة* تختلف من فئة إلى أخرى. في حالة تقدير الكثافة، يمكن أن يكون
        سجل كثافة النموذج على البيانات، وفي حالة اكتشاف الشذوذ، يمكن أن يكون
        عكس عامل الشذوذ للبيانات.

        إذا لم يكن المثمن مناسبًا بالفعل، فيجب أن يؤدي استدعاء هذه الطريقة
        إلى رفع :class:`exceptions.NotFittedError`.
"set_params"
تتوفر في أي أداة تقدير، وتأخذ وسائط الكلمات الرئيسية المقابلة للمفاتيح في: term: `get_params`. يتم توفير كل منها بقيمة جديدة لتعيينها بحيث يعكس استدعاء "get_params" بعد "set_params" تم تغيير: المصطلح: `parameters`. يستخدم معظم المقدرات التنفيذ في: class: `base.BaseEstimator`، والذي يتعامل مع المعلمات المضمنة، وإلا فإنه يحدد المعلمة كسمة للمقدّر. يتم تجاوز الطريقة في: class: `pipeline.Pipeline` والمقدرات ذات الصلة.

"split"
في أداة تقسيم CV (ليس مقدرًا)، تقبل هذه الطريقة المعلمات (X، y، groups)، حيث قد تكون جميعها اختيارية، وتعيد مؤشرًا إلى أزواج "train_idx، test_idx". كل من train_idx وtest_idx عبارة عن مصفوفة أعداد صحيحة أحادية الأبعاد، بقيم تتراوح من 0 إلى "X.shape[0] - 1" بأي طول، بحيث لا تظهر أي قيم في كل من "train_idx" و"test_idx" المقابل.

"التحويل"
في: مصطلح: `transformer`، يحول المدخلات، عادةً فقط: مصطلح: `X`، إلى مساحة محولة (عادة ما يتم تمييزها بواسطة: مصطلح: `Xt`). الإخراج هو مصفوفة أو مصفوفة متفرقة بطول: مصطلح: `n_samples` وبعدد أعمدة ثابت بعد: مصطلح: `fitting`.

إذا لم يتم: مصطلح: `fitted` المقدر بالفعل، فيجب أن يؤدي استدعاء هذه الطريقة إلى إثارة: class: `exceptions.NotFittedError`.

.. _glossary_parameters:

المعلمات
هذه الأسماء الشائعة لمعلمات، والتي تستخدم بشكل خاص في بناء المُقدِّر (راجع المفهوم: مصطلح "معلمة")، تظهر أيضًا أحيانًا كمعلمات لوظائف أو بُناة غير المُقدِّر.

.. glossary::

   ``class_weight``
      تُستخدم لتحديد أوزان العينات عند تناسب المصنفات كدالة لفئة "الهدف". عندما يكون "sample_weight" مدعومًا أيضًا ومُعطى، فإنه يُضرب في مساهمة "class_weight". وبالمثل، عندما تُستخدم "class_weight" في مهام "multioutput" (بما في ذلك "multilabel")، يتم ضرب الأوزان عبر المخرجات (أي أعمدة "y").

      بشكل افتراضي، يكون لجميع العينات وزن متساوٍ بحيث يتم ترجيح الفئات فعليًا حسب انتشارها في بيانات التدريب. يمكن تحقيق ذلك بشكل صريح باستخدام "class_weight={label1: 1, label2: 1, ...}" لجميع تسميات الفئات.

      بشكل عام، يتم تحديد "class_weight" كقاموس يقوم بمَوْضَعة تسميات الفئات إلى أوزان (``{class_label: weight}``)، بحيث يتم إعطاء كل عينة من الفئة المسماة ذلك الوزن.

      يمكن استخدام "class_weight='balanced'" لإعطاء جميع الفئات وزنًا متساويًا عن طريق إعطاء كل عينة وزنًا عكسيًا يتعلق بانتشار فئتها في بيانات التدريب: "n_samples / (n_classes * np.bincount(y))". ستُستخدم أوزان الفئات بشكل مختلف اعتمادًا على الخوارزمية: بالنسبة للنماذج الخطية (مثل SVM الخطي أو الانحدار اللوجستي)، ستعدل أوزان الفئات دالة الخسارة عن طريق ترجيح خسارة كل عينة بوزن فئتها. وبالنسبة لخوارزميات الأشجار، ستُستخدم أوزان الفئات لإعادة ترجيح معيار الانقسام. لاحظ مع ذلك أن هذا إعادة التوازن لا يأخذ في الاعتبار وزن العينات في كل فئة.

      بالنسبة للتصنيف متعدد المخرجات، يتم استخدام قائمة من القواميس لتحديد الأوزان لكل مخرج. على سبيل المثال، بالنسبة للتصنيف متعدد التصنيفات بأربع فئات، يجب أن تكون الأوزان "[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}]" بدلاً من "[{1:1}, {2:5}, {3:1}, {4:1}]".

      يتم التحقق من معلمة "class_weight" وتفسيرها باستخدام "utils.class_weight.compute_class_weight".

   ``cv``
      يحدد استراتيجية تقسيم الصدق التصادفي، كما هو مستخدم في الروتينات المستندة إلى الصدق التصادفي. "cv" متاح أيضًا في المُقدِّرات مثل "multioutput.ClassifierChain" أو "calibration.CalibratedClassifierCV" والتي تستخدم تنبؤات مُقدِّر واحد كبيانات تدريب لمُقدِّر آخر، لعدم المبالغة في تناسب الإشراف التدريبي.

      المدخلات الممكنة لـ "cv" عادة ما تكون:

      - رقم صحيح، يحدد عدد الطيات في الصدق التصادفي K-fold. سيتم تقسيم الصدق التصادفي K إلى طبقات عبر الفئات إذا كان المُقدِّر هو مصنف (يتم تحديده بواسطة "base.is_classifier") وقد تمثل "الأهداف" مشكلة تصنيف ثنائي أو متعدد الفئات (ولكن ليس متعدد المخرجات) (يتم تحديده بواسطة "utils.multiclass.type_of_target").
      - مثيل "cross-validation splitter". راجع "دليل المستخدم" للحصول على splitters المتاحة داخل Scikit-learn.
      - iterable يعطي تقسيمات التدريب/الاختبار.

      مع بعض الاستثناءات (خاصة عندما يكون عدم استخدام الصدق التصادفي على الإطلاق خيارًا)، يكون الافتراضي هو 5-fold.

      يتم التحقق من قيم "cv" وتفسيرها باستخدام "model_selection.check_cv".

   ``kernel``
      يحدد دالة النواة التي يجب استخدامها بواسطة خوارزميات طريقة النواة. على سبيل المثال، لكل من المُقدِّرات "svm.SVC" و"gaussian_process.GaussianProcessClassifier" معلمة "kernel" التي تأخذ اسم النواة التي سيتم استخدامها كسلسلة أو دالة نواة قابلة للاستدعاء تُستخدم لحساب مصفوفة النواة. لمزيد من المعلومات، راجع "kernel_approximation" و"gaussian_process" أدلة المستخدم.

   ``max_iter``
      بالنسبة للمُقدِّرات التي تنطوي على تحسين تكراري، يحدد هذا العدد الأقصى من التكرارات التي سيتم تنفيذها في "fit". إذا تم تشغيل "max_iter" من التكرارات بدون تقارب، فيجب رفع "ConvergenceWarning". لاحظ أن تفسير "تكرار واحد" غير متسق عبر المُقدِّرات: يستخدم البعض، ولكن ليس كلهم، للإشارة إلى حقبة واحدة (أي مرور عبر كل عينة في البيانات).

      FIXME ربما يجب أن تكون لدينا بعض الاختبارات الشائعة حول العلاقة بين "ConvergenceWarning" و"max_iter".

   ``memory``
      يستخدم بعض المُقدِّرات "joblib.Memory" لتخزين الحلول الجزئية أثناء التجهيز. لذلك، عندما يتم استدعاء "fit" مرة أخرى، يتم استذكار الحلول الجزئية ويمكن إعادة استخدامها.

      يمكن تحديد معلمة "memory" كسلسلة تحتوي على مسار إلى دليل، أو يمكن استخدام مثيل "joblib.Memory" (أو كائن له واجهة مماثلة، أي طريقة "cache")

   يتم التحقق من قيم "memory" وتفسيرها باستخدام "utils.validation.check_memory".

   ``metric``
      كمعلمة، هذه هي خطة لتحديد المسافة بين نقطتي بيانات. راجع "metrics.pairwise_distances". في الممارسة العملية، بالنسبة لبعض الخوارزميات، يمكن استخدام مسافة غير صحيحة (واحدة لا تلتزم بمتباينة المثلث، مثل المسافة التماثلية).

      XXX: يستخدم التجميع الهرمي "affinity" بهذا المعنى.

      نستخدم أيضًا "metric" للإشارة إلى مقاييس التقييم، ولكن نتجنب استخدام هذا المعنى كاسم معلمة.

   ``n_components``
      عدد الميزات التي يجب أن يحولها "المحول" الإدخال إليها. راجع "components_" للحالة الخاصة للمشروع المائل.

   ``n_iter_no_change``
      عدد التكرارات بدون تحسن في انتظار إيقاف الإجراء التكراري. يُعرف هذا أيضًا باسم معلمة "الصبر". يتم استخدامه عادةً مع "التوقف المبكر" لتجنب التوقف المبكر جدًا.

   ``n_jobs``
      تُستخدم هذه المعلمة لتحديد عدد العمليات أو الخيوط المتزامنة التي يجب استخدامها للروتينات الموازية باستخدام "joblib".

      "n_jobs" هو رقم صحيح، يحدد العدد الأقصى للعمال المتزامنين الذين يعملون. إذا تم إعطاء 1، فلن يتم استخدام أي موازاة joblib على الإطلاق، وهو أمر مفيد للتصحيح. إذا تم تعيينه على -1، فسيتم استخدام جميع وحدات المعالجة المركزية. بالنسبة لـ "n_jobs" أقل من -1، يتم استخدام (n_cpus + 1 + n_jobs). على سبيل المثال، مع "n_jobs=-2"، يتم استخدام جميع وحدات المعالجة المركزية باستثناء واحدة.

      "n_jobs" هو "None" بشكل افتراضي، مما يعني "غير محدد"؛ سيتم تفسيره بشكل عام على أنه "n_jobs=1"، ما لم يحدد سياق "joblib.Parallel" الخلفي الحالي خلاف ذلك.

      لاحظ أنه حتى إذا كان "n_jobs=1"، فقد يتم استخدام الموازاة منخفضة المستوى (عبر Numpy وOpenMP) في بعض التكوينات.

      لمزيد من التفاصيل حول استخدام "joblib" وتفاعلاته مع scikit-learn، يرجى الرجوع إلى ملاحظاتنا حول "الموازاة".

   ``pos_label``
      القيمة التي يجب ترميز التسميات الإيجابية بها في مشكلات التصنيف الثنائية التي لا يتم افتراض الفئة الإيجابية فيها. هذه القيمة مطلوبة عادةً لحساب مقاييس التقييم غير المتماثلة مثل الدقة والاستدعاء.

   ``random_state``
      عندما يكون التمييز العشوائي جزءًا من خوارزمية Scikit-learn، يمكن توفير معلمة "random_state" للتحكم في مولد الأرقام العشوائية المستخدم. لاحظ أن مجرد وجود "random_state" لا يعني أن التمييز العشوائي مستخدم دائمًا، فقد يعتمد على معلمة أخرى، مثل "shuffle"، يتم تعيينها.

      سيؤثر القيمة الممرورة على قابلية نتائج الدالة للتكرار ("fit"، "split"، أو أي دالة أخرى مثل "sklearn.cluster.k_means"). قد تكون قيمة "random_state" على النحو التالي:

      None (افتراضي)
          استخدم مثيل حالة عشوائي عالمي من "numpy.random". سيؤدي استدعاء الدالة عدة مرات إلى إعادة استخدام
          نفس المثيل، وسيؤدي إلى نتائج مختلفة.

      رقم صحيح
          استخدم مولد أرقام عشوائي جديد تمت تهيئته بواسطة الرقم الصحيح المُعطى. سيؤدي استخدام رقم صحيح إلى إنتاج نفس النتائج عبر استدعاءات مختلفة.
          ومع ذلك، فقد يكون من المفيد التحقق من استقرار نتائجك عبر عدد من الأرقام العشوائية المميزة المختلفة. الأرقام العشوائية الشائعة هي 0 و`42
          <https://en.wikipedia.org/wiki/Answer_to_the_Ultimate_Question_of_Life%2C_the_Universe%2C_and_Everything>`_. يجب أن تكون قيم الأرقام الصحيحة في النطاق `[0, 2**32 - 1]`.

      مثيل "numpy.random.RandomState"
          استخدم حالة عشوائية مقدمة، مما يؤثر فقط على المستخدمين الآخرين
          من مثيل الحالة العشوائية نفسه. سيؤدي استدعاء الدالة
          عدة مرات إلى إعادة استخدام نفس المثيل،
          وسيؤدي إلى نتائج مختلفة.

      يتم استخدام "utils.check_random_state" داخليًا للتحقق من إدخال "random_state" وإرجاع مثيل "numpy.random.RandomState".

      لمزيد من التفاصيل حول كيفية التحكم في عشوائية كائنات scikit-learn وتجنب الفخاخ الشائعة، يمكنك الرجوع إلى "randomness".

   ``scoring``
      يحدد دالة النتيجة التي يجب تعظيمها (عادةً بواسطة الصدق التصادفي)، أو - في بعض الحالات - نتائج وظائف النتيجة المتعددة التي يجب الإبلاغ عنها. قد تكون دالة النتيجة سلسلة مقبولة بواسطة "metrics.get_scorer" أو "scorer" قابل للاستدعاء، لا ينبغي الخلط بينه وبين "مقياس التقييم"، حيث أن الأخير له واجهة برمجة تطبيقات أكثر تنوعًا. قد يكون "التقييم" أيضًا "None"، وفي هذه الحالة يتم استخدام طريقة "score" للمُقدِّر. راجع "scoring_parameter" في "دليل المستخدم".

      عندما يمكن تقييم مقاييس متعددة، يمكن إعطاء "التقييم" إما كقائمة من السلاسل الفريدة، أو قاموس بأسماء كمفاتيح ودالات قابلة للاستدعاء كقيم أو دالة قابلة للاستدعاء تقوم بإرجاع قاموس. لاحظ أن هذا لا يحدد دالة النتيجة التي سيتم تعظيمها، وقد يتم استخدام معلمة أخرى مثل "refit" لهذا الغرض.

      يتم التحقق من معلمة "التقييم" وتفسيرها باستخدام "metrics.check_scoring".

   ``verbose``
      لا يتم التعامل مع التسجيل بشكل متسق في Scikit-learn في الوقت الحالي، ولكن عندما يكون خيارًا، تكون معلمة "verbose" متاحة عادةً لاختيار عدم التسجيل (يتم تعيينها على False). يجب أن يؤدي أي قيمة صحيحة إلى تمكين بعض التسجيل، ولكن قد تكون هناك حاجة إلى أرقام أكبر (على سبيل المثال، أعلى من 10) للتحقق من الفعالية الكاملة. يتم عادةً طباعة السجلات المفصلة إلى الإخراج القياسي.
      يجب ألا تنتج المُقدِّرات أي إخراج على الإخراج القياسي مع إعداد "verbose" الافتراضي.

   ``warm_start``

      عند تناسب مُقدِّر بشكل متكرر على نفس مجموعة البيانات، ولكن لقيم معلمات متعددة (مثل العثور على القيمة التي تعظم الأداء كما هو الحال في "grid search")، فقد يكون من الممكن إعادة استخدام جوانب النموذج المُدرب من قيمة المعلمة السابقة، مما يوفر الوقت. عندما تكون "warm_start" صحيحة، يتم استخدام سمات "fitted" الموجودة لتهيئة النموذج الجديد في استدعاء لاحق إلى "fit".

      لاحظ أن هذا لا ينطبق إلا على بعض النماذج وبعض المعلمات، وحتى بعض ترتيبات قيم المعلمات. بشكل عام، هناك تفاعل بين "warm_start" والمعلمة التي تتحكم في عدد تكرارات المُقدِّر.
بالنسبة للمُقدّرات المستوردة من :mod:`~sklearn.ensemble`، سوف يتفاعل معلمة ``warm_start`` مع ``n_estimators`` أو ``max_iter``. بالنسبة لهذه النماذج، يتوافق عدد التكرارات، المُبلغ عنه عبر ``len(estimators_)`` أو ``n_iter_``، مع العدد الإجمالي للمُقدّرات/التكرارات التي تم تعلمها منذ تهيئة النموذج. وبالتالي، إذا تم تهيئة نموذج مسبقًا بـ `N` مُقدّر، وتم استدعاء الدالة `fit` مع تعيين ``n_estimators`` أو ``max_iter`` إلى `M`، فسيقوم النموذج بتدريب `M - N` مُقدّرات جديدة.

تتبع النماذج الأخرى، التي تستخدم عادةً خوارزميات المُحَسَّلة المُتَوَزِّعة، سلوكًا مختلفًا. تعرض جميعها معلمة ``max_iter``. يتوافق المُبلغ عنه ``n_iter_`` مع عدد التكرارات التي تم إجراؤها أثناء آخر استدعاء للدالة ``fit`` وسيكون على الأكثر ``max_iter``. وبالتالي، لا نأخذ حالة المُقدّر منذ التهيئة في الاعتبار.

يحتفظ :term:`partial_fit` أيضًا بالنموذج بين الاستدعاءات، ولكنه يختلف: مع ``warm_start``، تتغير المعلمات وتظل البيانات (أكثر أو أقل) ثابتة عبر استدعاءات الدالة ``fit``؛ مع ``partial_fit``، تتغير مجموعة البيانات المصغرة وتظل معلمات النموذج ثابتة.

هناك حالات تريد فيها استخدام ``warm_start`` للتناسب مع بيانات مختلفة، ولكنها ذات صلة وثيقة. على سبيل المثال، قد يقوم المرء أولاً بالتناسب مع مجموعة فرعية من البيانات، ثم ضبط دقيق للبحث عن المعلمات على المجموعة الكاملة من البيانات. بالنسبة للتصنيف، يجب أن تحتوي جميع البيانات في تسلسل من استدعاءات ``warm_start`` إلى الدالة ``fit`` على عينات من كل فئة.

.. _glossary_attributes:

السمات
فيما يلي ترجمة للنص الموجود بتنسيق ReStructuredText إلى اللغة العربية:

==========

راجع المفهوم: المصطلح "attribute".

.. glossary::

    ``classes_``
        قائمة من تسميات الفئات التي يعرفها المصنف، حيث يتم تعيين كل تسمية فئة إلى فهرس رقمي يستخدم في تمثيل النموذج أو الإخراج. على سبيل المثال، يكون للمصفوفة الناتجة عن ``predict_proba`` أعمدة محاذاة مع ``classes_``. بالنسبة للمصنفات متعددة الإخراج، يجب أن تكون ``classes_`` قائمة من القوائم، مع قائمة تسميات لكل إخراج. يجب فرز الفئات لكل إخراج (رقميًا، أو أبجديًا بالنسبة للسلاسل النصية).

        عادةً ما يتم إدارة ``classes_`` وتعيينها إلى فهارس باستخدام ``preprocessing.LabelEncoder``.

    ``components_``
        مصفوفة تحويل أفيني الشكل ``(n_components, n_features)`` المستخدمة في العديد من المحولات الخطية حيث ``n_components`` هو عدد الميزات الإخراج و ``n_features`` هو عدد الميزات الإدخال.

        راجع أيضًا ``components_`` وهو خاصية مشابهة للنماذج الخطية.

    ``coef_``
        مصفوفة الأوزان/المعاملات لنموذج خطي عام، الشكل ``(n_features,)`` للتصنيف الثنائي والانحدار أحادي الإخراج، و ``(n_classes, n_features)`` للتصنيف متعدد الفئات، و ``(n_targets, n_features)`` للانحدار متعدد الإخراج. لاحظ أن هذا لا يشمل مصطلح الاعتراض (أو الانحياز) الذي يتم تخزينه في ``intercept_``.

        عندما تكون متاحة، عادةً ما لا يتم توفير ``feature_importances_`` أيضًا، ولكن يمكن حسابها على أنها القيمة المطلقة لكل ميزة في ``coef_``.

        راجع أيضًا ``components_`` وهو خاصية مشابهة للمحولات الخطية.

    ``embedding_``
        تمثيل مضغوط للبيانات التدريبية في خوارزميات التعلم على المنحنى، الشكل ``(n_samples, n_components)``، مطابق للإخراج من ``fit_transform``. راجع أيضًا ``labels_``.

    ``n_iter_``
        عدد التكرارات التي تم تنفيذها بالفعل عند ملاءمة خوارزمية تكرارية قد تتوقف عند التقارب. راجع أيضًا ``max_iter``.

    ``feature_importances_``
        متجه الشكل ``(n_features,)`` متاح في بعض النماذج لتوفير مقياس نسبي لأهمية كل ميزة في تنبؤات النموذج.

    ``labels_``
        متجه يحتوي على تسمية فئة لكل عينة من بيانات التدريب في خوارزميات التجميع، مطابق للإخراج من ``fit_predict``. راجع أيضًا ``embedding_``.

.. _glossary_sample_props:

خصائص البيانات والعينات
==========================

راجع المفهوم: المصطلح "sample property".

.. glossary::

    ``groups``
        تستخدم في روتين التقسيم الصليبي لتحديد العينات المترابطة. كل قيمة هي معرف بحيث، في مقسم CV المدعوم، قد لا تظهر العينات من بعض قيم "المجموعات" في كل من مجموعة التدريب ومجموعة الاختبار المقابلة. راجع :ref:`group_cv`.

    ``sample_weight``
        وزن نسبي لكل عينة. بشكل حدسي، إذا كانت جميع الأوزان أعداد صحيحة، يجب أن يكون النموذج أو الدرجة المرجحة مكافئة لتلك المحسوبة عند تكرار العينة عدد المرات المحددة في الوزن. يمكن تحديد الأوزان على أنها أرقام عشرية، بحيث تكون أوزان العينات عادةً متكافئة حتى عامل قياس إيجابي ثابت.

        هل هذا التفسير صحيح دائمًا في الممارسة العملية؟ لا توجد اختبارات مشتركة.

        يدعم بعض المقدرات، مثل أشجار القرار، الأوزان السلبية. قد لا يتم اختبار هذه الميزة أو توثيقها في العديد من المقدرات.

        هذا ليس صحيحًا تمامًا عندما تأخذ المعلمات الأخرى للنموذج في الاعتبار عدد العينات في منطقة ما، كما هو الحال في "min_samples" في ``cluster.DBSCAN``. في هذه الحالة، يصبح عدد العينات مجموع أوزانها.

        في التصنيف، يمكن أيضًا تحديد أوزان العينات كدالة للفئة باستخدام معلمة "class_weight" في المقدر.

    ``X``
        تشير إلى البيانات التي يتم ملاحظتها في وقت التدريب والتنبؤ، وتستخدم كمتغيرات مستقلة في التعلم. يكون الترميز بأحرف كبيرة للإشارة إلى أنه مصفوفة عادةً (راجع المصطلح "rectangular").
        عندما يكون مصفوفة، يمكن تمثيل كل عينة بواسطة متجه ميزات، أو متجه من المسافات المحسوبة مسبقًا (أو التشابه) مع كل عينة تدريب. قد لا يكون "X" مصفوفة، وقد يتطلب مستخرج ميزات أو مقياسًا زوجيًا لتحويله إلى مصفوفة قبل تعلم النموذج.

    ``Xt``
        اختصار لـ "transformed X".

    ``y``
    ``Y``
        تشير إلى البيانات التي قد يتم ملاحظتها في وقت التدريب كمتغير تابع في التعلم، ولكنها غير متوفرة في وقت التنبؤ، وعادة ما تكون الهدف من التنبؤ. قد يكون الترميز بأحرف كبيرة للإشارة إلى أنه مصفوفة، مما يمثل أهداف الإخراج المتعددة، على سبيل المثال؛ ولكن عادةً ما نستخدم "y" ونفعل ذلك أحيانًا حتى عند افتراض الإخراج المتعدد.