

Examples using ``sklearn.preprocessing.MinMaxScaler``
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


.. start-sphx-glr-thumbnails


.. raw:: html

    <div class="sphx-glr-thumbnails">

.. thumbnail-parent-div-open

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example visualizes some training loss curves for different stochastic learning strategies, including SGD and Adam. Because of time-constraints, we use several small datasets, for which L-BFGS might be more suitable. The general trend shown in these examples seems to carry over to larger datasets, however.">

.. only:: html

  .. image:: /auto_examples/neural_networks/images/thumb/sphx_glr_plot_mlp_training_curves_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_training_curves.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compare Stochastic learning strategies for MLPClassifier</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_training_curves.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This example constructs a pipeline that does dimensionality reduction followed by prediction with a support vector classifier. It demonstrates the use of GridSearchCV and Pipeline to optimize over different classes of estimators in a single CV run -- unsupervised PCA and NMF dimensionality reductions are compared to univariate feature selection during the grid search.">

.. only:: html

  .. image:: /auto_examples/compose/images/thumb/sphx_glr_plot_compare_reduction_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Selecting dimensionality reduction with Pipeline and GridSearchCV</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Feature 0 (median income in a block) and feature 5 (average house occupancy) of the california_housing_dataset have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators.">

.. only:: html

  .. image:: /auto_examples/preprocessing/images/thumb/sphx_glr_plot_all_scaling_thumb.png
    :alt:

  :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">Compare the effect of different scalers on data with outliers</div>
    </div>


.. only:: not html

 * :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`

.. thumbnail-parent-div-close

.. raw:: html

    </div>

