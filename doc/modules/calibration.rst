
.. _calibration:

=======================
معايرة الاحتمالات
=======================

.. currentmodule:: sklearn.calibration


عند إجراء التصنيف، غالبًا ما ترغب ليس فقط في توقع تسمية الفئة، ولكن أيضًا الحصول على احتمال التسمية المعنية. يمنحك هذا الاحتمال نوعًا من الثقة في التوقع. قد تعطيك بعض الطرز تقديرات ضعيفة لاحتمالات الفئة، وبعضها لا يدعم حتى توقع الاحتمالية (على سبيل المثال، بعض الحالات من :class:`~sklearn.linear_model.SGDClassifier`).
تتيح لك وحدة المعايرة معايرة أفضل لاحتمالات نموذج معين، أو إضافة دعم لتوقع الاحتمالية.

إن المصنفات المعايرة جيدًا هي مصنفات احتمالية يمكن تفسير إخراج طريقة :term:`predict_proba` مباشرة على أنه مستوى ثقة.
على سبيل المثال، يجب أن يصنف المصنف (الثنائي) المعاير جيدًا العينات بحيث من بين العينات التي أعطاها قيمة :term:`predict_proba` قريبة من، على سبيل المثال، 0.8، تنتمي حوالي 80٪ بالفعل إلى الفئة الإيجابية.

قبل أن نعرض كيفية إعادة معايرة المصنف، نحتاج أولاً إلى طريقة لاكتشاف مدى جودة معايرة المصنف.

.. note::
    تقيّم القواعد الصارمة للتسجيل الصحيح للتنبؤات الاحتمالية مثل :func:`sklearn.metrics.brier_score_loss` و :func:`sklearn.metrics.log_loss` المعايرة (الموثوقية) والقدرة التمييزية للنموذج، بالإضافة إلى عشوائية البيانات (الغموض) في نفس الوقت. يتبع هذا من تحليل درجة بrier المعروف ل Murphy [1] _. نظرًا لأنه ليس من الواضح أي المصطلح هو المسيطر، فإن النتيجة تكون محدودة الاستخدام لتقييم المعايرة وحدها (إلا إذا قام المرء بحساب كل مصطلح في التحليل). على سبيل المثال، خسارة بrier أقل لا تعني بالضرورة نموذجًا معايرًا بشكل أفضل، بل قد يعني أيضًا نموذجًا معايرًا أسوأ بكثير مع قوة تمييز أكبر بكثير، على سبيل المثال باستخدام العديد من الميزات الأخرى.

.. _calibration_curve:

منحنيات المعايرة
==========
    

[1] برايان ج. ميرفي. المهارة في التنبؤ الاحتمالي. الدورية الشهرية للأرصاد الجوية، 1(2):1-10، 1973.

منحنيات المعايرة، والتي يشار إليها أيضًا باسم "مخططات الموثوقية" (ويلكس 1995 [2]\_)، تقارن مدى جودة معايرة التنبؤات الاحتمالية لمصنف ثنائي. إنها ترسم وتيرة التسمية الإيجابية (لتكون أكثر دقة، تقدير *احتمال الحدث الشرطي* :math:`P(Y=1|\text{predict\_proba})`) على المحور ص مقابل الاحتمال المتوقع :term:`predict\_proba` لنموذج على المحور س. الجزء الصعب هو الحصول على قيم للمحور ص. في سكيت-ليرن، يتم تحقيق ذلك عن طريق تجميع التنبؤات بحيث يمثل المحور س متوسط الاحتمال المتوقع في كل مجموعة. ثم يكون المحور ص هو *نسبة الإيجابيات* بالنظر إلى تنبؤات تلك المجموعة، أي نسبة العينات التي تكون صفاتها هي الصفة الإيجابية (في كل مجموعة).

يتم إنشاء مخطط منحنى المعايرة العلوي باستخدام :func:`CalibrationDisplay.from\_estimator`، والذي يستخدم :func:`calibration\_curve` لحساب متوسط الاحتمالات المتوقعة ونسبة الإيجابيات لكل مجموعة. :func:`CalibrationDisplay.from\_estimator` يأخذ كمدخل مصنف مجهز، والذي يستخدم لحساب الاحتمالات المتوقعة. يجب أن يحتوي المصنف بالتالي على طريقة :term:`predict\_proba`. بالنسبة لعدد قليل من المصنفات التي ليس لها طريقة :term:`predict\_proba`، من الممكن استخدام :class:`CalibratedClassifierCV` لمعايرة مخرجات المصنف إلى احتمالات.

يعطي الرسم البياني السفلي بعض الأفكار حول سلوك كل مصنف من خلال إظهار عدد العينات في كل مجموعة احتمالية متوقعة.

.. figure:: ../auto\_examples/calibration/images/sphx\_glr\_plot\_compare\_calibration\_001.png
   :target: ../auto\_examples/calibration/plot\_compare\_calibration.html
   :align: center

.. currentmodule:: sklearn.linear\_model

:class:`LogisticRegression` من المرجح أن يعود بتنبؤات معايرة جيدًا بنفسه لأنه يحتوي على دالة ربط قيمة لمعامل خسارته، أي logit-link لـ :ref:`log\_loss`. في حالة عدم فرض عقوبة، يؤدي هذا إلى ما يسمى ب**خاصية التوازن**، انظر [8]\_ و:ref:`Logistic\_regression`. في الرسم البياني أعلاه، يتم إنشاء البيانات وفقًا لآلية خطية، والتي تتفق مع نموذج :class:`LogisticRegression` (النموذج "معين بشكل جيد")، ويتم ضبط قيمة معامل التنظيم `C` لتكون مناسبة (لا قوية جدًا ولا منخفضة جدًا). نتيجة لذلك، يعيد هذا النموذج تنبؤات دقيقة من طريقة `predict\_proba`. على النقيض من ذلك، تعيد النماذج الأخرى المعروضة احتمالات متحيزة؛ مع تحيزات مختلفة لكل نموذج.

.. currentmodule:: sklearn.naive\_bayes

:class:`GaussianNB` (نايف بايز) يميل إلى دفع الاحتمالات إلى 0 أو 1 (لاحظ الأعداد في الرسوم البيانية). هذا بشكل رئيسي لأنه يفترض أن السمات مستقلة شرطيًا بالنظر إلى الصفة، وهو ليس الحال في هذه المجموعة من البيانات التي تحتوي على سمتين زائدتين.

.. currentmodule:: sklearn.ensemble

:class:`RandomForestClassifier` يظهر السلوك المعاكس: تظهر الرسوم البيانية قممًا عند احتمالات تقريبية 0.2 و 0.9، بينما الاحتمالات القريبة من 0 أو 1 نادرة جدًا. يتم إعطاء تفسير لذلك من قبل نيكولاسكو-ميزيل وكاروانا [3]\_: "طرق مثل bagging والغابات العشوائية التي تقوم بمتوسط التنبؤات من مجموعة أساسية من النماذج يمكن أن تواجه صعوبة في إجراء تنبؤات بالقرب من 0 و 1 لأن التباين في النماذج الأساسية الكامنة سوف يؤدي إلى تحيز التنبؤات التي يجب أن تكون بالقرب من الصفر أو واحد بعيدًا عن هذه القيم. نظرًا لأن التنبؤات مقيدة بالفاصل [0،1]، فإن الأخطاء الناجمة عن التباين تميل إلى أن تكون أحادية الجانب بالقرب من الصفر وواحد. على سبيل المثال، إذا كان يجب على النموذج التنبؤ بـ p = 0 لحالة ما، فإن الطريقة الوحيدة التي يمكن لـ bagging تحقيقها هي إذا توقعت جميع الأشجار المعبأة صفرًا. إذا أضفنا ضوضاء إلى الأشجار التي يقوم bagging بحساب متوسطها، فإن هذه الضوضاء ستؤدي إلى قيام بعض الأشجار بالتنبؤ بقيم أكبر من 0 لهذه الحالة، وبالتالي تحريك متوسط تنبؤ المجموعة الكيسية بعيدًا عن 0. ونحن نلاحظ هذا التأثير بقوة مع الغابات العشوائية لأن أشجار المستوى الأساسي المدربة مع الغابات العشوائية لها تباين كبير نسبيًا بسبب تجزئة الميزات." نتيجة لذلك، يظهر منحنى المعايرة شكلًا سيجموديًا مميزًا، مما يشير إلى أن المصنف يمكنه الوثوق "بحدسه" أكثر وإعادة احتمالات أقرب إلى 0 أو 1 بشكل نموذجي.

.. currentmodule:: sklearn.svm

:class:`LinearSVC` (SVC) يظهر منحنى أكثر سيجموديًا من الغابة العشوائية، وهو أمر نموذجي لطرق الهامش الأقصى (قارن نيكولاسكو-ميزيل وكاروانا [3]\_)، والتي تركز على العينات التي يصعب تصنيفها والتي تقع بالقرب من حدود القرار (ناقلات الدعم).

معايرة مصنف
------------------------

.. currentmodule:: sklearn.calibration

تتكون معايرة المصنف من تركيب جهاز رجعي (يُسمى *معاير*) يقوم بتعيين مخرج المصنف (كما هو محدد بواسطة :term:`decision\_function` أو :term:`predict\_proba`) إلى احتمال معاير في [0، 1]. إذا تم الإشارة إلى مخرج المصنف لعينة معينة بواسطة :math:`f_i`، فإن المعاير يحاول التنبؤ باحتمال وقوع الحدث الشرطي :math:`P(y_i = 1 | f_i)`.

من الناحية المثالية، يتم تركيب المعاير على مجموعة بيانات مستقلة عن بيانات التدريب المستخدمة لتركيب المصنف في المقام الأول. هذا لأنه سيكون أداء المصنف على بيانات التدريب أفضل مما هو عليه بالنسبة للبيانات الجديدة. إن استخدام مخرج المصنف من بيانات التدريب لتركيب المعاير سيؤدي بالتالي إلى معاير متحيز يقوم بالتعيين إلى احتمالات أقرب إلى 0 و 1 مما ينبغي.

الاستخدام
   

[1]\_ INSERT REFERENCE

[2]\_ Wilks, D. S. (1995). *Statistical methods in the atmospheric sciences* (Vol. 100). Academic Press.

[3]\_ Niculescu-Mizil, A., & Caruana, R. (2005). Predicting good probabilities with supervised learning. In *Proceedings of the 22nd international conference on Machine learning* (pp. 625-632).

[8]\_ Foster, D. P., & George, E. I. (1994). The risk inflation criterion for multiple regression. *The Annals of Statistics*, 22(3), 1056-1082.

[INSERT REFERENCE]\_ INSERT REFERENCE

(ملاحظة: الرجاء استبدال [INSERT REFERENCE]\_ و [INSERT REFERENCE]\_ بالمراجع الصحيحة.)

إن فئة :class:`CalibratedClassifierCV` تُستخدم لمعايرة مصنف ما.

تستخدم فئة :class:`CalibratedClassifierCV` نهج التحقق المتقاطع لضمان استخدام بيانات غير متحيزة دائمًا لتناسب المعاير. يتم تقسيم البيانات إلى k من الأزواج `(train_set, test_set)` (كما هو محدد بواسطة `cv`). عند تعيين `ensemble=True` (الافتراضي)، يتم تكرار الإجراء التالي بشكل مستقل لكل تقسيم للتحقق المتقاطع:

1. يتم تدريب استنساخ `base_estimator` على مجموعة التدريب الفرعية
2. يقوم `base_estimator` المدرب بعمل تنبؤات على مجموعة الاختبار الفرعية
3. يتم استخدام التنبؤات لتناسب معاير (إما منحدر سيجمويدي أو متناظر) (عندما تكون البيانات متعددة الفئات، يتم تركيب معاير لكل فئة)

ينتج عن هذا مجموعة من k من الأزواج `(classifier, calibrator)` حيث يقوم كل معاير بتعيين إخراج المصنف المناظر له في [0، 1]. يتم عرض كل زوج في السمة `calibrated_classifiers_`، حيث يكون كل إدخال مصنفًا معايرًا مع طريقة :term:`predict_proba` التي تُخرج احتمالات معايرة. يتوافق إخراج :term:`predict_proba` لمثيل :class:`CalibratedClassifierCV` الرئيسي مع متوسط الاحتمالات المتوقعة لمقدّرات `k` في قائمة `calibrated_classifiers_`. يكون إخراج :term:`predict` هو الفصل الذي له أعلى احتمال.

من المهم اختيار `cv` بعناية عند استخدام `ensemble=True`. يجب أن تكون جميع الفئات موجودة في كل من مجموعات التدريب والاختبار الفرعية لكل تقسيم. عندما تكون فئة ما غائبة في مجموعة التدريب الفرعية، سيعود احتمال التنبؤ لتلك الفئة إلى 0 لزوج `(classifier, calibrator)` لهذا التقسيم. هذا يميل :term:`predict_proba` لأنه يأخذ متوسطًا عبر جميع الأزواج. عندما تكون فئة ما غائبة في مجموعة الاختبار الفرعية، يتم تركيب المعاير لتلك الفئة (ضمن زوج `(classifier, calibrator)` لهذا التقسيم) على بيانات بدون فئة إيجابية. ينتج عن هذا معايرة غير فعالة.

عند تعيين `ensemble=False`، يتم استخدام التحقق المتقاطع للحصول على تنبؤات "غير متحيزة" لجميع البيانات، عبر :func:`~sklearn.model_selection.cross_val_predict`. ثم يتم استخدام هذه التنبؤات غير المتحيزة لتدريب المعاير. تتكون السمة `calibrated_classifiers_` من زوج `(classifier, calibrator)` واحد فقط حيث يكون المصنف هو `base_estimator` المدرب على جميع البيانات. في هذه الحالة، يكون إخراج :term:`predict_proba` لـ :class:`CalibratedClassifierCV` هو الاحتمالات المتوقعة التي تم الحصول عليها من زوج `(classifier, calibrator)` الوحيد.

الميزة الرئيسية لـ `ensemble=True` هي الاستفادة من تأثير التجميع التقليدي (على غرار :ref:`bagging`). يجب أن تكون المجموعة الناتجة معايرة جيدًا وأكثر دقة قليلاً من `ensemble=False`. الميزة الرئيسية لاستخدام `ensemble=False` هي الحسابية: فهي تقلل إجمالي وقت التناسب من خلال تدريب زوج مصنف وقائم واحد فقط، وتقلل من حجم النموذج النهائي وتزيد من سرعة التنبؤ.

بدلاً من ذلك، يمكن معايرة مصنف مناسب مسبقًا عن طريق تعيين `cv="prefit"`. في هذه الحالة، لا يتم تقسيم البيانات ويتم استخدام جميعها لتناسب المعادلة. يعود الأمر إلى المستخدم للتأكد من أن البيانات المستخدمة لتناسب المصنف منفصلة عن البيانات المستخدمة لتناسب المعادلة.

تدعم فئة :class:`CalibratedClassifierCV` استخدام تقنيتين للتراجع عن المعايرة عبر معلمات `method`: `"sigmoid"` و `"isotonic"`.

.. _sigmoid_regressor:

سيجمويدي
^^^^^^^

يعتمد المنحدر السيجمويدي، `method="sigmoid"` على نموذج لوجستي بلات [4]_:

.. math::
       p(y_i = 1 | f_i) = \frac{1}{1 + \exp(A f_i + B)} \,,

حيث :math:`y_i` هو التسمية الحقيقية للعينة :math:`i` و :math:`f_i`
هو إخراج المصنف غير المعاير للعينة :math:`i`. :math:`A`
و :math:`B` هما رقمان حقيقيان يحددان عند تركيب المعادلة عبر
الاحتمال الأعظم.

يفترض الأسلوب السيجمويدي أن :ref:`منحنى المعايرة <calibration_curve>`
يمكن تصحيحه عن طريق تطبيق دالة سيجمويدية على التنبؤات الأولية. تم
تبرير هذا الافتراض بشكل تجريبي في حالة :ref:`svm` مع
دوال النواة الشائعة على مجموعات البيانات القياسية المختلفة في القسم 2.1 من بلات
1999 [4]_ ولكنه لا ينطبق بالضرورة بشكل عام. بالإضافة إلى ذلك، يعمل
نموذج اللوجستية بشكل أفضل إذا كان خطأ المعايرة متماثلًا، مما يعني أن
مخرجات المصنف لكل فئة ثنائية موزعة بشكل طبيعي مع
نفس التباين [7]_. يمكن أن يكون هذا مشكلة بالنسبة لمشاكل التصنيف غير المتوازنة للغاية، حيث لا يكون للمخرجات نفس التباين.

بشكل عام، هذا الأسلوب هو الأكثر فعالية لأحجام العينات الصغيرة أو عندما
يكون النموذج غير المعاير غير واثق وله أخطاء معايرة مماثلة لكل من
المخرجات العالية والمنخفضة.

متناظر
^^^^^^^^

يقوم `method="isotonic"` بتركيب معادلة متناظر غير بارامتري، والذي يُخرج
دالة متدرجة غير متناقصة، راجع :mod:`sklearn.isotonic`. إنه يخفض إلى أدنى حد:

.. math::
       \sum_{i=1}^{n} (y_i - \hat{f}_i)^2

مع مراعاة :math:`\hat{f}_i \geq \hat{f}_j` كلما
:math:`f_i \geq f_j`. :math:`y_i` هي التسمية الحقيقية
للعينة :math:`i` و :math:`\hat{f}_i` هي إخراج
المصنف المعاير للعينة :math:`i` (أي الاحتمال المعاير).
هذه الطريقة أكثر عمومية مقارنة بـ 'سيجمويدي' لأن القيد الوحيد
هو أن دالة التعيين متزايدة أحادية التزايد. وبالتالي فهي أكثر قوة لأنها
يمكن أن تصحح أي تشوه أحادي التزايد في النموذج غير المعاير.
ومع ذلك، فهي أكثر عرضة للازدحام، خاصة على مجموعات البيانات الصغيرة [6]_.

بشكل عام، سيؤدي 'متناظر' أداءً جيدًا أو أفضل من 'سيجمويدي' عندما
تكون هناك بيانات كافية (أكبر من ~ 1000 عينة) لتجنب الازدحام [3]_.

.. note:: التأثير على مقاييس الترتيب مثل AUC

    

المراجع
---------

.. [1] `Brier Score <https://en.wikipedia.org/wiki/Brier_score>`_
.. [2] `Proper Scoring Rules <https://www.stat.washington.edu/raftery/Research/PDF/Gneiting2007jasa.pdf>`_
.. [3] `Comparing Bayesian networks, support vector machines, and logistic regression for breast cancer diagnosis <https://link.springer.com/article/10.1007/s10994-007-5023-x>`_
.. [4] `Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods <https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/techreport.pdf>`_
.. [5] `Improving the Accuracy of Probability Estimates for Binary Classifiers with the Ensemble of Bayesian Networks <https://www.aaai.org/Papers/AAAI/2005/AAAI-2005-035.pdf>`_
.. [6] `Transforming Classifier Scores into Accurate Multiclass Probability Estimates <https://www.cs.uwaterloo.ca/~aawan/papers/ Zadrozny+Elkan-kdd02.pdf>`_
.. [7] `Obtaining Calibrated Probabilities from Boosting <https://www.cs.duke.edu/~cynthia/pubs/boost.pdf>`_

.. _svm: ../modules/generated/sklearn.svm.SVC.html
.. _calibration_curve: ../modules
بشكل عام، من المتوقع ألا تؤثر المعايرة على مقاييس الترتيب مثل ROC-AUC. ومع ذلك، قد تختلف هذه المقاييس بعد المعايرة عند استخدام `method="isotonic"` نظرًا لأن الانحدار الإسوتوني يدخل علاقات التساوي في الاحتمالات المتوقعة. يمكن اعتبار هذا ضمن عدم اليقين لتوقعات النموذج. في حال كنت ترغب بشدة في الحفاظ على الترتيب وبالتالي درجات AUC، استخدم `method="sigmoid"` الذي يعد تحويلًا أحاديًا صارمًا وبالتالي يحافظ على الترتيب.

دعم متعدد الفئات
^^^^^^^^^^^^^^^^^^

يدعم كل من المنحدرات الإسوتونية والسيجمويدية البيانات أحادية البعد فقط (على سبيل المثال، مخرجات التصنيف الثنائي) ولكن يتم توسيعها للتصنيف متعدد الفئات إذا كان `base_estimator` يدعم التنبؤات متعددة الفئات. للتنبؤات متعددة الفئات، يقوم :class:`CalibratedClassifierCV` بمعايرة كل فئة على حدة بطريقة :ref:`ovr_classification` [5]_. عند توقع الاحتمالات، يتم التنبؤ باحتمالات الفئة المعايرة لكل فئة بشكل منفصل. نظرًا لأن تلك الاحتمالات لا تؤدي بالضرورة إلى مجموع واحد، يتم إجراء ما بعد المعالجة لتطبيعها.

.. rubric:: أمثلة

* :ref:`sphx_glr_auto_examples_calibration_plot_calibration_curve.py`
* :ref:`sphx_glr_auto_examples_calibration_plot_calibration_multiclass.py`
* :ref:`sphx_glr_auto_examples_calibration_plot_calibration.py`
* :ref:`sphx_glr_auto_examples_calibration_plot_compare_calibration.py`

.. rubric:: المراجع

.. [1] آلان إتش مورفي (1973).
       :doi:`"تقسيم متجه جديد للدتيجة الاحتمالية"
       <10.1175/1520-0450(1973)012%3C0595:ANVPOT%3E2.0.CO;2>`
       مجلة الأرصاد الجوية التطبيقية والمناخ

.. [2] `على مجموعة احتمالات التوقع لفترات هطول متتالية.
       <https://journals.ametsoc.org/waf/article/5/4/640/40179>`_
       التنبؤ بالطقس، 5، 640-650.، ويلكس، د. س.، 1990أ

.. [3] `التنبؤ باحتمالات جيدة مع التعلم الخاضع للإشراف
       <https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf>`_،
       أ. نيكولاسكو-ميزيل و ر. كاروانا، ICML 2005


.. [4] `المخرجات الاحتمالية لآلات دعم النواقل والمقارنات
       لطرق الإمكانية المنتظمة.
       <https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf>`_
       ج. بلات، (1999)

.. [5] `تحويل درجات التصنيف إلى تقديرات احتمالية متعددة الفئات دقيقة.
       <https://dl.acm.org/doi/pdf/10.1145/775047.775151>`_
       ب. زادروزني و س. إلكان، (KDD 2002)

.. [6] `التنبؤ باحتمالات دقيقة مع خسارة الترتيب.
       <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4180410/>`_
       مينون أيه كيه، جيانغ إكس جي، فامبو إس، إلكان سي، أوهونو-ماتشادو إل.
       إجراءات المؤتمر الدولي للتعلم الآلي. 2012؛2012:703-710

.. [7] `ما بعد السيجمويدات: كيفية الحصول على احتمالات معايرة جيدًا من
       المصنفات الثنائية مع معايرة بيتا
       <https://projecteuclid.org/euclid.ejs/1513306867>`_
       كول، م.، سيلفا فيلهو، ت. م.، و فلاتش، ب. (2017).

.. [8] ماريو ف. ويثريتش، مايكل ميرز (2023).
       :doi:`"الأسس الإحصائية للتعلم الاكتواري وتطبيقاته"
       <10.1007/978-3-031-12409-9>`
       سبرينغر اكتواريال
