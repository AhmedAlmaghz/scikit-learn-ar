تعديل عتبة القرار للتنبؤ بالصنف
==================================================

من الأفضل تقسيم التصنيف إلى جزأين:

* المشكلة الإحصائية لتعلم نموذج للتنبؤ، في الوضع المثالي، احتمالات الفئة.
* مشكلة القرار لاتخاذ إجراء ملموس بناءً على تنبؤات الاحتمالية هذه.

دعونا نأخذ مثالًا بسيطًا يتعلق بتوقع حالة الطقس: تتعلق النقطة الأولى بالإجابة على "ما هي فرصة هطول الأمطار غدًا؟" في حين تتعلق النقطة الثانية بالإجابة على "هل يجب أن أحمل معي مظلة غدًا؟".

عندما يتعلق الأمر بواجهة برمجة تطبيقات scikit-learn، يتم معالجة النقطة الأولى من خلال تقديم الدرجات
باستخدام مصطلح التنبؤ بالاحتمالية أو دالة القرار. تعيد الدالة الأولى تقديرات الاحتمالية الشرطية لكل صنف، بينما تعيد الدالة الأخيرة درجة قرار لكل صنف.

يتم الحصول على القرار المقابل للعلامات باستخدام مصطلح التنبؤ. في التصنيف الثنائي، يتم بعد ذلك تحديد قاعدة قرار أو إجراء عن طريق تحديد عتبة الدرجات، مما يؤدي إلى التنبؤ بعلامة صنف واحدة لكل عينة. بالنسبة للتصنيف الثنائي في scikit-learn، يتم الحصول على تنبؤات علامة الفئة عن طريق قواعد القطع المرمزة بشكل ثابت: يتم التنبؤ بالصنف الإيجابي عندما تكون الاحتمالية الشرطية أكبر من 0.5 (تم الحصول عليها باستخدام مصطلح التنبؤ بالاحتمالية) أو إذا كانت درجة القرار أكبر من 0 (تم الحصول عليها باستخدام مصطلح دالة القرار).

هنا، نقدم مثالاً يوضح العلاقة بين تقديرات الاحتمالية الشرطية وعلامات الفئة::

    >>> from sklearn.datasets import make_classification
    >>> from sklearn.tree import DecisionTreeClassifier
    >>> X, y = make_classification(random_state=0)
    >>> classifier = DecisionTreeClassifier(max_depth=2, random_state=0).fit(X, y)
    >>> classifier.predict_proba(X[:4])
    array([[0.94     , 0.06     ],
           [0.94     , 0.06     ],
           [0.0416..., 0.9583...],
           [0.0416..., 0.9583...]])
    >>> classifier.predict(X[:4])
    array([0, 0, 1, 1])

في حين أن قواعد القطع المرمزة بشكل ثابت هذه قد تبدو معقولة في البداية كسلوك افتراضي، إلا أنها بالتأكيد ليست مثالية لمعظم حالات الاستخدام. دعونا نوضح ذلك بمثال.

لنأخذ في الاعتبار سيناريو يتم فيه نشر نموذج تنبئي لمساعدة الأطباء في اكتشاف الأورام. في هذا الإعداد، من المحتمل أن يكون الأطباء مهتمين بتحديد جميع المرضى المصابين بالسرطان وعدم تفويت أي شخص مصاب بالسرطان حتى يتمكنوا من تقديم العلاج المناسب لهم. وبعبارة أخرى، يولي الأطباء الأولوية لتحقيق معدل استرجاع مرتفع. يأتي هذا التركيز على الاسترجاع، بالطبع، مع المقايضة باحتمالية زيادة التنبؤات الإيجابية الخاطئة، مما يقلل من دقة النموذج. هذا هو الخطر الذي يكون الأطباء على استعداد لقبوله لأن تكلفة تفويت السرطان أعلى بكثير من تكلفة إجراء المزيد من الاختبارات التشخيصية. وبالتالي، عندما يتعلق الأمر بالبت فيما إذا كان يجب تصنيف مريض على أنه مصاب بالسرطان أم لا، فقد يكون من المفيد تصنيفه على أنه إيجابي للسرطان عندما يكون احتمال الإصابة بالسرطان أقل بكثير من 0.5.

ضبط عتبة القرار بعد التدريب
==================================

أحد الحلول لمعالجة المشكلة المذكورة في المقدمة هو ضبط عتبة القرار للمتنبئ بعد تدريب النموذج.
يتم ضبط هذه العتبة باستخدام التحقق من الصليب الداخلي. يتم اختيار العتبة المثلى لتعظيم مقياس معين.

توضح الصورة التالية ضبط عتبة القرار لمصنف تدرج تعزيزي. في حين أن المصنف الأصلي والمضبوط يوفران نفس
مخرجات التنبؤ بالاحتمالية وبالتالي منحنيات خصائص التشغيل المستلم (ROC) والدقة والاستدعاء، تختلف تنبؤات علامة الفئة بسبب عتبة القرار المضبوطة. يتنبأ المصنف الأصلي بفئة الاهتمام لاحتمالية أكبر من 0.5 في حين يتنبأ المصنف المضبوط بفئة الاهتمام لاحتمالية منخفضة جدًا (حوالي 0.02). تقوم عتبة القرار هذه بتحسين مقياس فائدة تحدده الشركة (في هذه الحالة شركة تأمين).

.. figure:: ../auto_examples/model_selection/images/sphx_glr_plot_cost_sensitive_learning_002.png
   :target: ../auto_examples/model_selection/plot_cost_sensitive_learning.html
   :align: center

خيارات لضبط عتبة القرار
--------------------------------------

يمكن ضبط عتبة القرار من خلال استراتيجيات مختلفة يتحكم فيها معلمة التقييم.

تتمثل إحدى طرق ضبط العتبة في تعظيم مقياس محدد مسبقًا في scikit-learn. يمكن العثور على هذه المقاييس عن طريق استدعاء دالة أسماء المقيّمين.
يتم استخدام دقة متوازنة بشكل افتراضي ولكن يجب ملاحظة أنه يجب اختيار مقياس ذي معنى لحالة الاستخدام الخاصة بالمستخدم.

.. note::

    من المهم ملاحظة أن هذه المقاييس تأتي مع معلمات افتراضية، وخاصة تسمية صنف الاهتمام (أي التسمية الإيجابية). لذلك، إذا لم تكن هذه التسمية صحيحة لتطبيقك، فيجب عليك تحديد مقيّم وتمرير التسمية الصحيحة
    (ومعلمات إضافية) باستخدام الدالة make_scorer. راجع قسم التقييم للحصول على معلومات حول كيفية تحديد دالة التقييم الخاصة بك. على سبيل المثال، نوضح كيفية تمرير المعلومات إلى المقيّم بأن التسمية ذات الاهتمام هي "0" عند تعظيم نتيجة F1::

        >>> from sklearn.linear_model import LogisticRegression
        >>> from sklearn.model_selection import TunedThresholdClassifierCV
        >>> from sklearn.metrics import make_scorer, f1_score
        >>> X, y = make_classification(
        ...   n_samples=1_000, weights=[0.1, 0.9], random_state=0)
        >>> pos_label = 0
        >>> scorer = make_scorer(f1_score, pos_label=pos_label)
        >>> base_model = LogisticRegression()
        >>> model = TunedThresholdClassifierCV(base_model, scoring=scorer)
        >>> scorer(model.fit(X, y), X, y)
        0.88...
        >>> # compare it with the internal score found by cross-validation
        >>> model.best_score_
        0.86...

ملاحظات مهمة حول التحقق من الصليب الداخلي
-------------------------------------------------------

يستخدم TunedThresholdClassifierCV بشكل افتراضي التحقق من صحة الصليب المتوازن 5 للضبط
عتبة القرار. تسمح معلمة السيرة الذاتية بالتحكم في استراتيجية التحقق من الصحة. من الممكن تجاوز التحقق من الصحة عن طريق
تعيين "cv"="prefit" وتوفير مصنف مناسب. في هذه الحالة، يتم ضبط عتبة القرار على البيانات المقدمة إلى
طريقة التجهيز.

ومع ذلك، يجب أن تكون حذرًا للغاية عند استخدام هذا الخيار. يجب ألا تستخدم مطلقًا نفس البيانات لتدريب المتنبئ وضبط عتبة القرار بسبب خطر الإفراط في التجهيز. راجع قسم المثال التالي لمزيد من التفاصيل (راجع قسم عدم وجود cv). إذا كانت لديك موارد محدودة، ففكر في استخدام رقم عائم لـ "cv" للحد من التقسيم الداخلي للتدريب والاختبار.

يجب ألا يتم استخدام خيار "cv"="prefit" إلا عندما يكون المتنبئ المقدم مدربًا بالفعل، وتريد فقط العثور على أفضل عتبة قرار باستخدام مجموعة تحقق صحة جديدة.

تعيين عتبة القرار يدويًا
---------------------------------------

ناقشت الأقسام السابقة استراتيجيات للعثور على عتبة قرار مثالية. من الممكن أيضًا تعيين عتبة القرار يدويًا باستخدام الفصل
FixedThresholdClassifier. في حالة عدم الرغبة في إعادة ملاءمة النموذج عند استدعاء طريقة التجهيز، يمكنك تعيين معلمة ما قبل التجهيز إلى True.

أمثلة
--------

- راجع المثال المعنون
  :ref:sphx_glr_auto_examples_model_selection_plot_tuned_decision_threshold.py،
  للحصول على نظرة ثاقبة على ضبط عتبة القرار بعد التدريب.
- راجع المثال المعنون
  :ref:sphx_glr_auto_examples_model_selection_plot_cost_sensitive_learning.py،
  لمعرفة المزيد عن التعلم الحساس للتكلفة وضبط عتبة القرار.