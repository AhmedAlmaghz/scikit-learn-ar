.. _performance-howto:

=========================
كيفية التحسين من أجل السرعة
=========================

ما يلي يعطي بعض الإرشادات العملية لمساعدتك في كتابة كود فعال لمشروع سكايت-ليرن.

.. note::

  في حين أنه من المفيد دائمًا إنشاء ملف تعريف لرمزك حتى تتمكن من **التحقق من افتراضات الأداء**، فمن المستحسن بشدة أيضًا **مراجعة الأدبيات** للتأكد من أن الخوارزمية المطبقة هي الأفضل في فئتها للمهمة قبل الاستثمار في تحسين التنفيذ المكلف.

  مرارًا وتكرارًا، تم استنفاد ساعات من الجهد المستثمر في تحسين تفاصيل التنفيذ المعقدة بسبب الاكتشاف اللاحق لـ **الحيل الخوارزمية** البسيطة، أو باستخدام خوارزمية مختلفة تمامًا تكون أكثر ملاءمة للمشكلة.

  يعطي القسم :ref:`warm-restarts` مثالًا على مثل هذه الحيلة.

بايثون، سي بايثون أو سي/سي++؟
========================

.. currentmodule:: sklearn

بشكل عام، يؤكد مشروع سكايت-ليرن على **قابلية القراءة** لرمز المصدر لتسهيل الأمر على مستخدمي المشروع للغوص في رمز المصدر حتى يتمكنوا من فهم كيفية تصرف الخوارزمية على بياناتهم، ولكن أيضًا من أجل سهولة الصيانة (من قبل المطورين).

عند تنفيذ خوارزمية جديدة، يوصى ببدء **التنفيذ في بايثون باستخدام نومبي وسايباي** مع الحرص على تجنب كود الحلقات باستخدام التعابير النمطية لتلك المكتبات. في الممارسة العملية، هذا يعني محاولة **استبدال أي حلقات متداخلة بمكالمات لطرق مصفوفة نومبي المكافئة**. الهدف هو تجنب إضاعة وحدة المعالجة المركزية في مفسر بايثون بدلاً من معالجة الأرقام لتناسب نموذجك الإحصائي. من الجيد عمومًا مراعاة نصائح الأداء في نومبي وسايباي:
https://scipy.github.io/old-wiki/pages/PerformanceTips

ومع ذلك، في بعض الأحيان، لا يمكن التعبير عن خوارزمية بكفاءة في كود نومبي المتجه البسيط. في هذه الحالة، تكون الاستراتيجية الموصى بها كما يلي:

1. **إنشاء ملف تعريف** للتنفيذ بايثون للعثور على عنق الزجاجة الرئيسي وعزله في **دالة على مستوى الوحدة النمطية مخصصة**. سيتم إعادة تنفيذ هذه الدالة كمكون إضافي مجمع.

2. إذا كان هناك تنفيذ **سي/سي++** جيد الصيانة ومرخص بموجب بي إس دي أو إم آي تي لنفس الخوارزمية التي ليست كبيرة جدًا، فيمكنك كتابة **غلاف سي بايثون** لها وإدراج نسخة من رمز مصدر المكتبة في شجرة مصدر سكايت-ليرن: تُستخدم هذه الاستراتيجية لفئات :class:`svm.LinearSVC`، و:class:`svm.SVC`، و:class:`linear_model.LogisticRegression` (غلافات لـ ليبلينير وليبس في إم).

3. خلاف ذلك، اكتب إصدارًا محسنًا من دالة بايثون الخاصة بك باستخدام **سي بايثون** مباشرةً. تُستخدم هذه الاستراتيجية لفئات :class:`linear_model.ElasticNet` و:class:`linear_model.SGDClassifier`، على سبيل المثال.

4. **نقل إصدار بايثون من الدالة إلى الاختبارات** واستخدمه للتحقق من أن نتائج المكون الإضافي المجمع متسقة مع الإصدار بايثون، والذي يسهل تصحيحه.

5. بمجرد تحسين الكود (ليس عنق الزجاجة البسيط الذي يمكن اكتشافه عن طريق إنشاء ملف تعريف)، تحقق مما إذا كان من الممكن وجود **توازي خشن** يمكن أن يكون قابلاً لـ **تعدد المعالجة** باستخدام فئة ``joblib.Parallel``.

.. _profiling-python-code:

إنشاء ملف تعريف لرمز بايثون
=====================

لإنشاء ملف تعريف لرمز بايثون، نوصي بكتابة نص برمجي يقوم بتحميل بياناتك وإعدادها، ثم استخدام ملف التعريف المدمج في آي بايثون لاستكشاف الجزء ذي الصلة من الكود بشكل تفاعلي.

لنفترض أننا نريد إنشاء ملف تعريف لوحدة نمطية لتحليل المصفوفة غير السالبة في سكايت-ليرن. دعنا نقوم بإعداد جلسة آي بايثون جديدة وتحميل مجموعة بيانات الأرقام كما هو الحال في مثال :ref:`sphx_glr_auto_examples_classification_plot_digits_classification.py`::

  In [1]: from sklearn.decomposition import NMF

  In [2]: from sklearn.datasets import load_digits

  In [3]: X, _ = load_digits(return_X_y=True)

قبل بدء جلسة إنشاء الملف التعريفي والانخراط في دورات التحسين، من المهم قياس وقت التنفيذ الإجمالي للدالة التي نريد تحسينها دون أي نوع من النفقات العامة لملف التعريف وحفظها في مكان ما للرجوع إليها لاحقًا::

  In [4]: %timeit NMF(n_components=16, tol=1e-2).fit(X)
  1 loops, best of 3: 1.7 s per loop

للاطلاع على ملف التعريف العام للأداء باستخدام أمر السحر ``%prun``::

  In [5]: %prun -l nmf.py NMF(n_components=16, tol=1e-2).fit(X)
           14496 function calls in 1.682 CPU seconds

     Ordered by: internal time
     List reduced from 90 to 9 due to restriction <'nmf.py'>

     ncalls  tottime  percall  cumtime  percall filename:lineno(function)
         36    0.609    0.017    1.499    0.042 nmf.py:151(_nls_subproblem)
       1263    0.157    0.000    0.157    0.000 nmf.py:18(_pos)
          1    0.053    0.053    1.681    1.681 nmf.py:352(fit_transform)
        673    0.008    0.000    0.057    0.000 nmf.py:28(norm)
          1    0.006    0.006    0.047    0.047 nmf.py:42(_initialize_nmf)
         36    0.001    0.000    0.010    0.000 nmf.py:36(_sparseness)
         30    0.001    0.000    0.001    0.000 nmf.py:23(_neg)
          1    0.000    0.000    0.000    0.000 nmf.py:337(__init__)
          1    0.000    0.000    1.681    1.681 nmf.py:461(fit)

عمود ``tottime`` هو الأكثر أهمية: فهو يعطي الوقت الإجمالي الذي يتم إنفاقه على تنفيذ كود دالة معينة، متجاهلاً الوقت المستغرق في تنفيذ الدوال الفرعية. يتم إعطاء الوقت الإجمالي الفعلي (كود محلي + مكالمات الدالة الفرعية) بواسطة عمود ``cumtime``.

لاحظ استخدام ``-l nmf.py`` الذي يقيد الإخراج إلى الأسطر التي تحتوي على سلسلة "nmf.py". هذا مفيد لإلقاء نظرة سريعة على البقعة الساخنة لوحدة نمطية بايثون نيمف نفسها، متجاهلاً أي شيء آخر.

فيما يلي بداية إخراج نفس الأمر دون تصفية ``-l nmf.py``::

  In [5] %prun NMF(n_components=16, tol=1e-2).fit(X)
           16159 function calls in 1.840 CPU seconds

     Ordered by: internal time

     ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       2833    0.653    0.000    0.653    0.000 {numpy.core._dotblas.dot}
         46    0.651    0.014    1.636    0.036 nmf.py:151(_nls_subproblem)
       1397    0.171    0.000    0.171    0.000 nmf.py:18(_pos)
       2780    0.167    0.000    0.167    0.000 {method 'sum' of 'numpy.ndarray' objects}
          1    0.064    0.064    1.840    1.840 nmf.py:352(fit_transform)
       1542    0.043    0.000    0.043    0.000 {method 'flatten' of 'numpy.ndarray' objects}
        337    0.019    0.000    0.019    0.000 {method 'all' of 'numpy.ndarray' objects}
       2734    0.011    0.000    0.181    0.000 fromnumeric.py:1185(sum)
          2    0.010    0.005    0.010    0.005 {numpy.linalg.lapack_lite.dgesdd}
        748    0.009    0.000    0.065    0.000 nmf.py:28(norm)
  ...

توضح النتائج أعلاه أن التنفيذ تهيمن عليه إلى حد كبير عمليات ضرب النقاط (تفويضها إلى بلاس). لذلك، من المحتمل ألا يكون هناك مكسب كبير متوقع من إعادة كتابة هذا الكود في سي بايثون أو سي/سي++: في هذه الحالة، من بين 1.7 ثانية من وقت التنفيذ الإجمالي، يتم إنفاق ما يقرب من 0.7 ثانية في الكود المجمع الذي يمكننا اعتباره الأمثل. من خلال إعادة كتابة بقية كود بايثون وافتراض أننا يمكن أن نحقق زيادة بنسبة 1000% في هذا الجزء (وهو أمر غير مرجح نظرًا لضحلة حلقات بايثون)، فلن نكسب أكثر من 2.4 مرة زيادة في السرعة بشكل عام.

لذلك، لا يمكن تحقيق تحسينات كبيرة إلا من خلال **التحسينات الخوارزمية** في هذا المثال (على سبيل المثال، محاولة العثور على عملية تكون مكلفة وغير مفيدة في نفس الوقت لتجنب حسابها بدلاً من محاولة تحسين تنفيذها).

ومع ذلك، لا يزال من المثير للاهتمام التحقق مما يحدث داخل دالة ``_nls_subproblem`` التي تعد البقعة الساخنة إذا كنا نعتبر كود بايثون فقط: فهي تستغرق حوالي 100% من الوقت التراكمي للوحدة النمطية. من أجل فهم أفضل لملف تعريف هذه الدالة المحددة، دعنا نقوم بتثبيت ``line_profiler`` وربطه بـ آي بايثون:

.. prompt:: bash $

  pip install line_profiler

**في آي بايثون 0.13+**، قم أولاً بإنشاء ملف تعريف تكوين:

.. prompt:: bash $

  ipython profile create

بعد ذلك، قم بتسجيل ملحق line_profiler في ``~/.ipython/profile_default/ipython_config.py``::

    c.TerminalIPythonApp.extensions.append('line_profiler')
    c.InteractiveShellApp.extensions.append('line_profiler')

سيقوم هذا بتسجيل أمر السحر ``%lprun`` في تطبيق آي بايثون الطرفي والمكونات الإضافية الأخرى مثل كونسول كواتنوت.

الآن، أعد تشغيل آي بايثون ودعنا نستخدم هذه اللعبة الجديدة::

  In [1]: from sklearn.datasets import load_digits

  In [2]: from sklearn.decomposition import NMF
    ... : from sklearn.decomposition._nmf import _nls_subproblem

  In [3]: X, _ = load_digits(return_X_y=True)

  In [4]: %lprun -f _nls_subproblem NMF(n_components=16, tol=1e-2).fit(X)
  Timer unit: 1e-06 s

  File: sklearn/decomposition/nmf.py
  Function: _nls_subproblem at line 137
  Total time: 1.73153 s

  Line #      Hits         Time  Per Hit   % Time  Line Contents
  ==============================================================
     137                                           def _nls_subproblem(V, W, H_init, tol, max_iter):
     138                                               """Non-negative least square solver
     ...
     170                                               """
     171        48         5863    122.1      0.3      if (H_init < 0).any():
     172                                                   raise ValueError("Negative values in H_init passed to NLS solver.")
     173
     174        48          139      2.9      0.0      H = H_init
     175        48       112141   2336.3      5.8      WtV = np.dot(W.T, V)
     176        48        16144    336.3      0.8      WtW = np.dot(W.T, W)
     177
     178                                               # values justified in the paper
     179        48          144      3.0      0.0      alpha = 1
     180        48          113      2.4      0.0      beta = 0.1
     181       638         1880      2.9      0.1      for n_iter in range(1, max_iter + 1):
     182       638       195133    305.9     10.2          grad = np.dot(WtW, H) - WtV
     183       638       495761    777.1     25.9          proj_gradient = norm(grad[np.logical_or(grad < 0, H > 0)])
     184       638         2449      3.8      0.1          if proj_zpaosition < tol:
     185        48          130      2.7      0.0              break
     186
     187      1474         4474      3.0      0.2          for inner_iter in range(1, 20):
     188      1474        83833     56.9      4.4              Hn = H - alpha * grad
     189                                                       # Hn = np.where(Hn > 0, Hn, 0)
     190      1474       194239    131.8     10.1              Hn = _pos(Hn)
     191      1474        48858     33.1      2.5              d = Hn - H
     192      1474       150407    102.0      7.8              gradd = np.sum(grad * d)
     193      1474       515390    349.7     26.9              dQd = np.sum(np.dot(WtW, d) * d)
     ...

من خلال النظر إلى القيم العليا في عمود "% Time"، يمكنك بسهولة تحديد التعبيرات الأكثر تكلفة التي تستحق عناية إضافية.

تحليل استخدام الذاكرة
بالتأكيد! فيما يلي ترجمة للنص المحدد من ReStructuredText إلى اللغة العربية:

يمكنك تحليل استخدام الذاكرة لأي كود Python بالتفصيل بمساعدة "memory_profiler". أولاً، قم بتثبيت أحدث إصدار:

.. prompt:: bash $

pip install -U memory_profiler

بعد ذلك، قم بإعداد التعويذات بطريقة مشابهة لـ "line_profiler".

**في IPython 0.11 أو أحدث**، قم أولاً بإنشاء ملف تعريف تكوين:

.. prompt:: bash $

ipython profile create

ثم قم بتسجيل الامتداد في "~/.ipython/profile_default/ipython_config.py" إلى جانب محلل الخط::

c.TerminalIPythonApp.extensions.append('memory_profiler')
c.InteractiveShellApp.extensions.append('memory_profiler')

سيقوم هذا بتسجيل أوامر التعويذات "%memit" و"%mprun" في تطبيق IPython terminal وواجهات المستخدم الرسومية الأخرى مثل qtconsole وnotebook.

مفيد لفحص استخدام الذاكرة، سطرًا بسطر، لوظائف رئيسية في برنامجك. وهو مشابه جدًا لـ "%lprun"، الذي تمت مناقشته في القسم السابق. على سبيل المثال، من دليل "أمثلة" في "memory_profiler"::

In [1] from example import my_func

In [2] %mprun -f my_func my_func()
Filename: example.py

Line # Mem usage Increment Line Contents
===============================================
3
4      5.97 MB    0.00 MB   def my_func():
5     13.61 MB    7.64 MB       a = [1] * (10 ** 6)
6    166.20 MB  152.59 MB       b = [2] * (2 * 10 ** 7)
7     13.61 MB -152.59 MB       del b
8     13.61 MB    0.00 MB       return a

تعويذة مفيدة أخرى يحددها "memory_profiler" هي "%memit"، والتي تشبه "%timeit". يمكن استخدامه كما يلي::

In [1]: import numpy as np

In [2]: %memit np.zeros(1e7)
maximum of 3: 76.402344 MB per loop

لمزيد من التفاصيل، راجع وثائق التعويذات باستخدام "%memit؟" و"%mprun؟".

استخدام Cython
==============

إذا كشف ملف تعريف الكود Python أن Overhead لمفسر Python أكبر بمقدار درجة واحدة أو أكثر من تكلفة الحساب العددي الفعلي (على سبيل المثال، حلقات "for" عبر مكونات المتجه، والتقييم المُدَجَّل للتعبير الشرطي، والحسابيات القياسية...)، فمن المحتمل أن يكون من المناسب استخراج الجزء الساخن من الكود كوظيفة مستقلة في ملف ".pyx"، وإضافة إعلانات النوع الثابت، ثم استخدام Cython لإنشاء برنامج C مناسب لتجميعها كنمودج امتداد Python.

تحتوي وثائق Cython على دليل تعليمي ودليل مرجعي لتطوير مثل هذا النموذج.
لمزيد من المعلومات حول التطوير باستخدام Cython لـ scikit-learn، راجع: ref: cython.

.. _profiling-compiled-extension:

إنشاء ملفات تعريف الامتدادات المجمعة
=================================

عند العمل مع الامتدادات المجمعة (المكتوبة في C/C++ مع غلاف أو مباشرة كتوسيع Cython)، يكون ملف تعريف Python الافتراضي عديم الفائدة: نحتاج إلى أداة مخصصة للتعرف على ما يحدث داخل الامتداد المجمع نفسه.

استخدام yep وgperftools
------------------------

من السهل إنشاء ملفات تعريف دون خيارات تجميع خاصة باستخدام yep:

- https://pypi.org/project/yep/
- https://fa.bianp.net/blog/2011/a-profiler-for-python-extensions

استخدام debugger، gdb
---------------------

* من المفيد استخدام "gdb" للتصحيح. للقيام بذلك، يجب استخدام مترجم Python الذي تم بناؤه مع دعم التصحيح (رموز التصحيح والتحسين المناسب). لإنشاء بيئة conda جديدة (قد تحتاج إلى إلغاء تنشيطها وإعادة تنشيطها بعد البناء/التثبيت) مع مترجم CPython الذي تم بناؤه من المصدر:

.. code-block:: bash

git clone https://github.com/python/cpython.git
conda create -n debug-scikit-dev
conda activate debug-scikit-dev
cd cpython
mkdir debug
cd debug
../configure --prefix=$CONDA_PREFIX --with-pydebug
make EXTRA_CFLAGS='-DPy_DEBUG' -j<num_cores>
make install

استخدام gprof
-----------

من أجل إنشاء ملفات تعريف الامتدادات Python المجمعة، يمكن استخدام "gprof" بعد إعادة تجميع المشروع باستخدام "gcc -pg" واستخدام متغير "python-dbg" من المفسر على Debian / Ubuntu: ومع ذلك، يتطلب هذا النهج أيضًا إعادة تجميع "numpy" و"scipy" مع "-pg" وهو أمر معقد للغاية.

لحسن الحظ، هناك أداتان بديلتان لإنشاء ملفات التعريف لا تتطلبان إعادة تجميع كل شيء.

استخدام valgrind / callgrind / kcachegrind
----------------------------------------

kcachegrind
~~~~~~~~~~~

يمكن استخدام "yep" لإنشاء تقرير ملف التعريف.
يوفر "kcachegrind" بيئة رسومية لعرض هذا التقرير:

.. prompt:: bash $

# تشغيل yep لإنشاء ملف تعريف بعض النصوص البرمجية Python
python -m yep -c my_file.py

.. prompt:: bash $

# افتح my_file.py.callgrin مع kcachegrind
kcachegrind my_file.py.prof

.. note::

يمكن تشغيل "yep" باستخدام الحجة "--lines" أو "-l" لتجميع تقرير ملف التعريف "سطرًا بسطر".

تعددية المعالجة باستخدام "joblib.Parallel"
=========================================

راجع وثائق joblib: https://joblib.readthedocs.io

.. _warm-restarts:

خدعة خوارزمية بسيطة: إعادة التشغيل الدافئ
====================================

راجع مدخل مسرد المصطلحات لـ: term: warm_start