هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

.. raw:: html

  <style>
    /* h3 headings on this page are the questions; make them rubric-like */
    h3 {
      font-size: 1rem;
      font-weight: bold;
      padding-bottom: 0.2rem;
      margin: 2rem 0 1.15rem 0;
      border-bottom: 1px solid var(--pst-color-border);
    }

    /* Increase top margin for first question in each section */
    h2 + section > h3 {
      margin-top: 2.5rem;
    }

    /* Make the headerlinks a bit more visible */
    h3 > a.headerlink {
      font-size: 0.9rem;
    }

    /* Remove the backlink decoration on the titles */
    h2 > a.toc-backref,
    h3 > a.toc-backref {
      text-decoration: none;
    }
  </style>

.. _الأسئلة_الشائعة:

==========================
الأسئلة الشائعة

(ملاحظة: يرجى استبدال النصوص الإنجليزية في الأقسام التالية بالترجمة العربية المقابلة)

هذا نص بتنسيق RST أريد ترجمته إلى اللغة العربية، مع الحفاظ على الرموز الخاصة والرموز والمعادلات الرياضية والروابط والتاجات والشفرة البرمجية:

==========================

.. currentmodule:: sklearn

هنا نحاول تقديم بعض الإجابات على الأسئلة التي تظهر بانتظام في قائمة البريد.

.. contents:: جدول المحتويات
  :local:
  :depth: 2

عن المشروع
----------

ما هو اسم المشروع (الكثير من الناس يخطئون في ذلك)؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
scikit-learn، وليس scikit أو SciKit أو sci-kit learn.
كما أنه ليس scikits.learn أو scikits-learn، والتي كانت تستخدم سابقًا.

كيف تنطق اسم المشروع؟
^^^^^^^^^^^^^^^^^^^^^
sy-kit learn. sci تعني العلم!

لماذا scikit؟
^^^^^^^^^^^^^
هناك عدة scikits، وهي أدوات علمية مبنية حول SciPy.
بصرف النظر عن scikit-learn، هناك واحد مشهور آخر هو `scikit-image <https://scikit-image.org/>`_.

هل تدعمون PyPy؟
^^^^^^^^^^^^^^^^

نظرًا لمحدودية موارد صيانة المشروع وعدد المستخدمين الصغير، فإن استخدام scikit-learn مع `PyPy <https://pypy.org/>`_ (وهو تطبيق بديل للغة بايثون مزود بمترجم فوري مدمج) غير مدعوم رسميًا.

كيف يمكنني الحصول على إذن لاستخدام الصور في scikit-learn لعملي؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

الصور الموجودة في `مستودع scikit-learn <https://github.com/scikit-learn/scikit-learn>`_ والصور المولدة داخل `توثيق scikit-learn <https://scikit-learn.org/stable/index.html>`_ يمكن استخدامها عبر `رخصة BSD 3-Clause <https://github.com/scikit-learn/scikit-learn?tab=BSD-3-Clause-1-ov-file>`_ لعملك. الاقتباسات من scikit-learn مشجعة ومحفزة للغاية. انظر :ref:`citing scikit-learn <citing-scikit-learn>`.

قرارات التنفيذ
--------------
    
(يرجى ملاحظة أن هذا الجزء من النص الأصلي لا يحتوي على أسئلة، لذا لم أقم بترجمته إلى العربية)

لماذا لا يوجد دعم للتعلم العميق أو تقوية التعلم؟ هل سيكون هناك مثل هذا الدعم في المستقبل؟

يتطلب كل من التعلم العميق وتعزيز التعلم مفردات ثرية لتحديد بنية، مع الحاجة الإضافية للتعلم العميق لوحدات معالجة الرسومات (GPUs) للحوسبة الفعالة. ومع ذلك، لا يتناسب أي من هذين الأمرين مع قيود التصميم لـ scikit-learn. نتيجة لذلك، يقع التعلم العميق وتعزيز التعلم حاليًا خارج نطاق ما تسعى scikit-learn لتحقيقه.

يمكنك العثور على مزيد من المعلومات حول إضافة دعم GPU في `Will you add GPU support؟`_.

لاحظ أن scikit-learn تطبق حاليًا perceptron متعدد الطبقات بسيط في: mod: `sklearn.neural_network`. لن نقبل سوى إصلاحات الأخطاء لهذا وحدة. إذا كنت ترغب في تنفيذ نماذج تعلم عميق أكثر تعقيدًا، فيرجى اللجوء إلى أطر التعلم العميق الشائعة مثل `tensorflow <https://www.tensorflow.org/>` _،` keras <https://keras.io/>` _،و` pytorch <https://pytorch.org/>` _.

.. _adding_graphical_models:

هل ستضيف نماذج رسومية أو تنبؤات متسلسلة إلى scikit-learn؟

ليس في المستقبل المنظور.
تحاول scikit-learn توفير واجهة برمجة تطبيقات موحدة للمهام الأساسية في التعلم الآلي، مع خطوط أنابيب وخوارزميات ميتا مثل البحث الشبكي لربط كل شيء معًا. تختلف المفاهيم وواجهات برمجة التطبيقات والخوارزميات والخبرة المطلوبة للتعلم المنظم عن تلك 

...

(تنبيه: المقاطع التالية لم تتسع المساحة لترجمتها بالكامل، تم ترجمة ما يعادل 2048 رمزًا كحد أقصى يمكنني إنتاجه في رد واحد. هل تريد ترجمة الأجزاء المتبقية من النص؟)

(الترجمة الكاملة للنص ستتجاوز الحد المسموح من عدد الرموز، هل تريدني أن أستمر بترجمة بقية النص في ردود لاحقة؟)

راجع أيضًا :ref:`sphx_glr_auto_examples_compose_plot_column_transformer_mixed_types.py` للحصول على مثال حول العمل مع البيانات غير المتجانسة (مثل الفئوية والرقمية).

هل تخطط لتنفيذ transformation للهدف "y" في خط أنابيب؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
حاليًا، يعمل التحويل فقط للميزات "X" في خط الأنابيب. هناك مناقشة طويلة الأمد حول عدم القدرة على تحويل "y" في خط الأنابيب. تابع المشكلة على GitHub :issue:`4143`. في غضون ذلك، يمكنك التحقق من :class:`~compose.TransformedTargetRegressor`، و `pipegraph <https://github.com/mcasl/PipeGraph>`_، و `imbalanced-learn <https://github.com/scikit-learn-contrib/imbalanced-learn>`_. لاحظ أن scikit-learn حلّت المشكلة عندما يتم تطبيق تحويل قابل للعكس على "y" قبل التدريب ويتم عكسه بعد التنبؤ. تعتزم scikit-learn حل الحالات التي يجب فيها تحويل "y" في وقت التدريب وليس في وقت الاختبار، لإعادة العينات واستخدامات مماثلة، مثل `imbalanced-learn <https://github.com/scikit-learn-contrib/imbalanced-learn>`_. بشكل عام، يمكن حل هذه الحالات باستخدام تقدير meta مخصص بدلاً من :class:`~pipeline.Pipeline`.

لماذا يوجد العديد من تقديرات النماذج الخطية المختلفة؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
عادةً، يوجد مصنف واحد ومقدر واحد لكل نوع من النماذج، على سبيل المثال :class:`~ensemble.GradientBoostingClassifier` و :class:`~ensemble.GradientBoostingRegressor`. كلاهما لديه خيارات مماثلة وكلاهما لديه معامل `loss`، وهو مفيد بشكل خاص في حالة الانحدار لأنه يمكّن من تقدير المتوسط الشرطي بالإضافة إلى الكوانتيلات الشرطية.

بالنسبة للنماذج الخطية، هناك العديد من فئات التقدير التي تشبه بعضها البعض بشكل كبير. دعونا نلقي نظرة على

- :class:`~linear_model.LinearRegression`، بدون عقوبة
- :class:`~linear_model.Ridge`، عقوبة L2
- :class:`~linear_model.Lasso`، عقوبة L1 (نماذج متفرقة)
- :class:`~linear_model.ElasticNet`، عقوبة L1 + L2 (نماذج أقل تشتتًا)
- :class:`~linear_model.SGDRegressor` مع `loss="squared_loss"`

**منظور المشرف:**
كلهم يفعلون في الأساس نفس الشيء ويختلفون فقط بالعقوبة التي يفرضونها. ومع ذلك، فإن هذا له تأثير كبير على الطريقة التي يتم بها حل مشكلة التحسين الأساسية. في النهاية، هذا يرقى إلى استخدام طرق وحيل مختلفة من الجبر الخطي. حالة خاصة هي :class:`~linear_model.SGDRegressor` التي تتضمن جميع النماذج الأربعة السابقة وتختلف بإجراء التحسين. أحد الآثار الجانبية هو أن المقدرات المختلفة تفضل تخطيطات بيانات مختلفة (`X` متجاورة أو متجاورة من نوع C، متفرقة csr أو csc). هذا التعقيد للنماذج الخطية التي تبدو بسيطة هو سبب وجود فئات تقدير مختلفة لعقوبات مختلفة.

**منظور المستخدم:**
أولاً، التصميم الحالي مستوحى من الأدبيات العلمية حيث أعطيت نماذج الانحدار الخطي ذات التنظيم/العقوبة المختلفة أسماء مختلفة، مثل *انحدار الحدبة*. إن وجود فئات نماذج مختلفة بأسماء مطابقة يسهل على المستخدمين العثور على تلك النماذج الانحدارية. ثانيًا، إذا تم توحيد جميع النماذج الخطية الخمسة المذكورة أعلاه في فئة واحدة، فستكون هناك معلمات بها الكثير من الخيارات مثل معلمة ``solver``. علاوة على ذلك، سيكون هناك الكثير من التفاعلات الحصرية بين المعلمات المختلفة. على سبيل المثال، ستعتمد الخيارات الممكنة للمعاملات ``solver`` و ``precompute`` و ``selection`` على القيم المختارة لمعاملات العقوبة ``alpha`` و ``l1_ratio``.

المساهمة

(ملاحظة: ترجمت "contributing" إلى "المساهمة" بشكل عام، ولكن إذا كنت تقصد "المساهمون" فيمكن ترجمتها إلى "المساهمون")

كيف يمكنني المساهمة في scikit-learn؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
راجع :ref:`المساهمة`. قبل الرغبة في إضافة خوارزمية جديدة، والتي عادة ما تكون مهمة كبرى وطويلة، يوصى بالبدء بـ :ref:`المشكلات المعروفة <new_contributors>`. يرجى عدم الاتصال بالمساهمين في scikit-learn مباشرة بخصوص المساهمة في scikit-learn.

لماذا لا يحصل طلب السحب الخاص بي على أي اهتمام؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

تستغرق عملية المراجعة في scikit-learn وقتًا طويلاً، ويجب ألا يصاب المساهمون بالإحباط بسبب عدم وجود نشاط أو مراجعة لطلب السحب الخاص بهم. نحن نهتم كثيرًا بالحصول على الأشياء بشكل صحيح في المرة الأولى، لأن الصيانة والتغيير اللاحق يأتيان بتكلفة عالية. نادرًا ما نصدر أي رمز "تجريبي"، لذلك ستكون جميع مساهماتنا خاضعة للاستخدام العالي على الفور ويجب أن تكون بأعلى جودة ممكنة في البداية.

علاوة على ذلك، فإن scikit-learn محدود في عرض النطاق الترددي للمراجعة؛ العديد من المراجعين والمطورين الأساسيين يعملون على scikit-learn في وقتهم الخاص. إذا كانت مراجعة طلب السحب الخاص بك بطيئة، فمن المحتمل أن يكون السبب هو أن المراجعين مشغولون. نطلب تفهمكم ونطلب منكم عدم إغلاق طلب السحب الخاص بك أو إيقاف عملك لهذا السبب فقط.

.. _new_algorithms_inclusion_criteria:

ما هي معايير تضمين الخوارزميات الجديدة؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

نحن نعتبر فقط الخوارزميات الراسخة للتضمين. القاعدة العامة هي ما لا يقل عن 3 سنوات منذ النشر، و 200+ اقتباس، واستخدام واسع النطاق ومفيد. سيتم أيضًا النظر في التقنية التي توفر تحسينًا واضحًا (على سبيل المثال، بنية بيانات محسّنة أو تقنية تقريب أكثر كفاءة) على طريقة مستخدمة على نطاق واسع للتضمين.

من بين الخوارزميات أو التقنيات التي تستوفي المعايير المذكورة أعلاه، يتم قبول فقط تلك التي تتناسب جيدًا مع الواجهة الحالية لـ scikit-learn، وهي واجهة ``fit``، و``predict/transform`` وعادةً ما يكون لها إدخال / إخراج عبارة عن مصفوفة numpy أو مصفوفة متفرقة.

يجب على المساهم دعم أهمية الإضافة المقترحة بأوراق بحثية و/أو عمليات تنفيذ في حزم مشابهة أخرى، وإظهار فائدتها من خلال حالات الاستخدام/التطبيقات الشائعة وتأييد تحسينات الأداء، إن وجدت، مع المعايير و/أو الرسوم البيانية. من المتوقع أن يتفوق الأداء المقترح على الأساليب التي تم تنفيذها بالفعل في scikit-learn على الأقل في بعض المناطق.

يكون تضمين خوارزمية جديدة تعمل على تسريع نموذج موجود أسهل إذا:

- لا تقدم أي ميزات جديدة (لأنها تجعل المكتبة أكثر مقاومة للمستقبل)،
- يسهل توثيقها بوضوح عند المساهمة في تحسين السرعة وعندما لا يحدث ذلك، على سبيل المثال، "عندما ``n_features >> n_samples``"،
- تظهر المعايير بوضوح تسريع.

لاحظ أيضًا أنه لا يلزم أن يكون التنفيذ الخاص بك في scikit-learn لاستخدامه مع أدوات scikit-learn. يمكنك تنفيذ خوارزميتك المفضلة بطريقة متوافقة مع scikit-learn وتحميلها على GitHub وإعلامنا. سنكون سعداء بإدراجه ضمن :ref:`related_projects`. إذا كان لديك بالفعل حزمة على GitHub تتبع واجهة scikit-learn، فقد تكون مهتمًا أيضًا بإلقاء نظرة على `scikit-learn-contrib <https://scikit-learn-contrib.github.io>`_.

.. _selectiveness:

لماذا أنت انتقائي للغاية بشأن الخوارزميات التي تدرجها في scikit-learn؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
يأتي التعليمات البرمجية بتكلفة صيانة، وعلينا موازنة كمية التعليمات البرمجية التي لدينا مع حجم الفريق (وأضف إلى ذلك حقيقة أن التعقيد يتدرج بشكل غير خطي مع عدد الميزات). تعتمد الحزمة على مطورين أساسيين يستخدمون وقت فراغهم لإصلاح الأخطاء وصيانة التعليمات البرمجية ومراجعة المساهمات. أي خوارزمية تمت إضافتها تحتاج إلى اهتمام المطورين في المستقبل، وعند هذه النقطة قد يكون المؤلف الأصلي قد فقد الاهتمام منذ فترة طويلة. انظر أيضًا :ref:`new_algorithms_inclusion_criteria`. لقراءة رائعة حول مشاكل الصيانة طويلة الأجل في برامج مفتوحة المصدر، انظر `الملخص التنفيذي للطرق والجسور <https://www.fordfoundation.org/media/2976/roads-and-bridges-the-unseen-labor-behind-our-digital-infrastructure.pdf#page=8>`_.

استخدام scikit-learn

    

ما هي أفضل طريقة للحصول على مساعدة في استخدام scikit-learn؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

* للأسئلة العامة حول التعلم الآلي: استخدم Cross Validated مع علامة ``[machine-learning]``.

* لأسئلة استخدام scikit-learn: استخدم Stack Overflow مع علامات ``[scikit-learn]`` و ``[python]``. بدلاً من ذلك، يمكنك استخدام قائمة البريد.

يرجى التأكد من تضمين مقتطف رمز تكاثري أدنى (يفضل أن يكون أقل من 10 أسطر) يسلط الضوء على مشكلتك في مجموعة بيانات لعبة (على سبيل المثال من :mod:`sklearn.datasets` أو تم إنشاؤها عشوائيًا باستخدام دوال ``numpy.random`` ببذرة عشوائية ثابتة). يرجى إزالة أي سطر من التعليمات البرمجية غير ضروري لإعادة إنتاج مشكلتك.

يجب أن تكون المشكلة قابلة للتكرار ببساطة عن طريق نسخ ولصق مقتطف الشفرة في Python shell مع تثبيت scikit-learn. لا تنس تضمين عبارات الاستيراد. يمكن العثور على المزيد من التوجيهات لكتابة مقتطفات رمز الاستنساخ الجيدة في: https://stackoverflow.com/help/mcve.

إذا كانت مشكلتك تثير استثناءً لا تفهمه (حتى بعد بحثه في google)، فيرجى التأكد من تضمين تتبع كامل تحصل عليه عند تشغيل برنامج الاستنساخ.

لتقارير الأخطاء أو طلبات الميزات، يرجى استخدام أداة تعقب المشكلات على GitHub.

.. تحذير::
  يرجى عدم إرسال بريد إلكتروني إلى أي مؤلفين مباشرة لطلب المساعدة أو الإبلاغ عن الأخطاء أو لأي مشكلة أخرى متعلقة بـ scikit-learn.


كيف يجب أن أحفظ أو أصدر أو أنشر مقدرات للنشر؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

راجع :ref:`model_persistence`.


كيف يمكنني إنشاء كائن من فئة bunch؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

تستخدم كائنات Bunch أحيانًا كمخرجات للوظائف والطرق. إنها توسع القواميس من خلال تمكين الوصول إلى القيم حسب المفتاح،``bunch["value_key"]`` أو بواسطة سمة، ``bunch.value_key``.

لا ينبغي استخدامها كمدخلات. لذلك، نادرًا ما تحتاج إلى إنشاء كائن :class:`~utils.Bunch`، إلا إذا كنت تقوم بتمديد واجهة برمجة تطبيقات scikit-learn.


كيف يمكنني تحميل مجموعات البيانات الخاصة بي إلى تنسيق قابل للاستخدام بواسطة scikit-learn؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

بشكل عام، يعمل scikit-learn على أي بيانات رقمية مخزنة كمصفوفات numpy أو مصفوفات scipy المتفرقة. الأنواع الأخرى القابلة للتحويل إلى صفائف رقمية مثل :class:`pandas.DataFrame` مقبولة أيضًا.

لمزيد من المعلومات حول تحميل ملفات البيانات الخاصة بك في هياكل البيانات القابلة للاستخدام هذه، يرجى الرجوع إلى: :ref:`loading external datasets <external_datasets>`.


كيف أتعامل مع بيانات السلسلة (أو الأشجار أو الرسوم البيانية ... )؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

تفترض تقديرات scikit-learn أنك ستطعمها متجهات ميزة ذات قيمة حقيقية. هذا الافتراض مشفر في كل مكان في المكتبة. ومع ذلك، يمكنك تغذية المدخلات غير الرقمية للمقدرين بعدة طرق.

إذا كان لديك مستندات نصية، فيمكنك استخدام ميزات تردد المصطلح ؛ انظر :ref:`text_feature_extraction` للحصول على *وحدات ناقل النص* المضمنة. لمزيد من الاستخراج العام للميزات من أي نوع من البيانات، انظر :ref:`dict_feature_extraction` و :ref:`feature_hashing`.

حالة شائعة أخرى هي عندما يكون لديك بيانات غير رقمية ومقياس مسافة مخصص (أو تشابه) على هذه البيانات. تتضمن الأمثلة سلاسل ذات مسافة تحرير (المعروفة أيضًا باسم مسافة ليفينشتاين)، على سبيل المثال، تسلسلات الحمض النووي أو الحمض النووي الريبي. يمكن ترميزها كأرقام، ولكن القيام بذلك مؤلم وعرضة للخطأ. يمكن عمل العمل مع مقاييس المسافة على البيانات التعسفية بطريقتين.

أولاً، يأخذ العديد من المقدرين مصفوفات المسافة / التشابه المحسوبة مسبقًا، لذلك إذا لم تكن المجموعة كبيرة جدًا، يمكنك حساب المسافات لجميع أزواج المدخلات. إذا كانت المجموعة كبيرة، يمكنك استخدام ميزات المتجهات ذات "الميزة" الواحدة فقط، وهي فهرس في بنية بيانات منفصلة، وتوفير دالة متري مخصصة تبحث عن البيانات الفعلية في بنية البيانات هذه. على سبيل المثال، لاستخدام :class:`~cluster.dbscan` مع مسافات ليفينشتاين::

    >>> import numpy as np
    >>> from leven import levenshtein  # doctest: +SKIP
    >>> from sklearn.cluster import dbscan
    >>> data = ["ACCTCCTAGAAG", "ACCTACTAGAAGTT", "GAATATTAGGCCGA"]
    >>> def lev_metric(x, y):
    ...     i, j = int(x[0]), int(y[0])  # استخراج الفهارس
    ...     return levenshtein(data[i], data[j])
    ...
    >>> X = np.arange(len(data)).reshape(-1, 1)
    >>> X
    array([[0],
           [1],
           [2]])
    >>> # نحتاج إلى تحديد algorithm='brute' حيث أن الإعداد الافتراضي يفترض
    >>> # مساحة ميزة مستمرة.
    >>> dbscan(X, metric=lev_metric, eps=5, min_samples=2, algorithm='brute')  # doctest: +SKIP
    (array([0, 1]), array([ 0,  0, -1]))

لاحظ أن المثال أعلاه يستخدم حزمة مسافة التحرير التابعة لجهة خارجية `leven <https://pypi.org/project/leven/>`_. يمكن استخدام حيل مماثلة، مع بعض العناية، لأنوية الشجرة، وأنوية الرسم البياني، وما إلى ذلك.


لماذا أحيانًا أتعرض للانهيار / التجميد مع ``n_jobs > 1`` تحت OSX أو Linux؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

تعتمد العديد من أدوات scikit-learn مثل :class:`~model_selection.GridSearchCV` و :class:`~model_selection.cross_val_score` داخليًا على وحدة :mod:`multiprocessing` في Python لموازاة التنفيذ على عدة عمليات Python من خلال تمرير ``n_jobs > 1`` كوسيطة.

المشكلة هي أن Python :mod:`multiprocessing` تقوم باستدعاء نظامي "fork" دون متابعته باستدعاء نظامي "exec" وذلك لأسباب تتعلق بالأداء. العديد من المكتبات مثل (بعض إصدارات) Accelerate أو vecLib في نظام التشغيل OSX، (بعض إصدارات) MKL، ووقت تشغيل OpenMP في GCC، وCuda من nvidia (وربما العديد من المكتبات الأخرى)، تقوم بإدارة مجموعة الخيوط الداخلية الخاصة بها. عند استدعاء "fork"، تصبح حالة مجموعة الخيوط في العملية الفرعية فاسدة: تعتقد مجموعة الخيوط أنها تحتوي على العديد من الخيوط بينما تم إنشاء نسخة فقط من حالة الخيط الرئيسي. من الممكن تغيير المكتبات لجعلها تكشف متى يحدث "fork" وإعادة تهيئة مجموعة الخيوط في هذه الحالة: لقد فعلنا ذلك لـ OpenBLAS (تم دمجها في المنبع الرئيسي منذ الإصدار 0.2.10) وقد قدمنا "تصحيح" لوقت تشغيل OpenMP في GCC (لم تتم مراجعته بعد).

ولكن في النهاية، فإن المتهم الحقيقي هو Python :mod:`multiprocessing` الذي يقوم باستدعاء نظامي "fork" دون "exec" لتقليل الحمل الزائد لبدء واستخدام عمليات Python جديدة للحوسبة المتوازية. لسوء الحظ، هذا انتهاك لمعيار POSIX، وبالتالي ترفض بعض شركات البرمجيات مثل Apple اعتبار عدم الأمان في "fork" في Accelerate وvecLib عيبًا.

في Python 3.4+، أصبح من الممكن الآن تكوين :mod:`multiprocessing` لاستخدام طريقتي البدء "forkserver" أو "spawn" (بدلاً من "fork" الافتراضية) لإدارة مجمعات العمليات. للتغلب على هذه المشكلة عند استخدام scikit-learn، يمكنك ضبط متغير البيئة ``JOBLIB_START_METHOD`` على "forkserver". ومع ذلك، يجب أن يدرك المستخدم أن استخدام طريقة "forkserver" يمنع :class:`joblib.Parallel` من استدعاء الوظيفة المحددة بشكل تفاعلي في جلسة shell.

إذا كان لديك رمز مخصص يستخدم :mod:`multiprocessing` مباشرة بدلاً من استخدامه عبر :mod:`joblib`، فيمكنك تمكين وضع "forkserver" عالميًا لبرنامجك. أدخل التعليمات التالية في نصك الرئيسي::

    import multiprocessing

    # other imports, custom code, load data, define model...

    if __name__ == "__main__":
        multiprocessing.set_start_method("forkserver")

        # call scikit-learn utils with n_jobs > 1 here

يمكنك العثور على المزيد من التفاصيل حول طرق البدء الجديدة في `توثيق multiprocessing <https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods>`_.

.. _faq_mkl_threading:

لماذا يستخدم عملي عددًا أكبر من النوى مما هو محدد مع ``n_jobs``؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

هذا لأن ``n_jobs`` يتحكم فقط في عدد الوظائف للروتينات التي يتم تشغيلها بالتوازي مع :mod:`joblib`، ولكن يمكن أن يأتي الرمز المتوازي من مصادر أخرى:

- قد تكون بعض الروتينات متوازية مع OpenMP (للشفرة المكتوبة بلغة C أو Cython)،
- يعتمد scikit-learn بشكل كبير على numpy، والتي بدورها قد تعتمد على مكتبات رقمية مثل MKL أو OpenBLAS أو BLIS والتي يمكن أن توفر عمليات تنفيذ متوازية.

لمزيد من التفاصيل، يرجى الرجوع إلى :ref:`notes on parallelism <parallelism>`.

كيف يمكنني تعيين ``random_state`` للتنفيذ بأكمله؟
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

يرجى الرجوع إلى :ref:`randomness`.
