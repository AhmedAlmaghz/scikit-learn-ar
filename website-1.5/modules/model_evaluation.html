
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="3.9. مقاييس الأداء وتقييمها: تقييم جودة التنبؤات كميًا" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://scikit-learn/stable/modules/model_evaluation.html" />
<meta property="og:site_name" content="scikit-learn" />
<meta property="og:description" content="هناك 3 واجهات برمجة تطبيقات (APIs) مختلفة لتقييم جودة تنبؤات النموذج: طريقة تقييم الأداء للمُقدِّر: تحتوي المُقدِّرات على طريقة “score” التي توفر معيار تقييم افتراضي للمشكلة التي صُممت لحلها. لا يت..." />
<meta property="og:image" content="https://scikit-learn/stable/_images/sphx_glr_plot_confusion_matrix_001.png" />
<meta property="og:image:alt" content="scikit-learn" />
<meta name="description" content="هناك 3 واجهات برمجة تطبيقات (APIs) مختلفة لتقييم جودة تنبؤات النموذج: طريقة تقييم الأداء للمُقدِّر: تحتوي المُقدِّرات على طريقة “score” التي توفر معيار تقييم افتراضي للمشكلة التي صُممت لحلها. لا يت..." />

    <title>3.9. مقاييس الأداء وتقييمها: تقييم جودة التنبؤات كميًا &#8212; scikit-learn 1.5.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/colors.css?v=cc94ab7d" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/custom.css?v=e4cb1417" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=44dfd65d"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=97f0b27d"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script data-domain="scikit-learn.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modules/model_evaluation';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.15.4';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://scikit-learn.org/dev/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.5.1';
        DOCUMENTATION_OPTIONS.show_version_warning_banner = true;
        </script>
    <script src="../_static/scripts/dropdown.js?v=e2048168"></script>
    <script src="../_static/scripts/version-switcher.js?v=a6dd8357"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3.10. منحنيات التحقق: رسم الدرجات لتقييم النماذج" href="learning_curve.html" />
    <link rel="prev" title="3.7. تعديل عتبة القرار للتنبؤ بالصنف" href="classification_threshold.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/scikit-learn-logo-small.png" class="logo__image only-light" alt="scikit-learn homepage"/>
    <script>document.write(`<img src="../_static/scikit-learn-logo-small.png" class="logo__image only-dark" alt="scikit-learn homepage"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    مرجع المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../getting_started.html">
    بدء الاستخدام
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    تاريخ الإصدارات
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../support.html">
    الدعم
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../related_projects.html">
    التعاون مع الأطر الأخرى وتحسينها
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../roadmap.html">
    خارطة الطريق
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../about.html">
    الحوكمة
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-2"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-2"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-2"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-2">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../user_guide.html">
    مرجع المستخدم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api/index.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://blog.scikit-learn.org/">
    Community
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../getting_started.html">
    بدء الاستخدام
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    تاريخ الإصدارات
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../glossary.html">
    Glossary
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://scikit-learn.org/dev/developers/index.html">
    Development
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../faq.html">
    FAQ
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../support.html">
    الدعم
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../related_projects.html">
    التعاون مع الأطر الأخرى وتحسينها
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../roadmap.html">
    خارطة الطريق
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../governance.html">
    Governance
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about.html">
    الحوكمة
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/scikit-learn/scikit-learn" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button id="pst-version-switcher-button-3"
      type="button"
      class="version-switcher__button btn btn-sm dropdown-toggle"
      data-bs-toggle="dropdown"
      aria-haspopup="listbox"
      aria-controls="pst-version-switcher-list-3"
      aria-label="Version switcher list"
    >
      Choose version  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div id="pst-version-switcher-list-3"
      class="version-switcher__menu dropdown-menu list-group-flush py-0"
      role="listbox" aria-labelledby="pst-version-switcher-button-3">
      <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../supervised_learning.html">1. التعلم الخَلفي</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../unsupervised_learning.html">2. التعلم غير الخاضع للإشراف</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="mixture.html">2.1. نماذج المزيج الغاوسي</a></li>

<li class="toctree-l2"><a class="reference internal" href="manifold.html">2.3. تعلم المنوال</a></li>





<li class="toctree-l2"><a class="reference internal" href="clustering.html">2.9. التجميع</a></li>
<li class="toctree-l2"><a class="reference internal" href="decomposition.html">2.10. تفكيك الإشارات إلى مكونات (مشاكل تحليل المصفوفة)</a></li>


<li class="toctree-l2"><a class="reference internal" href="covariance.html">2.13. التغاير التجريبي</a></li>


<li class="toctree-l2"><a class="reference internal" href="outlier_detection.html">2.16. تناسب غلاف إهليلجي</a></li>










<li class="toctree-l2"><a class="reference internal" href="density.html">2.27. تقدير الكثافة</a></li>


<li class="toctree-l2"><a class="reference internal" href="neural_networks_unsupervised.html">2.30. نماذج الشبكات العصبية (غير الخاضعة للإشراف)</a></li>

</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../model_selection.html">3. اختيار النموذج وتقييمه</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="cross_validation.html">3.1. التدقيق المتقاطع: تقييم أداء أداة التقدير</a></li>


<li class="toctree-l2"><a class="reference internal" href="grid_search.html">3.4. البحث الشامل عن الشبكة</a></li>


<li class="toctree-l2"><a class="reference internal" href="classification_threshold.html">3.7. تعديل عتبة القرار للتنبؤ بالصنف</a></li>

<li class="toctree-l2 current active"><a class="current reference internal" href="#">3.9. مقاييس الأداء وتقييمها: تقييم جودة التنبؤات كميًا</a></li>
<li class="toctree-l2"><a class="reference internal" href="learning_curve.html">3.10. منحنيات التحقق: رسم الدرجات لتقييم النماذج</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../inspection.html">4. التفتيش</a></li>
<li class="toctree-l1"><a class="reference internal" href="../visualizations.html">5. التمثيل المرئي</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data_transforms.html">6. تحويلات مجموعة البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="compose.html">6.1. خطوط الأنابيب ومقدّرات المُركّبات</a></li>


<li class="toctree-l2"><a class="reference internal" href="feature_extraction.html">6.4. استخراج الخصائص</a></li>


<li class="toctree-l2"><a class="reference internal" href="preprocessing.html">6.7. معالجة البيانات الأولية</a></li>




<li class="toctree-l2"><a class="reference internal" href="impute.html">6.12. إكمال القيم المفقودة</a></li>






<li class="toctree-l2"><a class="reference internal" href="unsupervised_reduction.html">6.19. PCA: التحليل التكويني الرئيسي</a></li>


<li class="toctree-l2"><a class="reference internal" href="random_projection.html">6.22. الإسقاط العشوائي</a></li>
<li class="toctree-l2"><a class="reference internal" href="kernel_approximation.html">6.23. طريقة Nystroem لتقريب النواة</a></li>




<li class="toctree-l2"><a class="reference internal" href="metrics.html">6.28. مقاييس الاقتران، الألفة والنواة</a></li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing_targets.html">6.29. تحويل هدف التنبؤ (<code class="docutils literal notranslate"><span class="pre">y</span></code>)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datasets.html">7. مرافق تحميل مجموعة البيانات</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datasets/toy_dataset.html">7.1. مجموعات البيانات التجريبية</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/real_world.html">7.2. مجموعات البيانات من العالم الحقيقي</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/sample_generators.html">7.3. المجموعات البيانات المولدة</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/loading_other_datasets.html">7.4. أمثلة</a></li>




</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../computing.html">8. الحوسبة باستخدام scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_persistence.html">9. نظرة عامة على سير العمل</a></li>




<li class="toctree-l1"><a class="reference internal" href="../common_pitfalls.html">14. المعالجة المسبقة غير المتسقة</a></li>

<li class="toctree-l1"><a class="reference internal" href="../dispatching.html">16. التشغيل التلقائي</a></li>
<li class="toctree-l1"><a class="reference internal" href="../machine_learning_map.html">17. اختيار المحلل المناسب</a></li>
<li class="toctree-l1"><a class="reference internal" href="../presentations.html">18. الموارد الخارجية، الفيديوهات، والمحاضرات</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../user_guide.html" class="nav-link">مرجع المستخدم</a></li>
    
    
    <li class="breadcrumb-item"><a href="../model_selection.html" class="nav-link"><span class="section-number">3. </span>اختيار النموذج وتقييمه</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="model-evaluation">
<span id="id1"></span><h1><span class="section-number">3.9. </span>مقاييس الأداء وتقييمها: تقييم جودة التنبؤات كميًا<a class="headerlink" href="#model-evaluation" title="Link to this heading">#</a></h1>
<p>هناك 3 واجهات برمجة تطبيقات (APIs) مختلفة لتقييم جودة تنبؤات النموذج:</p>
<ul class="simple">
<li><p><strong>طريقة تقييم الأداء للمُقدِّر</strong>: تحتوي المُقدِّرات على طريقة “score” التي توفر معيار تقييم افتراضي للمشكلة التي صُممت لحلها. لا يتم مناقشة هذا في هذه الصفحة، ولكن في وثائق كل مُقدِّر على حدة.</p></li>
<li><p><strong>معيار التقييم</strong>: تعتمد أدوات تقييم النماذج التي تستخدم المصادقة المتقاطعة (مثل model_selection.cross_val_score و model_selection.GridSearchCV) على استراتيجية “تقييم” داخلية. يتم مناقشة هذا في قسم “معيار التقييم”.</p></li>
<li><p><strong>دالات المقاييس</strong>: تنفذ وحدة sklearn.metrics دالات تقييم أخطاء التنبؤ لأغراض محددة. يتم تفصيل هذه المقاييس في الأقسام المتعلقة بمقاييس “التصنيف”، و”ترتيب التصنيف المتعدد التصنيفات”، و”الانحدار”، و”تصنيف التجميع”.</p></li>
</ul>
<p>أخيرًا، تعد “المُقدِّرات الوهمية” مفيدة للحصول على قيمة مرجعية أساسية لهذه المقاييس بالنسبة للتنبؤات العشوائية.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>بالنسبة للمقاييس “المقارنة”، بين العينات وليس المُقدِّرات أو التنبؤات، راجع قسم “مقاييس الأداء”.</p>
</div>
<p id="scoring-parameter">معيار التقييم: تحديد قواعد تقييم النماذج
اختيار وتقييم النموذج باستخدام أدوات مثل class:<code class="docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code> و func:<code class="docutils literal notranslate"><span class="pre">model_selection.cross_val_score</span></code>، تأخذ وسيطًا “scoring” الذي يتحكم في المقياس الذي تطبقه على المثمنات التي يتم تقييمها.</p>
<section id="id2">
<h2><span class="section-number">3.9.1. </span>الحالات الشائعة: القيم المحددة مسبقًا<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>بالنسبة لحالات الاستخدام الأكثر شيوعًا، يمكنك تعيين كائن مسجل درجات باستخدام وسيط “scoring”؛ يُظهر الجدول أدناه جميع القيم الممكنة. تتوافق جميع كائنات تسجيل النقاط مع الاتفاقية التي <strong>تفوق قيم الإرجاع الأعلى على القيم الأقل</strong>. وبالتالي، فإن المقاييس التي تقيس المسافة بين النموذج والبيانات، مثل func:<code class="docutils literal notranslate"><span class="pre">metrics.mean_squared_error</span></code>، متوفرة كـ neg_mean_squared_error والتي تعيد القيمة السالبة للمقياس.</p>
<p>أمثلة الاستخدام:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span><span class="p">,</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;recall_macro&#39;</span><span class="p">)</span>
<span class="go">array([0.96..., 0.96..., 0.96..., 0.93..., 1.        ])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>إذا تم تمرير اسم تسجيل درجات غير صحيح، فسيتم إلقاء خطأ “InvalidParameterError”.
يمكنك استرداد أسماء جميع المسجلين المتاحين عن طريق استدعاء
:func: ~ sklearn.metrics.get_scorer_names.</p>
</div>
</section>
<section id="scoring">
<span id="id3"></span><h2><span class="section-number">3.9.2. </span>تحديد استراتيجية تسجيل النقاط من وظائف القياس<a class="headerlink" href="#scoring" title="Link to this heading">#</a></h2>
<p>لا يتم تنفيذ وظائف القياس التالية كمسجلين مسمى،
في بعض الأحيان لأنها تتطلب معلمات إضافية، مثل
<code class="xref py py-func docutils literal notranslate"><span class="pre">fbeta_score</span></code>. لا يمكن تمريرها إلى وسيط “التسجيل”؛ بدلاً من ذلك، يجب تمرير دالة الاستدعاء الخاصة بها
<code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code> جنبًا إلى جنب مع قيمة المعلمات التي يمكن للمستخدم تعيينها.</p>
<p>تتمثل إحدى حالات الاستخدام النموذجية في لف وظيفة قياس موجودة في المكتبة
بقيم غير افتراضية لمعلماتها، مثل معلمة “beta” لوظيفة “fbeta_score”:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ftwo_scorer</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">fbeta_score</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LinearSVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]},</span>
<span class="gp">... </span>                    <span class="n">scoring</span><span class="o">=</span><span class="n">ftwo_scorer</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>تعرض الوحدة النمطية <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> أيضًا مجموعة من الوظائف البسيطة
قياس خطأ التنبؤ بالنظر إلى الحقيقة الأرضية والتنبؤ:</p>
<ul class="simple">
<li><p>الوظائف التي تنتهي بـ <code class="docutils literal notranslate"><span class="pre">_score</span></code> تعيد قيمة
قم بتعظيمها، كلما كان ذلك أفضل.</p></li>
<li><p>الوظائف التي تنتهي بـ <code class="docutils literal notranslate"><span class="pre">_error</span></code> أو <code class="docutils literal notranslate"><span class="pre">_loss</span></code> أو <code class="docutils literal notranslate"><span class="pre">_deviance</span></code> تعيد
قيمة للتقليل إلى الحد الأدنى، كلما انخفضت النتائج أفضل. عند التحويل
إلى كائن مسجل باستخدام <code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code>، قم بتعيين
معلمة “greater_is_better” إلى “False” (“True” بشكل افتراضي؛ راجع</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="كائنات-تسجيل-النقاط-المخصصة">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">كائنات تسجيل النقاط المخصصة<a class="headerlink" href="#كائنات-تسجيل-النقاط-المخصصة" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تتمثل حالة الاستخدام الثانية في بناء كائن تسجيل نقاط مخصص تمامًا
من دالة Python باستخدام <code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code>، والتي يمكنها
اتخاذ عدة معلمات:</p>
<ul class="simple">
<li><p class="sd-card-text">دالة Python التي تريد استخدامها (<code class="docutils literal notranslate"><span class="pre">my_custom_loss_func</span></code>
في المثال أدناه)</p></li>
<li><p class="sd-card-text">ما إذا كانت دالة Python تعيد درجة (<code class="docutils literal notranslate"><span class="pre">greater_is_better=True</span></code>،
الافتراضي) أو خسارة (<code class="docutils literal notranslate"><span class="pre">greater_is_better=False</span></code>). إذا كانت الخسارة، فسيتم إلغاء قيمة الدالة بواسطة</p></li>
</ul>
<p class="sd-card-text">كائن مسجل، بما يتوافق مع
اتفاقية التحقق من الصحة المتقاطعة التي تعيد المسجلات درجات أعلى للنماذج الأفضل.</p>
<ul class="simple">
<li><p class="sd-card-text">للتصنيف المقاييس فقط: ما إذا كانت دالة Python التي قدمتها تتطلب
احتمالات القرار المستمر. إذا كانت دالة التسجيل تقبل فقط تقديرات الاحتمال (على سبيل المثال: func:<code class="docutils literal notranslate"><span class="pre">metrics.log_loss</span></code>) ثم تحتاج إلى تعيين معلمة</p></li>
</ul>
<p class="sd-card-text">“response_method”، وبالتالي في هذه الحالة “response_method=”predict_proba”. لا تتطلب بعض وظائف التسجيل بالضرورة تقديرات الاحتمال ولكن قيم القرار غير المحددة
(على سبيل المثال: func:<code class="docutils literal notranslate"><span class="pre">metrics.roc_auc_score</span></code>). في هذه الحالة، يتم توفير قائمة مثل <code class="docutils literal notranslate"><span class="pre">response_method=[&quot;decision_function&quot;،</span> <span class="pre">&quot;predict_proba&quot;]</span></code>. في هذه الحالة،
سيستخدم المسجل أول طريقة متاحة، بالترتيب المعطى في القائمة،
لحساب الدرجات.</p>
<ul class="simple">
<li><p class="sd-card-text">أي معلمات إضافية، مثل “beta” أو “labels” في <code class="xref py py-func docutils literal notranslate"><span class="pre">f1_score</span></code>.</p></li>
</ul>
<p class="sd-card-text">فيما يلي مثال على بناء مسجلات مخصصة، وعلى استخدام
معلمة “greater_is_better”:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; def my_custom_loss_func(y_true، y_pred):
...     diff = np.abs(y_true - y_pred).max()
...     return np.log1p(diff)
...
&gt;&gt;&gt; # سيقوم المسجل بإلغاء قيمة الإرجاع لـ my_custom_loss_func،
&gt;&gt;&gt; # والتي ستكون np.log(2)، 0.693، نظرًا لقيم X
&gt;&gt;&gt; # و y المحددة أدناه.
&gt;&gt;&gt; score = make_scorer(my_custom_loss_func, greater_is_better=False)
&gt;&gt;&gt; X = [[1], [1]]
&gt;&gt;&gt; y = [0, 1]
&gt;&gt;&gt; from sklearn.dummy import DummyClassifier
&gt;&gt;&gt; clf = DummyClassifier(strategy=&#39;most_frequent&#39;, random_state=0)
&gt;&gt;&gt; clf = clf.fit(X, y)
&gt;&gt;&gt; my_custom_loss_func(y, clf.predict(X))
0.69...
&gt;&gt;&gt; score(clf, X, y)
-0.69...
</pre></div>
</div>
</div>
</details></section>
<section id="diy-scoring">
<span id="id4"></span><h2><span class="section-number">3.9.3. </span>تنفيذ كائن تسجيل النقاط الخاص بك<a class="headerlink" href="#diy-scoring" title="Link to this heading">#</a></h2>
<p>يمكنك إنشاء مسجلات نماذج أكثر مرونة من خلال إنشاء كائن تسجيل النقاط الخاص بك من الصفر، دون استخدام <code class="xref py py-func docutils literal notranslate"><span class="pre">make_scorer</span></code> factory.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="كيفية-بناء-مسجل-من-الصفر">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">كيفية بناء مسجل من الصفر<a class="headerlink" href="#كيفية-بناء-مسجل-من-الصفر" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">لكي تكون الدالة القابلة للاستدعاء مسجل درجات، يجب أن تلتزم بالبروتوكول المحدد بواسطة
القاعدتين التاليتين:</p>
<ul class="simple">
<li><p class="sd-card-text">يمكن استدعاؤه باستخدام معلمات “(estimator, X, y)”، حيث “estimator”
هو النموذج الذي يجب تقييمه، “X” هي بيانات التحقق، و “y” هي
الحقيقة الأرضية المستهدفة لـ “X” (في الحالة الخاضعة للإشراف) أو “None” (في
حالة عدم الإشراف).</p></li>
<li><p class="sd-card-text">إنه يعيد رقمًا عشريًا يحدد كمية
“دقة” تنبؤ “المقدر” على “X”، مع الإشارة إلى “y”.
مرة أخرى، وفقًا للاتفاقية، تكون الأرقام الأعلى أفضل، لذا إذا أعاد مسجل النقاط الخاص بك
الخسارة، يجب إلغاء قيمة تلك الخسارة.</p></li>
<li><p class="sd-card-text">متقدم: إذا كان يتطلب بيانات وصفية إضافية ليتم تمريرها إليه، فيجب أن يعرض
طريقة “get_metadata_routing” التي تعيد البيانات الوصفية المطلوبة. يجب أن يكون المستخدم قادرًا على تعيين البيانات الوصفية المطلوبة عبر
طريقة “set_score_request”. يرجى الاطلاع على: الدليل المرجعي للمستخدم &lt;metadata_routing&gt; و: الدليل المرجعي للمطور &lt;sphx_glr_auto_examples_miscellaneous_plot_metadata_routing.py&gt; لمزيد من التفاصيل.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="sd-card-text"><strong>استخدام مسجلات مخصصة في الوظائف حيث n_jobs &gt; 1</strong></p>
<p class="sd-card-text">في حين أن تعريف وظيفة تسجيل النقاط المخصصة بجانب وظيفة الاستدعاء
يجب أن تعمل خارج الصندوق مع الخلفية الافتراضية لـ joblib (loky)،
سيكون استيرادها من وحدة أخرى نهجًا أكثر متانة ويعمل
بشكل مستقل عن الخلفية joblib.</p>
<p class="sd-card-text">على سبيل المثال، لاستخدام “n_jobs” أكبر من 1 في المثال أدناه،
يتم حفظ وظيفة “custom_scoring_function” في وحدة أنشأها المستخدم
(<code class="docutils literal notranslate"><span class="pre">custom_scorer_module.py</span></code>) ويتم استيرادها:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; from custom_scorer_module import custom_scoring_function 
&gt;&gt;&gt; cross_val_score(model,
...  X_train،
...  y_train،
...  scoring=make_scorer(custom_scoring_function، greater_is_better=False)،
...  cv=5،
...  n_jobs=-1) 
</pre></div>
</div>
</div>
</div>
</details><p id="multimetric-scoring">استخدام تقييم المقياس المتعدد
يسمح سكيت-ليرن أيضًا بتقييم مقاييس متعددة في “GridSearchCV” و “RandomizedSearchCV” و “cross_validate”.</p>
<p>هناك ثلاث طرق لتحديد مقاييس تقييم متعددة لمعلمة “التقييم”:</p>
<ul>
<li><p>كقائمة قابلة للتكرار من المقاييس النصية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;precision&#39;</span><span class="p">]</span>
</pre></div>
</div>
</li>
<li><p>كـ “dict” يقوم بتعيين اسم المقيم إلى دالة التقييم:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
   <span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>
   <span class="o">&gt;&gt;&gt;</span> <span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">),</span>
   <span class="o">...</span>            <span class="s1">&#39;prec&#39;</span><span class="p">:</span> <span class="s1">&#39;precision&#39;</span><span class="p">}</span>

<span class="n">لاحظ</span> <span class="n">أن</span> <span class="n">قيم</span> <span class="n">القاموس</span> <span class="n">يمكن</span> <span class="n">أن</span> <span class="n">تكون</span> <span class="n">إما</span> <span class="n">دالات</span> <span class="n">تقييم</span> <span class="n">أو</span> <span class="n">إحدى</span> <span class="n">سلاسل</span> <span class="n">المقاييس</span> <span class="n">المحددة</span> <span class="n">مسبقًا</span><span class="o">.</span>
</pre></div>
</div>
</li>
<li><p>كدالة قابلة للاستدعاء تعيد قاموس النتائج:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># مجموعة بيانات ثنائية للتصنيف كمثال توضيحي</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span><span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">confusion_matrix_scorer</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>     <span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">... </span>     <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">... </span>     <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;tn&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;fp&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>             <span class="s1">&#39;fn&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;tp&#39;</span><span class="p">:</span> <span class="n">cm</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">scoring</span><span class="o">=</span><span class="n">confusion_matrix_scorer</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># الحصول على نتائج القيم الإيجابية الحقيقية لمجموعة الاختبار</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_tp&#39;</span><span class="p">])</span>
<span class="go">[10  9  8  7  8]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># الحصول على نتائج القيم السلبية لمجموعة الاختبار</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test_fn&#39;</span><span class="p">])</span>
<span class="go">[0 1 2 3 2]</span>
</pre></div>
</div>
</li>
</ul>
<p id="classification-metrics">مقاييس التصنيف
وينفذ نموذج sklearn.metrics العديد من دالات الخسارة، والنتيجة، والمرافق لقياس أداء التصنيف. وقد تتطلب بعض المقاييس تقديرات احتمالية للفئة الإيجابية، أو قيم الثقة، أو قيم القرارات الثنائية. تسمح معظم التطبيقات لكل عينة بتقديم مساهمة مرجحة في النتيجة الإجمالية، من خلال معلمة “sample_weight”.</p>
<p>وبعض هذه المقاييس مقيدة بحالات التصنيف الثنائية:</p>
<ul class="simple">
<li><p>precision_recall_curve</p></li>
<li><p>roc_curve</p></li>
<li><p>class_likelihood_ratios</p></li>
<li><p>det_curve</p></li>
</ul>
<p>بينما تعمل مقاييس أخرى أيضًا في حالة التصنيف المتعدد:</p>
<ul class="simple">
<li><p>balanced_accuracy_score</p></li>
<li><p>cohen_kappa_score</p></li>
<li><p>confusion_matrix</p></li>
<li><p>hinge_loss</p></li>
<li><p>matthews_corrcoef</p></li>
<li><p>roc_auc_score</p></li>
<li><p>top_k_accuracy_score</p></li>
</ul>
<p>كما تعمل بعض المقاييس في حالة التصنيف المتعدد بالعلامات:</p>
<ul class="simple">
<li><p>accuracy_score</p></li>
<li><p>classification_report</p></li>
<li><p>f1_score</p></li>
<li><p>fbeta_score</p></li>
<li><p>hamming_loss</p></li>
<li><p>jaccard_score</p></li>
<li><p>log_loss</p></li>
<li><p>multilabel_confusion_matrix</p></li>
<li><p>precision_recall_fscore_support</p></li>
<li><p>precision_score</p></li>
<li><p>recall_score</p></li>
<li><p>roc_auc_score</p></li>
<li><p>zero_one_loss</p></li>
<li><p>d2_log_loss_score</p></li>
</ul>
<p>وتعمل بعض المقاييس مع المشكلات الثنائية والمتعددة العلامات (ولكن ليس مع التصنيف المتعدد):</p>
<ul class="simple">
<li><p>average_precision_score</p></li>
</ul>
<p>في الأقسام الفرعية التالية، سنقوم بوصف كل من هذه الدالات، تسبقها بعض الملاحظات حول تعريف واجهة برمجة التطبيقات (API) والمقاييس الشائعة.</p>
<p>من التصنيف الثنائي إلى التصنيف المتعدد والمتعدد العلامات</p>
<p>تُعرَّف بعض المقاييس بشكل أساسي لمهمات التصنيف الثنائية (مثل f1_score، وroc_auc_score). وفي هذه الحالات، يتم بشكل افتراضي تقييم العلامة الإيجابية فقط، مع افتراض أن العلامة الإيجابية هي “1” بشكل افتراضي (على الرغم من أنه يمكن تكوين ذلك من خلال معلمة “pos_label”).</p>
<p>وعند تمديد مقياس ثنائي إلى مشكلات متعددة التصنيف أو متعددة العلامات، تتم معاملة البيانات على أنها مجموعة من المشكلات الثنائية، واحدة لكل فئة. ثم هناك عدد من الطرق لحساب المتوسط لمقاييس ثنائية عبر مجموعة من الفئات، وقد يكون كل منها مفيدًا في بعض السيناريوهات. وعند توفرها، يجب عليك الاختيار من بين هذه الطرق باستخدام معلمة “average”.</p>
<ul class="simple">
<li><p>“macro”: يحسب ببساطة متوسط المقاييس الثنائية، مما يعطي وزنًا متساويًا لكل فئة. وفي المشكلات التي تكون فيها الفئات النادرة مهمة على الرغم من ذلك، قد يكون المتوسط الحسابي طريقة لتسليط الضوء على أدائها. من ناحية أخرى، غالبًا ما يكون الافتراض بأن جميع الفئات متساوية في الأهمية غير صحيح، بحيث يؤدي المتوسط الحسابي إلى المبالغة في التأكيد على الأداء المنخفض لفئة نادرة.</p></li>
<li><p>“weighted”: يراعي اختلال التوازن بين الفئات عن طريق حساب متوسط المقاييس الثنائية التي يتم فيها ترجيح نتيجة كل فئة بوجودها في عينة البيانات الفعلية.</p></li>
<li><p>“micro”: يعطي كل زوج من العينات-الفئات مساهمة متساوية في المقياس الإجمالي (باستثناء ما ينتج عن “sample_weight”. بدلاً من جمع المقياس لكل فئة، يقوم هذا الأسلوب بجمع الأرباح والمقسومات التي تشكل المقاييس لكل فئة لحساب حاصل قسمة إجمالي. وقد يكون المتوسط الحسابي مفضلًا في الإعدادات متعددة العلامات، بما في ذلك التصنيف متعدد الفئات حيث يجب تجاهل فئة الأغلبية.</p></li>
<li><p>“samples”: ينطبق فقط على المشكلات متعددة العلامات. ولا يحسب مقياسًا لكل فئة، ولكنه يحسب المقياس عبر الفئات الفعلية والمتوقعة لكل عينة في بيانات التقييم، ويعيد متوسطها المرجح بـ “sample_weight”.</p></li>
<li><p>يؤدي تحديد “average=None” إلى إعادة مصفوفة بالنتيجة لكل فئة.</p></li>
</ul>
<p>وفي حين يتم توفير بيانات متعددة الفئات للمقياس، مثل أهداف ثنائية، كمصفوفة من علامات الفئات، يتم تحديد بيانات متعددة العلامات كمصفوفة مؤشرات، حيث تحتوي الخلية [i, j] على القيمة 1 إذا كانت العينة “i” تحتوي على العلامة “j” والقيمة 0 في غير ذلك.</p>
<p>دالة نتيجة الدقة</p>
<p>تحسب دالة accuracy_score دقة الدقة، إما كجزء (القيمة الافتراضية) أو كعدد (normalize=False) من التوقعات الصحيحة.</p>
<p>وفي التصنيف متعدد العلامات، تعيد الدالة دقة الجزء الفرعي. إذا تطابقت مجموعة التوقعات الصحيحة بالكامل لعينة ما مع مجموعة العلامات الصحيحة، فإن دقة الجزء الفرعي تساوي 1.0؛ وإلا فإنها تساوي 0.0.</p>
<p>إذا كان y_pred_i هو القيمة المتوقعة للقيمة الفعلية y_i، فإن جزء التوقعات الصحيحة على n_samples يتم تحديده على النحو التالي:</p>
<p>حيث 1(x) هي دالة المؤشر.</p>
<p>في حالة التصنيف متعدد العلامات مع مؤشرات العلامات الثنائية:</p>
<p>أمثلة</p>
<ul class="simple">
<li><p>راجع:ref:<code class="docutils literal notranslate"><span class="pre">sphx_glr_auto_examples_model_selection_plot_permutation_tests_for_classification.py&lt;sphx_glr_auto_examples_model_selection_plot_permutation_tests_for_classification.py&gt;</span></code> للحصول على مثال على استخدام نتيجة الدقة باستخدام ترتيبات البيانات.</p></li>
</ul>
<p>نتيجة دقة أعلى k</p>
<p>دالة top_k_accuracy_score هي تعميم لدالة accuracy_score. والفرق هو أنه يتم اعتبار التنبؤ صحيحًا طالما أن العلامة الصحيحة مرتبطة بواحدة من أعلى k نتائج متوقعة. ودالة accuracy_score هي حالة خاصة من k = 1.</p>
<p>وتغطي الدالة حالات التصنيف الثنائي والمتعدد الفئات ولكن ليس حالة التصنيف متعدد العلامات.</p>
<p>إذا كان y_pred_i,j هو الفئة المتوقعة للقيمة الفعلية y_i التي تتوافق مع أكبر نتيجة متوقعة j، فإن جزء التوقعات الصحيحة على n_samples يتم تحديده على النحو التالي:</p>
<p>حيث k هو عدد التخمينات المسموح بها و1(x) هي دالة المؤشر.</p>
<p>دالة نتيجة الدقة المتوازنة</p>
<p>تحسب دالة balanced_accuracy_score دقة الدقة المتوازنة، والتي تتجنب تقديرات الأداء المتضخمة في مجموعات البيانات غير المتوازنة. وهي المتوسط الحسابي لنتائج الاسترجاع لكل فئة أو، بشكل مكافئ، الدقة الخام حيث يتم ترجيح كل عينة وفقًا للعكس انتشار لفئتها الحقيقية.</p>
<p>وبالتالي، بالنسبة لبيانات متوازنة، تكون النتيجة مساوية للدقة.</p>
<p>وفي حالة التصنيف الثنائي، تكون الدقة المتوازنة مساوية للمتوسط الحسابي لحساسية (معدل الإيجابيات الحقيقية) والخصوصية (معدل السلبيات الحقيقية)، أو المساحة تحت منحنى ROC مع تنبؤات ثنائية بدلاً من النتائج:</p>
<p>إذا كان أداء المصنف جيدًا بالتساوي في كلتا الفئتين، فإن هذا المصطلح يقل إلى الدقة التقليدية (أي عدد التوقعات الصحيحة مقسومًا على العدد الإجمالي للتوقعات).</p>
<p>وعلى النقيض من ذلك، إذا كانت الدقة التقليدية أعلى من الصدفة فقط لأن المصنف يستفيد من مجموعة اختبار غير متوازنة، فإن الدقة المتوازنة، كما هو مناسب، ستنخفض إلى 1/عدد الفئات.</p>
<p>وتتراوح النتيجة من 0 إلى 1، أو عند استخدام “adjusted=True”، يتم إعادة تحجيمها إلى النطاق 1/(1-عدد الفئات) إلى 1، شاملاً ذلك، مع تسجيل الأداء العشوائي 0.</p>
<p>إذا كانت y_i هي القيمة الحقيقية للعينة i، وكانت w_i هي وزن العينة المقابل، فإننا نقوم بتعديل وزن العينة إلى:</p>
<p>حيث 1(x) هي دالة المؤشر.</p>
<p>وبالنظر إلى القيمة المتوقعة y_pred_i للعينة i، فإن الدقة المتوازنة يتم تحديدها على النحو التالي:</p>
<p>مع “adjusted=True”، تقوم الدقة المتوازنة بالإبلاغ عن الزيادة النسبية من الدقة المتوازنة (y, 0, w) = 1/عدد الفئات. وفي حالة التصنيف الثنائي، يُعرف هذا أيضًا باسم إحصائية J لYouden أو informedness.</p>
<p>ملاحظة</p>
<p>يبدو التعريف متعدد الفئات هنا أكثر التمديدات المعقولة للمقياس المستخدم في التصنيف الثنائي، على الرغم من عدم وجود توافق مؤكد في الآراء في الأدبيات:</p>
<ul class="simple">
<li><p>تعريفنا: <span id="id5">[Mosley2013]</span>، و[Kelleher2015]_، و[Guyon2015]_، حيث يعتمد <span id="id6">[Guyon2015]</span> الإصدار المعدل لضمان أن التوقعات العشوائية لديها نتيجة 0 والتوقعات المثالية لديها نتيجة 1.</p></li>
<li><p>دقة الفئة المتوازنة كما هو موصوف في <span id="id7">[Mosley2013]</span>: يتم حساب الحد الأدنى بين الدقة والاسترجاع لكل فئة. ثم يتم حساب متوسط هذه القيم على العدد الإجمالي للفئات للحصول على الدقة المتوازنة.</p></li>
<li><p>الدقة المتوازنة كما هو موصوف في <span id="id8">[Urbanowicz2015]</span>: يتم حساب متوسط الحساسية والخصوصية لكل فئة ثم حساب متوسطها على العدد الإجمالي للفئات.</p></li>
</ul>
<p>المراجع</p>
<p>Cohen’s kappa</p>
<p>تقوم دالة cohen_kappa_score بحساب إحصائية Cohen’s kappa. ويقصد بهذا المقياس مقارنة التصنيفات التي يقوم بها بشر مختلفون، وليس مصنفًا مقابل حقيقة أرضية.</p>
<p>ونتيجة kappa هي رقم بين -1 و1. وتعد النتائج أعلى 0.8 جيدة بشكل عام؛ وتشير النتيجة الصفرية أو الأقل إلى عدم وجود اتفاق (علامات عشوائية عمليًا).</p>
<p>ويمكن حساب نتائج kappa لمشكلات ثنائية أو متعددة الفئات، ولكن ليس لمشكلات متعددة العلامات (باستثناء حساب النتيجة لكل علامة يدويًا) وليس لأكثر من اثنين من المُصنِّفين.</p>
<p>مصفوفة الارتباك
وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">confusion_matrix</span></code> تقيم دقة التصنيف عن طريق حساب مصفوفة الارتباك مع كل صف مطابق للفئة الحقيقية (قد تستخدم ويكيبيديا ومرجع آخر اتفاقية مختلفة للمحاور).</p>
<p>بحسب التعريف، فإن الإدخال <span class="math notranslate nohighlight">\(i, j\)</span> في مصفوفة الارتباك هو عدد الملاحظات الموجودة بالفعل في المجموعة <span class="math notranslate nohighlight">\(i\)</span>، ولكن تم التنبؤ بها في المجموعة <span class="math notranslate nohighlight">\(j\)</span>. إليك مثال:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([[2, 0, 0],</span>
<span class="go">       [0, 0, 1],</span>
<span class="go">       [1, 0, 2]])</span>
</pre></div>
</div>
<p>يمكن استخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">ConfusionMatrixDisplay</span></code> لتمثيل مصفوفة الارتباك بصريًا كما هو موضح في مثال: ref:<code class="docutils literal notranslate"><span class="pre">sphx_glr_auto_examples_model_selection_plot_confusion_matrix.py</span></code>، والذي ينشئ الشكل التالي:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_confusion_matrix.html"><img alt="../_images/sphx_glr_plot_confusion_matrix_001.png" class="align-center" src="../_images/sphx_glr_plot_confusion_matrix_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
<p>يسمح معامل <code class="docutils literal notranslate"><span class="pre">normalize</span></code> بالإبلاغ عن النسب بدلاً من العد. يمكن تطبيع مصفوفة الارتباك بثلاث طرق مختلفة: <code class="docutils literal notranslate"><span class="pre">'pred'</span></code>، و <code class="docutils literal notranslate"><span class="pre">'true'</span></code>، و <code class="docutils literal notranslate"><span class="pre">'all'</span></code> والتي ستقسم العد على مجموع كل الأعمدة، أو الصفوف، أو المصفوفة بأكملها، على التوالي.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
<span class="go">array([[0.25 , 0.125],</span>
<span class="go">       [0.25 , 0.375]])</span>
</pre></div>
</div>
<p>بالنسبة للمشكلات الثنائية، يمكننا الحصول على عدد السلبيات الحقيقية، والإيجابيات الخاطئة، والسلبيات الخاطئة، والإيجابيات الحقيقية كما يلي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span>
<span class="go">(2, 1, 2, 3)</span>
</pre></div>
</div>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p>راجع <a class="reference internal" href="../auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"><span class="std std-ref">Confusion matrix</span></a>
لمثال على استخدام مصفوفة الارتباك لتقييم جودة إخراج المصنف.</p></li>
<li><p>راجع <a class="reference internal" href="../auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">Recognizing hand-written digits</span></a>
لمثال على استخدام مصفوفة الارتباك لتصنيف
الأرقام المكتوبة بخط اليد.</p></li>
<li><p>راجع <a class="reference internal" href="../auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a>
لمثال على استخدام مصفوفة الارتباك لتصنيف وثائق النص.</p></li>
</ul>
</section>
<section id="classification-report">
<span id="id9"></span><h2><span class="section-number">3.9.4. </span>تقرير التصنيف<a class="headerlink" href="#classification-report" title="Link to this heading">#</a></h2>
<p>تبني وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">classification_report</span></code> تقرير نصي يُظهر مقاييس التصنيف الرئيسية. إليك مثال صغير مع أسماء مستهدفة مخصصة
وتصنيفات مستنتجة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;class 2&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span><span class="p">))</span>
<span class="go">              precision    recall  f1-score   support</span>

<span class="go">     class 0       0.67      1.00      0.80         2</span>
<span class="go">     class 1       0.00      0.00      0.00         1</span>
<span class="go">     class 2       1.00      0.50      0.67         2</span>

<span class="go">    accuracy                           0.60         5</span>
<span class="go">   macro avg       0.56      0.50      0.49         5</span>
<span class="go">weighted avg       0.67      0.60      0.59         5</span>
</pre></div>
</div>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p>راجع <a class="reference internal" href="../auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"><span class="std std-ref">Recognizing hand-written digits</span></a>
لمثال على استخدام تقرير التصنيف لل
الأرقام المكتوبة بخط اليد.</p></li>
<li><p>راجع <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Custom refit strategy of a grid search with cross-validation</span></a>
لمثال على استخدام تقرير التصنيف لل
البحث الشبكي مع التصديق المتقاطع المتداخل.</p></li>
</ul>
</section>
<section id="hamming-loss">
<span id="id10"></span><h2><span class="section-number">3.9.5. </span>خسارة هامنج<a class="headerlink" href="#hamming-loss" title="Link to this heading">#</a></h2>
<p>تقوم وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">hamming_loss</span></code> بحساب متوسط خسارة هامنج أو <a class="reference external" href="https://en.wikipedia.org/wiki/Hamming_distance">مسافة هامنج</a> بين مجموعتين
من العينات.</p>
<p>إذا كان <span class="math notranslate nohighlight">\(\hat{y}_{i,j}\)</span> هي القيمة المتوقعة للعلامة <span class="math notranslate nohighlight">\(j\)</span>-th لعينة معينة <span class="math notranslate nohighlight">\(i\)</span>، <span class="math notranslate nohighlight">\(y_{i,j}\)</span> هي القيمة الحقيقية المقابلة،
<span class="math notranslate nohighlight">\(n_\text{samples}\)</span> هو عدد العينات و <span class="math notranslate nohighlight">\(n_\text{labels}\)</span>
هو عدد العلامات، عندئذٍ يتم تعريف خسارة هامنج <span class="math notranslate nohighlight">\(L_{Hamming}\)</span> كما يلي:</p>
<div class="math notranslate nohighlight">
\[L_{Hamming}(y, \hat{y}) = \frac{1}{n_\text{samples} * n_\text{labels}} \sum_{i=0}^{n_\text{samples}-1} \sum_{j=0}^{n_\text{labels} - 1} 1(\hat{y}_{i,j} \not= y_{i,j})\]</div>
<p>حيث <span class="math notranslate nohighlight">\(1(x)\)</span> هي <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">الدالة المؤشرة</a>.</p>
<p>المعادلة أعلاه لا تصح في حالة التصنيف متعدد الفئات.
يرجى الرجوع إلى الملاحظة أدناه لمزيد من المعلومات.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">hamming_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hamming_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.25</span>
</pre></div>
</div>
<p>في حالة التصنيف متعدد العلامات مع مؤشرات العلامات الثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hamming_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.75</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<blockquote>
<div><p>في التصنيف متعدد الفئات، تتوافق خسارة هامنج مع مسافة هامنج بين <code class="docutils literal notranslate"><span class="pre">y_true</span></code> و <code class="docutils literal notranslate"><span class="pre">y_pred</span></code> والتي تشبه
<a class="reference internal" href="#zero-one-loss"><span class="std std-ref">خسارة الصفر واحد</span></a> function. ومع ذلك، في حين أن الخسارة الصفرية-واحدة تعاقب مجموعات التنبؤ التي لا تتطابق بشكل صارم مع المجموعات الحقيقية، فإن خسارة هامنج تعاقب العلامات الفردية. وهكذا، فإن خسارة هامنج، التي تكون محصورة من الأعلى بواسطة الخسارة الصفرية-واحدة، تكون دائمًا بين الصفر والواحد، بما في ذلك؛ والتنبؤ بمجموعة فرعية صحيحة</p>
</div></blockquote>
<p>أو مجموعة فائقة من العلامات الحقيقية ستعطي خسارة هامنج بين
الصفر والواحد، باستثناء.</p>
</div>
<p id="precision-recall-f-measure-metrics">الدقة، الاستدعاء، ومقاييس F
بداهة، الدقة هي قدرة المصنف على عدم وسم عينة سلبية على أنها إيجابية، أما الاستدعاء فهو قدرة المصنف على إيجاد جميع العينات الإيجابية.</p>
<p>يمكن تفسير مقياس F (مقاييس F1 و F-beta) على أنه المتوسط الهارموني المرجح للدقة والاستدعاء. ويحصل مقياس F-beta على أفضل قيمة له عند 1 وأسوأ درجة له عند 0. عندما يكون بيتا = 1، يكون F-beta و F1 متكافئين، وتكون الدقة والاستدعاء متساويين في الأهمية.</p>
<p>تقوم دالة “precision_recall_curve” بحساب منحنى الدقة والاستدعاء من التصنيف الصحيح لعينة الاختبار ومن درجة معينة يمنحها المصنف، وذلك عن طريق تغيير عتبة القرار.</p>
<p>تقوم دالة “average_precision_score” بحساب المتوسط الدقيق (AP) من درجات التنبؤ. وتكون القيمة بين 0 و1، وكلما كانت أعلى كانت أفضل. يتم تعريف AP على النحو التالي:</p>
<p>AP = ∑(R_n - R_(n-1)) * P_n</p>
<p>حيث P_n و R_n هي الدقة والاستدعاء عند العتبة n. ومع التنبؤات العشوائية، يكون AP هو نسبة العينات الإيجابية.</p>
<p>تقدم المرجعان [Manning2008] و [Everingham2010] متغيرات بديلة لـ AP تُدخل منحنى الدقة والاستدعاء. حاليًا، لا تقوم دالة “average_precision_score” بتنفيذ أي متغير مُدخل. ويصف المرجعان [Davis2006] و [Flach2015] سبب كون الاستيفاء الخطي للنقاط على منحنى الدقة والاستدعاء مقياسًا متفائلاً بشكل مفرط لأداء المصنف. ويُستخدم هذا الاستيفاء الخطي عند حساب المساحة تحت المنحنى باستخدام قاعدة الترトラيد في دالة “auc”.</p>
<p>هناك عدة دوال تسمح لك بتحليل درجات الدقة والاستدعاء ومقاييس F:</p>
<p>autosummary:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">average_precision_score</span>
<span class="n">f1_score</span>
<span class="n">fbeta_score</span>
<span class="n">precision_recall_curve</span>
<span class="n">precision_recall_fscore_support</span>
<span class="n">precision_score</span>
<span class="n">recall_score</span>
</pre></div>
</div>
<p>لاحظ أن دالة “precision_recall_curve” مقيدة بالحالة الثنائية. وتدعم دالة “average_precision_score” التنسيقات متعددة التصنيفات والعلامات المتعددة بحساب درجة كل صنف بطريقة “واحد مقابل الباقي” (OvR) ومتوسطها أو عدم ذلك اعتمادًا على قيمة وسيط “average”.</p>
<p>تقوم الدالتان “PrecisionRecallDisplay.from_estimator” و “PrecisionRecallDisplay.from_predictions” برسم منحنى الدقة والاستدعاء على النحو التالي.</p>
<p>الصورة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">../</span><span class="n">auto_examples</span><span class="o">/</span><span class="n">model_selection</span><span class="o">/</span><span class="n">images</span><span class="o">/</span><span class="n">sphx_glr_plot_precision_recall_001</span><span class="o">.</span><span class="n">png</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">target<span class="colon">:</span></dt>
<dd class="field-odd"><p>../auto_examples/model_selection/plot_precision_recall.html#plot-the-precision-recall-curve</p>
</dd>
<dt class="field-even">scale<span class="colon">:</span></dt>
<dd class="field-even"><p>75</p>
</dd>
<dt class="field-odd">align<span class="colon">:</span></dt>
<dd class="field-odd"><p>center</p>
</dd>
</dl>
<p>الأمثلة</p>
<ul class="simple">
<li><p>انظر إلى: ref:sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py للحصول على مثال على استخدام “precision_score” و “recall_score” لتقدير المعلمات باستخدام البحث الشبكي مع التصديق المتقاطع المُعشش.</p></li>
<li><p>انظر إلى: ref:sphx_glr_auto_examples_model_selection_plot_precision_recall.py للحصول على مثال على استخدام “precision_recall_curve” لتقييم جودة إخراج المصنف.</p></li>
</ul>
<p>المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="manning2008" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Manning2008<span class="fn-bracket">]</span></span>
<p>C.D. Manning, P. Raghavan, H. Schütze, <a class="reference external" href="https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html">Introduction to Information Retrieval</a>, 2008.</p>
</div>
<div class="citation" id="everingham2010" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Everingham2010<span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="13">
<li><p>Everingham, L. Van Gool, C.K.I. Williams, J. Winn, A. Zisserman, <a class="reference external" href="https://citeseerx.ist.psu.edu/doc_view/pid/b6bebfd529b233f00cb854b7d8070319600cf59d">The Pascal Visual Object Classes (VOC) Challenge</a>, IJCV 2010.</p></li>
</ol>
</div>
<div class="citation" id="davis2006" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Davis2006<span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="10">
<li><p>Davis, M. Goadrich, <a class="reference external" href="https://www.biostat.wisc.edu/~page/rocpr.pdf">The Relationship Between Precision-Recall and ROC Curves</a>, ICML 2006.</p></li>
</ol>
</div>
<div class="citation" id="flach2015" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Flach2015<span class="fn-bracket">]</span></span>
<p>P.A. Flach, M. Kull, <a class="reference external" href="https://papers.nips.cc/paper/5867-precision-recall-gain-curves-pr-analysis-done-right.pdf">Precision-Recall-Gain Curves: PR Analysis Done Right</a>, NIPS 2015.</p>
</div>
</div>
<p>التصنيف الثنائي</p>
<p>في مهمة التصنيف الثنائي، يشير المصطلحان “إيجابي” و”سلبي” إلى تنبؤ المصنف، ويشير المصطلحان “صحيح” و”خاطئ” إلى ما إذا كان هذا التنبؤ يتوافق مع الحكم الخارجي (يُعرف أحيانًا باسم “الملاحظة”). وبناءً على هذه التعريفات، يمكننا صياغة الجدول التالي:</p>
<p>في هذا السياق، يمكننا تعريف مفهومي الدقة والاستدعاء:</p>
<p>الدقة = tp / (tp + fp)</p>
<p>الاستدعاء = tp / (tp + fn)</p>
<p>(يُطلق على الاستدعاء أحيانًا اسم “الحساسية”)</p>
<p>F-measure هو المتوسط الهارموني المرجح للدقة والاستدعاء، مع وزن مساهمة الدقة في المتوسط بواسطة معامل ما:</p>
<p>F_beta = (1 + beta^2) * (الدقة * الاستدعاء) / ((beta^2 * الدقة) + الاستدعاء)</p>
<p>لتجنب القسمة على الصفر عندما تكون الدقة والاستدعاء صفرًا، يحسب Scikit-Learn مقياس F باستخدام الصيغة المكافئة التالية:</p>
<p>F_beta = ((1 + beta^2) * tp) / ((1 + beta^2) * tp + fp + beta^2 * fn)</p>
<p>لاحظ أن هذه الصيغة غير محددة أيضًا عندما لا توجد نتائج إيجابية صحيحة أو خاطئة إيجابية أو خاطئة سلبية. وبشكل افتراضي، يتم حساب F-1 لمجموعة من السلبيات الصحيحة الحصرية على أنها 0، ومع ذلك يمكن تغيير هذا السلوك باستخدام وسيط “zero_division”.</p>
<p>فيما يلي بعض الأمثلة الصغيرة في التصنيف الثنائي:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">0.83...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">0.66...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.55...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">(array([0.66..., 1.        ]), array([1. , 0.5]), array([0.71..., 0.83...]), array([2, 2]))</span>


<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">precision</span>
<span class="go">array([0.5       , 0.66..., 0.5       , 1.        , 1.        ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">recall</span>
<span class="go">array([1. , 1. , 0.5, 0.5, 0. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">threshold</span>
<span class="go">array([0.1 , 0.35, 0.4 , 0.8 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>
<span class="go">0.83...</span>
</pre></div>
</div>
<p>التصنيف متعدد التصنيفات والعلامات المتعددة</p>
<p>في مهمة التصنيف متعدد التصنيفات والعلامات المتعددة، يمكن تطبيق مفاهيم الدقة والاستدعاء ومقاييس F على كل علامة بشكل مستقل.</p>
<p>هناك عدة طرق لدمج النتائج عبر العلامات، محددة بوسيط “average” في دوال “average_precision_score” و “f1_score” و “fbeta_score” و “precision_recall_fscore_support” و “precision_score” و “recall_score”، كما هو موضح أعلاه &lt;average&gt;.</p>
<p>لاحظ السلوكيات التالية عند حساب المتوسط:</p>
<ul class="simple">
<li><p>إذا تم تضمين جميع العلامات، فإن حساب المتوسط “micro” في إعداد متعدد التصنيفات سينتج عنه دقة واستدعاء ومقياس F متطابقة جميعها مع الدقة.</p></li>
<li><p>قد ينتج حساب المتوسط “weighted” مقياس F لا يقع بين الدقة والاستدعاء.</p></li>
<li><p>يتم حساب المتوسط “macro” لمقاييس F على أنه المتوسط الحسابي لمقاييس F لكل علامة/صنف، وليس المتوسط الهارموني للمتوسطات الحسابية للدقة والاستدعاء. ويمكن رؤية كلا الحسابين في الأدبيات ولكنهما غير متكافئين، راجع [OB2019] للتفاصيل.</p></li>
</ul>
<p>ولتوضيح ذلك أكثر، ضع في اعتبارك الملاحظات التالية:</p>
<ul class="simple">
<li><p>y هي مجموعة الأزواج <em>(sample، label)</em> الصحيحة</p></li>
<li><p>y_hat هي مجموعة الأزواج <em>(sample، label)</em> المتوقعة</p></li>
<li><p>L هي مجموعة العلامات</p></li>
<li><p>S هي مجموعة العينات</p></li>
<li><p>y_s هي المجموعة الفرعية لـ y التي تحتوي على العينة s، أي y_s := {(s’, l) in y | s’ = s}</p></li>
<li><p>y_l هي المجموعة الفرعية لـ y التي تحتوي على العلامة l</p></li>
<li><p>وبالمثل، y_hat_s و y_hat_l هما المجموعتان الفرعيتان لـ y_hat</p></li>
<li><p>P(A، B) := | A ∩ B | / <a href="#id59"><span class="problematic" id="id60">|B|</span></a> لمجموعتين A و B</p></li>
<li><p>R(A، B) := | A ∩ B | / <a href="#id61"><span class="problematic" id="id62">|A|</span></a> (تختلف الاتفاقيات حول التعامل مع A = ∅؛ يستخدم هذا التنفيذ R(A، B):=0، وبالمثل لـ P)</p></li>
<li><p>F_beta(A، B) := (1 + beta^2) * P(A، B) * R(A، B) / (beta^2 * P(A، B) + R(A، B))</p></li>
</ul>
<p>ثم يتم تعريف المقاييس على النحو التالي:
فيما يلي ترجمة لنص RST باللغة العربية مع اتباع التعليمات المذكورة:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.22...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.33...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
<span class="go">0.26...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">fbeta_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">0.23...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">(array([0.66..., 0.        , 0.        ]), array([1., 0., 0.]), array([0.71..., 0.        , 0.        ]), array([2, 2, 2]...))</span>
</pre></div>
</div>
<p>بالنسبة للتصنيف متعدد الفئات مع “الصنف السلبي”، من الممكن استبعاد بعض التصنيفات:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="gp">... </span><span class="c1"># استبعاد 0، لم يتم استدعاء أي تصنيف بشكل صحيح</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>وبالمثل، قد يتم أخذ التصنيفات غير الموجودة في عينة البيانات في الاعتبار عند حساب المتوسط الكلي.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.166...</span>
</pre></div>
</div>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="ob2019" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>OB2019<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://arxiv.org/abs/1911.03347">Opitz, J.; Burst, S. (2019). “Macro f1 and macro f1.”</a></p>
</div>
</div>
<p id="jaccard-similarity-score">معامل تشابه جاكارد
وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">jaccard_score</span></code> تحسب متوسط ‘معاملات التشابه جكارد &lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Jaccard_index">https://en.wikipedia.org/wiki/Jaccard_index</a>&gt;`_، والتي يطلق عليها أيضًا مؤشر جكارد، بين أزواج مجموعات العلامات.</p>
<p>معامل تشابه جكارد مع مجموعة العلامات المرجعية الحقيقية <span class="math notranslate nohighlight">\(y\)</span> ومجموعة العلامات المتوقعة <span class="math notranslate nohighlight">\(\hat{y}\)</span>، يتم تعريفه على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[J(y, \hat{y}) = \frac{|y \cap \hat{y}|}{|y \cup \hat{y}|}.\]</div>
<p>تطبق وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">jaccard_score</span></code> (مثل <code class="xref py py-func docutils literal notranslate"><span class="pre">precision_recall_fscore_support</span></code>) بشكل أصلي على الأهداف الثنائية. من خلال حسابها على أساس مجموعة، يمكن توسيع نطاقها لتطبيقها على التصنيفات المتعددة والمتعددة الفئات من خلال استخدام “المتوسط” (انظر <span class="xref std std-ref">above</span>).</p>
<p>في الحالة الثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">jaccard_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="go">0.6666...</span>
</pre></div>
</div>
<p>في حالة المقارنة ثنائية الأبعاد (على سبيل المثال، تشابه الصور):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;micro&quot;</span><span class="p">)</span>
<span class="go">0.6</span>
</pre></div>
</div>
<p>في حالة التصنيف المتعدد مع مؤشرات العلامات الثنائية:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;samples&#39;</span><span class="p">)</span>
<span class="go">0.5833...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.6666...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_</span> <span class="n">topscorer</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.5, 0.5, 1. ])</span>
</pre></div>
</div>
<p>يتم تحويل مشكلات التصنيف المتعدد إلى الشكل الثنائي ومعاملتها مثل مشكلة التصنيف المتعدد المقابلة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([1. , 0. , 0.33...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)</span>
<span class="go">0.44...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">jaccard_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
<span class="go">0.33...</span>
</pre></div>
</div>
</section>
<section id="hinge-loss">
<span id="id13"></span><h2><span class="section-number">3.9.6. </span>خسارة المفصل<a class="headerlink" href="#hinge-loss" title="Link to this heading">#</a></h2>
<p>تحسب وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code> متوسط المسافة بين
النموذج والبيانات باستخدام
<a class="reference external" href="https://en.wikipedia.org/wiki/Hinge_loss">خسارة المفصل</a>، وهو مقياس أحادي الجانب
لا يأخذ في الاعتبار سوى أخطاء التنبؤ. (تُستخدم خسارة المفصل في مصنفات الهامش الأقصى مثل آلات المتجهات الداعمة.)</p>
<p>إذا كانت العلامة الحقيقية <span class="math notranslate nohighlight">\(y_i\)</span> لمهمة تصنيف ثنائي مشفرة على النحو
<span class="math notranslate nohighlight">\(y_i=\left\{-1, +1\right\}\)</span> لكل عينة <span class="math notranslate nohighlight">\(i\)</span>؛ و <span class="math notranslate nohighlight">\(w_i\)</span>
هو القرار المتوقع المقابل (مصفوفة ذات شكل (<code class="docutils literal notranslate"><span class="pre">n_samples</span></code>،) كما
يتم إخراجه بواسطة طريقة <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>)، عندئذٍ يتم تعريف خسارة المفصل على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[L_\text{Hinge}(y, w) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} \max\left\{1 - w_i y_i, 0\right\}\]</div>
<p>إذا كان هناك أكثر من علامتين، فإن <code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code> تستخدم متغيرًا متعدد الفئات
بسبب كرامر وسينجر.
<a class="reference external" href="https://jmlr.csail.mit.edu/papers/volume2/crammer01a/crammer01a.pdf">هنا</a> هي
الورقة التي تصفها.</p>
<p>في هذه الحالة، القرار المتوقع هو مصفوفة ذات شكل (<code class="docutils literal notranslate"><span class="pre">n_samples</span></code>،
<code class="docutils literal notranslate"><span class="pre">n_labels</span></code>). إذا كانت <span class="math notranslate nohighlight">\(w_{i, y_i}\)</span> هي القرار المتوقع لعلامة حقيقية
<span class="math notranslate nohighlight">\(y_i\)</span> للعينة <span class="math notranslate nohighlight">\(i\)</span>-th؛ و
<span class="math notranslate nohighlight">\(\hat{w}_{i, y_i} = \max\left\{w_{i, y_j}~|~y_j \ne y_i \right\}\)</span>
هو الحد الأقصى
للقرارات المتوقعة لجميع العلامات الأخرى، عندئذٍ يتم تعريف خسارة المفصل متعدد الفئات
على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[L_\text{Hinge}(y, w) = \frac{1}{n_\text{samples}}
\sum_{i=0}^{n_\text{samples}-1} \max\left\{1 + \hat{w}_{i, y_i}
- w_{i، y_i}، 0\right\}\]</div>
<p>فيما يلي مثال صغير يوضح استخدام وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code>
مع مصنف SVM في مشكلة ذات فئتين:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">hinge_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">LinearSVC(random_state=0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span>
<span class="go">array([-2.18...,  2.36...,  0.09...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hinge_loss</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">pred_decision</span><span class="p">)</span>
<span class="go">0.3...</span>
</pre></div>
</div>
<p>فيما يلي مثال يوضح استخدام وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">hinge_loss</span></code>
مع مصنف SVM في مشكلة متعددة الفئات:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">LinearSVC</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="go">LinearSVC()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pred_decision</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">decision_function</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hinge_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">pred_decision</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="go">0.56...</span>
</pre></div>
</div>
</section>
<section id="log-loss">
<span id="id16"></span><h2><span class="section-number">3.9.7. </span>خسارة السجل<a class="headerlink" href="#log-loss" title="Link to this heading">#</a></h2>
<p>خسارة السجل، والتي يطلق عليها أيضًا خسارة الانحدار اللوجستي أو
خسارة الانتروبيا المتقاطعة، يتم تعريفها على تقديرات الاحتمالية. يتم
استخدامه بشكل شائع في الانحدار اللوجستي (المتعدد الحدود) والشبكات العصبية، وكذلك
في بعض المتغيرات من التوقع الأقصى، ويمكن استخدامه لتقييم
نواتج الاحتمالية (<code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>) لمصنف بدلاً من تنبؤاته المحددة.</p>
<p>بالنسبة للتصنيف الثنائي مع علامة حقيقية <span class="math notranslate nohighlight">\(y \in \{0,1\}\)</span>
وتقدير احتمالية <span class="math notranslate nohighlight">\(p = \operatorname{Pr}(y = 1)\)</span>،
تكون خسارة السجل لكل عينة هي الاحتمالية السالبة للاحتمالية
للمصنف بالنظر إلى العلامة الحقيقية:</p>
<div class="math notranslate nohighlight">
\[L_{\log}(y, p) = -\log \operatorname{Pr}(y|p) = -(y \log (p) + (1 - y) \log (1 - p))\]</div>
<p>يتم توسيع هذا إلى حالة الفئات المتعددة على النحو التالي.
دع العلامات الحقيقية لمجموعة من العينات
يتم تشفيرها كمصفوفة مؤشر ثنائي 1-of-K <span class="math notranslate nohighlight">\(Y\)</span>،
أي <span class="math notranslate nohighlight">\(y_{i,k} = 1\)</span> إذا كانت العينة <span class="math notranslate nohighlight">\(i\)</span> لها علامة <span class="math notranslate nohighlight">\(k\)</span>
مأخوذة من مجموعة من <span class="math notranslate nohighlight">\(K\)</span> العلامات.
دع <span class="math notranslate nohighlight">\(P\)</span> تكون مصفوفة من تقديرات الاحتمالية،
مع <span class="math notranslate nohighlight">\(p_{i,k} = \operatorname{Pr}(y_{i,k} = 1)\)</span>.
عندئذٍ تكون خسارة السجل للمجموعة بأكملها هي</p>
<div class="math notranslate nohighlight">
\[L_{\log}(Y, P) = -\log \operatorname{Pr}(Y|P) = - \frac{1}{N} \sum_{i=0}^{N-1} \sum_{k=0}^{K-1} y_{i,k} \log p_{i,k}\]</div>
<p>ولرؤية كيف يعمم هذا خسارة السجل الثنائية المعطاة أعلاه،
لاحظ أنه في الحالة الثنائية،
<span class="math notranslate nohighlight">\(p_{i,0} = 1 - p_{i,1}\)</span> و <span class="math notranslate nohighlight">\(y_{i,0} = 1 - y_{i,1}\)</span>،
لذا فإن توسيع المبلغ الداخلي على <span class="math notranslate nohighlight">\(y_{i,k} \in \{0,1\}\)</span>
يعطي خسارة السجل الثنائية.</p>
<p>تحسب وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">log_loss</span></code> خسارة السجل بالنظر إلى قائمة من العلامات المرجعية
ومصفوفة احتمالية، كما هو موضح بواسطة طريقة “predict_proba” للمصنف.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">.9</span><span class="p">,</span> <span class="mf">.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">.8</span><span class="p">,</span> <span class="mf">.2</span><span class="p">],</span> <span class="p">[</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">.01</span><span class="p">,</span> <span class="mf">.99</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.1738...</span>
</pre></div>
</div>
<p>يشير “ [0.9، 0.1]” الأول في “y_pred” إلى احتمال 90% أن العينة الأولى
لها علامة 0. خسارة السجل غير سالبة.</p>
</section>
<section id="matthews-corrcoef">
<span id="id17"></span><h2><span class="section-number">3.9.8. </span>معامل ارتباط ماثيوز<a class="headerlink" href="#matthews-corrcoef" title="Link to this heading">#</a></h2>
<p>تحسب وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code>
<a class="reference external" href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">معامل ارتباط ماثيوز (MCC)</a>
لفئات ثنائية. اقتباسا من ويكيبيديا:</p>
<blockquote>
<div><p>“يُستخدم معامل ارتباط ماثيوز في التعلم الآلي كمقياس
لجودة التصنيفات الثنائية (ذات الفئتين). يأخذ في الاعتبار
القيم الصحيحة والإيجابية والسلبية الكاذبة ويُنظر إليه عمومًا
على أنه مقياس متوازن يمكن استخدامه حتى إذا كانت الفئات
ذات أحجام مختلفة جدًا. MCC هو في جوهره معامل ارتباط
القيمة بين -1 و +1. يمثل المعامل 1 تنبؤًا مثاليًا،
0 تنبؤًا عشوائيًا متوسطًا و -1 تنبؤًا عكسيًا.
يُعرف الإحصائي أيضًا باسم معامل في.”</p>
</div></blockquote>
<p>في الحالة الثنائية (ذات الفئتين)، <span class="math notranslate nohighlight">\(tp\)</span>، <span class="math notranslate nohighlight">\(tn\)</span>، <span class="math notranslate nohighlight">\(fp\)</span> و
<span class="math notranslate nohighlight">\(fn\)</span> هي على التوالي عدد القيم الصحيحة الإيجابية، والقيم السلبية الصحيحة، والقيم الإيجابية الكاذبة
والسلبيات الكاذبة، يتم تعريف MCC على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[MCC = \frac{tp \times tn - fp \times fn}{\sqrt{(tp + fp)(tp + fn)(tn + fp)(tn + fn)}}.\]</div>
<p>في حالة الفئات المتعددة، يمكن تعريف معامل ارتباط ماثيوز `
&lt;<a class="reference external" href="http://rk.kvl.dk/introduction/index.html">http://rk.kvl.dk/introduction/index.html</a>&gt;`_ من حيث
<code class="xref py py-func docutils literal notranslate"><span class="pre">confusion_matrix</span></code> <span class="math notranslate nohighlight">\(C\)</span> لـ <span class="math notranslate nohighlight">\(K\)</span> الفئات. لتبسيط
التعريف، ضع في اعتبارك المتغيرات المتوسطة التالية:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(t_k=\sum_{i}^{K} C_{ik}\)</span> عدد المرات التي تحدث فيها الفئة <span class="math notranslate nohighlight">\(k\)</span> بشكل حقيقي،</p></li>
<li><p><span class="math notranslate nohighlight">\(p_k=\sum_{i}^{K} C_{ki}\)</span> عدد المرات التي تم التنبؤ فيها بالفئة <span class="math notranslate nohighlight">\(k\)</span>،</p></li>
<li><p><span class="math notranslate nohighlight">\(c=\sum_{k}^{K} C_{kk}\)</span> العدد الإجمالي للعينات التي تم التنبؤ بها بشكل صحيح،</p></li>
<li><p><span class="math notranslate nohighlight">\(s=\sum_{i}^{K} \sum_{j}^{K} C_{ij}\)</span> العدد الإجمالي للعينات.</p></li>
</ul>
<p>عندئذٍ يتم تعريف MCC متعدد الفئات على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[MCC = \frac{
    c \times s - \sum_{k}^{K} p_k \times t_k
}{\sqrt{
    (s^2 - \sum_{k}^{K} p_k^2) \times
    (s^2 - \sum_{k}^{K} t_k^2)
}}\]</div>
<p>عندما يكون هناك أكثر من علامتين، لن يتراوح نطاق قيمة MCC
بعد الآن بين -1 و +1. بدلاً من ذلك، ستكون القيمة الدنيا في مكان ما بين -1 و0
اعتمادًا على عدد وتوزيع العلامات المرجعية الحقيقية. القيمة القصوى
هي دائمًا +1.
للحصول على معلومات إضافية، راجع <a class="reference internal" href="#wikipediamcc2021" id="id18"><span>[WikipediaMCC2021]</span></a>.</p>
<p>فيما يلي مثال صغير يوضح استخدام وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">matthews_corrcoef</span></code>
:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">matthews_corrcoef</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">matthews_corrcoef</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">-0.33...</span>
</pre></div>
</div>
<aside class="topic">
<p class="topic-title">المراجع:</p>
<div role="list" class="citation-list">
<div class="citation" id="wikipediamcc2021" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">WikipediaMCC2021</a><span class="fn-bracket">]</span></span>
<p>مساهمون في ويكيبيديا. معامل في.
ويكيبيديا، الموسوعة الحرة. 21 أبريل 2021، 12:21 بتوقيت وسط أوروبا الصيفي.
متاح في: <a class="reference external" href="https://en.wikipedia.org/wiki/Phi_coefficient">https://en.wikipedia.org/wiki/Phi_coefficient</a>
تم الوصول إليه في 21 أبريل 2021.</p>
</div>
</div>
</aside>
<p id="multilabel-confusion-matrix">مصفوفة الارتباك متعددة التصنيفات
تقوم دالة :func: <code class="docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code> بحساب مصفوفة التباس متعددة التصنيفات خاصة بالصنف (افتراضيًا) أو خاصة بالعينة (عند samplewise=True) لتقييم دقة التصنيف. كما تعامل دالة multilabel_confusion_matrix البيانات متعددة التصنيفات كما لو كانت متعددة التصنيفات، حيث أن هذا التحول يُطبق بشكل شائع لتقييم مشكلات متعددة التصنيفات باستخدام مقاييس التصنيف الثنائي (مثل الدقة، والاستدعاء، وما إلى ذلك).</p>
<p>عند حساب مصفوفة التباس متعددة التصنيفات خاصة بالصنف <span class="math notranslate nohighlight">\(C\)</span>، يكون عدد السلبيات الحقيقية للصنف <span class="math notranslate nohighlight">\(i\)</span> هو <span class="math notranslate nohighlight">\(C_{i,0,0}\)</span>، والسلبيات الخاطئة هي <span class="math notranslate nohighlight">\(C_{i,1,0}\)</span>، والإيجابيات الحقيقية هي <span class="math notranslate nohighlight">\(C_{i,1,1}\)</span>، والإيجابيات الخاطئة هي <span class="math notranslate nohighlight">\(C_{i,0,1}\)</span>.</p>
<p>هذا مثال يوضح استخدام دالة :func: <code class="docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code> مع مصفوفة مؤشر متعددة التصنيفات كمدخل:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">multilabel_confusion_matrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">array([[[1, 0],</span>
<span class="go">        [0, 1]],</span>

<span class="go">       [[1, 0],</span>
<span class="go">        [0, 1]],</span>

<span class="go">       [[0, 1],</span>
<span class="go">        [1, 0]]])</span>
</pre></div>
</div>
<p>أو يمكن إنشاء مصفوفة التباس لكل تسميات العينة:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">samplewise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">array([[[1, 0],</span>
<span class="go">        [1, 1]],</span>

<span class="go">       [[1, 1],</span>
<span class="go">        [0, 1]]])</span>
</pre></div>
</div>
<p>هذا مثال يوضح استخدام دالة :func: <code class="docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code> مع مدخل متعدد التصنيفات:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span>
<span class="gp">... </span>                            <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;ant&quot;</span><span class="p">,</span> <span class="s2">&quot;bird&quot;</span><span class="p">,</span> <span class="s2">&quot;cat&quot;</span><span class="p">])</span>
<span class="go">array([[[3, 1],</span>
<span class="go">        [0, 2]],</span>

<span class="go">       [[5, 0],</span>
<span class="go">        [1, 0]],</span>

<span class="go">       [[2, 1],</span>
<span class="go">        [1, 2]]])</span>
</pre></div>
</div>
<p>فيما يلي بعض الأمثلة التي توضح استخدام دالة :func: <code class="docutils literal notranslate"><span class="pre">multilabel_confusion_matrix</span></code> لحساب الاستدعاء (أو الحساسية)، والخصوصية، ومعدل السقوط، ومعدل الإخفاق لكل صنف في مشكلة مع مصفوفة مؤشر متعددة التصنيفات كمدخل.</p>
<p>حساب الاستدعاء
<a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">recall</a>
(المعروف أيضًا باسم معدل الإيجابيات الحقيقية أو الحساسية) لكل صنف:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mcm</span> <span class="o">=</span> <span class="n">multilabel_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tp</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fn</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fp</span> <span class="o">=</span> <span class="n">mcm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
<span class="go">array([1. , 0.5, 0. ])</span>
</pre></div>
</div>
<p>حساب الخصوصية
<a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">specificity</a>
(المعروف أيضًا باسم معدل السلبيات الحقيقية) لكل صنف:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
<span class="go">array([1. , 0. , 0.5])</span>
</pre></div>
</div>
<p>حساب معدل السقوط
<a class="reference external" href="https://en.wikipedia.org/wiki/False_positive_rate">fall out</a>
(المعروف أيضًا باسم معدل الإيجابيات الخاطئة) لكل صنف:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fp</span> <span class="o">/</span> <span class="p">(</span><span class="n">fp</span> <span class="o">+</span> <span class="n">tn</span><span class="p">)</span>
<span class="go">array([0. , 1. , 0.5])</span>
</pre></div>
</div>
<p>حساب معدل الإخفاق
<a class="reference external" href="https://en.wikipedia.org/wiki/False_positives_and_false_negatives">miss rate</a>
(المعروف أيضًا باسم معدل السلبيات الخاطئة) لكل صنف:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fn</span> <span class="o">/</span> <span class="p">(</span><span class="n">fn</span> <span class="o">+</span> <span class="n">tp</span><span class="p">)</span>
<span class="go">array([0. , 0.5, 1. ])</span>
</pre></div>
</div>
<p id="roc-metrics">Receiver operating characteristic (ROC)
حساب دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">roc_curve</span></code> لمنحنى خاصية تشغيل المستقبل (ROC) أو منحنى ROC. ونقلاً عن ويكيبيديا:</p>
<blockquote>
<div><p>“منحنى خاصية تشغيل المستقبل (ROC)، أو ببساطة منحنى ROC، هو رسم بياني يوضح أداء نظام تصنيف ثنائي بينما يتم تغيير عتبة التمييز. يتم إنشاؤه عن طريق رسم نسبة الإيجابيات الحقيقية من الإيجابيات (TPR = معدل الإيجابية الحقيقية) مقابل نسبة الإيجابيات الخاطئة من السلبيات (FPR = معدل الإيجابية الخاطئة)، عند إعدادات العتبة المختلفة. كما يُعرف TPR بالحساسية، وFPR هو واحد ناقص النوعية أو معدل السلبيات الحقيقية.”</p>
</div></blockquote>
<p>تتطلب هذه الدالة القيمة الثنائية الصحيحة والدرجات المستهدفة، والتي يمكن أن تكون إما تقديرات احتمالية للفئة الإيجابية أو قيم الثقة أو القرارات الثنائية. فيما يلي مثال صغير على كيفية استخدام دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">roc_curve</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.35</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fpr</span>
<span class="go">array([0. , 0. , 0.5, 0.5, 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tpr</span>
<span class="go">array([0. , 0.5, 0.5, 1. , 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">thresholds</span>
<span class="go">array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])</span>
</pre></div>
</div>
<p>مقارنة بمقاييس مثل دقة المجموعة الفرعية أو فقدان هامينج أو نتيجة F1، لا تتطلب ROC تحسين عتبة لكل تسمية.</p>
<p>تقوم دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code>، والتي يشار إليها بـ ROC-AUC أو AUROC، بحساب المساحة تحت منحنى ROC. وبهذه الطريقة، يتم تلخيص معلومات المنحنى في رقم واحد.</p>
<p>يوضح الشكل التالي منحنى ROC ونتيجة ROC-AUC لمصنف يهدف إلى التمييز بين زهرة فيرجينيكا وباقي الأنواع في مجموعة بيانات <a class="reference internal" href="../datasets/toy_dataset.html#iris-dataset"><span class="std std-ref">Iris plants dataset</span></a>:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_roc.html"><img alt="../_images/sphx_glr_plot_roc_001.png" class="align-center" src="../_images/sphx_glr_plot_roc_001.png" style="width: 480.0px; height: 360.0px;" />
</a>
<p>للحصول على مزيد من المعلومات، راجع مقال ويكيبيديا حول AUC.</p>
<section id="roc-auc-binary">
<span id="id19"></span><h3><span class="section-number">3.9.8.1. </span>الحالة الثنائية<a class="headerlink" href="#roc-auc-binary" title="Link to this heading">#</a></h3>
<p>في <strong>الحالة الثنائية</strong>، يمكنك إما توفير تقديرات الاحتمالية، باستخدام طريقة <code class="docutils literal notranslate"><span class="pre">classifier.predict_proba()</span></code>، أو قيم القرار غير المعرفة بعتبة التي تعطيها طريقة <code class="docutils literal notranslate"><span class="pre">classifier.decision_function()</span></code>. في حالة توفير تقديرات الاحتمالية، يجب توفير احتمال الفئة ذات التسمية “الأكبر”. يقابل التسمية “الأكبر” <code class="docutils literal notranslate"><span class="pre">classifier.classes_[1]</span></code> وبالتالي <code class="docutils literal notranslate"><span class="pre">classifier.predict_proba(X)[:,</span> <span class="pre">1]</span></code>. لذلك، يكون معامل <code class="docutils literal notranslate"><span class="pre">y_score</span></code> من الحجم (n_samples،).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">classes_</span>
<span class="go">array([0, 1])</span>
</pre></div>
</div>
<p>يمكننا استخدام تقديرات الاحتمالية المقابلة لـ <code class="docutils literal notranslate"><span class="pre">clf.classes_[1]</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_score</span><span class="p">)</span>
<span class="go">0.99...</span>
</pre></div>
</div>
<p>وبخلاف ذلك، يمكننا استخدام قيم القرار غير المعرفة بعتبة</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="go">0.99...</span>
</pre></div>
</div>
</section>
<section id="roc-auc-multiclass">
<span id="id20"></span><h3><span class="section-number">3.9.8.2. </span>حالة التصنيف متعدد الفئات<a class="headerlink" href="#roc-auc-multiclass" title="Link to this heading">#</a></h3>
<p>يمكن أيضًا استخدام دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code> في <strong>التصنيف متعدد الفئات</strong>. يتم دعم إستراتيجيتي المتوسط حاليًا: تحسب خوارزمية واحد-مقابل-واحد متوسط درجات ROC AUC الزوجية، وتحسب خوارزمية واحد-مقابل-الباقي متوسط درجات ROC AUC لكل فئة مقابل جميع الفئات الأخرى. في كلتا الحالتين، يتم توفير التسميات المتوقعة في مصفوفة بالقيم من 0 إلى <code class="docutils literal notranslate"><span class="pre">n_classes</span></code>، وتتوافق الدرجات مع تقديرات الاحتمالية بأن عينة ما تنتمي إلى فئة معينة. تدعم خوارزميتا OvO وOvR الوزن بالتساوي (<code class="docutils literal notranslate"><span class="pre">average='macro'</span></code>) ووفقًا للانتشار (<code class="docutils literal notranslate"><span class="pre">average='weighted'</span></code>).</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="خوارزمية-واحد-مقابل-واحد">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">خوارزمية واحد-مقابل-واحد<a class="headerlink" href="#خوارزمية-واحد-مقابل-واحد" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يحسب متوسط AUC لجميع المجموعات الزوجية الممكنة من الفئات. <a class="reference internal" href="#ht2001" id="id21"><span>[HT2001]</span></a> يعرف مقياس AUC متعدد الفئات المرجح بالتساوي على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{c(c-1)}\sum_{j=1}^{c}\sum_{k &gt; j}^c (\text{AUC}(j | k) +
\text{AUC}(k | j))\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(c\)</span> هو عدد الفئات و:math:<code class="docutils literal notranslate"><span class="pre">text{AUC}(j</span> <span class="pre">|</span> <span class="pre">k)</span></code> هو AUC مع الفئة <span class="math notranslate nohighlight">\(j\)</span> كفئة إيجابية والفئة <span class="math notranslate nohighlight">\(k\)</span> كفئة سلبية. بشكل عام، <span class="math notranslate nohighlight">\(\text{AUC}(j | k) \neq \text{AUC}(k | j)\)</span> في حالة الفئات المتعددة. يتم استخدام هذه الخوارزمية عن طريق تعيين وسيط <code class="docutils literal notranslate"><span class="pre">multiclass</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'ovo'</span></code> و``average`` إلى <code class="docutils literal notranslate"><span class="pre">'macro'</span></code>.</p>
<p class="sd-card-text">يمكن تمديد مقياس AUC متعدد الفئات <a class="reference internal" href="#ht2001" id="id22"><span>[HT2001]</span></a> ليكون مرجحًا بالانتشار على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{c(c-1)}\sum_{j=1}^{c}\sum_{k &gt; j}^c p(j \cup k)(
\text{AUC}(j | k) + \text{AUC}(k | j))\]</div>
<p class="sd-card-text">حيث <span class="math notranslate nohighlight">\(c\)</span> هو عدد الفئات. يتم استخدام هذه الخوارزمية عن طريق تعيين وسيط <code class="docutils literal notranslate"><span class="pre">multiclass</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'ovo'</span></code> و``average`` إلى <code class="docutils literal notranslate"><span class="pre">'weighted'</span></code>. يعيد خيار <code class="docutils literal notranslate"><span class="pre">'weighted'</span></code> متوسطًا مرجحًا بالانتشار كما هو موضح في <a class="reference internal" href="#fc2009" id="id23"><span>[FC2009]</span></a>.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="خوارزمية-واحد-مقابل-الباقي">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">خوارزمية واحد-مقابل-الباقي<a class="headerlink" href="#خوارزمية-واحد-مقابل-الباقي" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يحسب AUC لكل فئة مقابل الباقي <a class="reference internal" href="#pd2000" id="id24"><span>[PD2000]</span></a>. الخوارزمية متطابقة وظيفيًا مع حالة التصنيف متعدد التسميات. لتمكين هذه الخوارزمية، قم بتعيين وسيط <code class="docutils literal notranslate"><span class="pre">multiclass</span></code> إلى <code class="docutils literal notranslate"><span class="pre">'ovr'</span></code>. بالإضافة إلى المتوسط “macro” <a class="reference internal" href="#f2006" id="id25"><span>[F2006]</span></a> و”weighted” <a class="reference internal" href="#f2001" id="id26"><span>[F2001]</span></a>، تدعم OvR المتوسط “micro”.</p>
<p class="sd-card-text">في التطبيقات التي لا يمكن فيها تحمل معدل إيجابية خاطئة مرتفع، يمكن استخدام وسيط <code class="docutils literal notranslate"><span class="pre">max_fpr</span></code> للدالة <code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code> لتلخيص منحنى ROC حتى الحد المعطى.</p>
<p class="sd-card-text">يوضح الشكل التالي منحنى ROC المتوسط-الميكرو ونتيجة ROC-AUC المقابلة لمصنف يهدف إلى التمييز بين الأنواع المختلفة في مجموعة بيانات <a class="reference internal" href="../datasets/toy_dataset.html#iris-dataset"><span class="std std-ref">Iris plants dataset</span></a>:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_roc.html"><img alt="../_images/sphx_glr_plot_roc_002.png" class="align-center" src="../_images/sphx_glr_plot_roc_002.png" style="width: 480.0px; height: 360.0px;" />
</a>
</div>
</details></section>
<section id="roc-auc-multilabel">
<span id="id27"></span><h3><span class="section-number">3.9.8.3. </span>حالة التصنيف متعدد التسميات<a class="headerlink" href="#roc-auc-multilabel" title="Link to this heading">#</a></h3>
<p>في <strong>التصنيف متعدد التسميات</strong>، يتم تمديد دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">roc_auc_score</span></code> عن طريق حساب المتوسط على التسميات كما هو موضح في <span class="xref std std-ref">above</span>. في هذه الحالة، يجب توفير مصفوفة <code class="docutils literal notranslate"><span class="pre">y_score</span></code> من الشكل <code class="docutils literal notranslate"><span class="pre">(n_samples،</span> <span class="pre">n_classes)</span></code>. لذلك، عند استخدام تقديرات الاحتمالية، يجب تحديد احتمال الفئة ذات التسمية “الأكبر” لكل مخرج.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_multilabel_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.multioutput</span> <span class="kn">import</span> <span class="n">MultiOutputClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_multilabel_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inner_clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;liblinear&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultiOutputClassifier</span><span class="p">(</span><span class="n">inner_clf</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])</span>
</pre></div>
</div>
<p>وقيم القرار لا تتطلب مثل هذا المعالجة.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeClassifierCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">RidgeClassifierCV</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_score</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])</span>
</pre></div>
</div>
<p class="rubric">الأمثلة</p>
<ul class="simple">
<li><p>راجع <a class="reference internal" href="../auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py"><span class="std std-ref">Multiclass Receiver Operating Characteristic (ROC)</span></a> لمثال على استخدام ROC لتقييم جودة مخرجات مصنف.</p></li>
<li><p>راجع <a class="reference internal" href="../auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"><span class="std std-ref">Receiver Operating Characteristic (ROC) with cross validation</span></a> لمثال على استخدام ROC لتقييم جودة مخرجات مصنف، باستخدام التحقق الصليبي.</p></li>
<li><p>راجع <a class="reference internal" href="../auto_examples/applications/plot_species_distribution_modeling.html#sphx-glr-auto-examples-applications-plot-species-distribution-modeling-py"><span class="std std-ref">Species distribution modeling</span></a> لمثال على استخدام ROC لوضع نموذج لتوزيع الأنواع.</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="ht2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HT2001<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id21">1</a>,<a role="doc-backlink" href="#id22">2</a>)</span>
<p>Hand, D.J. and Till, R.J., (2001). <a class="reference external" href="http://link.springer.com/article/10.1023/A:1010920819831">A simple generalisation
of the area under the ROC curve for multiple class classification problems.</a>
Machine learning, 45(2), pp. 171-186.</p>
</div>
<div class="citation" id="fc2009" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id23">FC2009</a><span class="fn-bracket">]</span></span>
<p>Ferri, Cèsar &amp; Hernandez-Orallo, Jose &amp; Modroiu, R. (2009).
<a class="reference external" href="https://www.math.ucdavis.edu/~saito/data/roc/ferri-class-perf-metrics.pdf">An Experimental Comparison of Performance Measures for Classification.</a>
Pattern Recognition Letters. 30. 27-38.</p>
</div>
<div class="citation" id="pd2000" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id24">PD2000</a><span class="fn-bracket">]</span></span>
<p>Provost, F., Domingos, P. (2000). <a class="reference external" href="https://fosterprovost.com/publication/well-trained-pets-improving-probability-estimation-trees/">Well-trained PETs: Improving
probability estimation trees</a>
(Section 6.2), CeDER Working Paper #IS-00-04, Stern School of Business,
New York University.</p>
</div>
<div class="citation" id="f2006" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id25">F2006</a><span class="fn-bracket">]</span></span>
<p>Fawcett, T., 2006. <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S016786550500303X">An introduction to ROC analysis.</a>
Pattern Recognition Letters, 27(8), pp. 861-874.</p>
</div>
<div class="citation" id="f2001" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id26">F2001</a><span class="fn-bracket">]</span></span>
<p>Fawcett, T., 2001. <a class="reference external" href="https://ieeexplore.ieee.org/document/989510/">Using rule sets to maximize
ROC performance</a>
In Data Mining, 2001.
Proceedings IEEE International Conference, pp. 131-138.</p>
</div>
</div>
<p id="det-curve">منحنى مبادلة خطأ الكشف (DET)
وظيفة <code class="xref py py-func docutils literal notranslate"><span class="pre">det_curve</span></code> تحسب منحنى مبادلة خطأ الكشف (DET) <a class="reference internal" href="#wikipediadet2017" id="id28"><span>[WikipediaDET2017]</span></a>.
اقتباس من ويكيبيديا:</p>
<blockquote>
<div><p>“مخطط مبادلة خطأ الكشف (DET) هو رسم بياني لمعدلات الخطأ لأنظمة التصنيف الثنائية، حيث يرسم معدل الرفض الخاطئ مقابل معدل القبول الخاطئ. يتم ضبط محور x ومحور y بشكل غير خطي بواسطة الانحرافات المعيارية العادية الخاصة بهما (أو ببساطة عن طريق التحول اللوغاريتمي)، مما يؤدي إلى منحنيات مبادلة أكثر خطية من منحنيات ROC، وتستخدم معظم مساحة الصورة لتسليط الضوء على الاختلافات المهمة في منطقة التشغيل الحرجة.”</p>
</div></blockquote>
<p>منحنيات DET هي تنويع لمنحنيات خاصية التشغيل المستلم (ROC) حيث يتم رسم معدل السلبي الكاذب على المحور y بدلاً من معدل الإيجابي الحقيقي.
عادة ما يتم رسم منحنيات DET على مقياس الانحراف المعياري الطبيعي عن طريق التحول بـ <span class="math notranslate nohighlight">\(\phi^{-1}\)</span> (مع <span class="math notranslate nohighlight">\(\phi\)</span> كونها دالة التوزيع التراكمي).
توضح منحنيات الأداء الناتجة بوضوح مبادلة أنواع الأخطاء لخوارزميات التصنيف المعطاة.
راجع <a class="reference internal" href="#martin1997" id="id29"><span>[Martin1997]</span></a> للحصول على أمثلة وتحفيز إضافي.</p>
<p>يقارن هذا الشكل بين منحنيات ROC وDET لمصنفين مثالين في نفس مهمة التصنيف:</p>
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_det.html"><img alt="../_images/sphx_glr_plot_det_001.png" class="align-center" src="../_images/sphx_glr_plot_det_001.png" style="width: 825.0px; height: 375.0px;" />
</a>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الخصائص">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الخصائص<a class="headerlink" href="#الخصائص" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">تشكل منحنيات DET منحنى خطي على مقياس الانحراف المعياري العادي إذا كانت درجات الكشف موزعة بشكل طبيعي (أو قريبة من التوزيع الطبيعي).
وقد أظهر <a class="reference internal" href="#navratil2007" id="id30"><span>[Navratil2007]</span></a> أن العكس ليس صحيحًا بالضرورة وأن التوزيعات العامة أكثر قدرة على إنتاج منحنيات DET الخطية.</p></li>
<li><p class="sd-card-text">ينشر تحويل مقياس الانحراف المعياري العادي النقاط بحيث يشغل مساحة أكبر نسبيًا من الرسم البياني.
لذلك، قد يكون من الأسهل التمييز بين المنحنيات ذات أداء التصنيف المماثل في مخطط DET.</p></li>
<li><p class="sd-card-text">مع كون معدل السلبي الكاذب “معكوسًا” لمعدل الإيجابي الحقيقي، فإن نقطة الكمال لمنحنيات DET هي الأصل (على عكس الركن العلوي الأيسر لمنحنيات ROC).</p></li>
</ul>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التطبيقات-والقيود">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التطبيقات والقيود<a class="headerlink" href="#التطبيقات-والقيود" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يسهل فهم منحنيات DET وتسمح بالتقييم المرئي السريع لأداء المصنف.
بالإضافة إلى ذلك، يمكن الرجوع إلى منحنيات DET لتحليل العتبة واختيار نقطة التشغيل.
وهذا مفيد بشكل خاص إذا كانت مقارنة أنواع الأخطاء مطلوبة.</p>
<p class="sd-card-text">من ناحية أخرى، لا توفر منحنيات DET مقياسها كرقم واحد.
لذلك، بالنسبة للتقييم التلقائي أو المقارنة مع مهام تصنيف أخرى، قد تكون المقاييس مثل المساحة تحت منحنى ROC أكثر ملاءمة.</p>
</div>
</details><p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>راجع <a class="reference internal" href="../auto_examples/model_selection/plot_det.html#sphx-glr-auto-examples-model-selection-plot-det-py"><span class="std std-ref">Detection error tradeoff (DET) curve</span></a>
لمقارنة مثال بين منحنيات خاصية التشغيل المستلم (ROC)
ومنحنيات مبادلة خطأ الكشف (DET).</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="wikipediadet2017" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id28">WikipediaDET2017</a><span class="fn-bracket">]</span></span>
<p>مساهمو ويكيبيديا. مبادلة خطأ الكشف.
ويكيبيديا، الموسوعة الحرة. 4 سبتمبر 2017، الساعة 23:33 بتوقيت غرينتش.
متاح في: <a class="reference external" href="https://en.wikipedia.org/w/index.php?title=Detection_error_tradeoff&amp;oldid=798982054">https://en.wikipedia.org/w/index.php?title=Detection_error_tradeoff&amp;oldid=798982054</a>.
تم الوصول إليه في 19 فبراير 2018.</p>
</div>
<div class="citation" id="martin1997" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">Martin1997</a><span class="fn-bracket">]</span></span>
<p>A. Martin, G. Doddington, T. Kamm, M. Ordowski، وM. Przybocki،
<a class="reference external" href="https://ccc.inaoep.mx/~villasen/bib/martin97det.pdf">منحنى DET في تقييم أداء مهمة الكشف</a>، NIST 1997.</p>
</div>
<div class="citation" id="navratil2007" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id30">Navratil2007</a><span class="fn-bracket">]</span></span>
<p>J. Navractil and D. Klusacek,
<a class="reference external" href="https://ieeexplore.ieee.org/document/4218079">“On Linear DETs”</a>،
2007 IEEE International Conference on Acoustics،
Speech and Signal Processing - ICASSP ‘07، Honolulu،
HI، 2007، الصفحات IV-229-IV-232.</p>
</div>
</div>
</section>
</section>
<section id="zero-one-loss">
<span id="id31"></span><h2><span class="section-number">3.9.9. </span>خسارة الصفر واحد<a class="headerlink" href="#zero-one-loss" title="Link to this heading">#</a></h2>
<p>تحسب دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">zero_one_loss</span></code> مجموع أو متوسط خسارة التصنيف 0-1 (<span class="math notranslate nohighlight">\(L_{0-1}\)</span>) على <span class="math notranslate nohighlight">\(n_{\text{samples}}\)</span>. بشكل افتراضي، تقوم الدالة بالمعايرة على العينة. للحصول على مجموع <span class="math notranslate nohighlight">\(L_{0-1}\)</span>، قم بتعيين “normalize” إلى “False”.</p>
<p>في التصنيف متعدد التصنيفات، تقوم دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">zero_one_loss</span></code> بتصنيف المجموعة الفرعية على أنها
واحد إذا تطابقت تسمياتها بشكل صارم مع التوقعات، وصفر إذا حدثت أي أخطاء. بشكل افتراضي، تقوم الدالة بإرجاع النسبة المئوية للمجموعات الفرعية المتوقعة بشكل غير مثالي. للحصول على عدد هذه المجموعات الفرعية بدلاً من ذلك، قم بتعيين “normalize” إلى “False”.</p>
<p>إذا كان <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> هي القيمة المتوقعة
للعينة i و <span class="math notranslate nohighlight">\(y_i\)</span> هي القيمة الصحيحة المقابلة،
يتم تعريف الخسارة 0-1 <span class="math notranslate nohighlight">\(L_{0-1}\)</span> على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[L_{0-1}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1(\hat{y}_i \not= y_i)\]</div>
<p>حيث <span class="math notranslate nohighlight">\(1(x)\)</span> هي <a class="reference external" href="https://en.wikipedia.org/wiki/Indicator_function">الدالة المؤشر</a>. يمكن أيضًا حساب الخسارة الصفرية الواحدة على النحو التالي: الخسارة الصفرية الواحدة = 1 - الدقة.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">zero_one_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.25</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>في حالة التصنيف متعدد التصنيفات مع مؤشرات التصنيف الثنائية، حيث تحتوي مجموعة التصنيفات الأولى [0,1] على خطأ:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="go">0.5</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">zero_one_loss</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>  <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>راجع <a class="reference internal" href="../auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">Recursive feature elimination with cross-validation</span></a>
لمثال على استخدام الخسارة الصفرية الواحدة لإجراء القضاء التراجعي على الميزات مع التصديق المتقاطع.</p></li>
</ul>
</section>
<section id="brier-score-loss">
<span id="id33"></span><h2><span class="section-number">3.9.10. </span>خسارة نتيجة برير<a class="headerlink" href="#brier-score-loss" title="Link to this heading">#</a></h2>
<p>تقوم دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">brier_score_loss</span></code> بحساب
<a class="reference external" href="https://en.wikipedia.org/wiki/Brier_score">نتيجة برير</a>
للطبقات الثنائية <a class="reference internal" href="#brier1950" id="id35"><span>[Brier1950]</span></a>. اقتباس من ويكيبيديا:</p>
<blockquote>
<div><p>“نتيجة برير هي دالة تسجيل صحيحة تقيس دقة التوقعات الاحتمالية. تنطبق على المهام التي يجب أن تعين فيها التوقعات الاحتمالات لمجموعة من النتائج المتبادلة الحصرية.”</p>
</div></blockquote>
<p>تعيد هذه الدالة متوسط مربع الخطأ للنتيجة الفعلية
<span class="math notranslate nohighlight">\(y \in \{0,1\}\)</span> وتقدير الاحتمال المتوقع
<span class="math notranslate nohighlight">\(p = \operatorname{Pr}(y = 1)\)</span> (<a class="reference internal" href="../glossary.html#term-predict_proba"><span class="xref std std-term">predict_proba</span></a>) كما هو موضح بواسطة:</p>
<div class="math notranslate nohighlight">
\[BS = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}} - 1}(y_i - p_i)^2\]</div>
<p>تقع خسارة نتيجة برير أيضًا بين 0 و1 وكلما انخفضت القيمة (كان متوسط مربع الفرق أصغر)، زادت دقة التوقع.</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.metrics import brier_score_loss
&gt;&gt;&gt; y_true = np.array([0, 1, 1, 0])
&gt;&gt;&gt; y_true_categorical = np.array([&quot;spam&quot;، &quot;ham&quot;، &quot;ham&quot;، &quot;spam&quot;])
&gt;&gt;&gt; y_prob = np.array([0.1, 0.9, 0.8, 0.4])
&gt;&gt;&gt; y_pred = np.array([0, 1, 1, 0])
&gt;&gt;&gt; brier_score_loss(y_true, y_prob)
0.055
&gt;&gt;&gt; brier_score_loss(y_true, 1 - y_prob, pos_label=0)
0.055
&gt;&gt;&gt; brier_score_loss(y_true_categorical, y_prob, pos_label=&quot;ham&quot;)
0.055
&gt;&gt;&gt; brier_score_loss(y_true, y_prob &gt; 0.5)
0.0
</pre></div>
</div>
<p>يمكن استخدام نتيجة برير لتقييم مدى جودة معايرة المصنف.
ومع ذلك، لا يعني انخفاض خسارة نتيجة برير دائمًا معايرة أفضل.
ويرجع ذلك إلى أنه، بالقياس على تحليل الانحياز-التشتت لمتوسط مربع الخطأ، يمكن تحليل خسارة نتيجة برير إلى خسارة المعايرة وخسارة التنقيح <a class="reference internal" href="#bella2012" id="id36"><span>[Bella2012]</span></a>. يتم تعريف خسارة المعايرة على أنها متوسط مربع الانحراف عن الاحتمالات التجريبية المستمدة من ميل شرائح ROC. يمكن تعريف خسارة التنقيح على أنها الخسارة المثالية المتوقعة كما تم قياسها بواسطة المساحة تحت منحنى التكلفة المثالية. يمكن أن تتغير خسارة التنقيح بشكل مستقل عن خسارة المعايرة، وبالتالي فإن انخفاض خسارة نتيجة برير لا يعني دائمًا معايرة نموذج أفضل. “فقط عندما تبقى خسارة التنقيح كما هي، فإن انخفاض خسارة نتيجة برير يعني دائمًا معايرة أفضل”
<a class="reference internal" href="#bella2012" id="id37"><span>[Bella2012]</span></a>، <a class="reference internal" href="#flach2008" id="id38"><span>[Flach2008]</span></a>.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>راجع <a class="reference internal" href="../auto_examples/calibration/plot_calibration.html#sphx-glr-auto-examples-calibration-plot-calibration-py"><span class="std std-ref">Probability calibration of classifiers</span></a>
لمثال على استخدام خسارة نتيجة برير لمعايرة احتمالية المصنفات.</p></li>
</ul>
<p class="rubric">المراجع</p>
<div role="list" class="citation-list">
<div class="citation" id="brier1950" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id35">Brier1950</a><span class="fn-bracket">]</span></span>
<p>G. Brier، <a class="reference external" href="ftp://ftp.library.noaa.gov/docs.lib/htdocs/rescue/mwr/078/mwr-078-01-0001.pdf">التحقق من التوقعات المعبر عنها من حيث الاحتمالية</a>،
Monthly weather review 78.1 (1950)</p>
</div>
<div class="citation" id="bella2012" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Bella2012<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id36">1</a>,<a role="doc-backlink" href="#id37">2</a>)</span>
<p>Bella، Ferri، Hernández-Orallo، and Ramírez-Quintana
<a class="reference external" href="http://dmip.webs.upv.es/papers/BFHRHandbook2010.pdf">“معايرة نماذج التعلم الآلي”</a>
في Khosrow-Pour، M. “التعلم الآلي: المفاهيم والمنهجيات والأدوات
والتطبيقات.” هيرشي، بنسلفانيا: معلومات العلوم المرجعية (2012).</p>
</div>
<div class="citation" id="flach2008" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id38">Flach2008</a><span class="fn-bracket">]</span></span>
<p>Flach، Peter، and Edson Matsubara. <a class="reference external" href="https://drops.dagstuhl.de/opus/volltexte/2008/1382/">“On classification, ranking،
and probability estimation.”</a>
Dagstuhl Seminar Proceedings. Schloss Dagstuhl-Leibniz-Zentrum fr Informatik (2008).</p>
</div>
</div>
<p id="class-likelihood-ratios">فيما يلي ترجمة لنص RST باللغة الإنجليزية إلى اللغة العربية، مع اتباع التعليمات المحددة:</p>
<p>تحسب دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">class_likelihood_ratios</span></code> نسب الاحتمالية الإيجابية والسلبية <span class="math notranslate nohighlight">\(LR_\pm\)</span> للفئات الثنائية، والتي يمكن تفسيرها على أنها نسبة الاحتمالات بعد الاختبار إلى الاحتمالات قبل الاختبار كما هو موضح أدناه. ونتيجة لذلك، فإن هذا المقياس لا يتأثر بنسبة انتشار الفئة (عدد العينات في الفئة الإيجابية مقسوماً على العدد الإجمالي للعينات) ويمكن <strong>استقراؤه بين المجموعات السكانية بغض النظر عن أي اختلال محتمل في الفئة</strong>.</p>
<p>لذلك، تعد مقاييس <span class="math notranslate nohighlight">\(LR_\pm\)</span> مفيدة للغاية في الحالات التي تكون فيها البيانات المتاحة لتعلم وتقييم مصنف هي مجموعة دراسة ذات فئات متوازنة تقريبًا، مثل دراسة الحالات والشواهد، في حين أن التطبيق المستهدف، أي السكان عمومًا، لديه انتشار منخفض جدًا.</p>
<p>نسبة الاحتمالية الإيجابية <span class="math notranslate nohighlight">\(LR_+\)</span> هي احتمال أن يتنبأ المصنف بشكل صحيح بأن عينة ما تنتمي إلى الفئة الإيجابية مقسومة على احتمال التنبؤ بالفئة الإيجابية لعينة تنتمي إلى الفئة السلبية:</p>
<div class="math notranslate nohighlight">
\[LR_+ = \frac{\text{PR}(P+|T+)}{\text{PR}(P+|T-)}.\]</div>
<p>يشير الرمز هنا إلى التصنيف المتوقع (<span class="math notranslate nohighlight">\(P\)</span>) أو الفعلي (<span class="math notranslate nohighlight">\(T\)</span>) والرمز <span class="math notranslate nohighlight">\(+\)</span> و:math:<code class="docutils literal notranslate"><span class="pre">-</span></code> يشيران إلى الفئة الإيجابية والسلبية، على التوالي، على سبيل المثال:math:<code class="docutils literal notranslate"><span class="pre">P+</span></code> يعني “إيجابي متوقع”.</p>
<p>وبالمثل، فإن نسبة الاحتمالية السلبية <span class="math notranslate nohighlight">\(LR_-\)</span> هي احتمال تصنيف عينة من الفئة الإيجابية على أنها تنتمي إلى الفئة السلبية مقسومة على احتمال التصنيف الصحيح لعينة من الفئة السلبية:</p>
<div class="math notranslate nohighlight">
\[LR_- = \frac{\text{PR}(P-|T+)}{\text{PR}(P-|T-)}.\]</div>
<p>بالنسبة للمصنفات التي تزيد عن الصدفة، فإن <span class="math notranslate nohighlight">\(LR_+\)</span> أعلى من 1 <strong>كلما كان أفضل</strong>، في حين أن <span class="math notranslate nohighlight">\(LR_\)</span>- تتراوح من 0 إلى 1 و <strong>كلما انخفضت كانت أفضل</strong>. تشير قيم <span class="math notranslate nohighlight">\(LR_\pm\approx 1\)</span> إلى مستوى الصدفة.</p>
<p>لاحظ أن الاحتمالات تختلف عن العد، على سبيل المثال، <span class="math notranslate nohighlight">\(\operatorname{PR}(P+|T+)\)</span> لا يساوي عدد العد الإيجابي الصحيح “tp” (راجع <a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">صفحة ويكيبيديا</a> للصيغ الفعلية).</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_likelihood_ratios.html#sphx-glr-auto-examples-model-selection-plot-likelihood-ratios-py"><span class="std std-ref">Class Likelihood Ratios to measure classification performance</span></a></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="التفسير-عبر-الانتشار-المختلف">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">التفسير عبر الانتشار المختلف<a class="headerlink" href="#التفسير-عبر-الانتشار-المختلف" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">يمكن تفسير نسب احتمالية الفئات من حيث نسبة الاحتمالات (قبل الاختبار وبعده):</p>
<div class="math notranslate nohighlight">
\[\text{post-test odds} = \text{Likelihood ratio} \times \text{pre-test odds}.\]</div>
<p class="sd-card-text">ترتبط الاحتمالات بشكل عام بالاحتمالات عن طريق:</p>
<div class="math notranslate nohighlight">
\[\text{odds} = \frac{\text{probability}}{1 - \text{probability}},\]</div>
<p class="sd-card-text">أو ما يعادلها</p>
<div class="math notranslate nohighlight">
\[\text{probability} = \frac{\text{odds}}{1 + \text{odds}}.\]</div>
<p class="sd-card-text">في مجموعة سكانية معينة، يتم إعطاء الاحتمالية السابقة بواسطة الانتشار. من خلال تحويل الاحتمالات إلى احتمالات، يمكن ترجمة نسب الاحتمالية إلى احتمال الانتماء الحقيقي إلى أي من الفئات قبل وبعد توقع المصنف:</p>
<div class="math notranslate nohighlight">
\[\text{post-test odds} = \text{Likelihood ratio} \times
\frac{\text{pre-test probability}}{1 - \text{pre-test probability}},\]</div>
<div class="math notranslate nohighlight">
\[\text{post-test probability} = \frac{\text{post-test odds}}{1 + \text{post-test odds}}.\]</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="الانحرافات-الرياضية">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">الانحرافات الرياضية<a class="headerlink" href="#الانحرافات-الرياضية" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">نسبة الاحتمالية الإيجابية غير محددة عندما <span class="math notranslate nohighlight">\(fp = 0\)</span>، والتي يمكن تفسيرها على أنها تحديد المصنف لحالات إيجابية بشكل مثالي. إذا كان <span class="math notranslate nohighlight">\(fp = 0\)</span> وإضافة إلى ذلك <span class="math notranslate nohighlight">\(tp = 0\)</span>، فإن هذا يؤدي إلى قسمة الصفر على الصفر. يحدث هذا، على سبيل المثال، عند استخدام مصنف غبي يتوقع دائمًا الفئة السلبية وبالتالي يتم فقدان تفسيره كمصنف مثالي.</p>
<p class="sd-card-text">نسبة الاحتمالية السلبية غير محددة عندما <span class="math notranslate nohighlight">\(tn = 0\)</span>. هذا الانحراف غير صالح، لأن <span class="math notranslate nohighlight">\(LR_- &gt; 1\)</span> من شأنه أن يشير إلى زيادة في احتمالية انتماء عينة إلى الفئة الإيجابية بعد تصنيفها على أنها سلبية، كما لو أن فعل التصنيف تسبب في الحالة الإيجابية. ويشمل ذلك حالة المصنف الغبي الذي يتوقع دائمًا الفئة الإيجابية (أي عندما <span class="math notranslate nohighlight">\(tn=fn=0\)</span>).</p>
<p class="sd-card-text">كلتا نسبتي احتمالية الفئة غير محددتين عندما <span class="math notranslate nohighlight">\(tp=fn=0\)</span>، مما يعني أنه لم تكن هناك عينات من الفئة الإيجابية موجودة في مجموعة الاختبار. يمكن أن يحدث هذا أيضًا عند التحقق من صحة البيانات غير المتوازنة للغاية.</p>
<p class="sd-card-text">في جميع الحالات السابقة، تثير دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">class_likelihood_ratios</span></code> بشكل افتراضي رسالة تحذير مناسبة وتعيد القيمة <code class="docutils literal notranslate"><span class="pre">nan</span></code> لتجنب التلوث عند حساب المتوسط عبر طيات التحقق من صحة التداخل.</p>
<p class="sd-card-text">للحصول على توضيح عملي لدالة <code class="xref py py-func docutils literal notranslate"><span class="pre">class_likelihood_ratios</span></code>، راجع المثال أدناه.</p>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="المراجع">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">المراجع<a class="headerlink" href="#المراجع" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing">صفحة ويكيبيديا لنسب الاحتمالية في الاختبار التشخيصي</a></p></li>
<li><p class="sd-card-text">Brenner, H., &amp; Gefeller, O. (1997).
Variation of sensitivity, specificity, likelihood ratios and predictive
values with disease prevalence.
Statistics in medicine, 16(9), 981-991.</p></li>
</ul>
</div>
</details></section>
<section id="d2">
<span id="d2-score-classification"></span><h2><span class="section-number">3.9.11. </span>درجة D² للتصنيف<a class="headerlink" href="#d2" title="Link to this heading">#</a></h2>
<p>تحسب درجة D² نسبة الانحراف الموضح.
إنها تعميم لـ R²، حيث يتم تعميم الخطأ المربعي واستبداله بانحراف التصنيف المحدد <span class="math notranslate nohighlight">\(\text{dev}(y، \ hat {y})\)</span>
(على سبيل المثال، خسارة السجل). D² هي شكل من أشكال <em>درجة المهارة</em>.
يتم حسابه على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[D^2(y، \ hat {y}) = 1 - \frac{\ text {dev} (y، \ hat {y})}{\ text {dev} (y، y_ {\ text {null}})} \,.\]</div>
<p>حيث <span class="math notranslate nohighlight">\(y_ {\ text {null}}\)</span> هو التنبؤ الأمثل لنموذج يعتمد فقط على المعترض (على سبيل المثال، نسبة الفئة لكل فئة في حالة خسارة السجل).</p>
<p>مثل R²، أفضل درجة ممكنة هي 1.0 ويمكن أن تكون سلبية (لأن
يمكن أن يكون النموذج أسوأ بشكل تعسفي). من شأن نموذج ثابت يتوقع دائمًا <span class="math notranslate nohighlight">\(y_ {\ text {null}}\)</span>، بغض النظر عن ميزات الإدخال، أن يحصل على درجة D² تساوي 0.0.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-d2-لخسارة-السجل">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة D2 لخسارة السجل<a class="headerlink" href="#درجة-d2-لخسارة-السجل" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تقوم دالة <code class="xref py py-func docutils literal notranslate"><span class="pre">d2_log_loss_score</span></code> بتنفيذ الحالة الخاصة</p>
</div>
</details><p>من D² بخسارة السجل، راجع <a class="reference internal" href="#log-loss"><span class="std std-ref">خسارة السجل</span></a>، أي:</p>
<div class="math notranslate nohighlight">
\[\ text {dev} (y، \ hat {y}) = \ text {log_loss} (y، \ hat {y}).\]</div>
<p>فيما يلي بعض أمثلة الاستخدام لدالة <code class="xref py py-func docutils literal notranslate"><span class="pre">d2_log_loss_score</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">d2_log_loss_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span>
</pre></div>
</div>
<p>…    [0.5, 0.25, 0.25]،
…    [0.5، 0.25، 0.25]،
…    [0.5، 0.25، 0.25]،
…    [0.5، 0.25، 0.25]،
… ]
&gt;&gt;&gt; d2_log_loss_score (y_true، y_pred)
0.0
&gt;&gt;&gt; y_true = [1، 2، 3]
&gt;&gt;&gt; y_pred = [
…    [0.98، 0.01، 0.01]،
…    [0.01، 0.98، 0.01]،
…    [0.01، 0.01، 0.98]،
… ]
&gt;&gt;&gt; d2_log_loss_score (y_true، y_pred)
0.981…
&gt;&gt;&gt; y_true = [1، 2، 3]
&gt;&gt;&gt; y_pred = [
…    [0.1، 0.6، 0.3]،
…    [0.1، 0.6، 0.3]،
…    [0.4، 0.5، 0.1]،
… ]
&gt;&gt;&gt; d2_log_loss_score (y_true، y_pred)
-0.552…</p>
<p id="multilabel-ranking-metrics">مقاييس الترتيب متعددة التصنيفات
في التعلم متعدد التصنيفات، يمكن أن يكون لكل عينة أي عدد من العلامات الصحيحة المرتبطة بها. والهدف هو إعطاء درجات عالية وترتيب أفضل للعلامات الصحيحة.</p>
</section>
<section id="id43">
<h2><span class="section-number">3.9.12. </span>خطأ التغطية<a class="headerlink" href="#id43" title="Link to this heading">#</a></h2>
<p>تحسب دالة coverage_error متوسط عدد العلامات التي يجب تضمينها في التنبؤ النهائي بحيث يتم التنبؤ بجميع العلامات الصحيحة. وهذا مفيد إذا كنت تريد معرفة عدد العلامات الأعلى تصنيفًا التي يجب التنبؤ بها في المتوسط دون إغفال أي علامة صحيحة. وبالتالي، فإن أفضل قيمة لهذا المقياس هي متوسط عدد العلامات الصحيحة.</p>
<p>ملاحظة:</p>
<p>درجة تنفيذنا أعلى بواحد من تلك المذكورة في Tsoumakas et al.، 2010. وهذا يوسعها للتعامل مع الحالة المتدهورة التي يكون فيها للنسخة 0 علامات صحيحة.</p>
<p>رسميًا، بالنظر إلى مصفوفة المؤشرات الثنائية لعلامات الحقيقة الأرضية y ∈ {0, 1}n_samples × n_labels ومقياس مرتبط بكل علامة ^f ∈ R^n_samples × n_labels، يتم تعريف التغطية على النحو التالي:</p>
<p>التغطية (y، ^f) = 1 / n_samples ∑_ {i=0} ^ {n_samples - 1} <a href="#id63"><span class="problematic" id="id64">max_</span></a> {j: <a href="#id65"><span class="problematic" id="id66">y_</span></a> {ij} = 1} <a href="#id67"><span class="problematic" id="id68">rank_</span></a> {ij}</p>
<p>مع <a href="#id69"><span class="problematic" id="id70">rank_</span></a> {ij} = | {k: ^f_ {ik} ≥ ^f_ {ij}|}.</p>
<p>نظرًا لتعريف الترتيب، يتم كسر التعادل في “y_scores” عن طريق إعطاء الترتيب الأقصى الذي كان سيتم تعيينه لجميع القيم المتعادلة.</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; استيراد numpy كما np
&gt;&gt;&gt; من sklearn.metrics استيراد coverage_error
&gt;&gt;&gt; y_true = np.array ([[1،0،0]، [0،0،1]])
&gt;&gt;&gt; y_score = np.array ([[0.75،0.5،1]، [1،0.2،0.1]])
&gt;&gt;&gt; coverage_error (y_true، y_score)
</pre></div>
</div>
<p>2.5</p>
</section>
<section id="id44">
<h2><span class="section-number">3.9.13. </span>متوسط دقة التصنيف بالعلامات<a class="headerlink" href="#id44" title="Link to this heading">#</a></h2>
<p>تنفذ دالة label_ranking_average_precision_score متوسط دقة التصنيف بالعلامات (LRAP). يرتبط هذا المقياس بدالة average_precision_score، ولكنه يعتمد على مفهوم تصنيف العلامات بدلاً من الدقة والاستدعاء.</p>
<p>متوسط دقة التصنيف بالعلامات (LRAP) يحسب متوسط الإجابة على السؤال التالي عبر العينات: بالنسبة لكل علامة صحيحة، ما هي النسبة من العلامات الأعلى مرتبة التي كانت صحيحة؟ سيكون مقياس الأداء هذا أعلى إذا تمكنت من إعطاء ترتيب أفضل للعلامات المرتبطة بكل عينة. النتيجة التي يتم الحصول عليها أكبر دائمًا بشكل صارم من 0، وأفضل قيمة هي 1. إذا كان هناك علامة واحدة ذات صلة لكل عينة، فإن متوسط دقة التصنيف بالعلامات يعادل متوسط الرتبة المتبادلة &lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Mean_reciprocal_rank">https://en.wikipedia.org/wiki/Mean_reciprocal_rank</a>&gt;.</p>
<p>رسميًا، بالنظر إلى مصفوفة المؤشرات الثنائية لعلامات الحقيقة الأرضية y ∈ {0, 1}n_samples × n_labels ومقياس مرتبط بكل علامة ^f ∈ R^n_samples × n_labels، يتم تعريف متوسط الدقة على النحو التالي:</p>
<p>LRAP (y، ^f) = 1 / n_samples ∑_ {i=0} ^ {n_samples - 1} 1 / || y_i ||_0 ∑_ {j: <a href="#id71"><span class="problematic" id="id72">y_</span></a> {ij} = 1} | mathcal {L} _ {ij}| / <a href="#id73"><span class="problematic" id="id74">rank_</span></a> {ij}</p>
<p>حيث
mathcal {L} _ {ij} = {k: <a href="#id75"><span class="problematic" id="id76">y_</span></a> {ik} = 1، ^f_ {ik} ≥ ^f_ {ij}|، <a href="#id77"><span class="problematic" id="id78">rank_</span></a> {ij} = | {k: ^f_ {ik} ≥ ^f_ {ij}|، | · | يحسب عدد عناصر المجموعة (أي عدد العناصر في المجموعة)، و|| · ||_0 هو ||| l_0 ||| “norm” (الذي يحسب عدد العناصر غير الصفرية في متجه).</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; استيراد numpy كما np
&gt;&gt;&gt; من sklearn.metrics استيراد label_ranking_average_precision_score
&gt;&gt;&gt; y_true = np.array ([[1،0،0]، [0،0،1]])
&gt;&gt;&gt; y_score = np.array ([[0.75،0.5،1]، [1،0.2،0.1]])
&gt;&gt;&gt; label_ranking_average_precision_score (y_true، y_score)
</pre></div>
</div>
<p>0.416…</p>
</section>
<section id="id45">
<h2><span class="section-number">3.9.14. </span>خسارة الترتيب<a class="headerlink" href="#id45" title="Link to this heading">#</a></h2>
<p>تحسب دالة label_ranking_loss خسارة الترتيب التي تحسب متوسط عدد أزواج العلامات التي يتم ترتيبها بشكل غير صحيح عبر العينات، أي أن العلامات الصحيحة لها درجة أقل من العلامات الخاطئة، مرجحة بالعكس عدد أزواج الترتيب من العلامات الخاطئة والصحيحة. أقل خسارة ترتيب يمكن تحقيقها هي الصفر.</p>
<p>رسميًا، بالنظر إلى مصفوفة المؤشرات الثنائية لعلامات الحقيقة الأرضية y ∈ {0, 1}n_samples × n_labels ومقياس مرتبط بكل علامة ^f ∈ R^n_samples × n_labels، يتم تعريف خسارة الترتيب على النحو التالي:</p>
<p>خسارة الترتيب (y، ^f) = 1 / n_samples ∑_ {i=0} ^ {n_samples - 1} 1 / || y_i ||_0 (n_labels - || y_i ||_0) | { (k، l): ^f_ {ik} ≤ ^f_ {il}، <a href="#id79"><span class="problematic" id="id80">y_</span></a> {ik} = 1، <a href="#id81"><span class="problematic" id="id82">y_</span></a> {il} = 0|</p>
<p>حيث | · | يحسب عدد عناصر المجموعة (أي عدد العناصر في المجموعة)، و|| · ||_0 هو ||| l_0 ||| “norm” (الذي يحسب عدد العناصر غير الصفرية في متجه).</p>
<p>فيما يلي مثال صغير على استخدام هذه الدالة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; استيراد numpy كما np
&gt;&gt;&gt; من sklearn.metrics استيراد label_ranking_loss
&gt;&gt;&gt; y_true = np.array ([[1،0،0]، [0،0،1]])
&gt;&gt;&gt; y_score = np.array ([[0.75،0.5،1]، [1،0.2،0.1]])
&gt;&gt;&gt; label_ranking_loss (y_true، y_score)
</pre></div>
</div>
<p>0.75…
&gt;&gt;&gt; # مع التنبؤ التالي، يكون لدينا خسارة مثالية ودنيا
&gt;&gt;&gt; y_score = np.array ([[1.0،0.1،0.2]، [0.1،0.2،0.9]])
&gt;&gt;&gt; label_ranking_loss (y_true، y_score)
0.0</p>
<p>مراجع</p>
<ul class="simple">
<li><p>تسوماكاس، ج.، كاتاكيس، آي.، وفلاهافاس، آي. (2010). التنقيب عن البيانات متعددة التصنيفات. في
دليل اكتشاف البيانات والتعدين (ص. 667-685). سبرينجر الولايات المتحدة الأمريكية.</p></li>
</ul>
</section>
<section id="id46">
<h2><span class="section-number">3.9.15. </span>المكسب التراكمي المخفض<a class="headerlink" href="#id46" title="Link to this heading">#</a></h2>
<p>مكسب تراكمي مخفض (DCG) والمكسب التراكمي المخفض العادي (NDCG) هي مقاييس الترتيب التي يتم تنفيذها في sklearn.metrics.dcg_score و sklearn.metrics.ndcg_score؛ وهي تقارن الترتيب المتوقع بالدرجات الحقيقية، مثل ملاءمة الإجابات لاستعلام.</p>
<p>من صفحة ويكيبيديا لمكسب تراكمي مخفض:</p>
<p>“المكسب التراكمي المخفض (DCG) هو مقياس لجودة الترتيب. في استرجاع المعلومات، يتم استخدامه غالبًا لقياس فعالية خوارزميات محرك البحث أو التطبيقات ذات الصلة. باستخدام مقياس الملاءمة المتدرجة لوثائق مجموعة النتائج التي تم إرجاعها من استعلام محرك البحث، يقيس DCG فائدة المستند أو المكسب بناءً على موضعه في قائمة النتائج. يتم تراكم المكسب من أعلى إلى أسفل قائمة النتائج، مع خصم مكسب كل نتيجة لاحقة وفقًا للوضع في قائمة النتائج”</p>
<p>يقوم DCG بترتيب الأهداف الحقيقية (مثل ملاءمة إجابات الاستعلام) في الترتيب المتوقع، ثم يضربها في انخفاض لوغاريتمي ويجمع النتيجة. يمكن تقصير المجموع بعد النتائج الأولى K، وفي هذه الحالة نطلق عليه DCG&#64;K.</p>
<p>NDCG، أو NDCG&#64;K هو DCG مقسومًا على DCG الذي تم الحصول عليه من خلال التنبؤ المثالي، بحيث يكون دائمًا بين 0 و1. عادة ما يتم تفضيل NDCG على DCG.</p>
<p>مقارنة بخسارة الترتيب، يمكن أن يأخذ NDCG في الاعتبار درجات الملاءمة، بدلاً من الترتيب الحقيقي. لذا إذا كانت الحقيقة الأرضية تتكون فقط من ترتيب، فيجب تفضيل خسارة الترتيب؛ إذا كانت الحقيقة الأرضية تتكون من درجات الفائدة الفعلية (على سبيل المثال، 0 لعدم الملاءمة، 1 للملاءمة، 2 للملاءمة للغاية)، يمكن استخدام NDCG.</p>
<p>بالنسبة لعينة واحدة، بالنظر إلى متجه القيم الحقيقية المستمرة لكل هدف y ∈ RM، حيث M هو عدد الإخراج، والتنبؤ ^y، والذي يؤدي وظيفة الترتيب f، تكون نتيجة DCG هي</p>
<p>∑_ {r=1} ^ min (K، M) <a href="#id83"><span class="problematic" id="id84">y_</span></a> {f (r)} / log (1 + r)</p>
<p>ونتيجة NDCG هي نتيجة DCG مقسومة على نتيجة DCG التي تم الحصول عليها لـ y.</p>
<p>مراجع</p>
<ul class="simple">
<li><p>صفحة ويكيبيديا للمكسب التراكمي المخفض
&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain">https://en.wikipedia.org/wiki/Discounted_cumulative_gain</a>&gt;.</p></li>
<li><p>جارفيلين، ك.، وكيكالينين، ج. (2002).
تقييم تقنيات استرجاع المعلومات المتراكمة. معاملات ACM على
أنظمة المعلومات (TOIS)، 20 (4)، 422-446.</p></li>
<li><p>وانغ، واي، ووانغ، ل.، ولي، واي، وآخرون.، وهى، تى. (2013، مايو).
تحليل نظري لتدابير NDCG. في وقائع المؤتمر السنوي السادس والعشرين
حول نظرية التعلم (COLT 2013)</p></li>
<li><p>ماكشيري، ف.، ونجورك، م. (2008، مارس). حساب مقاييس أداء استرجاع المعلومات بكفاءة في وجود الدرجات المتعادلة. في
المؤتمر الأوروبي حول استرجاع المعلومات (ص. 414-421). سبرينجر،
برلين هايدلبرغ.</p></li>
</ul>
<p>مقياس الانحدار
يوفر نموذج sklearn.metrics العديد من دالات الخسارة، والنتيجة، والمنفعة لقياس أداء الانحدار. وقد تم تحسين بعضها للتعامل مع حالة الإخراج المتعدد: mean_squared_error، وmean_absolute_error، وr2_score، وexplained_variance_score، وmean_pinball_loss، وd2_pinball_score، وd2_absolute_error_score.</p>
<p>تملك هذه الدالات وسيطًا كلميًا multioutput يحدد طريقة حساب متوسط الدرجات أو الخسائر لكل هدف فردي. الافتراضي هو “uniform_average”، والذي يحدد متوسطًا موزونًا بشكل موحد عبر الإخراج. إذا تم تمرير مصفوفة ndarray ذات شكل (n_outputs,)، فسيتم تفسير إدخالاتها على أنها أوزان ويتم إرجاع المتوسط الموزون المقابل. إذا كان multioutput هو “raw_values”، فسيتم إرجاع جميع الدرجات أو الخسائر الفردية غير المعدلة في مصفوفة ذات شكل (n_outputs,).</p>
<p>تقبل دالتا r2_score وexplained_variance_score قيمة إضافية هي “variance_weighted” لمعامل multioutput. يؤدي هذا الخيار إلى وزن كل درجة فردية بواسطة انحراف متغير الهدف المقابل. يحدد هذا الإعداد الكمية الإجمالية للانحراف غير المحدد المقبوض. إذا كانت متغيرات الهدف ذات مقاييس مختلفة، فإن هذه الدرجة تمنح أهمية أكبر لشرح متغيرات الانحراف الأعلى.</p>
<p>R² score، معامل التحديد</p>
<p>تحسب دالة r2_score معامل التحديد، والذي يشار إليه عادةً بـ R².</p>
<p>يمثل نسبة التباين (من y) الذي تم شرحه بواسطة المتغيرات المستقلة في النموذج. فهو يوفر مؤشرًا على ملاءمة النموذج وبالتالي مقياسًا للكيفية التي من المحتمل أن يتم بها التنبؤ بالنماذج غير المرئية من خلال نسبة التباين الموضح.</p>
<p>نظرًا لأن هذا التباين يعتمد على مجموعة البيانات، فقد لا يكون R² قابلًا للمقارنة بشكل مفيد عبر مجموعات بيانات مختلفة. أفضل نتيجة ممكنة هي 1.0 ويمكن أن تكون سلبية (لأن النموذج يمكن أن يكون أسوأ بشكل تعسفي). سيحصل النموذج الثابت الذي يتوقع دائمًا القيمة المتوقعة (المتوسطة) لـ y، بغض النظر عن ميزات الإدخال، على نتيجة R² تساوي 0.0.</p>
<p>ملاحظة: عندما يكون متوسط بقايا التنبؤ صفرًا، تكون نتيجة R² وexplained_variance_score متطابقة.</p>
<p>إذا كان y_hat_i هو القيمة المتوقعة للعينة i وy_i هي القيمة الصحيحة المقابلة لما مجموعه n من العينات، فإن R² المقدرة معرفة على النحو التالي:</p>
<p>R²(y, y_hat) = 1 - (مجموع i=1 إلى n من (y_i - y_hat_i) تربيع) / (مجموع i=1 إلى n من (y_i - y_bar) تربيع)</p>
<p>حيث y_bar = 1/n * مجموع i=1 إلى n من y_i و مجموع i=1 إلى n من (y_i - y_hat_i) تربيع = مجموع i=1 إلى n من epsilon_i تربيع.</p>
<p>لاحظ أن دالة r2_score تحسب R² غير المعدل بدون تصحيح الانحياز في انحراف عينة y.</p>
<p>في الحالة الخاصة التي يكون فيها الهدف الحقيقي ثابتًا، لا يكون R² محدودًا: فهو إما NaN (تنبؤات مثالية) أو “-Inf” (تنبؤات غير مثالية). قد تمنع هذه الدرجات غير المحدودة تنفيذ تحسين النموذج بشكل صحيح، مثل الضبط الدقيق للتحقق من صحة التقاطع. لهذا السبب، فإن السلوك الافتراضي لـدالة r2_score هو استبدالها بـ 1.0 (تنبؤات مثالية) أو 0.0 (تنبؤات غير مثالية). إذا تم تعيين force_finite إلى False، فستعود هذه الدرجة إلى تعريف R² الأصلي.</p>
<p>فيما يلي مثال صغير على استخدام دالة r2_score:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.948...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;variance_weighted&#39;</span><span class="p">)</span>
<span class="go">0.938...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;uniform_average&#39;</span><span class="p">)</span>
<span class="go">0.936...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="go">array([0.965..., 0.908...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="go">0.925...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">nan</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">-inf</span>
</pre></div>
</div>
<p>أمثلة:</p>
<ul class="simple">
<li><p>راجع: ref:<code class="docutils literal notranslate"><span class="pre">sphx_glr_auto_examples_linear_model_plot_lasso_and_elasticnet.py</span></code> لمثال على استخدام نتيجة R² لتقييم Lasso وElastic Net على إشارات متفرقة.</p></li>
</ul>
<p>متوسط الخطأ المطلق</p>
<p>تحسب دالة mean_absolute_error متوسط الخطأ المطلق، وهو مقياس للمخاطرة يقابل القيمة المتوقعة لقيمة الخطأ المطلق أو فقدان القيمة المطلقة.</p>
<p>إذا كان y_hat_i هو القيمة المتوقعة للعينة i، وy_i هي القيمة الصحيحة المقابلة، فإن متوسط الخطأ المطلق (MAE) المقدر على n_samples معرف على النحو التالي:</p>
<p>MAE(y, y_hat) = 1/n_samples * مجموع i=0 إلى n_samples-1 من | y_i - y_hat_i <a href="#id47"><span class="problematic" id="id48">|</span></a>.</p>
<p>فيما يلي مثال صغير على استخدام دالة mean_absolute_error:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.75</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="go">array([0.5, 1. ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="go">0.85...</span>
</pre></div>
</div>
<p>متوسط الخطأ التربيعي</p>
<p>تحسب دالة mean_squared_error متوسط الخطأ التربيعي، وهو مقياس للمخاطرة يقابل القيمة المتوقعة لقيمة الخطأ التربيعي أو الخسارة.</p>
<p>إذا كان y_hat_i هو القيمة المتوقعة للعينة i، وy_i هي القيمة الصحيحة المقابلة، فإن متوسط الخطأ التربيعي (MSE) المقدر على n_samples معرف على النحو التالي:</p>
<p>MSE(y, y_hat) = 1/n_samples * مجموع i=0 إلى n_samples-1 من (y_i - y_hat_i) تربيع.</p>
<p>فيما يلي مثال صغير على استخدام دالة mean_squared_error:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.375</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.7083...</span>
</pre></div>
</div>
<p>أمثلة:</p>
<ul class="simple">
<li><p>راجع: ref:<code class="docutils literal notranslate"><span class="pre">sphx_glr_auto_examples_ensemble_plot_gradient_boosting_regression.py</span></code> لمثال على استخدام متوسط الخطأ التربيعي لتقييم الانحدار التدريجي.</p></li>
</ul>
<p>إن أخذ الجذر التربيعي لـ MSE، والذي يُطلق عليه الخطأ التربيعي الجذري المتوسط (RMSE)، هو مقياس شائع آخر يوفر مقياسًا بوحدات متغير الهدف. يتوفر RSME من خلال دالة root_mean_squared_error.</p>
<p>متوسط الخطأ التربيعي اللوغاريتمي</p>
<p>تحسب دالة mean_squared_log_error مقياس مخاطرة يقابل القيمة المتوقعة لقيمة الخطأ التربيعي اللوغاريتمي (الربعي) أو الخسارة.</p>
<p>إذا كان y_hat_i هو القيمة المتوقعة للعينة i، وy_i هي القيمة الصحيحة المقابلة، فإن متوسط الخطأ التربيعي اللوغاريتمي (MSLE) المقدر على n_samples معرف على النحو التالي:</p>
<p>MSLE(y, y_hat) = 1/n_samples * مجموع i=0 إلى n_samples-1 من (لوغاريتم e (1 + y_i) - لوغاريتم e (1 + y_hat_i)) تربيع.</p>
<p>حيث لوغاريتم e (x) يعني اللوغاريتم الطبيعي لـ x. من الأفضل استخدام هذا المقياس عندما يكون للهدف نمو أسّي، مثل تعداد السكان، أو متوسط مبيعات سلعة ما على مدى سنوات، وما إلى ذلك. لاحظ أن هذا المقياس يعاقب التقدير الأقل من المتوقع أكثر من التقدير الأعلى من المتوقع.</p>
<p>فيما يلي مثال صغير على استخدام دالة mean_squared_log_error:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.039...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.044...</span>
</pre></div>
</div>
<p>يتوفر الجذر التربيعي المتوسط التربيعي اللوغاريتمي (RMSLE) من خلال دالة root_mean_squared_log_error.</p>
<p>متوسط الخطأ المئوي المطلق</p>
<p>متوسط الخطأ المئوي المطلق (MAPE)، المعروف أيضًا باسم متوسط الانحراف المئوي المطلق (MAPD)، هو مقياس تقييم لمشكلات الانحدار. فكرة هذا المقياس هي الحساسية للأخطاء النسبية. على سبيل المثال، لا يتغير بواسطة مقياس عالمي للمتغير الهدف.</p>
<p>إذا كان y_hat_i هو القيمة المتوقعة للعينة i وy_i هي القيمة الصحيحة المقابلة، فإن متوسط الخطأ المئوي المطلق (MAPE) المقدر على n_samples معرف على النحو التالي:</p>
<p>MAPE(y, y_hat) = 1/n_samples * مجموع i=0 إلى n_samples-1 من | y_i - y_hat_i | / max(epsilon, | y_i <a href="#id49"><span class="problematic" id="id50">|</span></a>)</p>
<p>حيث epsilon هو عدد صغير تعسفي ولكنه موجب بشكل صارم لتجنب النتائج غير المحددة عندما تكون y تساوي صفرًا.</p>
<p>تدعم دالة mean_absolute_percentage_error الإخراج المتعدد.</p>
<p>فيما يلي مثال صغير على استخدام دالة mean_absolute_percentage_error:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_percentage_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1e6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">1.2e6</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.2666...</span>
</pre></div>
</div>
<p>في المثال أعلاه، إذا كنا قد استخدمنا “mean_absolute_error”، لتجاهلنا قيم الحجم الصغيرة وعكس الخطأ في التنبؤ بقيمة الحجم الأعلى فقط. ولكن يتم حل هذه المشكلة في حالة MAPE لأنه يحسب الخطأ النسبي المئوي فيما يتعلق بالإخراج الفعلي.</p>
<p>متوسط الخطأ المطلق</p>
<p>متوسط الخطأ المطلق مثير للاهتمام بشكل خاص لأنه مقاوم للقيم الشاذة. يتم حساب الخسارة عن طريق أخذ متوسط القيم المطلقة لجميع الاختلافات بين الهدف والتنبؤ.</p>
<p>إذا كان y_hat_i هو القيمة المتوقعة للعينة i وy_i هي القيمة الصحيحة المقابلة، فإن متوسط الخطأ المطلق (MedAE) المقدر على n_samples معرف على النحو التالي:</p>
<p>MedAE(y, y_hat) = الوسيط (| y_1 - y_hat_1 <a href="#id51"><span class="problematic" id="id52">|</span></a>، …، | y_n - y_hat_n <a href="#id53"><span class="problematic" id="id54">|</span></a>).</p>
<p>لا تدعم دالة median_absolute_error الإخراج المتعدد.</p>
<p>فيما يلي مثال صغير على استخدام دالة median_absolute_error:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">median_absolute_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">median_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p>الخطأ الأقصى
وظيفة :func: ‘max_error’ تحسب الحد الأقصى للخطأ المتبقي، وهو مقياس يلتقط خطأ أسوأ الحالات بين القيمة المتوقعة والقيمة الحقيقية. في نموذج الانحدار أحادي الإخراج المناسب تمامًا، ستكون القيمة “max_error” هي “0” على مجموعة التدريب وعلى الرغم من أن هذا من غير المرجح أن يحدث في العالم الحقيقي، إلا أن هذا المقياس يوضح مدى الخطأ الذي كان لدى النموذج عند تناسبه.</p>
<p>إذا كانت :math: ‘y_i^’ هي القيمة المتوقعة للعينة :math: ‘i’-th، و :math: ‘y_i’ هي القيمة الحقيقية المقابلة، إذن يتم تعريف الخطأ الأقصى على النحو التالي</p>
<div class="math notranslate nohighlight">
\[\text{Max Error}(y, \hat{y}) = \max(| y_i - \hat{y}_i |)\]</div>
<p>هنا مثال صغير على استخدام وظيفة :func: ‘max_error’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">max_error</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">6</span>
</pre></div>
</div>
<p>وظيفة :func: ‘max_error’ لا تدعم الإخراج المتعدد.</p>
</section>
<section id="explained-variance-score">
<span id="id55"></span><h2><span class="section-number">3.9.16. </span>درجة التباين الموضحة<a class="headerlink" href="#explained-variance-score" title="Link to this heading">#</a></h2>
<p>تحسب وظيفة :func: ‘explained_variance_score’ درجة تباين الانحدار الموضحة ‘
&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Explained_variation">https://en.wikipedia.org/wiki/Explained_variation</a>&gt;’.</p>
<p>إذا كان :math: ‘y^’ هو إخراج الهدف المقدر، و :math: ‘y’ إخراج الهدف المقابل (الصحيح)، و :math: ‘Var’ هو ‘
التباين &lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Variance">https://en.wikipedia.org/wiki/Variance</a>&gt;’، مربع الانحراف المعياري، يتم تقدير التباين الموضح على النحو التالي:</p>
<div class="math notranslate nohighlight">
\[explained\_{}variance(y, \hat{y}) = 1 - \frac{Var\{ y - \hat{y}\}}{Var\{y\}}\]</div>
<p>أفضل نتيجة ممكنة هي 1.0، والقيم الأقل هي الأسوأ.</p>
<aside class="topic">
<p class="topic-title">رابط إلى :ref: ‘r2_score’</p>
<p>الفرق بين درجة التباين الموضحة و :ref: ‘r2_score’ هو أن درجة التباين الموضحة لا تحسب الانزياح المنهجي في التنبؤ. ولهذا السبب، يجب تفضيل :ref: ‘r2_score’ بشكل عام.</p>
</aside>
<p>في الحالة الخاصة التي يكون فيها الهدف الحقيقي ثابتًا، لا تكون درجة التباين الموضحة محدودة: إما “NaN” (تنبؤات مثالية) أو “-Inf” (تنبؤات غير مثالية). قد تمنع هذه الدرجات غير المحدودة إجراء تحسين النموذج الصحيح مثل الضبط الدقيق للتحقق من صحة الشبكة المتقاطعة. ولهذا السبب، السلوك الافتراضي لـ :func: ‘explained_variance_score’ هو استبدالها بـ 1.0 (تنبؤات مثالية) أو 0.0 (تنبؤات غير مثالية). يمكنك تعيين معلمة “force_finite” إلى “False” لمنع حدوث هذا الإصلاح والعودة إلى درجة التباين الموضحة الأصلية.</p>
<p>هنا مثال صغير على استخدام وظيفة :func: ‘explained_variance_score’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">explained_variance_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.957...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="s1">&#39;raw_values&#39;</span><span class="p">)</span>
<span class="go">array([0.967..., 1.        ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">multioutput</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span>
<span class="go">0.990...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">nan</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explained_variance_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">force_finite</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">-inf</span>
</pre></div>
</div>
</section>
<section id="mean-tweedie-deviance">
<span id="id56"></span><h2><span class="section-number">3.9.17. </span>متوسط ​​انحرافات بويسون وغاما وتويد<a class="headerlink" href="#mean-tweedie-deviance" title="Link to this heading">#</a></h2>
<p>تقوم وظيفة :func: ‘mean_tweedie_deviance’ بحساب متوسط ​​انحراف تويد ‘
&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance">https://en.wikipedia.org/wiki/Tweedie_distribution#The_Tweedie_deviance</a>&gt;’
مع معلمة “power” (:math: ‘p’). هذا مقياس يستحث قيم التوقع المتوقعة لأهداف الانحدار.</p>
<p>توجد الحالات الخاصة التالية،</p>
<ul class="simple">
<li><p>عندما “power=0” فهو مكافئ لـ :func: ‘mean_squared_error’.</p></li>
<li><p>عندما “power=1” فهو مكافئ لـ :func: ‘mean_poisson_deviance’.</p></li>
<li><p>عندما “power=2” فهو مكافئ لـ :func: ‘mean_gamma_deviance’.</p></li>
</ul>
<p>إذا كان :math: ‘y_i^’ هو القيمة المتوقعة للعينة :math: ‘i’-th، و :math: ‘y_i’ هي القيمة الحقيقية المقابلة، إذن متوسط ​​انحراف تويد (D) لقوة :math: ‘p’، المقدرة على :math: ‘n_samples’
يتم تعريفها على النحو التالي</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{D}(y, \hat{y}) = \frac{1}{n_\text{samples}}
\sum_{i=0}^{n_\text{samples} - 1}
\begin{cases}
(y_i-\hat{y}_i)^2, &amp; \text{for }p=0\text{ (Normal)}\\
2(y_i \log(y_i/\hat{y}_i) + \hat{y}_i - y_i),  &amp; \text{for }p=1\text{ (Poisson)}\\
2(\log(\hat{y}_i/y_i) + y_i/\hat{y}_i - 1),  &amp; \text{for }p=2\text{ (Gamma)}\\
2\left(\frac{\max(y_i,0)^{2-p}}{(1-p)(2-p)}-
\frac{y_i\,\hat{y}_i^{1-p}}{1-p}+\frac{\hat{y}_i^{2-p}}{2-p}\right),
&amp; \text{otherwise}
\end{cases}\end{split}\]</div>
<p>انحراف تويد هو دالة متجانسة من الدرجة “2-power”.
وهكذا، فإن توزيع غاما مع “power=2” يعني أن القياس المتزامن لـ “y_true” و “y_pred” ليس له تأثير على الانحراف. بالنسبة لتوزيع بويسون، “power=1” ينحرف الخطي، وبالنسبة للتوزيع الطبيعي ( “power=0”)، انحراف رباعي. بشكل عام، كلما زادت “power” قل وزن الانحرافات القصوى بين القيم الحقيقية والمتوقعة.</p>
<p>على سبيل المثال، دعنا نقارن تنبؤين 1.5 و150، وكلاهما أكبر بنسبة 50% من قيمتهما الحقيقية المقابلة.</p>
<p>الخطأ التربيعي المتوسط ( “power=0”) حساس جدًا لفرق التنبؤ بالنقطة الثانية،:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_tweedie_deviance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">0.25</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">100.</span><span class="p">],</span> <span class="p">[</span><span class="mf">150.</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">2500.0</span>
</pre></div>
</div>
<p>إذا قمنا بزيادة “power” إلى 1،:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">0.18...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">100.</span><span class="p">],</span> <span class="p">[</span><span class="mf">150.</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">18.9...</span>
</pre></div>
</div>
<p>ينخفض الفرق في الأخطاء. أخيرًا، عن طريق الضبط، “power=2”:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.14...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_tweedie_deviance</span><span class="p">([</span><span class="mf">100.</span><span class="p">],</span> <span class="p">[</span><span class="mf">150.</span><span class="p">],</span> <span class="n">power</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.14...</span>
</pre></div>
</div>
<p>سنحصل على أخطاء متطابقة. الانحراف عندما “power=2” حساس فقط للأخطاء النسبية.</p>
</section>
<section id="pinball-loss">
<span id="id57"></span><h2><span class="section-number">3.9.18. </span>خسارة بينبول<a class="headerlink" href="#pinball-loss" title="Link to this heading">#</a></h2>
<p>تُستخدم وظيفة :func: ‘mean_pinball_loss’ لتقييم الأداء التنبئي لنماذج الانحدار الكمي.</p>
<div class="math notranslate nohighlight">
\[\text{pinball}(y, \hat{y}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}}-1}  \alpha \max(y_i - \hat{y}_i, 0) + (1 - \alpha) \max(\hat{y}_i - y_i, 0)\]</div>
<p>تكون قيمة خسارة بينبول مكافئة لنصف :func: ‘mean_absolute_error’ عندما يتم تعيين معلمة الكمية “alpha” على 0.5.</p>
<p>هنا مثال صغير على استخدام وظيفة :func: ‘mean_pinball_loss’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_pinball_loss</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="go">0.03...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="go">0.3...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="go">0.3...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="go">0.03...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>من الممكن بناء كائن مسجل باختيار محدد لـ “alpha”:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean_pinball_loss_95p</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">mean_pinball_loss</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</pre></div>
</div>
<p>يمكن استخدام مسجل كهذا لتقييم الأداء العام لنموذج الانحدار الكمي عبر التحقق من صحة الشبكة المتقاطعة:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingRegressor</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">estimator</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;quantile&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">mean_pinball_loss_95p</span><span class="p">)</span>
<span class="go">array([13.6..., 9.7..., 23.3..., 9.5..., 10.4...])</span>
</pre></div>
</div>
<p>من الممكن أيضًا بناء كائنات مسجلة لضبط دقة المعلمات. يجب تبديل علامة الخسارة لضمان أن “الأكبر أفضل” كما هو موضح في المثال المرتبط أدناه.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>راجع :ref: ‘sphx_glr_auto_examples_ensemble_plot_gradient_boosting_quantile.py’
لمثال على استخدام خسارة بينبول لتقييم وضبط دقة معلمات نماذج الانحدار الكمي على بيانات ذات ضجيج غير متماثل ونقاط خارجة عن المنحنى.</p></li>
</ul>
</section>
<section id="d2-score">
<span id="id58"></span><h2><span class="section-number">3.9.19. </span>درجة D²<a class="headerlink" href="#d2-score" title="Link to this heading">#</a></h2>
<p>تحسب درجة D² كسر الانحراف الموضح.
إنه تعميم لـ R²، حيث يتم تعميم الخطأ التربيعي واستبداله
بواسطة انحراف اختيار :math: ‘dev (y، y^)’
(على سبيل المثال، تويد، بينبول أو متوسط ​​الخطأ المطلق). D² هو شكل من أشكال <em>نتيجة المهارة</em>.
يتم حسابه على النحو التالي</p>
<div class="math notranslate nohighlight">
\[D^2(y, \hat{y}) = 1 - \frac{\text{dev}(y, \hat{y})}{\text{dev}(y, y_{\text{null}})} \,.\]</div>
<p>حيث :math: ‘y_null’ هو التنبؤ الأمثل لنموذج ذو معامل وحيد (على سبيل المثال، متوسط ​​‘y_true’ لحالة تويد، الوسيط للخطأ المطلق والكمية “alpha” للخسارة بينبول).</p>
<p>مثل R²، أفضل نتيجة ممكنة هي 1.0 ويمكن أن تكون سلبية (لأن
يمكن أن يكون النموذج أسوأ بشكل تعسفي). من شأن نموذج ثابت يتوقع دائمًا
:math: ‘y_null’، بغض النظر عن ميزات الإدخال، الحصول على درجة D² تساوي 0.0.</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-d²-تويد">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة D² تويد<a class="headerlink" href="#درجة-d²-تويد" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تقوم وظيفة :func: ‘d2_tweedie_score’ بتنفيذ الحالة الخاصة لـ D²
حيث :math: ‘dev (y، y^)’ هو انحراف تويد، راجع :ref: ‘mean_tweedie_deviance’.
يُعرف أيضًا باسم D² Tweedie ويرتبط بفهرس نسبة احتمال ماكفادن.</p>
<p class="sd-card-text">تحدد وسيطة “power” طاقة تويد كما هو الحال في
:func: ‘mean_tweedie_deviance’. لاحظ أنه بالنسبة لـ <code class="docutils literal notranslate"><span class="pre">power=0</span></code>،
:func: ‘d2_tweedie_score’ يساوي :func: ‘r2_score’ (لأهداف فردية).</p>
<p class="sd-card-text">يمكن بناء كائن مسجل باختيار محدد لـ “power” عن طريق:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; from sklearn.metrics import d2_tweedie_score، make_scorer
&gt;&gt;&gt; d2_tweedie_score_15 = make_scorer(d2_tweedie_score، power=1.5)
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-d²-بينبول">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة D² بينبول<a class="headerlink" href="#درجة-d²-بينبول" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تقوم وظيفة :func: ‘d2_pinball_score’ بتنفيذ الحالة الخاصة
من D² مع خسارة بينبول، راجع :ref: ‘pinball_loss’، أي:</p>
<div class="math notranslate nohighlight">
\[\text{dev}(y, \hat{y}) = \text{pinball}(y, \hat{y}).\]</div>
<p class="sd-card-text">تحدد وسيطة “alpha” منحدر خسارة بينبول كما هو الحال في
:func: ‘mean_pinball_loss’ (:ref: ‘pinball_loss’). فهو يحدد
مستوى الكمية “alpha” الذي يكون فيه كل من خسارة بينبول و D²
الأمثل. لاحظ أنه بالنسبة لـ “alpha=0.5” (الافتراضي) :func: ‘d2_pinball_score’
يساوي :func: ‘d2_absolute_error_score’.</p>
<p class="sd-card-text">يمكن بناء كائن مسجل باختيار محدد لـ “alpha” عن طريق:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; from sklearn.metrics import d2_pinball_score، make_scorer
&gt;&gt;&gt; d2_pinball_score_08 = make_scorer(d2_pinball_score، alpha=0.8)
</pre></div>
</div>
</div>
</details><details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3" id="درجة-الخطأ-المطلق-d²">
<summary class="sd-summary-title sd-card-header">
<span class="sd-summary-text">درجة الخطأ المطلق D²<a class="headerlink" href="#درجة-الخطأ-المطلق-d²" title="Link to this dropdown">#</a></span><span class="sd-summary-state-marker sd-summary-chevron-right"><svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-right" viewBox="0 0 24 24" aria-hidden="true"><path d="M8.72 18.78a.75.75 0 0 1 0-1.06L14.44 12 8.72 6.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018l6.25 6.25a.75.75 0 0 1 0 1.06l-6.25 6.25a.75.75 0 0 1-1.06 0Z"></path></svg></span></summary><div class="sd-summary-content sd-card-body docutils">
<p class="sd-card-text">تقوم وظيفة :func: ‘d2_absolute_error_score’ بتنفيذ الحالة الخاصة لـ
:ref: ‘mean_absolute_error’:</p>
<div class="math notranslate nohighlight">
\[\text{dev}(y, \hat{y}) = \text{MAE}(y, \hat{y}).\]</div>
<p class="sd-card-text">فيما يلي بعض أمثلة الاستخدام لوظيفة :func: ‘d2_absolute_error_score’:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">d2_absolute_error_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_absolute_error_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">0.764...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d2_absolute_error_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y_pred</span>
</pre></div>
</div>
</div>
</details><p>فيما يلي ترجمة لنص RST باللغة الإنجليزية إلى اللغة العربية مع اتباع التعليمات المحددة:</p>
<p>من بين طرق تقييم جودة نماذج الانحدار، يوفر scikit-learn فئة
<code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionErrorDisplay</span></code>. تسمح هذه الفئة بالتفتيش البصري على أخطاء التنبؤ لنموذج بطريقتين مختلفتين.</p>
<p>توضح الصورة على اليسار القيم الفعلية مقابل القيم المتوقعة. بالنسبة لمهمة انحدار خالية من الضوضاء تهدف إلى التنبؤ بالتوقع الشرطي لـ “y”، سيعرض نموذج الانحدار المثالي نقاط البيانات على القطر المحدد بواسطة القيم المتوقعة تساوي القيم الفعلية. وكلما ابتعدنا عن هذا الخط الأمثل، زاد خطأ النموذج. في إعداد أكثر واقعية مع ضوضاء غير قابلة للاختزال، أي عندما لا يمكن تفسير جميع تغيرات “y” بواسطة الميزات في “X”، فإن أفضل نموذج سيؤدي إلى سحابة من النقاط المتراصة حول القطر.</p>
<p>تجدر الإشارة إلى أن ما سبق لا ينطبق إلا عندما تكون القيم المتوقعة هي القيمة المتوقعة لـ “y” معطى “X”. وهذا هو الحال عادةً في نماذج الانحدار التي تقلل من دالة هدف متوسط مربع الخطأ أو بشكل أكثر عمومية <a class="reference internal" href="#mean-tweedie-deviance"><span class="std std-ref">متوسط انحراف تويد</span></a> لأي قيمة لمعلمة “القوة” الخاصة بها.</p>
<p>عند رسم تنبؤات لمقدّر يتنبأ بمئويّة “y” معطى “X”، على سبيل المثال <code class="xref py py-class docutils literal notranslate"><span class="pre">QuantileRegressor</span></code> أو أي نموذج آخر يقلل من <a class="reference internal" href="#pinball-loss"><span class="std std-ref">خسارة بينبول</span></a>، من المتوقع أن تكون نسبة من النقاط إما أعلى أو أسفل القطر اعتمادًا على مستوى المئوي المقدر.</p>
<p>وعموماً، على الرغم من أن هذا المخطط سهل القراءة، إلا أنه لا يخبرنا حقًا بما يجب علينا فعله للحصول على نموذج أفضل.</p>
<p>يوضح المخطط الموجود على الجانب الأيمن البقايا (أي الفرق بين القيم الفعلية والمتوقعة) مقابل القيم المتوقعة.</p>
<p>يجعل هذا المخطط من السهل تصور ما إذا كانت البقايا تتبع توزيعًا متماثل التباين أو غير متماثل التباين
&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity">https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity</a>&gt;`_.</p>
<p>على وجه الخصوص، إذا كان التوزيع الحقيقي لـ “y|X” يتبع توزيع بواسون أو جاما، فمن المتوقع أن يتزايد تباين بقايا النموذج الأمثل مع القيمة المتوقعة لـ “E[y|X]” (إما خطيًا لتوزيع بواسون أو تربيعيًا لتوزيع جاما).</p>
<p>عند ملاءمة نموذج الانحدار التربيعي الأقل (راجع <code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code> و <code class="xref py py-class docutils literal notranslate"><span class="pre">Ridge</span></code>)، يمكننا استخدام هذا المخطط للتحقق مما إذا كان بعض افتراضات النموذج
&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Ordinary_least_squares#Assumptions">https://en.wikipedia.org/wiki/Ordinary_least_squares#Assumptions</a>&gt;`_
يتم استيفاؤها، وعلى وجه الخصوص، يجب أن تكون البقايا غير مترابطة، ويجب أن يكون متوسط قيمتها صفرًا، ويجب أن يكون تباينها ثابتًا (تماثل التباين).</p>
<p>إذا لم يكن الأمر كذلك، وإذا أظهر مخطط البقايا بعض الهياكل على شكل موزة، فهذا يشير إلى أن النموذج محدد بشكل خاطئ وقد يكون من المفيد إجراء هندسة ميزات غير خطية أو التبديل إلى نموذج انحدار غير خطي.</p>
<p>راجع المثال أدناه لمشاهدة تقييم النموذج الذي يستخدم هذا العرض.</p>
<p class="rubric">أمثلة</p>
<ul class="simple">
<li><p>راجع <a class="reference internal" href="../auto_examples/compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py"><span class="std std-ref">Effect of transforming the targets in regression model</span></a> لمثال حول كيفية استخدام <code class="xref py py-class docutils literal notranslate"><span class="pre">PredictionErrorDisplay</span></code> لتصور تحسين جودة التنبؤ لنموذج الانحدار الذي تم الحصول عليه عن طريق تحويل الهدف قبل التعلم.</p></li>
</ul>
<p id="clustering-metrics">مقاييس التجميع
فيما يلي ترجمة للنص المكتوب بتنسيق RST إلى اللغة العربية، مع اتباع التعليمات المحددة:</p>
<hr class="docutils" />
<p>ينفذ نموذج <a class="reference internal" href="../api/sklearn.metrics.html#module-sklearn.metrics" title="sklearn.metrics"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.metrics</span></code></a> العديد من دالات الخسارة والتقييم والمرافق. لمزيد من المعلومات، راجع قسم <span class="xref std std-ref">clustering_evaluation</span> لتقييم التجميع، وقسم <span class="xref std std-ref">biclustering_evaluation</span> لتقييم التجميع الثنائي.</p>
<p id="dummy-estimators">عند إجراء التعلم تحت الإشراف، تتضمن إحدى عمليات التحقق من الصحة البسيطة مقارنة النموذج الخاص بك بقواعد الإبهام البسيطة. وينفذ <code class="xref py py-class docutils literal notranslate"><span class="pre">DummyClassifier</span></code> العديد من هذه الاستراتيجيات البسيطة للتصنيف:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">stratified</span></code>: ينشئ تنبؤات عشوائية مع مراعاة توزيع فئات مجموعة التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">most_frequent</span></code>: يتنبأ دائمًا بالفئة الأكثر شيوعًا في مجموعة التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prior</span></code>: يتنبأ دائمًا بالفئة التي تزيد من دقة الفئة (مثل <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code>)، وتُرجع دالة <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> دقة الفئة.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">uniform</span></code>: ينشئ تنبؤات عشوائية بشكل منتظم.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">constant</span></code>: يتنبأ دائمًا بفئة ثابتة يوفرها المستخدم. الدافع الرئيسي لهذه الطريقة هو حساب درجة F1، عندما تكون الفئة الإيجابية أقلية.</p></li>
</ul>
<p>ملاحظة: مع جميع هذه الاستراتيجيات، تتجاهل طريقة <code class="docutils literal notranslate"><span class="pre">predict</span></code> بيانات الإدخال تمامًا!</p>
<p>لتوضيح <code class="xref py py-class docutils literal notranslate"><span class="pre">DummyClassifier</span></code>، دعنا أولاً نقوم بإنشاء مجموعة بيانات غير متوازنة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">[</span><span class="n">y</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>بعد ذلك، دعنا نقارن دقة <code class="docutils literal notranslate"><span class="pre">SVC</span></code> و <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.63...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="go">DummyClassifier(random_state=0, strategy=&#39;most_frequent&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.57...</span>
</pre></div>
</div>
<p>يمكننا أن نرى أن <code class="docutils literal notranslate"><span class="pre">SVC</span></code> لا يؤدي بشكل أفضل بكثير من النموذج الوهمي. الآن، دعنا نغير النواة:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.94...</span>
</pre></div>
</div>
<p>يمكننا أن نرى أن الدقة قد تحسنت إلى ما يقرب من 100%. يوصى باستخدام استراتيجية التحقق من الصلاحية المتقاطعة للحصول على تقدير أفضل للدقة، إذا لم تكن مكلفة للغاية من حيث وحدة المعالجة المركزية. لمزيد من المعلومات، راجع القسم <span class="xref std std-ref">cross_validation</span>. علاوة على ذلك، إذا كنت ترغب في التحسين في مساحة المعلمات، فمن المستحسن بشدة استخدام المنهجية المناسبة؛ راجع القسم <span class="xref std std-ref">grid_search</span> للحصول على التفاصيل.</p>
<p>وبشكل عام، عندما تكون دقة النموذج قريبة جدًا من العشوائية، فهذا يعني على الأرجح أن هناك خطأ ما: الميزات غير مفيدة، أو معامل النموذج غير مضبوط بشكل صحيح، أو يعاني النموذج من عدم توازن البيانات، وما إلى ذلك.</p>
<p>كما ينفذ <code class="xref py py-class docutils literal notranslate"><span class="pre">DummyRegressor</span></code> أربع قواعد بسيطة للإبهام للتنبؤ:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean</span></code>: يتنبأ دائمًا بمتوسط أهداف التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">median</span></code>: يتنبأ دائمًا بالوسيط لأهداف التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">quantile</span></code>: يتنبأ دائمًا بمنوال محدد من قبل المستخدم لأهداف التدريب.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">constant</span></code>: يتنبأ دائمًا بقيمة ثابتة يوفرها المستخدم.</p></li>
</ul>
<p>في جميع هذه الاستراتيجيات، تتجاهل طريقة <code class="docutils literal notranslate"><span class="pre">predict</span></code> بيانات الإدخال تمامًا.</p>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="prev-next-area">
    <a class="left-prev"
       href="classification_threshold.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">3.7. </span>تعديل عتبة القرار للتنبؤ بالصنف</p>
      </div>
    </a>
    <a class="right-next"
       href="learning_curve.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.10. </span>منحنيات التحقق: رسم الدرجات لتقييم النماذج</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>
                </footer>
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">3.9.1. الحالات الشائعة: القيم المحددة مسبقًا</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scoring">3.9.2. تحديد استراتيجية تسجيل النقاط من وظائف القياس</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diy-scoring">3.9.3. تنفيذ كائن تسجيل النقاط الخاص بك</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-report">3.9.4. تقرير التصنيف</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hamming-loss">3.9.5. خسارة هامنج</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hinge-loss">3.9.6. خسارة المفصل</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-loss">3.9.7. خسارة السجل</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matthews-corrcoef">3.9.8. معامل ارتباط ماثيوز</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-binary">3.9.8.1. الحالة الثنائية</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-multiclass">3.9.8.2. حالة التصنيف متعدد الفئات</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#roc-auc-multilabel">3.9.8.3. حالة التصنيف متعدد التسميات</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zero-one-loss">3.9.9. خسارة الصفر واحد</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#brier-score-loss">3.9.10. خسارة نتيجة برير</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d2">3.9.11. درجة D² للتصنيف</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id43">3.9.12. خطأ التغطية</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id44">3.9.13. متوسط دقة التصنيف بالعلامات</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id45">3.9.14. خسارة الترتيب</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id46">3.9.15. المكسب التراكمي المخفض</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explained-variance-score">3.9.16. درجة التباين الموضحة</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-tweedie-deviance">3.9.17. متوسط ​​انحرافات بويسون وغاما وتويد</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pinball-loss">3.9.18. خسارة بينبول</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d2-score">3.9.19. درجة D²</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/modules/model_evaluation.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2007 - 2024, scikit-learn developers (BSD License).
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>